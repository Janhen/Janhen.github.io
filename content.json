[{"title":"SpringBoot动态参数和配置","date":"2021-06-16T16:43:40.000Z","path":"2021/06/17/SpringBoot动态参数和配置/","text":"配置动态化在部署和测试 SpringBoot 应用时，会分环境、分架构，需要根据不同的场景指定动态参数。 配置加载默认配置文件的查找路径： file:./config/ file:./ classpath:/config/ classpath:/ 配置文件放到 jar 包同层目录下，或是 config 子目录下，启动 jar 包加载配置文件实现配置项的覆盖。 1234├── app.jar├── application.yml└── config └── appliaction.yml spring.config.location 指定外部的配置文件 1java -jar app.jar --spring.config.location=classpath:/default.properties,classpath:/override.properties 命令参数 运行时在 app.jar 后指定额外的 springboot 参数 运行时在 app.jar 前指定 JVM 参数，可指定 springboot 内部处理的参数，或者程序内部对特定 jvm 参数处理的 1234567# 指定钉钉报警的 tokenjava -jar -Ddingding.token=xxcxcxcxcxcxc app.jar# 指定运行环境java -jar app.jar --spring.profiles.active=prod# 指定钉钉报警的 token，对应程序中获取该参数java -jar app.jar --dingding.token=xxdfsdfdsf 环境变量在配置文件中指定环境变量 配合 Docker 容器指定环境变量，实现不同环境的参数配置 123456#==========================================================# datasource config#==========================================================spring.datasource.url=jdbc:mysql://$&#123;MYSQL_ADDR:172.17.10.127&#125;:$&#123;MYSQL_PORT:3306&#125;/test?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;allowMultiQueries=true&amp;serverTimezone=Asia/Shanghaispring.datasource.username=$&#123;DB_USER:root&#125;spring.datasource.password=$&#123;DB_PASS:test123&#125; 静态变量通过阿里的 arthas 工具，使用 ognl 表达式更改程序中的静态变量值，实现配置的动态化。 spring profilespring 自带的环境区分，划分方式： 在 resource 目录下定义 application-dev.yml, application-prod.yml 不同的文件进行区分 通过在同一个文件中使用 --- 分开各个环境的内容 各个不同的环境对应的架构不同，如 redis 在测试环境使用单点的在生产环境使用 redis sentinel。 maven profile根据不同环境编译打包的插件不一样，根据环境需要增加 maven deploy, maven docker 相关的插件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;default&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;deploy&lt;/id&gt; &lt;activation&gt; &lt;property&gt; &lt;name&gt;deploy&lt;/name&gt; &lt;/property&gt; &lt;/activation&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;false&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;docker&lt;/id&gt; &lt;activation&gt; &lt;property&gt; &lt;name&gt;docker&lt;/name&gt; &lt;/property&gt; &lt;/activation&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-image&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;dockerDirectory&gt;$&#123;project.basedir&#125;/src/main/docker&lt;/dockerDirectory&gt; &lt;imageName&gt;$&#123;docker.registry&#125;/test/$&#123;project.artifactId&#125; &lt;/imageName&gt; &lt;imageTags&gt; &lt;imageTag&gt;$&#123;project.version&#125;&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;forceTags&gt;true&lt;/forceTags&gt; &lt;labels&gt; &lt;label&gt;VERSION=$&#123;project.version&#125;&lt;/label&gt; &lt;/labels&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar &lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;push-image&lt;/id&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;serverId&gt;$&#123;docker.server.id&#125; &lt;/serverId&gt; &lt;imageName&gt; $&#123;docker.registry&#125;/test/$&#123;project.artifactId&#125;:$&#123;project.version&#125; &lt;/imageName&gt; &lt;registryUrl&gt;&lt;http://$&gt;&#123;docker.registry&#125;&lt;/registryUrl&gt; &lt;retryPushCount&gt;3&lt;/retryPushCount&gt; &lt;retryPushTimeout&gt;60&lt;/retryPushTimeout&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt;&lt;/profiles&gt; Ref24. Externalized Configuration","tags":[]},{"title":"Spark-数据倾斜","date":"2021-05-07T07:45:41.000Z","path":"2021/05/07/Spark-数据倾斜/","text":"数据倾斜概述数据倾斜： Task 之间数据分配的非常不均匀 DataSkew 的原因： 数据倾斜一般发生在 shuffle 过程中。 数据异常： key 有大量的空值/默认值 Map Task 数据倾斜 数据文件大小不一致，数据压缩格式不可切分 接收的数据源，如 Kafka 对应的数据分区不均匀 Reduce task 数据倾斜： 数据存在很多空值或缺省值 Shuffle： 外因，Shuffle 操作涉及到大量的磁盘、网络 IO 、对作业型任务影响极大 Key 分布不均匀： 内部原因 Shuffle + Key 分布不均匀(主因)： 主要原因为 shuffle + key 分布不均 DataSkew 问题定位： 了解数据 key 的分布情况 一般通过 Spark Web UI 或其他监控方式出现的异常来进行综合判断 查看代码中可能导致 shuffle 的算子出现 DataSkew 的影响: OutOfMemory，某个 Task 莫名出现内存移除情况, 一般情况下，OOM 的原因都是数据倾斜 某个 Task 执行特别慢, 大量数据交由一个 Task 处理，拖累整个程序 Shuffle 过程报错 数据倾斜处理 数据的预处理： 过滤空值/默认值，filter + coalesce 小区数据源带来的数据倾斜 避免 Shuffle: 通过程序避免使用 shuffle 的算子完成相应的任务，通过改写程序实现。 减少 Shuffle 过程中的数量 使用 groupBy –&gt; reduceByKey / aggregateByKey 通过 Map 端的 Join 来减少 选择新的可用于聚合/join 的 key 根据业务，选择新的 key 去做聚合或 join。可尝试使用更细的维度。 改变 reduce 的并行度: 一般情况下不管用，数据倾斜可能是由很多 key 造成的 加盐强行打散 Key: 处理 ****shuffle + key 不能分散。 为数据量特别大的 Key 增加随机前/后缀，使得原来 Key 相同的数据变为 Key 不相同的数据，从而使倾斜的数据集分散到不同的 Task 中，彻底解决数据倾斜问题。 自定义 Partitioner: 使用自定义的 Partitioner，将原本被分配到同一个 Task 的不同 Key 分配到不同 Task。 加盐打散 Key两阶段聚合 不能改变原来的结果 对于聚合类的 shuffle 操作导致的数据倾斜，效果较好。一般可以解决掉 DataSkew，将 Spark 作业的性能提升数倍以上。 仅适用于聚合类的 shuffle 操作，适用范围相对较窄。如果是 join 类的 shuffle 操作，需要选择其他的解决方案。 执行步骤： 加盐打散 key。给每个 key 都加一个随机数，如 10 以内的随机数。此时 key 就被打散了 局部聚合。对打上随机数的数据，执行一次聚合操作，得到结果 全局聚合。将各个 key 的前缀去掉，再进行一次聚合操作，得到最终结果 采样倾斜 key 并拆分 join 操作 使用场景：计算两个 RDD /两张表中的 key 分布情况。如果出现数据倾斜，是其中一个 RDD/Hive 表中的少数几个 key 的数据量过大，而另一个 RDD/Hive 表中的所有 key 都分布比较均匀，那么采用这个解决方案比较合适。 处理步骤： 1、对包含少数几个数据量过大的 key 的那个 RDD，通过 sample 算子采样出一份样本来，然后统计一下每个 key 的数量，计算出数据量最大的是哪几个 key； 2、将这几个 key 对应的数据从原来的 RDD 中拆分出来，形成一个单独的 RDD，并给每个 key 都打上 n 以内的随机数作为前缀，而不会导致倾斜的大部分 key 形成另外一个 RDD； 3、将需要 join 的另一个 RDD，也过滤出来那几个倾斜 key 对应的数据并形成一个单独的 RDD，将每条数据膨胀成 n 条数据，这 n 条数据都按顺序附加一个 0~n 的前缀，不会导致倾斜的大部分 key 也形成另外一个 RDD； 4、再将附加了随机前缀的独立 RDD 与另一个膨胀 n 倍的独立 RDD 进行 join，此时就可以将原先相同的 key 打散成 n 份，分散到多个 task 中去进行 join 了； 5、另外两个普通的 RDD 就照常 join 即可； 6、最后将两次 join 的结果使用 union 算子合并起来即可，就是最终的 join 结果。 使用随机前缀和扩容再进行 join 业务场景：如果在进行 join 操作时，RDD 中有大量的 key 导致数据倾斜，进行分拆 key 没什么意义，此时就只能使用最后一种方案来解决问题了。 处理步骤： 1、选一个 RDD，将每条数据都打上一个 n 以内的随机前缀(打散) 2、对另外一个 RDD 进行扩容，将每条数据都扩容成 n 条数据，扩容出来的每条数据都依次打上一个 0~n 的前缀 3、将两个处理后的 RDD 进行 join 即可 扩容保证能正常 join 的执行 使用注意事项： 如果两个 RDD 都很大，那么将 RDD 进行 N 倍的扩容显然行不通 使用扩容的方式通常能缓解数据倾斜，不能彻底解决数据倾斜问题","tags":[{"name":"Spark","slug":"Spark","permalink":"http://example.com/tags/Spark/"}]},{"title":"Spark-Shuffle 过程和原理","date":"2021-05-05T08:55:56.000Z","path":"2021/05/05/Spark-Shuffle过程/","text":"Shuffle按照一定的规则对数据重新分区的过程就是 Shuffle。需要 Shuffle 是因为某种具有共同特征的数据汇聚到一个计算节点上进行计算。 Shuffle 过程中包含了许多低效的操作，包括磁盘 IO、序列化、网络数据传输等。 Shuffle 分类 Hash Shuffle V1 两个严重问题：生成大量文件，占用文件描述符，同时引入 DiskObjectWriter 带来的 Writer Handler 的缓存也非常消耗内存。如果在 Reduce Task 时需要合并操作的话，会把数据放在一个 HashMap 中进行合并，如果数据量较大，很容易引发 OOM Hash Shuffle V2 在 v1 基础上引入 File Consolidation 一个 Executor 上所有的 Map Task 生成的分区文件只有一份，即将所有的 Map Task 相同的分区文件合并，这样每个 Executor 上最多只生成 N 个分区文件。 Sort Shuffle V1 每个 Task 不会为后续的每个 Task 创建单独的文件，而是将所有对结果写入同一个文件。该文件中的记录首先是按照 Partition Id 排序，每个 Partition 内部再按照 Key 进行排序，Map Task 运行期间会顺序写每个 Partition 的数据，同时生成一个索引文件记录每个 Partition 的大小和偏移量。 在 Reduce 阶段，Reduce Task 拉取数据做 Combine 时不再采用 HashMap，而是采用 ExternalAppendOnlyMap，该数据结构在做 Combine 时，如果内存不足，会刷写磁盘，避免(AppendOnlyMap)大数据情况下的 OOM。 Sort Shuffle 解决了 Hash Shuffle 的所有弊端，但是因为需要其 Shuffle 过程需要对记录进行排序，所以在性能上有所损失。 Tungsten-Sort Based Shuffle(Unsafe Shuffle) 1.5+ 后开始钨丝计划，优化内存和 CPU 的使用，使用了堆外内存进一步提升 Spark 的性能。 将数据记录用二进制的方式存储，直接在序列化的二进制数据上 Sort 而不是在 Java 对象上。减少内存的使用和 GC 的开销，避免 Shuffle 过程中频繁的序列化以及反序列化。 排序过程中，提供 cache-efficient sorter，使用一个 8 bytes 的指针，把排序转化成了一个指针数组的排序，极大的优化了排序性能。 使用要求： Shuffle 阶段不能有 aggregate 操作，对于 aggretateByKey 之类的算子无法使用。 分区数不能超过 2^24 序列化支持 relocation，如 kyro 序列化 Sort Shuffle V2 Spark1.6+，把 Sort Shuffle 和 Tungsten-Sort Based Shuffle 全部统一到 Sort Shuffle 中，如果检测到满足 Tungsten-Sort Based Shuffle 条件会自动采用 Tungsten-Sort Based Shuffle，否则采用 Sort Shuffle。 sort-based shuffle 的缺陷 mapper 的 Task 数量过大，依旧会产生大量小文件，此时在 shuffle 传递数据的过程中 reducer 端，reduce 会需要同时大量的记录进行反序列化，导致大量的内存消耗和 GC 的巨大负担，造成系统缓慢甚至崩溃。 如果需要在分片内也进行排序，此时需要进行 mapper 端和 reducer 端的两次排序。 ShuffleWriter 执行流程 数据先写入一个内存数据结构中。不同的 shuffle 算子，可能选用不同的数据结构 如果是 reduceByKey 聚合类的算子，选用 Map(ExternalAppendOnlyMap) 数据结构，一边通过 Map 进行聚合，一边写入内存 如果是 join 类的 shuffle 算子，那么选用 Array(CompactBuffer) 数据结构，直接写入内存 检查是否达到内存阈值。每写一条数据进入内存数据结构之后，就会判断一下，是否达到了某个临界阈值。如果达到临界阈值的话，那么就会将内存数据结构中的数据溢写到磁盘，并清空内存数据结构 数据排序。在溢写到磁盘文件之前，会先根据 key 对内存数据结构中已有的数据进行排序。排序过后，会分批将数据写入磁盘文件。默认的 batch 数量是 10000 条，也就是说，排序好的数据，会以每批 1 万条数据的形式分批写入磁盘文件 数据写入缓冲区。写入磁盘文件是通过 Java 的 BufferedOutputStream 实现的。BufferedOutputStream 是 Java 的缓冲输出流，首先会将数据缓冲在内存中，当内存缓冲满溢之后再一次写入磁盘文件中，这样可以减少磁盘 IO 次数，提升性能 重复写多个临时文件。一个 Task 将所有数据写入内存数据结构的过程中，会发生多次磁盘溢写操作，会产生多个临时文件 临时文件合并。最后将所有的临时磁盘文件进行合并，这就是 merge 过程。此时会将之前所有临时磁盘文件中的数据读取出来，然后依次写入最终的磁盘文件之中写索引文件。由于一个 Task 就只对应一个磁盘文件，也就意味着该 task 为下游 stage 的 task 准备的数据都在这一个文件中，因此还会单独写一份索引文件，其中标识了下游各个 Task 的数据在文件中的 start offset 与 end offset。 SortShuffleManager当前 ShuffleManager 唯一实现类。在基于排序的 shuffle 中，传入记录根据其目标分区 id 进行排序，然后写入单个映射输出文件。Reducers 获取这个文件的连续区域，以便读取映射输出中属于它们的部分。在 map 输出数据太大而无法装入内存的情况下，可以将输出的排序子集溢出到磁盘，并合并那些磁盘上的文件以生成最终的输出文件。 getReader(): 返回读取 shuffle 过程的数据的 reader，当前使用的位置 当前获取的位置： CoGroupedRDD、ShuffledRDD、SubtractedRDD、ShuffledRowRDD getWriter(): 根据条件判断选择哪种 ShuffleWriter，可选择 BypassMergeSortShuffleWriter, UnsafeShuffleWriter, SortShuffleWriter registerShuffle(): 注册 shuffle 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485private[spark] class SortShuffleManager(conf: SparkConf) extends ShuffleManager with Logging &#123; /** * A mapping from shuffle ids to the number of mappers producing output for those shuffles. */ private[this] val numMapsForShuffle = new ConcurrentHashMap[Int, Int]() override val shuffleBlockResolver = new IndexShuffleBlockResolver(conf) /** * Obtains a [[ShuffleHandle]] to pass to tasks. */ override def registerShuffle[K, V, C]( shuffleId: Int, numMaps: Int, dependency: ShuffleDependency[K, V, C]): ShuffleHandle = &#123; if (SortShuffleWriter.shouldBypassMergeSort(conf, dependency)) &#123; // 小于 bypassMerge(spark.shuffle.sort.bypassMergeThreshold) 的阈值分区数，不需要 map 端的聚合， // 然后直接写入MnumPartitions 文件，并在最后将它们连接起来。这避免了两次序列化和反序列化来合并溢出的文件，缺点是一次打开多个文件，从而分配给缓冲区更多的内存 new BypassMergeSortShuffleHandle[K, V]( shuffleId, numMaps, dependency.asInstanceOf[ShuffleDependency[K, V, V]]) &#125; else if (SortShuffleManager.canUseSerializedShuffle(dependency)) &#123; // 尝试以序列化的形式缓冲映射输出，因为这样更有效率 new SerializedShuffleHandle[K, V]( shuffleId, numMaps, dependency.asInstanceOf[ShuffleDependency[K, V, V]]) &#125; else &#123; // 缓冲区映射以反序列化形式输出 new BaseShuffleHandle(shuffleId, numMaps, dependency) &#125; &#125; /** * 获取一系列 reduce 分区的读取器(startPartition 到 endPartition-1，包括在内)。通过 reduce 任务调用 executor。 * 当前使用到的位置： * - CoGroupedRDD * - ShuffledRDD * - SubtractedRDD * - ShuffledRowRDD */ override def getReader[K, C]( handle: ShuffleHandle, startPartition: Int, endPartition: Int, context: TaskContext): ShuffleReader[K, C] = &#123; // shuffle 过程的 reader, 当前 ShuffleReader 的唯一实现类 new BlockStoreShuffleReader( handle.asInstanceOf[BaseShuffleHandle[K, _, C]], startPartition, endPartition, context) &#125; // 获取给定分区的写入器。通过 map 任务调用 executor override def getWriter[K, V]( handle: ShuffleHandle, // 根据传入的 ShuffleHandle 获取到 mapId: Int, context: TaskContext): ShuffleWriter[K, V] = &#123; numMapsForShuffle.putIfAbsent( handle.shuffleId, handle.asInstanceOf[BaseShuffleHandle[_, _, _]].numMaps) val env = SparkEnv.get handle match &#123; // 序列化的 Shuffle 处理，使用 UnsafeShuffleWriter case unsafeShuffleHandle: SerializedShuffleHandle[K @unchecked, V @unchecked] =&gt; new UnsafeShuffleWriter( env.blockManager, shuffleBlockResolver.asInstanceOf[IndexShuffleBlockResolver], context.taskMemoryManager(), unsafeShuffleHandle, mapId, context, env.conf) // 跳过 mergeSort 的 shuffle 处理 case bypassMergeSortHandle: BypassMergeSortShuffleHandle[K @unchecked, V @unchecked] =&gt; new BypassMergeSortShuffleWriter( env.blockManager, shuffleBlockResolver.asInstanceOf[IndexShuffleBlockResolver], bypassMergeSortHandle, mapId, context, env.conf) // 通用的 ShuffleWriter 处理 case other: BaseShuffleHandle[K @unchecked, V @unchecked, _] =&gt; new SortShuffleWriter(shuffleBlockResolver, other, mapId, context) &#125; &#125; ...&#125; 123456789101112131415161718192021222324252627282930313233343536private[spark] object SortShuffleManager extends Logging &#123; /** * 在以序列化形式缓冲映射输出时 SortShuffleManager 支持的最大 shuffle 输出分区数。 * 这是一种极端的防御性编程措施，因为一次 shuffle 极不可能产生超过 1600 万个输出分区。 * */ val MAX_SHUFFLE_OUTPUT_PARTITIONS_FOR_SERIALIZED_MODE = PackedRecordPointer.MAXIMUM_PARTITION_ID + 1 /** * 用于确定 shuffle 是否可使用优化的序列化 shuffle path 是否应该退回到对反序列化对象进行操作的 original path */ def canUseSerializedShuffle(dependency: ShuffleDependency[_, _, _]): Boolean = &#123; val shufId = dependency.shuffleId val numPartitions = dependency.partitioner.numPartitions // 需要依赖对应的序列化器支持 relocation if (!dependency.serializer.supportsRelocationOfSerializedObjects) &#123; log.debug(s&quot;Can&#x27;t use serialized shuffle for shuffle $shufId because the serializer, &quot; + s&quot;$&#123;dependency.serializer.getClass.getName&#125;, does not support object relocation&quot;) false &#125; else if (dependency.mapSideCombine) &#123; // 不可为 MapSideCombine log.debug(s&quot;Can&#x27;t use serialized shuffle for shuffle $shufId because we need to do &quot; + s&quot;map-side aggregation&quot;) false &#125; else if (numPartitions &gt; MAX_SHUFFLE_OUTPUT_PARTITIONS_FOR_SERIALIZED_MODE) &#123; // 2^24 // 分区数小于 2^24 log.debug(s&quot;Can&#x27;t use serialized shuffle for shuffle $shufId because it has more than &quot; + s&quot;$MAX_SHUFFLE_OUTPUT_PARTITIONS_FOR_SERIALIZED_MODE partitions&quot;) false &#125; else &#123; log.debug(s&quot;Can use serialized shuffle for shuffle $shufId&quot;) true &#125; &#125;&#125; 与 Hadoop Shuffle 的比较二者从功能上看是相似的；从 High Level来看，没有本质区别。 何时进行 fetch Map 端的数据： Hadoop 中有一个 Map 完成，Reduce 便可以去 fetch 数据了，MR Shuffle 不必等到所有 Map 任务完成；而 Spark shuffle 必须等到父 stage 完成，也就是父 stage 的 map 操作全部完成才能去 fetch 数据。这是因为 spark 必须等到父 stage 执行完，才能执行子 stage，主要是为了迎合 stage 规则 何时执行 Reduce 端的聚合： Hadoop 的 Reduce 要等到 fetch 完全部数据，才将数据传入 reduce 函数进行聚合，Spark 是一边 fetch 一边聚合。 分区有序的要求： Hadoop 的 Shuffle 是 sort-base 的，那么不管是 Map 的输出，还是 Reduce 的输出，都是 partition 内有序的，而 spark 不要求 partition 内有限 Shuffle WriterBypassMergeSortShuffleWriter 与 Hash Shuffle 的实现基本相同，区别在于 map task 输出汇总一个文件，同时还会产生一个 index file 特点： 类似于Hash Shuffle，多了文件的合并 对于大量 reduce 分区的 shuffle，是低效的，因为同时为所有分区打开单独的序列化器和文件流 Writer 流程： 每个 Map Task 为每个下游 reduce task 创建一个临时磁盘文件，并将数据按 key 进行 hash 然后根据 hash 值写入内存缓冲，缓冲写满之后再溢写到磁盘文件； 最后将所有临时磁盘文件都合并成一个磁盘文件，并创建索引文件； 在 shuffle 过程中会创建很多磁盘文件，最后多了一个磁盘文件合并的过程。Shuffle Read 的性能会更好； Bypass 方式与普通的 Sort Shuffle 方式的不同点： 磁盘写机制不同 根据 key 求 hash，减少了数据排序操作，提高了性能 选择条件： 分区数 &lt;=200(spark.shuffle.sort.bypassMergeThreshold) 非聚合操作 没有指定排序 不是 mapSideCombine UnsafeShuffleWriter 序列化的排序方式： 在序列化排序模式中，传入的记录一旦传递给 shuffle 写入器就会被序列化，并在排序期间以序列化的形式进行缓冲。 序列化排序方式的优化： 它的排序操作是序列化的二进制数据，而不是 Java 对象，这减少了内存消耗和 GC 开销。此优化要求记录序列化器具有某些属性，以允许在不反序列化的情况下重新排序序列化的记录。 它使用专用的高效缓存排序器([[ShuffleExternalSorter]])对压缩记录指针和分区id数组进行排序。通过在排序数组中每条记录只使用 8 个字节的空间，这可以将更多的数组放入缓存中 spill 合并过程对属于同一分区的序列化记录块进行操作，合并过程中不需要反序列化记录。 当 spill 压缩编解码器支持连接压缩数据时，spill merge 只是将序列化的 spill 分区和压缩的 spill 分区连接起来，以产生最终的输出分区。这允许使用高效的数据复制方法，如 NIO 的 transferTo，并避免了在合并期间分配解压缩缓冲区或复制缓冲区的需要。 选择条件： shuffle 序列化器支持 object relocation, 目前 KryoSerializer 或 SparkSQL 自定义的一些序列化方式支持 分区数 &lt; 2^24(16777216) shuffle 依赖项不指定聚合或输出顺序，即 mapSideCombine 为 false。 设置堆外内存大小 SortShuffleWriter 对于没有选择 BypassMergeSortShuffleWriter、UnsafeShuffleWriter 的，默认选择 SortShuffleWriter。 执行流程： 数据先写入内存数据结构。聚合类操作写入 Map，非聚合类算子写入 Array 检查是否达到内存阈值。非实时检查，不定时采样，不准确 数据排序 数据写入缓冲区(32k) 重复写多个临时文件 最后临时文件合并为数据文件 写索引文件 将文件位置、计算状态等封装到 MapStatus 中，汇报给 Driver MapOutputTracker Shuffle 过程中的中间数据的元信息，由 MapOutputTracker 负责管理。 Shuffle Writer 会将中间数据保存到 Block 里面，然后将数据的位置发送给 MapOutputTracker。Shuffle Reader 通过向 MapOutputTracker 获取中间数据的位置之后，才能读取到数据。 MapOutputTracker： 跟踪 map 阶段输出的位置，在 executor 和 driver 端都存在。 trackerEndpoint： 一个 RpcEndpointRef MapOutputTrackerMaster： 存在于 driver 端，DAGScheduler 使用该类注册 map 输出状态和查找统计信息执行位置感知减少任务调度。 负责管理所有 shuffleMapTask 的输出数据，每个 shuffleMapTask 执行完后会把执行结果（MapStatus）注册到 MapOutputTrackerMaster MapOutputTrackerMaster 会处理 executor 发送的 GetMapOutputStatuses 请求，并返回 serializedMapStatus 给 executor 端 MapOutputTrackerMasterEndpoint：存在于 driver 端 MapOutputTrackerWorker： 存在于 executor 端 负责为 reduce 任务提供 shuffleMapTask 的输出数据信息（MapStatus） 如果 MapOutputTrackerWorker 在本地没有找到请求的 shuffle 的 mapStatus，则会向 MapOutputTrackerMasterEndpoint 发送 GetMapOutputStatuses 请求获取对应的 mapStatus 123456789101112131415161718private[spark] class MapOutputTrackerMasterEndpoint( override val rpcEnv: RpcEnv, tracker: MapOutputTrackerMaster, conf: SparkConf) extends RpcEndpoint with Logging &#123; // 处理 GetMapOutputStatuses、StopMapOutputTracker 的偏函数 override def receiveAndReply(context: RpcCallContext): PartialFunction[Any, Unit] = &#123; case GetMapOutputStatuses(shuffleId: Int) =&gt; val hostPort = context.senderAddress.hostPort logInfo(&quot;Asked to send map output locations for shuffle &quot; + shuffleId + &quot; to &quot; + hostPort) // MapOutputTrackerMaster 发送 GetMapOutputMessage val mapOutputStatuses = tracker.post(new GetMapOutputMessage(shuffleId, context)) case StopMapOutputTracker =&gt; logInfo(&quot;MapOutputTrackerMasterEndpoint stopped!&quot;) context.reply(true) stop() &#125; ...&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private[spark] class MapOutputTrackerMaster( conf: SparkConf, broadcastManager: BroadcastManager, isLocal: Boolean) extends MapOutputTracker(conf) &#123; private val minSizeForBroadcast = conf.getSizeAsBytes(&quot;spark.shuffle.mapOutput.minSizeForBroadcast&quot;, &quot;512k&quot;).toInt // spark.rpc.message.maxSize 默认为 128M private val maxRpcMessageSize = RpcUtils.maxMessageSizeBytes(conf) // requests for map output statuses private val mapOutputRequests = new LinkedBlockingQueue[GetMapOutputMessage] // 用于处理映射输出状态请求的线程池。 // 这是一个单独的线程池，以确保我们不会阻塞普通的调度程序线程。 private val threadpool: ThreadPoolExecutor = &#123; val numThreads = conf.getInt(&quot;spark.shuffle.mapOutput.dispatcher.numThreads&quot;, 8) val pool = ThreadUtils.newDaemonFixedThreadPool(numThreads, &quot;map-output-dispatcher&quot;) for (i &lt;- 0 until numThreads) &#123; pool.execute(new MessageLoop) &#125; pool &#125; // 发送消息 def post(message: GetMapOutputMessage): Unit = &#123; // 放到 LinkedBlockingQueue 阻塞队列中 mapOutputRequests.offer(message) &#125; // 用于发送消息的 message loop， threadpool 中执行的任务 private class MessageLoop extends Runnable &#123; override def run(): Unit = &#123; try &#123; while (true) &#123; try &#123; // 消费阻塞队列中的 GetMapOutputMessage 消息 val data = mapOutputRequests.take() if (data == PoisonPill) &#123; // Put PoisonPill back so that other MessageLoops can see it. mapOutputRequests.offer(PoisonPill) return &#125; val context = data.context val shuffleId = data.shuffleId val hostPort = context.senderAddress.hostPort logDebug(&quot;Handling request to send map output locations for shuffle &quot; + shuffleId + &quot; to &quot; + hostPort) val shuffleStatus = shuffleStatuses.get(shuffleId).head context.reply( shuffleStatus.serializedMapStatus(broadcastManager, isLocal, minSizeForBroadcast)) &#125; catch &#123; case NonFatal(e) =&gt; logError(e.getMessage, e) &#125; &#125; &#125; catch &#123; case ie: InterruptedException =&gt; // exit &#125; &#125; &#125; ...&#125; Shuffle Reader Map Task 执行完毕后会将文件位置、计算状态等信息封装到 MapStatus 中，通过 MapOutPutTrackerWorker 对象将其发送给 Driver 进程的 MapOutPutTrackerMaster Reduce Task 开始执行之前会先让本进程中的 MapOutputTrackerWorker 向 Driver 进程中的 MapOutputTrackerMaster 发动请求，获取磁盘文件位置等信息 当所有的 Map Task 执行完毕后，Driver 进程中的 MapOutputTrackerMaster 获得了所有的 Shuffle 文件的信息。此时 MapOutPutTrackerMaster 会告诉 MapOutPutTrackerWorker 磁盘小文件的位置信息 完成之前的操作之后，由 BlockTransforService 去 Executor 所在的节点拉数据，默认会启动五个子线程。每次拉取的数据量不能超过 48M spark.reducer.maxSizeInFlight: shuffle reader 时候，一次 fetch 不能过多，不能超过的数据量，默认为 48M, 空间是由这 5 个 fetch 线程共享的 BlockStoreShuffleReader: 当前 ShuffleReader 的唯一实现类 read(): 读取 reduce 任务的组合键值 ShuffleBlockFetcherIterator: 获取多个块的迭代器。对于本地块，它从本地块管理器获取。对于远程块，它使用提供的 BlockTransferService 获取。 创建 (BlockID, InputStream) 元组，对远程获取进行了限制，不会超过 maxBytesInFlight，避免使用太多的内存 Shuffle 的优化开发过程中的优化： 减少 Shuffle 过程中的数据量： 使用高性能算子，如使用 filter + coalesce 过滤不需要的值并减少分区数，使用 reduceByKey 替代 groupByKey 有 mapSideCombine 减少聚合的数据量， 避免 Shuffle： 更改代码避免 shuffle，使用 map 端的 join 避免， 如使用 colasce 替代 repartititon, repartitionAndSortxxx 将会产生两个 shuffle 的合并为一个 参数优化： 调节 map 端缓冲区大小 spark.shuffle.file.buffer 默认值为32K，shuffle write 阶段 buffer 缓冲大小。将数据写到磁盘文件之前，会先写入 buffer 缓冲区，缓冲写满后才溢写到磁盘 调节 reduce 端拉取数据缓冲区大小 spark.reducer.maxSizeInFlight 默认值为48M。设置shuffle read阶段buffer缓冲区大小，这个buffer缓冲决定了每次能够拉取多少数据 在内存资源充足的情况下，可适当增加参数的大小（如96m），减少拉取数据的次数及网络传输次数，进而提升性能 合理设置参数，性能会有 1%~5% 的提升 调节 reduce 端拉取数据重试次数及等待间隔，Shuffle read 阶段拉取数据时，如果因为网络异常导致拉取失败，会自动进行重试。 Shuffle read阶段拉取数据时，如果因为网络异常导致拉取失败，会自动进行重试 spark.shuffle.io.maxRetries，默认值3。最大重试次数 spark.shuffle.io.retryWait，默认值5s。每次重试拉取数据的等待间隔 一般调高最大重试次数，不调整时间间隔 调节 Sort Shuffle 排序操作阈值 如果shuffle reduce task的数量小于阈值，则shuffle write过程中不会进行排序操作，而是直接按未经优化的Hash Shuffle方式写数据，最后将每个task产生的 所有临时磁盘文件都合并成一个文件，并创建单独的索引文 spark.shuffle.sort.bypassMergeThreshold，默认值为200 当使用SortShuffleManager时，如果的确不需要排序操作，建议将这个参数调大 调节 Shuffle 内存大小，分配多一些的比例给执行内存用于 Shuffle 配置参数Shuffle 中的重要参数： spark.local.dir: Shuffle 缓存目录 spark.shuffle.file.buffer： shuffle write 阶段 buffer 缓冲大小，将数据写到磁盘文件之前，会先写入 buffer 缓冲中，待缓冲写满之后，才会溢写到磁盘。默认值为 32K。 spark.reducer.maxSizeInFlight： shuffle read 阶段 buffer 缓冲区大小。默认值为 48M。 spark.shuffle.io.maxRetries： Shuffle read 阶段拉取数据失败时的最大重试次数。默认值 3。 spark.shuffle.io.retryWait： Shuffle read 阶段拉取数据失败重试时的等待时间。默认值 5s。 spark.shuffle.sort.bypassMergeThreshold： 使用 bypassMergeSortShuffleWriter 机制，RDD 分区数的限制阈值。默认值为 200。 spark.memory.fraction &amp; spark.memory.storageFraction： 调整 Shuffle 相关内存所占的比例 spark.memory.fraction： 缺省值 0.6。存储内存和执行内存占（heap 内存 - 300M）的百分比 spark.memory.storageFraction： 缺省值 0.5 存储内存与 （存储内存与执行内存之和）的百分比 spark.shuffle.manager： 通过反射方式生成的 SortShuffleManager 的实例。默认为 SortShuffleManager。 Spark 1.5 以后，有三个可选项：hash、sort 和 tungsten-sort。 spark.shuffle.consolidateFiles： spark.shuffle.mapOutput.minSizeForBroadcast：默认值 512K spark.shuffle.mapOutput.dispatcher.numThreads: 默认值为 8，map 端输出派发线程池中的线程数","tags":[{"name":"Spark","slug":"Spark","permalink":"http://example.com/tags/Spark/"}]},{"title":"Spark-Join的原理","date":"2021-05-05T08:29:59.000Z","path":"2021/05/05/Spark-SQL中Join的实现/","text":"Spark 物理计划阶段，join Selection 类会根据 join hints 策略，Join 表的大小、join 是否是等值 join、参与 join 的 key 是否可排序等条件选择最终的 join 策略。 Spark 支持的 join 类型： inner join: 内连接 left outer join: 左外连接 right outer join: 右外连接 full outer join: 全连接 full outer join 仅采用 sort merge join 实现，左边和右表既要作为 streamIter，又要作为 buildIter left semi join: 以左表为准，在右表中查找匹配的记录，如果查找成功，则仅返回左边的记录，否则返回 null left anti join: 以左表为准，在右表中查找匹配的记录，如果查找成功，则返回 null，否则仅返回左边的记录 cross join: 五种 Join 策略 Broadcast hash join (BHJ): 将小表的数据广播到 Spark 所有的 Executor，作业中较常见 Shuffle hash join（SHJ）: 是大表和小表进行 join 时选择的一种策略 Shuffle sort merge join (SMJ)： join 表都很大的时候选择，作业中较常见 Shuffle-and-replicate nested loop join: 又称笛卡尔积 join，非等值连接的时候可能使用 Broadcast nested loop join (BNLJ): JoinSelection选择策略： Join 的 Key 为等值 Join 来选择 BHJ、SHJ、SMJ 中的一个； Join 的 Key 为不等值 Join 或者没有指定 Join 条件，则会选择 BNLJ 或 Shuffe-and-replicate nested loop join SparkStrategies.JoinSelection 的 apply 对各种 join 策略的选择： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109object JoinSelection extends Strategy with PredicateHelper &#123; /** * 匹配输出应该足够小以用于广播连接的计划，小表的大小小于配置 spark.sql.autoBroadcastJoinThreshold(10M) */ private def canBroadcast(plan: LogicalPlan): Boolean = &#123; plan.stats.sizeInBytes &gt;= 0 &amp;&amp; plan.stats.sizeInBytes &lt;= conf.autoBroadcastJoinThreshold &#125; /** * 该 plan 的单个分区应该足够小，可以构建哈希表。 */ private def canBuildLocalHashMap(plan: LogicalPlan): Boolean = &#123; plan.stats.sizeInBytes &lt; conf.autoBroadcastJoinThreshold * conf.numShufflePartitions &#125; /** * 返回计划a是否比计划b小很多(3X)。 * 构建哈希映射的成本比排序高，我们应该只在一个比其他表小得多的表上构建哈希映射。因为我们没有行数的统计信息，所以这里使用字节大小作为估计。 */ private def muchSmaller(a: LogicalPlan, b: LogicalPlan): Boolean = &#123; a.stats.sizeInBytes * 3 &lt;= b.stats.sizeInBytes &#125; def apply(plan: LogicalPlan): Seq[SparkPlan] = plan match &#123; // --- BroadcastHashJoin -------------------------------------------------------------------- // broadcast hints were specified // 广播提示被指定 case ExtractEquiJoinKeys(joinType, leftKeys, rightKeys, condition, left, right) if canBroadcastByHints(joinType, left, right) =&gt; val buildSide = broadcastSideByHints(joinType, left, right) Seq(joins.BroadcastHashJoinExec( leftKeys, rightKeys, joinType, buildSide, condition, planLater(left), planLater(right))) // broadcast hints were not specified, so need to infer it from size and configuration. // 没有指定广播提示，所以需要从大小和配置推断它。 case ExtractEquiJoinKeys(joinType, leftKeys, rightKeys, condition, left, right) // 选择 BroadcastHashJoin 策略，需要为等值连接，广播的小小符合 if canBroadcastBySizes(joinType, left, right) =&gt; val buildSide = broadcastSideBySizes(joinType, left, right) Seq(joins.BroadcastHashJoinExec( leftKeys, rightKeys, joinType, buildSide, condition, planLater(left), planLater(right))) // --- ShuffledHashJoin --------------------------------------------------------------------- // 选择 ShuffledHashJoin case ExtractEquiJoinKeys(joinType, leftKeys, rightKeys, condition, left, right) // 配置中不是优先 SortMergeJoin // 且 Join 类型符合要求 // 且 可以构建本地的 HashMap // 且足够小(返回计划a是否比计划b小很多(3X)) 或 leftKeys 不可排序 if !conf.preferSortMergeJoin &amp;&amp; canBuildRight(joinType) &amp;&amp; canBuildLocalHashMap(right) &amp;&amp; muchSmaller(right, left) || !RowOrdering.isOrderable(leftKeys) =&gt; Seq(joins.ShuffledHashJoinExec( leftKeys, rightKeys, joinType, BuildRight, condition, planLater(left), planLater(right))) // 和上面相同逻辑，转换下 left,right 进行比较 case ExtractEquiJoinKeys(joinType, leftKeys, rightKeys, condition, left, right) if !conf.preferSortMergeJoin &amp;&amp; canBuildLeft(joinType) &amp;&amp; canBuildLocalHashMap(left) &amp;&amp; muchSmaller(left, right) || !RowOrdering.isOrderable(leftKeys) =&gt; // 选择 ShuffledHashJoin 策略 Seq(joins.ShuffledHashJoinExec( leftKeys, rightKeys, joinType, BuildLeft, condition, planLater(left), planLater(right))) // --- SortMergeJoin ------------------------------------------------------------ // 等值连接，leftKeys 是可排序的情况下选择 case ExtractEquiJoinKeys(joinType, leftKeys, rightKeys, condition, left, right) if RowOrdering.isOrderable(leftKeys) =&gt; // 选择 SortMergeJoin 策略 joins.SortMergeJoinExec( leftKeys, rightKeys, joinType, condition, planLater(left), planLater(right)) :: Nil // --- Without joining keys ------------------------------------------------------------ // Pick BroadcastNestedLoopJoin if one side could be broadcast case j @ logical.Join(left, right, joinType, condition) if canBroadcastByHints(joinType, left, right) =&gt; val buildSide = broadcastSideByHints(joinType, left, right) // 选择 BroadcastNestedLoopJoin(BNLJ) joins.BroadcastNestedLoopJoinExec( planLater(left), planLater(right), buildSide, joinType, condition) :: Nil case j @ logical.Join(left, right, joinType, condition) if canBroadcastBySizes(joinType, left, right) =&gt; val buildSide = broadcastSideBySizes(joinType, left, right) joins.BroadcastNestedLoopJoinExec( planLater(left), planLater(right), buildSide, joinType, condition) :: Nil // Pick CartesianProduct for InnerJoin case logical.Join(left, right, _: InnerLike, condition) =&gt; joins.CartesianProductExec(planLater(left), planLater(right), condition) :: Nil case logical.Join(left, right, joinType, condition) =&gt; val buildSide = broadcastSide( left.stats.hints.broadcast, right.stats.hints.broadcast, left, right) // This join could be very slow or OOM joins.BroadcastNestedLoopJoinExec( planLater(left), planLater(right), buildSide, joinType, condition) :: Nil // --- Cases where this strategy does not apply --------------------------------------------- case _ =&gt; Nil &#125; &#125;&#125; Join 策略BroadcastHashJoin将小表的数据广播到 Spark 所有的 Executor 端，只能用于等值连接。避免了 Shuﬄe 操作。一般而言，Broadcast Hash Join 会比其他 Join 策略执行的要快。 Join 步骤： 利用 collect 算子将小表的数据从 Executor 端拉到 Driver 端 在 Driver 端调用 sparkContext.broadcast 广播到所有 Executor 端 在 Executor 端使用广播的数据与大表进行 Join 操作 使用条件： 必须为等值连接，不要求 Join 的 keys 可排序 小表大小小于 spark.sql.autoBroadcastJoinThreshold(default 10M)设定的值 ShuffleHashJoin与 BHJ 都是在大表和小表进行 Join 的时候选择的一种策略。 Join 步骤：把大表和小表按照相同的分区算法和分区数进行分区(Join 的 keys 进行分区)，保证了 hash 值一样的数据都分发到同一个分区中，然后在同一个 Executor 中两张表 hash 值一样的分区就可以在本地进行 hash Join 。在进行 Join 之前，还会对小表的分区构建 Hash Map。 使用条件： 必须为等值连接 不是优先 SortMergeJoin，即配置 spark.sql.join.preferSortMergeJoin 为 false 小表的大小（plan.stats.sizeInBytes）必须小于 spark.sql.autoBroadcastJoinThreshold(10M) * spark.sql.shuffle.partitions（200） 小表大小（stats.sizeInBytes）的三倍必须小于等于大表的大小（stats.sizeInBytes） SortMergeJoin对表的大小没有条件，不管分区多大，SortMergeJoin 都不用把一侧的数据全部加载到内存中，而是即用即丢；两个序列都有序。从头遍历，碰到 key 相同的就输出，如果不同，左边小就继续取左边，反之取右边，提高了大数据量下sql join 的稳定性。 Join 步骤： 将两张表按照 join key 进行shuﬄe，保证join key值相同的记录会被分在相应的分区 对每个分区内的数据进行排序 排序后再对相应的分区内的记录进行连接 使用条件： 等值连接 参与 join 的 key 可排序 BroadcastNestedLoopJoin123for record_1 in relation_1: for record_2 in relation_2: # join condition is executed 在某些情况会对某张表重复扫描多次，效率非常低下，会根据相关条件对小表进行广播，以减少表的扫描次数。 支持等值和不等值 Join，支持所有的 Join 类型。 CartesianProductJoinjoin 表未指定连接条件时使用 相关配置影响 join 策略选择的配置 spark.sql.autoBroadcastJoinThreshold： 使用 broadcast hash join 的阈值，默认为 10M，为 -1 表示关闭这种连接方式 spark.sql.join.preferSortMergeJoin： 是否尝试使用 Shuffle Hash Join，默认为 true spark.sql.shuffle.partitions： 默认 200","tags":[{"name":"Spark","slug":"Spark","permalink":"http://example.com/tags/Spark/"},{"name":"SparkSQL","slug":"SparkSQL","permalink":"http://example.com/tags/SparkSQL/"}]},{"title":"数据结构设计","date":"2021-04-19T14:53:47.000Z","path":"2021/04/19/数据结构设计/","text":"队列与栈Array 实现 Queue和 Java 中的 ArrayDequeue 实现类似，记录队列头部和尾部的索引实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Queue&lt;E&gt; &#123; private E[] data; private int N; private int frontIdx; private int tailIdx; public Queue(int capacity) &#123; data = (E[]) new Object[capacity]; frontIdx = 0; tailIdx = 0; N = 0; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public int size() &#123; return N; &#125; public void enqueue(E e) &#123; if (N == data.length) throw new IllegalArgumentException(&quot;LinkedQueue is full.&quot;); data[tailIdx] = e; tailIdx = (tailIdx + 1) % data.length; N++; &#125; public E dequeue() &#123; if (isEmpty()) throw new NoSuchElementException(&quot;LinkedQueue is empty.&quot;); E oldFront = data[frontIdx]; data[frontIdx] = null; frontIdx = (frontIdx + 1) % data.length; N--; return oldFront; &#125; public E peek() &#123; if (isEmpty()) throw new NoSuchElementException(&quot;LinkedQueue is empty.&quot;); return data[frontIdx]; &#125;&#125; Array 实现 Stack1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.NoSuchElementException;public class Stack&lt;E&gt; &#123; private E[] data; private int N; public Stack(int capacity) &#123; data = (E[]) new Object[capacity]; N = 0; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public int size() &#123; return N; &#125; public void push(E e) &#123; if (N == data.length) throw new NoSuchElementException(&quot;Stack is empty.&quot;); data[N] = e; N++; &#125; public E pop() &#123; if (isEmpty()) throw new NoSuchElementException(&quot;Stack is empty.&quot;); E oldTop = data[N - 1]; data[N - 1] = null; N--; return oldTop; &#125; public E peek() &#123; if (isEmpty()) throw new NoSuchElementException(&quot;Stack is empty.&quot;); return data[N - 1]; &#125;&#125; Stack 实现 Queue12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.NoSuchElementException;import java.util.Stack;class MyQueue &#123; private Stack&lt;Integer&gt; in = new Stack&lt;&gt;(); // peek element always is first put element when pop or peek operation private Stack&lt;Integer&gt; out = new Stack&lt;&gt;(); public void push(int x) &#123; in.push(x); &#125; public int pop() &#123; if (empty()) &#123; throw new NoSuchElementException(); &#125; in2out(); return out.pop(); &#125; public int peek() &#123; if (empty()) &#123; throw new NoSuchElementException(); &#125; in2out(); return out.peek(); &#125; public boolean empty() &#123; return in.isEmpty() &amp;&amp; out.isEmpty(); &#125; private void in2out() &#123; // maintain out first pop is first input if (out.isEmpty()) &#123; while (!in.isEmpty()) &#123; out.push(in.pop()); &#125; &#125; &#125;&#125; Queue 实现 Stack两个队列实现, 在弹出时进行结构调整 peek, poll O(N) push O(1) 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.LinkedList;import java.util.NoSuchElementException;import java.util.Queue;class MyStack &#123; private Queue&lt;Integer&gt; data = new LinkedList&lt;&gt;(); private Queue&lt;Integer&gt; help = new LinkedList&lt;&gt;(); public void push(int x) &#123; data.offer(x); &#125; public int pop() &#123; if (empty()) throw new NoSuchElementException(); while (data.size() &gt; 1) help.offer(data.poll()); int oldTop = data.poll(); swap(); return oldTop; &#125; public int top() &#123; if (empty()) throw new NoSuchElementException(); while (data.size() &gt; 1) help.offer(data.poll()); int top = data.poll(); help.offer(top); swap(); return top; &#125; public boolean empty() &#123; return data.isEmpty(); &#125; private void swap() &#123; Queue&lt;Integer&gt; t = data; data = help; help = t; &#125;&#125; 方式二： 一个队列实现 同一个队列实现, 将队尾元素重新插入到队首元素实现逆序 push O(N) pop O(1) 1234567891011121314151617181920212223242526272829303132import java.util.LinkedList;import java.util.NoSuchElementException;import java.util.Queue;class MyStack2 &#123; private Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); public void push(int x) &#123; queue.offer(x); int cnt = queue.size(); // reverse queue element, offer(poll()) while (cnt-- &gt; 1) &#123; queue.offer(queue.poll()); &#125; &#125; public int pop() &#123; if (empty()) throw new NoSuchElementException(); return queue.poll(); &#125; public int top() &#123; if (empty()) throw new NoSuchElementException(); return queue.peek(); &#125; public boolean empty() &#123; return queue.isEmpty(); &#125;&#125; 猫狗队列实现一种狗猫队列的结构，要求如下： 用户可以调用 1234567add 方法，将cat类或dog类的实例放入队列中； 用户可以调用pollAll 方法，将队列中所有的实例按照进队列的先后顺序依次弹出； 用户可以调用pollDog 方法，将队列中dog类的实例按照进队列的先后顺序依次弹出； 用户可以调用pollCat 方法，将队列中cat类的实例按照进队列的先后顺序依次弹出； 用户可以调用isEmpty 方法，检查队列中是否还有dog或cat的实例； 用户可以调用isDogEmpty 方法，检查队列中是否有dog类的实例； 用户可以调用isCatEmpty 方法，检查队列中是否有cat类的实例。 每个 Pet 加入时通过 index 标识次序, 用于弹出时比较. 分开存储, Cat、Dog 分别存放到一个队列中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class Pet &#123; private String type; public Pet(String type) &#123; this.type = type; &#125; public String getPetType() &#123; return this.type; &#125;&#125;public class Cat extends Pet &#123; public Cat() &#123; super(&quot;cat&quot;); &#125;&#125;public class Dog extends Pet &#123; public Dog() &#123; super(&quot;dog&quot;); &#125;&#125;import java.util.LinkedList;import java.util.Queue;public class CatDogQueue &#123; private Queue&lt;WrappedPet&gt; dogs = new LinkedList&lt;&gt;(); private Queue&lt;WrappedPet&gt; cats = new LinkedList&lt;&gt;(); private int sequence; // as index to keep order public boolean isEmpty() &#123; return dogs.isEmpty() &amp;&amp; cats.isEmpty(); &#125; public boolean isCatEmpty() &#123; return cats.isEmpty(); &#125; public boolean isDogEmpty() &#123; return dogs.isEmpty(); &#125; public void offer(Pet pet) &#123; // add pet to different queue by pet type if (pet instanceof Dog) &#123; dogs.add(new WrappedPet(pet, sequence++)); &#125; else if (pet instanceof Cat) &#123; cats.add(new WrappedPet(pet, sequence++)); &#125; else &#123; throw new IllegalArgumentException(&quot;not a dog or cat&quot;); &#125; &#125; public Pet poll() &#123; if (isEmpty()) &#123; throw new IllegalArgumentException(&quot;queue is empty&quot;); &#125; // one queue is empty if (dogs.isEmpty()) &#123; return cats.poll().getPet(); &#125; if (cats.isEmpty()) &#123; return dogs.poll().getPet(); &#125; // compare sequence number return dogs.peek().getCount() &lt; cats.peek().getCount() ? dogs.poll().getPet() : cats.poll().getPet(); &#125; public Cat pollCat() &#123; if (cats.isEmpty()) &#123; throw new IllegalArgumentException(&quot;have no cat&quot;); &#125; return (Cat) cats.poll().getPet(); &#125; public Dog pollDog() &#123; if (dogs.isEmpty()) &#123; throw new IllegalArgumentException(&quot;have no dog&quot;); &#125; return (Dog) dogs.poll().getPet(); &#125; static class WrappedPet &#123; private Pet pet; private int count; public WrappedPet(Pet pet, int count) &#123; this.pet = pet; this.count = count; &#125; public Pet getPet() &#123; return pet; &#125; public int getCount() &#123; return count; &#125; &#125;&#125; 带有最小值的栈min 栈与 data 栈存放元素个数不一致 min 栈只存放小元素 12345678910111213141516171819202122232425262728293031323334import java.util.NoSuchElementException;import java.util.Stack;class MinStack &#123; private Stack&lt;Integer&gt; data = new Stack&lt;&gt;(); private Stack&lt;Integer&gt; min = new Stack&lt;&gt;(); public void push(int x) &#123; if (data.isEmpty() || x &lt;= min.peek()) &#123; min.push(x); &#125; data.push(x); &#125; public void pop() &#123; if (data.isEmpty()) throw new NoSuchElementException(); if (data.peek().equals(min.peek())) min.pop(); data.pop(); &#125; public int top() &#123; if (data.isEmpty()) throw new NoSuchElementException(); return data.peek(); &#125; public int getMin() &#123; if (data.isEmpty()) throw new NoSuchElementException(); return min.peek(); &#125;&#125; 其他LRU 实现leetcode 12345678910LRUCache cache = new LRUCache( 2 );cache.put(1, 1);cache.put(2, 2);cache.get(1); // returns 1cache.put(3, 3); // evicts key 2cache.get(2); // returns -1 (not found)cache.put(4, 4); // evicts key 1cache.get(1); // returns -1 (not found)cache.get(3); // returns 3cache.get(4); // returns 4 使用构建一个双向链表来维护 LRU 的关系，一个 Map 对应 element value → Node 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import java.util.HashMap;class LRUCache &#123; private HashMap&lt;Integer, Node&gt; cache; private int capacity; private Node head; private Node tail; private class Node &#123; Node prev; Node next; Integer key; Integer val; public Node(Integer k, Integer v) &#123; this.key = k; this.val = v; &#125; &#125; public LRUCache(int capacity) &#123; this.capacity = capacity; this.cache = new HashMap&lt;&gt;(capacity * 4 / 3); &#125; public int get(int key) &#123; if (!cache.containsKey(key)) &#123; return -1; &#125; Node node = cache.get(key); remove(node); setHead(node); return node.val; &#125; public void put(int key, int value) &#123; if (cache.containsKey(key)) &#123; Node oldNode = cache.get(key); oldNode.val = value; remove(oldNode); setHead(oldNode); &#125; else &#123; Node newNode = new Node(key, value); if (cache.size() &gt;= capacity) &#123; System.out.println(&quot;Cache is FULL! Removing &quot; + tail.val + &quot; from cache...&quot;); cache.remove(tail.key); remove(tail); &#125; setHead(newNode); cache.put(key, newNode); &#125; &#125; // remove from list node, note head tail edge private void remove(Node node) &#123; if (node.prev != null) &#123; node.prev.next = node.next; &#125; else &#123; head = node.next; &#125; if (node.next != null) &#123; node.next.prev = node.prev; &#125; else &#123; tail = node.prev; &#125; &#125; // make node(newNode or accessed node) to head private void setHead(Node node) &#123; node.next = head; node.prev = null; // init or remove no element if (head != null) &#123; head.prev = node; &#125; head = node; // init or remove no element if (tail == null) &#123; tail = head; &#125; &#125;&#125; LFU 实现123456789101112131415headList 1 &lt;-&gt; 3 &lt;-&gt; 4 &lt;-&gt; 7 F G H I ^ ^ ^ ^ | | | | v v v v A D ^ | v C ^ | v E 数据流中的中位数nowcoder 思路: 原始拆分存储在不同的容器中 通过维护左右两个堆实现, 左边的为最大堆, 右边的为最小堆 插入元素时, 若当前容器大小为偶数, 通过先放入右边的最大堆, 之后弹出左边最大堆的堆顶元素放入右边的最小堆实现有序性 12345678910111213141516171819202122232425262728293031323334import java.util.NoSuchElementException;import java.util.PriorityQueue;public class Solution &#123; // max heap private PriorityQueue&lt;Integer&gt; leftSmall = new PriorityQueue&lt;&gt;((o1, o2) -&gt; o2 - o1); // min heap private PriorityQueue&lt;Integer&gt; rightBig = new PriorityQueue&lt;&gt;(); private int N; public void Insert(Integer num) &#123; if (N % 2 == 0) &#123; // even, put rightBig AND ordered leftSmall.offer(num); rightBig.offer(leftSmall.poll()); &#125; else &#123; // odd, right N/2+1 rightBig.offer(num); leftSmall.offer(rightBig.poll()); &#125; N++; &#125; public Double GetMedian() &#123; if (isEmpty()) throw new NoSuchElementException(); if (N % 2 == 0) return (leftSmall.peek() + rightBig.peek()) / 2.0; else return (double) rightBig.peek(); &#125; public boolean isEmpty() &#123; return leftSmall.isEmpty() &amp;&amp; rightBig.isEmpty(); &#125;&#125; BiMap一对一的映射 一个 Map 实现 1234567891011121314151617181920212223import java.util.HashMap;import java.util.Map;class OneToOneMap&lt;K, V&gt; &#123; private Map&lt;K, V&gt; map = new HashMap&lt;&gt;(); public V get(K key) &#123; return map.get(key); &#125; public boolean put(K key, V val) &#123; if (map.containsKey(key)) &#123; if (!map.get(key).equals(val)) return false; &#125; else &#123; // O(n) if (map.containsValue(val)) return false; map.put(key, val); &#125; return true; &#125;&#125; 两个 Map 实现 分别保存 key 和 val，使用一个 sequence 来唯一确定是否相等 1234567891011121314151617181920import java.util.HashMap;import java.util.Map;import java.util.Objects;class OneToOneMap2&lt;K, V&gt; &#123; private Map&lt;K, Integer&gt; map1 = new HashMap&lt;&gt;(); private Map&lt;V, Integer&gt; map2 = new HashMap&lt;&gt;(); private int sequence; // O(1) public boolean put(K key, V val) &#123; Integer keyReplace = map1.put(key, sequence); Integer valReplace = map2.put(val, sequence); if (Objects.equals(keyReplace, valReplace) == false) &#123; return false; &#125; sequence++; return true; &#125;&#125; 带有最大值的滑动窗口leetcode-sliding-window-maximum 123456789101112Input: nums &#x3D; [1,3,-1,-3,5,3,6,7], and k &#x3D; 3Output: [3,3,5,5,6,7]Explanation:Window position Max--------------- -----[1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7 方式一： 单调的双向队列实现 offer, poll O(1) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import java.util.Deque;import java.util.LinkedList;import java.util.NoSuchElementException;import java.util.Queue;public class MaxQueue &#123; // keep original enqueue order private Queue&lt;Tuple&gt; queue = new LinkedList&lt;&gt;(); // Monotone decreasing, last element is max private Deque&lt;Tuple&gt; qmax = new LinkedList&lt;&gt;(); // increasing sequence private int sequencer = 0; public void offer(int val) &#123; // poll not meet to main monotonicity while (!qmax.isEmpty() &amp;&amp; val &gt;= qmax.peekLast().val) &#123; qmax.pollLast(); &#125; Tuple tuple = new Tuple(val, sequencer++); queue.offer(tuple); qmax.offerLast(tuple); &#125; public int poll() &#123; if (queue.isEmpty()) &#123; throw new NoSuchElementException(); &#125; Tuple oldFront = queue.poll(); // remove relate max value if (qmax.peekFirst().idx == oldFront.idx) &#123; qmax.pollFirst(); &#125; return oldFront.val; &#125; public int max() &#123; if (queue.isEmpty()) &#123; throw new NoSuchElementException(); &#125; return qmax.peekFirst().val; &#125; // wrapped value with idx to record original put order static class Tuple &#123; int val; int idx; Tuple(int val, int idx) &#123; this.val = val; this.idx = idx; &#125; &#125;&#125; 方式二： 使用堆实现 offer, poll O(nlogn) 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.LinkedList;import java.util.NoSuchElementException;import java.util.PriorityQueue;import java.util.Queue;public class MaxQueue2 &#123; Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); PriorityQueue&lt;Integer&gt; heap = new PriorityQueue&lt;&gt;((o1, o2) -&gt; o2 - o1); public void offer(int e) &#123; queue.offer(e); heap.offer(e); &#125; public int poll() &#123; if (isEmpty()) throw new NoSuchElementException(); int oldFront = queue.poll(); if (oldFront == heap.peek()) heap.poll(); // time: O(nlogn) return oldFront; &#125; public int peek() &#123; if (isEmpty()) throw new NoSuchElementException(); return queue.peek(); &#125; // O(1) 获取队列中的最大值 public int max() &#123; if (isEmpty()) throw new NoSuchElementException(); return heap.peek(); &#125; public boolean isEmpty() &#123; return queue.isEmpty(); &#125; public int size() &#123; return queue.size(); &#125;&#125; 方式三： 使用 MaxStack 实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import java.util.NoSuchElementException;import java.util.Stack;public class MaxQueue3 &#123; static class MaxStack &#123; private Stack&lt;Integer&gt; data = new Stack&lt;&gt;(); private Stack&lt;Integer&gt; max = new Stack&lt;&gt;(); public void push(int e) &#123; if (max.isEmpty()) &#123; max.push(e); &#125; else if (e &gt;= max.peek()) &#123; max.push(e); &#125; data.push(e); &#125; public int pop() &#123; if (data.isEmpty()) throw new NoSuchElementException(); Integer oldTop = data.pop(); if (max.peek() == oldTop) max.pop(); return oldTop; &#125; public int peek() &#123; if (data.isEmpty()) throw new NoSuchElementException(); return data.peek(); &#125; public int max() &#123; if (max.isEmpty()) throw new NoSuchElementException(); return max.peek(); &#125; public boolean isEmpty() &#123; return data.isEmpty(); &#125; public int size() &#123; return data.size(); &#125; &#125; private MaxStack in = new MaxStack(); private MaxStack out = new MaxStack(); public void offer(int e) &#123; in.push(e); &#125; public int poll() &#123; if (isEmpty()) throw new NoSuchElementException(); if (out.isEmpty()) &#123; while (!in.isEmpty()) out.push(in.pop()); &#125; return out.pop(); &#125; public int peek() &#123; if (isEmpty()) throw new NoSuchElementException(); if (out.isEmpty()) while (!in.isEmpty()) out.push(in.pop()); return out.peek(); &#125; // O(1) 获取队列中的最大值 public int max() &#123; if (isEmpty()) throw new NoSuchElementException(); return Math.max(in.isEmpty() ? Integer.MIN_VALUE : in.max(), out.isEmpty() ? Integer.MIN_VALUE : out.max()); &#125; public boolean isEmpty() &#123; return in.isEmpty() &amp;&amp; out.isEmpty(); &#125; public int size() &#123; return in.size() + out.size(); &#125;&#125; 数据流中第一个重复元素nowcoder 通过 Map 记录当前所有字节流中的词频, loopArrQueue 保留原始的字节流插入顺序,同时保证 loopArrQueue 的队首元素词频为 1 12345678910111213141516171819202122232425import java.util.HashMap;import java.util.LinkedList;import java.util.Map;import java.util.Queue;public class Solution &#123; private Map&lt;Character, Integer&gt; freqs = new HashMap&lt;&gt;(); // record original sequence private Queue&lt;Character&gt; queue = new LinkedList&lt;&gt;(); public void Insert(char ch) &#123; freqs.put(ch, freqs.getOrDefault(ch, 0) + 1); queue.offer(ch); while (!queue.isEmpty() &amp;&amp; freqs.get(queue.peek()) &gt; 1) &#123; queue.poll(); // pop head of queue and keep head freq is 1 &#125; &#125; public char FirstAppearingOnce() &#123; if (queue.isEmpty()) &#123; return &#x27;#&#x27;; &#125; return queue.peek(); &#125;&#125;","tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}]},{"title":"Spark实现KNN近邻算法","date":"2021-04-16T02:32:24.000Z","path":"2021/04/16/Spark实现KNN近邻算法/","text":"KNN 近邻算法算法描述 KNN 算法描述 KNN（k-NearestNeighbor）又被称为最近邻算法。 思路是：若一个样本在特征空间中的 k 个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。 KNN 算法是机器学习中最简单的方法之一。KNN 是一种分类算法，KNN 没有显式的学习过程，即没有训练阶段，待收到新样本后直接进行处理。 距离计算 计算待测案例与训练样本之间的距离，常用的距离有欧式距离、曼哈顿距离、余弦距离等。 在欧几里得空间中，点x =(x1,…,xn)和 y =(y1,…,yn)之间的欧氏距离为 欧几里得距离 算法实现流程： 读文件中的测试数据、训练数据集，形成数据集 X,Y 求数据集 Y 中的每个点到数据集 X 中每个点的位置，得到数据集 D 找到数据集 D 中最小的 K 个点 求 K 个点的分布情况 返回前 K 个点中出现频率最高的类别作为测试数据的预测分类 鸢尾花数据集数据集内包含 3 类共 150 条 记录，每类各 50 个数据， 记录都有 4 项特征：花萼长度、花萼宽度、花瓣长度、花瓣宽度，可以通过这 4个 特征预测鸢尾花卉属于哪一品种(iris-setosa, iris-versicolour, iris-virginica)。 原始的数据集：Iris.csv 1234567891011Id,SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species1,5.1,3.5,1.4,0.2,Iris-setosa2,4.9,3.0,1.4,0.2,Iris-setosa3,4.7,3.2,1.3,0.2,Iris-setosa..52,6.4,3.2,4.5,1.5,Iris-versicolor53,6.9,3.1,4.9,1.5,Iris-versicolor..102,5.8,2.7,5.1,1.9,Iris-virginica103,7.1,3.0,5.9,2.1,Iris-virginica.. 未知的数据集：unknown_iris.csv 1238888,5.7,4.4,1.5,0.4,Iris-setosa227777,5.5,2.4,4.0,1.4,Iris-versicolor226666,6.8,3.2,5.1,2.3,Iris-virginica22 算法实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import org.apache.spark.broadcast.Broadcastimport org.apache.spark.rdd.RDDimport org.apache.spark.&#123;SparkConf, SparkContext&#125;object KNNDriver &#123; private val K = 15 def main(args: Array[String]): Unit = &#123; val conf: SparkConf = new SparkConf().setAppName(&quot;knn-test&quot;).setMaster(&quot;local[4]&quot;) val sc = new SparkContext(conf) sc.setLogLevel(&quot;WARN&quot;) // 读取实际的数据 id, (x1,y1,z1,e1) val realRdd: RDD[(String, Array[Double])] = sc.textFile(&quot;data/Iris.csv&quot;).map(line =&gt; &#123; val fields: Array[String] = line.split(&quot;,&quot;) if (fields(0).equals(&quot;Id&quot;)) &#123; (&quot;unknown&quot;, Array(-1.0)) &#125; else &#123; (fields.last, fields.init.tail.map(_.toDouble)) &#125; &#125;) val realBc: Broadcast[Array[(String, Array[Double])]] = sc.broadcast(realRdd.collect) // 读取待验证的数据 val toValidRdd: RDD[(String, Array[Double])] = sc.textFile(&quot;data/unknown_iris.csv&quot;).map(line =&gt; &#123; val fields: Array[String] = line.split(&quot;,&quot;) if (fields(0).equals(&quot;Id&quot;)) &#123; (&quot;unknown&quot;, Array(-1.0)) &#125; else &#123; (fields.last, fields.init.tail.map(_.toDouble)) &#125; &#125;) val varData: Array[(String, Array[Double])] = toValidRdd.collect() varData.foreach(elem =&gt; &#123; val res: Array[(Double, String)] = realBc.value.map(point =&gt; (distance(point._2, elem._2), point._1)) val kNeastNeighbor: Array[(Double, String)] = res.sortBy(_._1).take(K) val labels: Array[String] = kNeastNeighbor.map(_._2) print(s&quot;TestData: $&#123;elem._2.toBuffer&#125;, NearestNeighbor: &quot;) labels.groupBy(x =&gt; x).mapValues(_.length).foreach(print) println() &#125;) sc.stop() &#125; // 多个点之间的欧式距离 def distance(x: Array[Double], y: Array[Double]): Double = &#123; math.sqrt(x.zip(y).map(z =&gt; math.pow(z._1 - z._2, 2)).sum) &#125;&#125; 算法输出： 123TestData: ArrayBuffer(5.7, 4.4, 1.5, 0.4), NearestNeighbor: (Iris-setosa,15)TestData: ArrayBuffer(5.5, 2.4, 4.0, 1.4), NearestNeighbor: (Iris-versicolor,15)TestData: ArrayBuffer(6.8, 3.2, 5.1, 2.3), NearestNeighbor: (Iris-virginica,14)(Iris-versicolor,1) 优缺点优点： 训练时间复杂度低，为O(n)； 简单，易于理解； 可用于非线性分类； 缺点： 使用懒散学习方法，基本上不学习，导致预测时速度比起逻辑回归之类的算法慢； KNN 模型可解释性不强。 分类的时候，未考虑权重等因素，仅根据投票数量来决定分类结果。 Refk-nearest neighbors algorithm - Wikipedia 欧几里得距离 - 维基百科，自由的百科全书","tags":[{"name":"Spark","slug":"Spark","permalink":"http://example.com/tags/Spark/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"Spark-内存管理与持久化","date":"2021-04-09T07:10:07.000Z","path":"2021/04/09/Spark-内存管理与持久化/","text":"内存管理静态内存管理 Spark 2.0 以前版本采用静态内存管理机制。存储内存、执行内存和其他内存的大小在 Spark 应用程序运行期间均为固定的。 容易造成存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。目前已经被淘汰。 统一内存管理 Spark 2.0 之后引入统一内存管理机制，存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域，统一内存管理的堆内内存结构。 可以借用内存 最重要的优化在于动态占用机制 在执行过程中：执行内存的优先级 &gt; 存储内存的优先级 凭借统一内存管理机制，Spark 在一定程度上提高了堆内和堆外内存资源的利用率， 降低了开发者维护 Spark 内存的难度 存储内存管理RDD 持久化机制 Task 在启动之初读取一个分区时： 先判断这个分区是否已经被持久化 如果没有则需要检查 Checkpoint 或按照血统重新计算。 RDD 的持久化由 Spark 的 Storage(BlockManager) 模块负责，实现了 RDD 与物理存储的解耦合。 Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后 唯一对应一个Block。 RDD 缓存过程 RDD 缓存的源头：Other (Iterator / 内存空间不连续) Record 的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一 Partition 的不同 Record 的存储空间并不连续。 RDD 在缓存到存储内存之后，Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间 将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为展开（Unroll）。 淘汰与落盘 存储内存的淘汰规则为： 被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存 新旧 Block 不能属于同一个 RDD，避免循环淘汰 旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题 遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。 12345678910private[spark] class MemoryStore( conf: SparkConf, blockInfoManager: BlockInfoManager, serializerManager: SerializerManager, memoryManager: MemoryManager, blockEvictionHandler: BlockEvictionHandler) extends Logging &#123; private val entries = new LinkedHashMap[BlockId, MemoryEntry[_]](32, 0.75f, true) ...&#125; 执行内存管理主要用来存储任务在执行 Shuffle 时占用的内存 Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据 Spark 的存储内存和执行内存使用不同的管理方式： 对存储内存来说，Spark 用一个 LinkedHashMap 来集中管理所有的 Block， Block 由需要缓存的 RDD 的 Partition 转化而成； 对执行内存来说，Spark 用 AppendOnlyMap 来存储 Shuffle 过程中的数据， 在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制。 数据持久化数据持久化/缓存的目的： Spark 默认数据存放在内存中，适合高速迭代，多个步骤只有第一个输入数据，中间不产生临时数据，风险很高，容易出错，需要进行容错。 RDD 出错/分片可以根据血统重新计算出来，如果没有父 RDD 进行 persist 或者 cache，就需要重新做，耗时较大。将数据缓存起来，方便进行迭代计算。 RDD 持久化RDD 中的数据持久化： 对于 Spark 中 RDD 不支持的持久化方式，可使用 foreachPartition 进行自定义。 12345saveAsObjectFile()saveAsTextFile()saveAsHadoopFile()saveAsHadoopDataset()saveAsSequenceFile() cache 和 persist 比较都是用于将一个 RDD 缓存，之后使用的时候就不用重新计算了，节省程序运行时间 cache 只有一个默认的缓存级别 MEMORY_ONLY, cache 调用了persist，而 persist 可以根据情况设置其它的缓存级别； executor 执行的时候，默认 60% 做 cache，40% 做 task 操作，persist 是最根本的函数，最底层的函数。 persist 适用场景 特定步骤耗时高 计算的链条长，重新计算步骤多 checkpoint 所在的 rdd 要持久化 persist shuffle 之后进行 percist, shuffle 需要进行网络传输，风险大 shuffle 之前进行 precast，框架默认将数据持久化到磁盘，自动执行的 cache 和 checkpoint 比较cache 和 checkpoint 是有显著区别的，缓存把 RDD 计算出来然后放在内存中，但是 RDD 的依赖链还在， 当某个点某个 executor 挂掉了，上面 cache 的 RDD 就会丢掉，需要通过依赖链重放计算。checkpoint 是把 RDD 保存在 HDFS 中，是多副本可靠存储，依赖链可以丢掉，斩断了依赖链，在 executor 发生故障的时候，从 HDFS 中取出，无需重放计算。 Partition 与 Block 的关联关系 HDFS 中的 Block 是分布式存储的最小单位，等分，可设置冗余，可能有一部分磁盘空间的浪费 Spark 中的 Partition 是 RDD 的最小单元，RDD 是由分布在各个节点上的 Partition 组成。Partition 指的是 Spark 计算过程中，生成的数据在计算空间内的最小单元，同一份数据(RDD) 的 partition 大小不一、数量不定，根据 Application 里的算子和最初读入的数据分块决定 Block 位于存储空间、Partition 位于计算空间，Block 的大小是固定的，Partition 的大小是不固定的。 BlockManager 管理数据块。是一个嵌入在 Spark 中的 key-value 型分布式存储系统，也是 Master-Slave 结构的，RDD-cache、 shuffle-output、broadcast 等的实现都是基于 BlockManager 来实现的。 BlockManager 中的组件： DiskStore：负责对磁盘数据进行读写 MemoryStore：负责对内存数据进行读写 BlockTransferService：负责建立到远程其他节点 BlockManager 的连接，对远程其他节点的 BlockManager 的数据进行读写 存储和管理机制： 每个节点上存储的 block 信息都会汇报给 Driver 端的 BlockManager Master 作统一管理，BlockManager 对外提供 get 和 set 数据接口，可将数据存储在 Memory、Disk、Off-heap。 BlockManger 在 Spark 中的使用 shuffle 的过程中使用 BlockManager 作为数据的中转站 将广播变量发送到 Executor 时， broadcast 底层使用的数据存储层 spark streaming 一个 ReceiverInputDStream 接收到的数据，先放在 BlockManager 中， 然后封装为一个 BlockRdd 进行下一步运算 如果对一个 RDD 进行了 cache，CacheManager 也是把数据放在了 BlockManager 中， 后续 Task 运行的时候可以直接从 CacheManager 中获取到缓存的数据，不用再从头计算 相关配置 spark.storage.memoryFraction 用于设置 RDD 持久化数据在 Executor 内存中能占的比例，默认是 0.6， 默认 Executor 60% 的内存，可以用来保存持久化的 RDD 数据。根据的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘； 如果持久化操作比较多，可以提高 spark.storage.memoryFraction 参数，使得更多的持久化数据保存在内存中，提高数据的读取性能，如果 shuffle 的操作比较多，有很多的数据读写操作到 JVM 中，那么应该调小一点，节约出更多的内存给 JVM，避免过多的 JVM gc 发生。 spark.shuffle.memoryFraction 为 Spark 调优中的重要参数，shuffle 从上一个 task 拉去数据过来，要在Executor进行聚合操作， 聚合操作时使用Executor内存的比例由该参数决定，默认是20%如果聚合时数据超过了该大小，那么就会spill到磁盘，极大降低性能； 如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例， 避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用， 那么同样建议调低这个参数的值。 RefBlockManager - The Internals of Apache Spark","tags":[{"name":"Spark","slug":"Spark","permalink":"http://example.com/tags/Spark/"}]},{"title":"MySQL-管理","date":"2021-04-08T17:10:05.000Z","path":"2021/04/09/MySQL-管理/","text":"基本管理查看数据库中行数大于 0 的表 1234567891011121314151617181920-- 查找表行大于0的SELECT CONCAT(table_schema, &#x27;.&#x27;, table_name) AS TABLE_NAME ,engine AS TABLE_ENGINE ,table_type AS TABLE_TYPE ,table_rows AS TABLE_ROWS ,CONCAT(ROUND(data_length / ( 1024 * 1024), 2), &#x27;M&#x27;) AS TB_DATA_SIZE ,CONCAT(ROUND(index_length / ( 1024 * 1024), 2), &#x27;M&#x27;) AS TB_IDX_SIZE ,CONCAT(ROUND((data_length + index_length ) / ( 1024 * 1024 ), 2), &#x27;M&#x27;) AS TOTAL_SIZE ,CASE WHEN data_length =0 THEN 0 ELSE ROUND(index_length / data_length, 2) END AS TB_INDX_RATE ,CONCAT(ROUND( data_free / 1024 / 1024,2), &#x27;MB&#x27;) AS TB_DATA_FREE ,CASE WHEN (data_length + index_length) = 0 THEN 0 ELSE ROUND(data_free/(data_length + index_length),2) END AS TB_FRAG_RATEFROM information_schema.TABLES WHERE TABLE_ROWS &gt; 0 AND table_name in (&#x27;entitylog&#x27;,&#x27;iterfacelog&#x27;,&#x27;stockshiftflow&#x27;,&#x27;stockoperlog&#x27;)ORDER BY data_length limit 0, 20 命令执行 -e: 执行 SQL 语句 -D: 连接的数据库 -s, --silent: 使用 tab 作为分隔符，row ⇒ line，用于制作报表 -C, --compress: 使用压缩在 client/server 之间 输出： 配合 Excel 制表 -B: 使用 Tab 替换分隔符 -N: 不输出列信息 -E: 垂直输出，展示格式 -H: 以 HTML 输出 -X: 以 XML 输出 1234# 连接 DB 执行 SQL，让结果按照特定格式显示，方便 awk, sed 处理mysql -uroot -p$MYSQL_ROOT_PASSWORD -h&lt;ip&gt; -D school -e &quot;SELECT * FROM student;&quot;mysql -udbuser -p123456 -h&lt;ip&gt; -D school -N -B -e &quot;SELECT * FROM student;&quot;mysql -udbuser -p123456 -h&lt;ip&gt; -D school -N -H -B -e &quot;SELECT * FROM student;&quot; &gt; result.html 服务信息查看查看最近的 InnoDB 信息 1SHOW ENGINE INNODB STATUS \\\\G 查看存储过程 1SHOW PROCEDURE STATUE LIKE &#x27;.*&#x27; \\\\G 查看函数 1SHOW FUNCTION STATUE LIKE &#x27;.*&#x27; \\\\G 查找出所有 function,routines 1SELECT SPECIFIC_NAME FROM information_schema.Routines \\\\G 查看服务器状态 1show status like &#x27;%lock%&#x27;\\\\G 查询是否锁表 12# 记录当前锁表状态 show OPEN TABLES where In_use &gt; 0 查询 MySQL 进程 123# Top 100show processlistshow full processlist; 查看正在锁的事务 1SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 查看等待锁的事务 1SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; 慢查询 123456-- 查看慢查询时间show variables like &quot;long_query_time&quot;;-- 查看慢查询配置情况show status like &quot;%slow_queries%&quot;;-- 查看慢查询日志路径show variables like &quot;%slow%&quot;; 查看当前有那些表是打开的 12show open tables;show open tables from database; 查看服务器超时参数 12345678910111213141516show variables like ‘%timeout%’;-- 隔离级别SHOW VARIBALES LIKE &#x27;ios%&#x27;-- innodbSHOW VARIABLES LIKE &#x27;innodb_file_per_table&#x27;-- 日志缓冲区SHOW VARIABLES lIKE &#x27;innodb_log_buffer_size&#x27;-- 表的索引信息查看SHOW INDEX FROM &lt;mytab&gt;-- 表信息查看SHOW CREATE TABLE &lt;mytab&gt; \\\\G-- warning 出现后的查看show warnings;-- 时区设置set time_zone=&#x27;+10:00&#x27;;-- 隔离级别设置SET SESSSION TRANSACTION LEVEL 用户与权限对于连接程序的账户，不给予 ALERT 权限，但是给定 DML 语句的 EXEC，让用户通过 EXEC 执行函数或是存储过程来变更表结构，防止权限造成的表结构更改混乱问题 权限 创建检查账号: 123grant select,process,super,replication slave on . to &#x27;mysql_check&#x27;@&#x27;x.x.x.x&#x27; identified by &#x27;mysql_check&#x27;; flush privileges; 如何在给定场景下为某用户授权？ 对于对接的数据库授权，主要为 DML 权限 如何为用户授权 遵循最小权限原则 使用 Grant 命令对用户授权(非改 db) 用户管理流程规范 数据库用户管理流程规范 (1) 最小权限原则 (2) 密码强度策略 (3) 密码过期原则。5.7 中引入 (4) 限制历史密码重用原则 定义账号 如何定义MySQL数据库账号？ (1) 用户名@可访问控制列表 1.%：代表可以从所有外部主机访问 2.192.168.1.%：表示可以从192.168.1网段访问 3.localhost: DB服务器本地访问 (2) 使用CREATE USER命令建立用户 8.0 信息更多 如何从一个实例迁移数据库账号到另一个实例？ 根据 mysql 的数据库版本是否一致判断 一致，备份 mysql 数据库，目的实例进行恢复 - 不一致，到处授权 sql 1234567891011121314151617181920pt-show-grants u=root，p=123456，h=localhostshow priviledges; CREATE USER userinfo IDENTIFIED BY &#x27;3UuQuskw2k%k&#x27;;RENAME USER userinfo TO janhen;DROP USER janhen;SHOW GRANTS FOR janhen;-- 授权给新增的用户GRANT SELECT,UPDATE,INSERT,DELETE ON openapi.* TO openapi;-- 取消授权REVOKE DELETE ON openapi.* FROM openapi;、-- 更改密码SET PASSWORD FOR openapi = PASSWORD(&#x27;!BrJ%4MROWvN&#x27;);SET PASSWORD FOR &#x27;dbadmin&#x27;@&#x27;localhost&#x27; = bigshark;-- 设置登陆用户的密码SET PASSWORD = PASSWORD(&#x27;xxxxx&#x27;); 权限查看 1show grants for &#x27;test&#x27;@&#x27;%&#x27; 权限收回 1revoke insert on test.* from &#x27;test&#x27;@&#x27;%&#x27; 常见权限 (1) 管理权限 不提供 MySQL 的 root 权限，给管理员权限，防止误操作 12345GRANT ALL PRIVILEGESON *.* TO &#x27;janhenadmin&#x27;@&#x27;sjfksjfaksdjfad&#x27; WITH GRANT OPTIONgrant super,process,file on *.* to &#x27;janhen&#x27;@&#x27;%&#x27; (2) 数据库的读写权限 主要用于系统对接使用， SELECT, INSERT, UPDATE, DELETE, EXECUTE 1234GRANT SELECT,INSERT,UPDATE,DELETE,EXECUTE ON openapi.* TO &#x27;openapi&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123&#x27; (3) 监控权限 用于命令行监控，或是 Prometheus 进行监控信息的获取 基本的主从命令 对于统计数据库的权限 基本的要求： SHOW MASTER LOGS SHOW ENGINE INNODB STATUS SHOW VIEW, PROCESS, REPLICATION CLIENT, SELECT and SHOW DATABASES 对 mysql 表的查看 (4) 备份权限 通过 mysqldump 或是 xtracback 执行备份，需要对 VIEW、Function、event 等进行备份 SELECT, RELOAD, LOCK TABLES, REPLICATION CLIENT, SHOW VIEW, EVENT, PROCESS 123GRANT select,reload,lock tables,replication client,show view,event,process ON *.* TO &#x27;backup&#x27;@&#x27;%&#x27;; (5) 登陆权限 1grant usage on *.* to &#x27;test&#x27;@&#x27;%&#x27; MySQL 监控概述监控什么 1、可用性: 端口检测，执行 select 1 或 show status 作为测试 SQL 2、性能监控: 并发线程监控 3、对主从复制进行监控 4、服务器资源的监控 可用性监控 本地 | 网络, 自带命令 ping 进行检测 1mysqladmin -umonitor -p -h pingtelnet ip db_port 2、Telent 连接 3、程序通过网络建立数据库 @Q: 确定 DB 是否读写 read_only 参数，主从中注意，定期检查 简单查询 SELECT @@version 连接数量监控： 123456-- 运行最大show variables like &#x27;max_connections&#x27;;-- 当前连接show global status like &#x27;Threads_connected&#x27;;-- 比例监控Threads_connected/max_connections&gt;0.8; 性能监控 @Q: QPS 和 TPS TPS 每秒的事务数量 123CRU QPS=(Queries2-Queries1)/(Uptime_since_flush_status2- Uptime_since_flush_status1)TPS=((Com_insert2+Com_update2+Com_delete2)- (Com_insert1+Com_update1+Com_delete1))/ (Uptime_ since_flush_status2-Uptime_since_flush_ status1) 主从复制监控 @Q: 监控主从复制链路的状态 123456Master_Log_File:mysql-bin.001083Read_Master_Log_Pos:228613650Relay_Log_File:mysqld-relay-bin.003606Relay_Log_Pos:228613813Relay_Master_Log_File:mysql-bin.001083Slave_Io_Running:Yes Slave_SQL_Running:Yes Replicate_Do__DB: Replicate_Iqnore_DB: @Q: 主从延迟 #{。。。} @Q: 验证主从复制的数据一致性 MySQL 信息查看 不使用其他的工具，借助 MySQL 自带的命令或表进行查看 MySQL 状态信息查看 收集这些信息可以用于检测数据库的运行情况 分为全局状态、会话状态 123show processlist; show status; show status like ‘%下面变量%’; Aborted_clients 由于客户没有正确关闭连接已经死掉,已经放弃的连接数量. Flush_commands 执行FLUSH命令的次数. Aborted_connects 尝试已经失败的MySQL服务器的连接的次数. Max_used_connections 同时使用的连接的最大数目. Slow_queries：要花超过long_query_time时间的查询数量. Open_tables 打开表的数量. Open_files 打开文件的数量. Open_streams 打开流的数量(主要用于日志记载） Opened_tables 已经打开的表的数量. Threads_connected 当前打开的连接的数量. INFORMATION_SCHEMA 辅助表信息 transaction 1SELECT * FROM information_schema.INNODB_TRX; PERFORMANCE_SCHEMA 1SHOW STATUS LIKE &#x27;perf%&#x27;; 可不与 mysql 在同一个机器上，作为额外的监控组件进行操作 支持服务器分组，支持多个 mysql 连接，较少的配置易于执行 InnotopInnotop 为 MySQL和 InnoDB 事务/状态的监视器，类似 MySQL 的 top 命令，显示查询、InnoDB 事务、锁等待、死锁、打开的表、复制的状态、缓冲信息等。 运行的参数 d：多久时间更新一次 h：连接的主机名 p：连接的端口 S：socket的位置 u：连接的用户 c: 指定配置文件运行 # 进行服务器分组@ 进行选择连接 12innotop -h 127.0.0.1 \\\\ -u root -p$MYSQL_ROOT_PASSWORD 服务器分组 保存配置 1234567891011[server_groups]inner&#x3D;master233 slave158[&#x2F;server_groups] [connections]master233&#x3D;user&#x3D;slave have_user&#x3D;1 pass&#x3D;slave have_pass&#x3D;1 dsn&#x3D;DBI:mysql:;host&#x3D;172.17.10.233;port&#x3D;3306 savepass&#x3D;1slave158&#x3D;user&#x3D;slave have_user&#x3D;1 pass&#x3D;slave have_pass&#x3D;1 dsn&#x3D;DBI:mysql:;host&#x3D;172.17.10.158;port&#x3D;3306 savepass&#x3D;1[&#x2F;connections] 面板 M: 主从情况 T: 事务情况 O: 打开的表 是否在使用，是否被锁住 数据存储碎片化概述碎片分类 三种类型的数据碎片化 行碎片（Row fragmentation） 行间碎片（Intra-row fragmentaion） 剩余空间碎片（Free space fragmentation） 碎片的影响 磁盘上索引页的物理排序不接近页面上记录的索引排序，或者64页块中有许多未使用的页面被分配给索引 占用的空间比“应该”占用的空间多，所有 InnoDB 数据和索引都存储在 B-trees 中，它们的 fill factor 可能在50％到100％之间变化。 表扫描需要比“应该”花费更多的时间。 碎片查看 (1)碎片大小=数据总大小-实际表空间文件大小 (2)数据总大小=data_length+index_length=15220736 (3)实际表空间文件大小=rowsavg_rog_length=29933550=14966750 (4)碎片大小=（15220736-14966750)/1024/1024=0.2M 123456789101112131415161718192021show table status from mall like &#x27;stockshiftflow&#x27; \\\\G;show table status from mall like &#x27;stockoperlog&#x27; \\\\G;-- 查询空闲空间超过 50M 大小的表SELECT CONCAT(table_schema, &#x27;.&#x27;, table_name) AS TABLE_NAME ,engine AS TABLE_ENGINE ,table_type AS TABLE_TYPE ,table_rows AS TABLE_ROWS ,CONCAT(ROUND(data_length / ( 1024 * 1024), 2), &#x27;M&#x27;) AS TB_DATA_SIZE ,CONCAT(ROUND(index_length / ( 1024 * 1024), 2), &#x27;M&#x27;) AS TB_IDX_SIZE ,CONCAT(ROUND((data_length + index_length ) / ( 1024 * 1024 ), 2), &#x27;M&#x27;) AS TOTAL_SIZE ,CASE WHEN data_length =0 THEN 0 ELSE ROUND(index_length / data_length, 2) END AS TB_INDX_RATE ,CONCAT(ROUND( data_free / 1024 / 1024,2), &#x27;MB&#x27;) AS TB_DATA_FREE ,CASE WHEN (data_length + index_length) = 0 THEN 0 ELSE ROUND(data_free/(data_length + index_length),2) END AS TB_FRAG_RATEFROM information_schema.TABLES WHERE ROUND(DATA_FREE/1024/1024,2) &gt;=50ORDER BY data_free DESClimit 0, 20; 碎片整理optimize table table_name OPTIMIZE 操作会暂时锁住表,而且数据量越大,耗费的时间也越长。 OPTIMIZE TABLE 后，表的变化跟存储引擎有关。 对于 INNODB 表,OPTIMIZE TABLE 映射到 ALTER TABLE … FORCE（或者这样翻译：在 InnoDB 表中等价 ALTER TABLE … FORCE），它重建表以更新索引统计信息并释放聚簇索引中未使用的空间。当您在InnoDB表上运行时，它会显示在 OPTIMIZE TABLE 的输出中 对于 innodb_file_per_table=1 的 InnoDB 表，OPTIMIZE TABLE 会重组表和索引的物理存储，将空闲空间释放给操作系统。也就是说 OPTIMIZE TABLE [tablename] 这种方式只适用于独立表空间 ALTER TABLE table_name ENGINE = Innodb 实际上重新整理碎片了.当执行优化操作时,实际执行的是一个空的 ALTER 命令,但是这个命令也会起到优化的作用,它会重建整个表,删掉未使用的空白空间。 ALTER TABLE ENGINE= INNODB,会重新整理在聚簇索引上的数据和索引。 在有些情况下，ALTER TABLE xxxx ENGINE= INNODB 更好。例如old_alter_table 系统变量没有启用等等。另外对于 MyISAM 类型表，使用 ALTER TABLE xxxx ENGINE= INNODB 是明显要优于 OPTIMIZE TABLE 这种方法的。 1ALTER TABLE stockshiftflow ENGINE = Innodb; pt-online-schema-change 12345678910pt-online-schema-change \\\\ --user=$&#123;user&#125; \\\\ --password=$&#123;passwd&#125; \\\\ --host=$&#123;host&#125; \\\\ P=3306,D=$&#123;database&#125;,t=$table \\\\ --charset=utf8 \\\\ --alter=&quot;ENGINE=InnoDB&quot; \\\\ --nocheck-replication-filters \\\\ --alter-foreign-keys-method=auto \\\\ --execute 执行脚本文件名 clean_pieces.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/bin/bash##********************************************************************#$1 : 清理碎片的数据库名称#$2 : 清理碎片的表名称#Description: 清理 MySQL 表的碎片#args=($*)database=$&#123;args[0]&#125;tables=( $&#123;args[@]:1&#125; )echo &quot;database: $database&quot;for table in &quot;$&#123;tables[@]&#125;&quot;;do echo &quot;table: $table&quot;donehost=&#x27;127.0.0.1&#x27;user=&#x27;root&#x27;passwd=$MYSQL_ROOT_PASSWORDfor table in &quot;$&#123;tables[@]&#125;&quot;dosql=&quot;select CONCAT(table_schema, &#x27;.&#x27;, table_name) AS TABLE_NAME, concat(round(sum((DATA_LENGTH+Index_length)/1024/1024),2),&#x27;MB&#x27;) AS TABLE_SIZE, concat(round(sum(DATA_LENGTH/1024/1024),2),&#x27;MB&#x27;) AS DATA_SIZE, concat(round(sum(Index_length/1024/1024),2),&#x27;MB&#x27;) AS INDEX_SIZE, table_rows AS TABLE_ROWS, CASE WHEN data_length =0 THEN 0 ELSE ROUND(index_length / data_length, 2) END AS TB_INDX_RATEfrom TABLES where table_schema=&#x27;$database&#x27; and table_name=&#x27;$table&#x27;&quot;echo &quot;--------------------&quot;echo &quot;--------------- $(date +%s) Database: $database, Table: $table, Begin clean ... --------------- &quot;mysql -u$user -p$passwd -P3306 -h$host information_schema -e &quot;$sql&quot;time pt-online-schema-change \\\\ --user=$&#123;user&#125; \\\\ --password=$&#123;passwd&#125; \\\\ --host=$&#123;host&#125; \\\\ P=3306,D=$&#123;database&#125;,t=$table \\\\ --charset=utf8 \\\\ --alter=&quot;ENGINE=InnoDB&quot; \\\\ --nocheck-replication-filters \\\\ --alter-foreign-keys-method=auto \\\\ --executemysql -u$user -p$passwd -P3306 -h$host information_schema -e &quot;$sql&quot;done 执行 CASE 12# 清理 mall 数据库中表 interfacelog stockoperatelog stockshiftflow 的碎片bash clean_pieces.sh mall interfacelog stockoperatelog stockshiftflow MySQL 配置服务器参数基本参数 123auto-increment-increment &#x3D; 2 auto-increment-offset &#x3D; 2 slave-skip-errors &#x3D; all InnoDb基本参数 状态变量 基本配置 innodb_buffer_pool_size 缓冲池并不仅仅缓存素引：它还会缓存行的数据、自适应哈希索引、插入缓冲（Insert Buffer）、锁，以及其他内部数据结构。 来帮助延迟写入，可合并多个写入操作 innodb_log_file_size max_connections 最大连接数，阿里云的 MySQL5.8, 8C16G 默认为 4000 Innodb 参数 innodb_file_per_table 每张表都是一个独立表空间，对应每张表都是一个 idb 文件。 配置成独立表空间后可以对表进行数据、索引碎片整理。 Innodb_flush_log_at_trx_commit 事务刷写磁盘日志的策略 0: 数据不安全，适合配置 slave 机器 1: 默认值，最安全的设置，每次事务后日志都会刷新到磁盘。 2: 每秒刷新一次事务，有丢失的风险，对于 master 有时可以接受; MySQL 进挂掉，不会丢任何事务，整个服务器挂了或断点，可能会丢失一些事务 缓冲区大小 Innodb read io threads innodb write io threads 以上两个参数決定了 Innodb 读写的 I0 进程数，默认为 4 Innodb stats on metadata 决定了 MYSQL 在什么情況下会刷新 innodb 表的统计信息。 配置的内容： 个数 - 字节 - 开启与关闭 - 百分比 table_cache: 表可被缓存的数量 key_buffer_size: 以字节为单位 max_heap_table_size: 指定隐式内存临时表最大允许的大小 table_cache_size: 结果值比缓存中的表数小，MYSQL 将从缓存中删除不常使用的表 thread_cache_size: query_cache_size: sort_buffer_size: innodb_buffer_pool_pages_dirty: 状态变量，缓冲池中的脏页数量 innodb_buffer_pool_instances: 5.5+ 新增 open_files_limit: 设置的较少，可能出现 too many open files 参数动态配置 12345set sort_buffer_size = &lt;value&gt;set GLOBAL sort_buffer_size = &lt;value&gt;SET @@sort_buffer_size := &lt;value&gt;SET @@session.sort_buffer_size := &lt;value&gt;@@global.sort_buffer_size := &lt;value&gt; 控制 Innodb 并发 innodb_thread_concurrency: 并发设置，默认为 0，表示不限制 建议并发值 = CPU 数量 * 磁盘数量 * 2 innodb_thread_sleep_delay: 微秒为单位, 在进入内核线程超过运行的数量后，第一次休眠的时间，之后重试，若不能进入，则放入到等待队列，由 OS 处理 innodb_concurrency_tickets: 较少小改 innodb commit concurrency: 変量控制有多少个线程可以在同时间提交 排序 max_length_for_sort_data： 影响使用哪种排序算法 max_connect_errors: 网络、配置、权限等问题导致大连个链接重试，记录黑名单设置的大，有效地禁用主机黑名单 read_only： 建议备库设置成只读模式 slave_net_timeout： 默 1h，可缩短到 1min I/O 配置 innodb_log_file_in_group 主从配置 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断 1062: 一些主键重复 1032: 主从数据库数据不一致 1slave_skip_errors&#x3D;1062 忽略指定的数据库同步 1binlog-ignore-db&#x3D;mysql sync_binlog 控制何时 binlog 刷新到磁盘上 0: 由 OS 进行控制 1: 每次事务提交的时候写入，最为安全，但影响性能 连接参数Connection createDatabaseIfNotExist： 默认为 false rollbackOnPooledClose: 默认为 true, 在 Driver 因为问题回滚.. useAffectedRows: 默认为 false Session characterEncoding=utf8: 设置 session 对应的编码格式，告知 server 返回的结果编码格式，默认为 “autodetect”。 useUnicode=true： 使用 Unicode serverTimezone=Asia/Shanghai： 设置时区 Networking connectTimeout： 默认为 0，连接超时, 单位 ms socketTimeout: 默认为 0，单位 ms. 网络 socket 操作的超时时间 maxAllowedPacket： 默认为 65535，最大允许发送的网络包 Packet 大小 useCompression： 默认为 false，使用 zlib 压缩，当与服务器通信的时候 Statements cacheDefaultTimezone： 默认为 true，缓存客户端默认时区，MySQL8.0.20 后添加的 queryTimeoutKillsConnection: 默认 false Performance Extensions If ‘cacheCallableStmts’ is enabled, how many callable statements should be cached? Default: 100 metadataCacheSize: 结果元数据缓存的大小，在 cacheResultSetMetaData 设置为 true 时有效，默认 50 prepStmtCacheSize： 多少 prepared statements 被缓存，默认 25 rewriteBatchedStatements=true：默认 false，重写批量的语句，提高批量的操作效率 allowMultiQueries=true： 允许多查询 归档数据库配置可定期对 MySQL 进行数据归档，可考虑使用 Archive 存储引擎，对于归档的数据库可适当减少配置，关闭一些耗时的配置。 配置如下： 使用 4G 的 innodb 缓冲区 更改事务隔离级别为 READ-UNCOMMITTED，一般只是导入导出无事务操作 适当调整 mysqldump 的 max_allowed_packet，方便进行必要数据的恢复 关闭慢查询、binlog 减小相应的 buffer 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697[mysqld]port &#x3D; 3306socket &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sockpid-file &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.piddatadir &#x3D; &#x2F;var&#x2F;lib&#x2F;mysqllog-error &#x3D; &#x2F;var&#x2F;log&#x2F;mysql&#x2F;mysql-error.logtmpdir &#x3D; &#x2F;tmp# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links&#x3D;0# binlog setting#log-bin &#x3D; mysql-bin#binlog_format &#x3D; MIXED # can be mixed, decrease ..#binlog_format &#x3D; ROW # can be mixed, decrease ..#binlog_row_image &#x3D; minimalsync_binlog &#x3D; 1 # default 0 affect performance， # safe to guarantee replicationslave_net_timeout &#x3D; 60 # defacult 3600#expire_logs_days &#x3D; 7#relay_log &#x3D; mysql-relay#server_id &#x3D; &#123;&#123;server_id | default(&#39;555&#39;)&#125;&#125;#log_bin_trust_function_creators &#x3D; 1wait_timeout &#x3D; 57600interactive_timeout &#x3D; 57600max_allowed_packet &#x3D; 512M # or 100Mevent_scheduler &#x3D; 1max_connections &#x3D; 2000# log setting &#123;slow query, not using indexs&#125;#slow_query_log &#x3D; &#123;&#123;slow_query_log | default(&#39;0&#39;)&#125;&#125;#slow_query_log_file &#x3D; mysql-slow.log#long_query_time &#x3D; &#123;&#123;long_query_time | default(&#39;0.20&#39;)&#125;&#125;#log_queries_not_using_indexes &#x3D; &#123;&#123;log_queries_not_using_indexes | default(&#39;0&#39;)&#125;&#125;# charactercharacter-set-server &#x3D; utf8mb4# txtransaction-isolation &#x3D; READ-UNCOMMITTED #REPEATABLE-READ req for ACID, SERIALIZABLE req XA# innodb#innodb_buffer_pool_size &#x3D; 768Minnodb_buffer_pool_size &#x3D; 4G # old 128M, 70%-80% mache meminnodb_log_file_size &#x3D; 32M # old 500M, total 1G, can bigger to 1024M # Note: modify need to move old file to other position,may start fail # 64G_RAM+ &#x3D; 768, 24G_RAM+ &#x3D; 512, 8G_RAM+ &#x3D; 256, 2G_RAM+ &#x3D; 128#innodb_log_files_in_group &#x3D; 2 # defacult 2innodb_log_buffer_size &#x3D; 64M # defalut 8Minnodb_buffer_pool_instances &#x3D; 8 # defaultinnodb_flush_log_at_trx_commit &#x3D; 2 # defalut 1, per second trx flush 2&#x2F;0 &#x3D; perf, 1 &#x3D; ACIDinnodb_file_per_table &#x3D; 1innodb_lock_wait_timeout &#x3D; 60 # timeout 500innodb_status_output &#x3D; ONinnodb_status_output_locks &#x3D; ONinnodb_print_all_deadlocks &#x3D; ONinnodb_read_io_threads &#x3D; 6 # default 4innodb_write_io_threads &#x3D; 6 # default 4#innodb_thread_concurrency &#x3D; 16 # default 0 recommend 2x core quantity#innodb_additional_mem_pool_size &#x3D; 8M #default 8M#innodb_open_files &#x3D; 2000 # default 2000, can open *.idb file count# buffer settingsort_buffer_size &#x3D; 256K # default 0.25Mjoin_buffer_size &#x3D; 256K # default 0.25M, can bigger to 128Mread_buffer_size &#x3D; 512K # default 0.125Mread_rnd_buffer_size &#x3D; 512K # default 0.25M#max_length_for_sort_data &#x3D; 1024 # default 1024#max_connect_errors &#x3D; 100 # defacult 100#innodb_doublewrite &#x3D; 1 # default on#thread_concurrency &#x3D; 12 # default 10 recommend 2x CPU cores#thread_cache_size &#x3D; 28 # defacult 28 recommend 5% of max_connections#open_files_limit &#x3D; 1048576 # default 1048576# MyISAM#key_buffer_size &#x3D; 32M # default 8M#query_cache_size &#x3D; 1M # default 1M# table sizetmp_table_size &#x3D; 128M # default 16Mmax_heap_table_size &#x3D; 128M # default 16M recommend same size as tmp_table_size# concatgroup_concat_max_len &#x3D; 100000000[mysql]default-character-set &#x3D; utf8mb4[client]default-character-set &#x3D; utf8mb4[mysqldump]quickquote-namesmax_allowed_packet &#x3D; 256M 配置案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596[mysqld]port = 3306socket = /var/run/mysqld/mysqld.sockpid-file = /var/run/mysqld/mysqld.piddatadir = /var/lib/mysqllog-error = /var/log/mysql/mysql-error.logtmpdir = /tmp# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# binlog settinglog-bin = mysql-bin#binlog_format = MIXED # can be mixed, decrease ..binlog_format = ROW # can be mixed, decrease ..binlog_row_image = minimal#sync_binlog = 1 # default 0 affect performance， # safe to guarantee replicationslave_net_timeout = 60 # defacult 3600expire_logs_days = 7relay_log = mysql-relayserver_id = 199192log_bin_trust_function_creators = 1wait_timeout = 57600interactive_timeout = 57600max_allowed_packet = 256M # or 100Mevent_scheduler = 1max_connections = 2000# log setting &#123;slow query, not using indexs&#125;slow_query_log = 1slow_query_log_file = mysql-slow.loglong_query_time = 0.20log_queries_not_using_indexes = 1# charactercharacter-set-server = utf8mb4# txtransaction-isolation = REPEATABLE-READ #REPEATABLE-READ req for ACID, SERIALIZABLE req XA# innodbinnodb_buffer_pool_size = 18G # old 128M, 70%-80% mache meminnodb_log_file_size = 500M # old 500M, total 1G, can bigger to 1024M # Note: modify need to move old file to other position,may start fail # 64G_RAM+ = 768, 24G_RAM+ = 512, 8G_RAM+ = 256, 2G_RAM+ = 128#innodb_log_files_in_group = 2 # defacult 2innodb_log_buffer_size = 8M # defalut 8Minnodb_buffer_pool_instances = 8 # defaultinnodb_flush_log_at_trx_commit = 2 # defalut 1, per second trx flush 2/0 = perf, 1 = ACIDinnodb_file_per_table = 1innodb_lock_wait_timeout = 60 # timeout 500innodb_status_output = ONinnodb_status_output_locks = ONinnodb_print_all_deadlocks = ONinnodb_read_io_threads = 6 # default 4innodb_write_io_threads = 6 # default 4#innodb_thread_concurrency = 16 # default 0 recommend 2x core quantity#innodb_additional_mem_pool_size = 8M #default 8M#innodb_open_files = 2000 # default 2000, can open *.idb file count# buffer settingsort_buffer_size = 1M # default 0.25Mjoin_buffer_size = 1M # default 0.25M, can bigger to 128Mread_buffer_size = 1M # default 0.125Mread_rnd_buffer_size = 1M # default 0.25M#max_length_for_sort_data = 1024 # default 1024#max_connect_errors = 100 # defacult 100#innodb_doublewrite = 1 # default on#thread_concurrency = 12 # default 10 recommend 2x CPU cores#thread_cache_size = 28 # defacult 28 recommend 5% of max_connections#open_files_limit = 1048576 # default 1048576# MyISAM#key_buffer_size = 32M # default 8M#query_cache_size = 1M # default 1M# table sizetmp_table_size = 128M # default 16Mmax_heap_table_size = 128M # default 16M recommend same size as tmp_table_size# concatgroup_concat_max_len = 100000000[mysql]default-character-set = utf8mb4[client]default-character-set = utf8mb4[mysqldump]quickquote-namesmax_allowed_packet = 128Mr 其他MySql 大表数据删除Mysql 官网对于大表数据的删除说明 If you are deleting many rows from a large table, you may exceed the lock table size for an InnoDB table. To avoid this problem, or simply to minimize the time that the table remains locked, the following strategy (which does not use DELETE at all) might be helpful: Select the rows not to be deleted into an empty table that has the same structure as the original table: INSERT INTO t_copy SELECT * FROM t WHERE … ; Use RENAME TABLE to atomically move the original table out of the way and rename the copy to the original name: RENAME TABLE t TO t_old, t_copy TO t; Drop the original table: 123456INSERT INTO copy_interfacelog SELECT * FROM mall.servicelog WHERE logtime between &#x27;2020-04-07 02:00:00&#x27; and &#x27;2020-04-14 10:23:24&#x27;;-- 使用 mysqldump, file...备份恢复RENAME TABLE mall.servicelog TO mall.old_servicelog copy_interfacelog TO interfacelog; 通过 INSERT INTO &lt;table-name&gt; SELECT .. 筛选出不需要删除的数据 1234567DELETE FROM `table` WHERE (whatever criteria) ORDER BY `id` LIMIT 1000MYSQL=&quot;mysql -uroot -p$MYSQL_ROOT_PASSWORD &quot;sql=&quot;select uuid from mail.interfacelog where (condition) order by uuid desc limit 1000 &quot;for i in `seq 1 1000`; do $MYSQL -e &quot;$sql&quot; | sed &#x27;s;/|;;g&#x27; | awk &#x27;&#123;if(NR&gt;1)print &quot;delete from table_name where uuid = &quot;,$1,&quot;;&quot; &#125;&#x27; | $MYSQL; done RefDeleting millions of rows in MySQL MySQL :: MySQL 8.0 Reference Manual :: 13.7.3.4 OPTIMIZE TABLE Statement 官网对于 OPTIMIZE TABLE 说明 潇湘隐者 MySQL 数据存储碎片化 Optimized my.cnf configuration for MySQL/MariaSQL (on Ubuntu, CentOS etc. servers) 优化的 mysql 配置 Ten MySQL performance tuning settings after installation percona 网站对于 MySQL 性能调整配置说明 https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-reference-configuration-properties.html 官网对于属性的配置 What’s the difference between cachePrepStmts and useServerPrepStmts in MySQL JDBC Driver https://stackoverflow.com/questions/2993251/jdbc-batch-insert-performance 批量操作参数的更改","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"MySQL-备份与恢复","date":"2021-04-08T17:06:57.000Z","path":"2021/04/09/MySQL-备份与恢复/","text":"备份概述 备份决定了数据库的安全，在主从不一致的情况下删除从库的所有数据，进行数据重新整理。 对于 MyISAM 备份 1FLUSH TABLES WITH READ LOCK; 备份策略逻辑备份： 结果为 sql 文件，方法适用于所有 Engine 物理备份： 数据库目录的拷贝，对于内存表只备份结构 备份的内容： 事务的 innodb 表，不带有事务的(无法保证一致性) 函数(routines)、触发器、视图 包含的表，有时无需对整个数据库所有的表进行备份，只需要备份重要的业务表，用于以后的恢复 排除的表，在做全量备份的时候，排除掉日志表、记录表、备份表等与业务非强相关的表，提高备份的效率 备份的类型： 热备份： 在线备份，不需要任何的服务停机时间，ibbackup 商业工具可实现 冷备份： 备份 .frm, .idb 文件，需要离线备份 温备份： 非离线备份，在线执行，会影响线上的数据库运行 备份的方案: 全量备份 增量备份 压缩备份 加密备份 备份的数据存放到另一块物理磁盘上或是传输到另一台机器上 12345678910SELECT data INTO OUTFILE xxx.txtLOAD data INFILE xxx.txt INTO TABLEselect * from dc_mp_fans into outfile &#x27;/data/fans.txt&#x27;;zip fans.zip /data/fans.txtscp fans.zip root@ip:/data/ unzip /data/fans.zipload data infile &#x27;/data/fans.txt&#x27; into table wxa_fans( id,appid,openid,unionid,created_at); 备份场景 备份业务中重要的业务表 日志表的归档，归档到另一个表中 备份/导出/ETL 到大数据平台 强制恢复处理恢复过程中启动不起来的情况 MySQL 配置参数 innodb_force_recovery 控制 1: (SRV_FORCE_IGNORE_CORRUPT): 忽略检查到的 corrupt 页。 2: (SRV_FORCE_NO_BACKGROUND): 阻止主线程的运行，如主线程需要执行 full purge 操作，会导致 crash。 3: (SRV_FORCE_NO_TRX_UNDO): 不执行事务回滚操作。 4: (SRV_FORCE_NO_IBUF_MERGE): 不执行插入缓冲的合并操作。 5: (SRV_FORCE_NO_UNDO_LOG_SCAN): 不查看重做日志，InnoDB 存储引擎会将未提交的事务视为已提交。 6: (SRV_FORCE_NO_LOG_REDO): 不执行前滚的操作。 当 innodb_purge_threads 和 innodb_force_recovery 一起设置会出现一种loop 现象 12innodb_force_recovery&#x3D;6innodb_purge_thread&#x3D;0 当设置参数值大于0后，可以对表进行 select,create,drop 操作,但 insert,update 或者 delete 这类操作是不允许的 MySQL crash 或者 MySQL 数据库服务器 crash 会导致各种各样的问题 ，比如主备之间的 error 1594 (5.6 版本开启crash-safe ，会最大程度上避免 error 1594的问题)，error 1236， 日志损坏，数据文件损坏等。 物理文件离线备份离线方式的备份，需要停止整个服务 存在复制过程中的文件损坏，对应表空间没法使用，数据库服务一直尝试重启 注意数据库的 .frm, .idb 的权限 660；目录为 700；目录的属主为 mysql:mysql 基于日志点的恢复增量恢复 备份二进制日志，使用 FLUSH LOGS 开始一个新的二进制日志 https://dba.stackexchange.com/questions/60722/how-to-recover-truncate-table-in-mysql mysqlbinlog： --start-position: 开始位置 --stop-position: 停止位置 1234567891011mysqlbinlog -v mysqlbin.000002 | grep -B5 TRUNCATE --colormysqlbinlog \\\\ --start-position=1603 \\\\ --stop-position=919664 \\\\ mysqlbin.000002 &gt; /mysqlbackup/binlog_`date +%y%m%d%H`.sqlshow binary logs;show master logs;SHOW BINLOG EVENTS;show binlog events in &quot;mysql-bin.000005&quot;;mysqlbinlog binlog.[0-9]* | mysql -u root -p 导入导出可直接使用 DBver, Navicate, DataGrip 等图形化连接客户端进行各种格式的导出，包含 INSERT 语句、UPDATE 语句、HTML 表格、CSV(TSV)、JSON、格式化的text文本、Markdown 的表格等。 SELECT … INTO OUTFILE 需要登录的 mysql 账号具有 FILE 权限 123select * from entitylog into outfile &#x27;/var/lib/mysql/backup/entitylog.txt&#x27;;-- 指定分割符合换行符， 导出为 CSV 格式select * from entitylog into outfile &#x27;/var/lib/mysql/backup/entitylog.txt&#x27; fields terminated by &#x27;,&#x27; enclosed by &#x27;&quot;&#x27; lines terminated by &#x27;\\\\r\\\\n&#x27;; mysql 命令导出 12-- 导出为 CSV 格式mysql -uroot -p -e &quot;select * from entitylog&quot; --skip-column-names test|sed -e &quot;s/[\\\\t]/,/&quot; -e &quot;s/$/\\\\r/&quot; &gt; entity.txt mysqldump MySQL 自带的备份工具，可以对数据库进行全备份和部分备份,不支持增量备份。 使用场景： 10G 以下的数据库操作简单 缺点： 数据量范围：30G –&gt; TB级别 的时候备份、恢复操作很慢，效率低 基本配置： -h / -P / -u / -p: 基本连接参数 --single-transaction: 保证导出的数据一致性，保证备份 InnoDB 的一致性逻辑备份，和 –lock-tables 选项是互斥的 -l / --lock-tables:一般用于 MyIsam 备份，与上面的互斥 x, --lock-all-tables: 数据库 -master-data: [1/2] 备份内容配置: --all-databases: 备份全部的 DB --databases &lt;db1&gt; &lt;db2&gt;: 备份指定的多个数据库 --tables a1 a2: 备份指定的多个 Table -w, --where=&quot;&quot;: 备份表中筛选后的数据 -R, --routines: 备份 procedures, functions --triggers: 备份触发器 -e, --events: --no-data: 只导出表结构，不导出数据 控制输出内容配置： --skip-add-drop-table: 取消每个数据表创建之前添加 drop 数据表语句(默认每个表之前存在drop语句)，对于部分恢复的情况下需要注意。 --skip-add-locks: 跳过锁表语句 --no-create-info： 导出的 SQL 中不包含 create table 语句 --set-gtid-purged： 跳过导 GTID --add-drop-database: 增加删除数据库 sql（默认不会） -opt： 等同于 --add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, --disable-keys，默认开启 -c, --complete-insert: 生成的 Insert 语句中带有字段名称, insert into T(col1,col2..) values(…) 其他配置 –-lock-all-tables: 锁住所有的表，表变为只读的 –master-data=: 将当前服务器的binlog的位置和文件名追加到输出文件，不会停止当前服务器的主从服务 -F: 生成新的 binlog 文件 -C： 启用压缩传递 --dump-slave 全量备份1234mysqldump --all-databases \\\\ --master-data \\\\ --single-transaction \\\\ &gt; backup_$(date +%y%m%d).sql 多服务器数据传输1234mysqldump --host=h1 -uroot -proot --databases db1 | mysql --host=h2 -uroot -proot db2# 压缩传输mysqldump --host=192.168.80.137 -uroot -proot -C --databases test | mysql --host=192.168.80.133 -uroot -proot test 压缩备份线上环境导入导出使用 123456789# 压缩备份mysqldump -P3306 \\\\ -uroot -p \\\\ -q -Q --set-gtid-purged=OFF \\\\ --default-character-set=utf8 \\\\ --hex-blob --skip-lock-tables \\\\ --databases abc 2&gt;/abc.err |gzip &gt;/abc.sql.gz# 还原gunzip -c abc.sql.gz | mysql -uroot -p -vvv -P3306 --default-character-set=utf8 abc 1&gt; abc.log 2&gt;abc.err 按条件备份备份指定数据库 123456789mysqldump \\\\ -hlocalhost -P3306 \\\\ -uroot -p$MYSQL_ROOT_PASSWORD \\\\ --add-drop-table \\\\ --master-data=2 \\\\ --single-transaction \\\\ --routines --triggers --events \\\\ --databases account basic report \\\\ &gt; backup_$(date +%y%m%d).sql 备份满足特定条件的表 12345678910111213# 备份指定时间的日志数据mysqldump -uroot -p$MYSQL_ROOT_PASSWORD \\\\ --databases basic \\\\ --tables interfacelog \\\\ --where=&quot;logtime &lt; &#x27;2020-05-01 00:00:00&#x27; and logtime &gt; &#x27;2020-04-08 00:00:00&#x27;&quot; \\\\ &gt; backup-interfacelog-`date +%y%m%d` # 从重命名的表中备份数据mysqldump -uroot -proot \\\\ --databases basic \\\\ --tables old_interfacelog \\\\ --where=&quot;logtime between &#x27;2020-04-13 00:00:00&#x27; and &#x27;2020-04-14 00:00:00&#x27;&quot; \\\\ &gt; backup-interfacelog-`date +%y%m%d` 备份表并在 insert 语句中插入字段 使用场景： 备份数据，并恢复到变更表结构的该表 归档表重命名原始表名，对应 INSERT INTO 与生产库的表名一致 对于表结构变更的，需要 Insert 增加字段名 用于从归档到生产库的，需要去除逻辑备份前面的 Drop 语句 1234567891011121314151617181920212223# 测试输出的结果db=accounttable=entitylogtime mysqldump -uroot -p$MYSQL_ROOT_PASSWORD \\\\ --databases $db \\\\ --tables $table \\\\ --complete-insert \\\\ --skip-add-locks \\\\ --no-create-info \\\\ --skip-add-drop-table \\\\ --where=&quot;1=1 limit 0,1&quot; \\\\ &gt; test.sqldb=facilitytable=&quot;stockoperlog &quot;time mysqldump -uroot -p$MYSQL_ROOT_PASSWORD \\\\ --databases $db \\\\ --complete-insert \\\\ --tables $table \\\\ --no-create-info \\\\ --skip-add-locks \\\\ --skip-add-drop-table \\\\ --where=&quot;logtime &gt; &#x27;2021-01-01 00:00:00&#x27;&quot; \\\\ &gt; stockoperlog_210101_`date +%y%m%d`.sql 备份表结构1234mysqldump -uroot -proot \\\\ --no-data \\\\ --databases account \\\\ &gt; /tmp/account_schema.sql 备份恢复专门创建一个备份数据库，查询出必要的数据，之后插入到实际使用的表 使用 table 进行恢复，只对需要的进行恢复 进行时间点的恢复 前提： 一个时间点的全备 对应的 binlog 123456# 将 SQL 恢复到指定的数据库mysql -uroot -proot \\\\ basic &lt; backup_200604_basic.sqlmysql -uroot -proot \\\\ account &lt; backup_200604_account.sql xtrabackup 可对数据库进行全备和增量备份，使用 binlog 对数据库进行时间点的… 支持在线的物理备份 配置 在 my.cnf 中指定 12[xtrabackup]target_dir &#x3D; &#x2F;data&#x2F;backups&#x2F;mysql&#x2F; 基础参数 --print-defaults: 打印程序参数和列表并退出 --target-dir=&lt;path&gt;: 备份到的目标文件夹 --backup: take backup to target-dir --prepare: 准备备份以在备份上启动 mysql 服务器。 --export: --print-param: --rate-limit: 限制备份脚本的吞吐量 备份过滤的参数： --tables=name / : 根据正则表达式过滤表名，过滤列表根据 --tables-file=name: 根据文件中的 database.table 进行过滤 --databases=name: 根据数据库列表过滤 --tables-exclude=name: 排除指定的表, 与 --tables 相反，优先级比 --tables 高 --databases-exclude=name: 排除指定的数据库 压缩备份参数 --compress[=name]: 是否进行压缩备份 --compress： 进行压缩备份 --compress-threads=N: 指定压缩的线程数 --decompress: 解压缩恢复备份数据 增量备份参数 --incremental-basedir=&lt;path&gt;： 增量备份基于的全量备份文件夹 数据库恢复参数 --copy-back: 复制之前所有的文件 其他参数 --slave-info: 主从复制备份有效 --safe-slave-backup: –-binlog-info[=name] 全量备份123456789MYSQL_BACKUP_DIR=/var/log/mysql/backups/$dir_name/Full_$(date +%Y.%m.%d_%H.%M.%S)mkdir -p $MYSQL_BACKUP_DIRxtrabackup --backup \\\\ --target-dir=$MYSQL_BACKUP_DIR \\\\ -uroot -proot xtrabackup --prepare \\\\ --target-dir=$MYSQL_BACKUP_DIR \\\\ -uroot -proot 有条件的全量备份xtrabackup 当前只能指定到表级别，没法对表的数据进行筛选 若需要对表的内容进行筛选，可考虑使用 mysqldump 进行逻辑备份，配合 xtrbackup 的物理备份实现 排除指定表进行备份 可根据实际需要列出需要排除的大表，拼接成正则或是到文件中进行过滤； 可通过 (.*log.*|.*record.*|.*bak.*|.*\\\\d+.*) 正则表达式进行排除不相关的表； 1234567891011121314151617181920212223242526272829# 1. define back infoMYSQL_BACKUP_DIR=/var/lib/mysql/backupback_up_dir=$MYSQL_BACKUP_DIR/Full_$(date +%Y.%m.%d_%H.%M.%S)# 1.2 compare back info# Filter pattern: (.*log.*|.*record.*|.*bak.*|.*\\\\d+.*)mkdir -p $back_up_dirtable_exclude_names=( &quot;account.entitylog&quot; &quot;account.mqlog&quot; &quot;basic.interfacelog&quot; &quot;basic.article_bak&quot;)function join() &#123; local IFS=&quot;$1&quot; shift echo &quot;$*&quot;&#125;join_str=$(join \\\\| &quot;$&#123;table_exclude_names[@]&#125;&quot;)exclude_table=&quot;($join_str)&quot;echo &quot;exclude_table: $exclude_table&quot;# 2. 非压缩备份time xtrabackup --backup \\\\ --host=127.0.0.1 \\\\ -uroot -proot \\\\ --tables-exclude=&quot;$exclude_table&quot; \\\\ --datadir=/var/lib/mysql/ \\\\ --target-dir=$back_up_dir 备份指定的表 单独备份表的话需要表在独立的表空间，对应 innodb_file_per_table=1 压缩备份需要使用 qpress 工具 1234567891011121314151617# 安装 qpresspercona-release enable toolsapt-get updateapt-get install qpressMYSQL_BACKUP_DIR=/var/log/mysql/backups/$dir_name/Full_$(date +%Y.%m.%d_%H.%M.%S)mkdir -p $MYSQL_BACKUP_DIR xtrabackup --backup \\\\ --compress \\\\ --compress-threads=4 \\\\ --target-dir=$MYSQL_BACKUP_DIR # 解压缩xtrabackup --decompress \\\\ --target-dir=/data/compressed/xtrabackup --copy-back \\\\ --target-dir=/data/backups/ 数据恢复 数据目录在恢复前必须为空 在执行恢复前，MySQL 服务需要关闭 12xtrabackup --copy-back \\\\ --target-dir=$MYSQL_BACKUP_DIR 增量备份增量并压缩备份 12345678datadir=/var/lib/mysql/backupxtrabackup --user=root \\\\ --password=root \\\\ --backup \\\\ --compress \\\\ --compress-threads=4 \\\\ --target-dir=$&#123;datadir&#125;/inc$&#123;today&#125; \\\\ --incremental-basedir=/var/lib/mysql/backup/Full_2020.08.23 比较偏移的点 123456789101112131415cat xtrabackup_checkpointsbackup_type = full-backupedfrom_lsn = 0to_lsn = 10820498082last_lsn = 10820498082compact = 0recover_binlog_info = 0flushed_lsn = 10820475795backup_type = incrementalfrom_lsn = 10820498082to_lsn = 10820575291last_lsn = 10820575291compact = 0recover_binlog_info = 0flushed_lsn = 10820572909 数据库恢复准备 可以在任何机器上运行 prepare 命令，无需在原始服务器上, 可复制备份到指定机器上进行恢复 准备步骤使用此嵌入式 InnoDB 对复制的数据文件执行崩溃恢复 1xtrabackup --prepare --target-dir=/data/backups/ 复制与授权复制备份文件 方式一: 使用 xtraback 提供的功能 1xtrabackup --copy-back --target-dir=/data/backups/ 方式二: 使用 rsync 或 cp 复制备份文件到指定目录 12rsync -avrP /data/backup/ /var/lib/mysql/# 2 cp 授权 1chown -R mysql:mysql /var/lib/mysql 其他对于数据量大的情况，可以考虑将大表的数据通过 ETL 工具导出到大数据平台进行存储，业务系统中只保留最近 1年的数据。 RefMySQL mysqldump数据导出详解 MySql数据库备份与恢复–使用mysqldump 导入与导出方法总结_helloxiaozhe的博客-CSDN博客_mysqldump备份数据库 MySql数据库备份与恢复——使用mysqldump 导入与导出方法总结 Percona XtraBackup - Documentation Percona XtraBackup 2.4 官方文档 Partial Backups Percona 官网部分备份说明文档 使用innobackupex对数据库进行部分备份(指定表或数据库) 使用innobackupex对数据库进行部分备份(指定表或数据库) MySQL 导出数据 MySQL 导出数据","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"Mysql-日志","date":"2021-04-08T17:06:49.000Z","path":"2021/04/09/Mysql-日志/","text":"慢查询日志 MySQL 的动态参数，可以随关随停 慢查询优化优化策略： 调优 TOP10, 之后迭代… 业务扩展，用户流量增加，进一步调优 慢查询日志的性能剖析工具：汇总一些信息，自动排序 查看慢日志： 正常的格式 explain EXPLAIN 关键字模拟优化器执行 SQL 查询语句 12345explain select star, evaluator_no from indicator_evaluate order by evaluator_no desc; id: 代表执行的顺序 type: 找到数据行的方式, 数据的访问类型，取值为如下 all: 全表扫描 index: ALL 和 INDEX 都读全表，INDEX 从索引读， ALL 从硬盘读 range： between, in, &gt;, &lt; 等的查询，无需扫全表 ref：非唯一性索引扫描，返回匹配.. eq_ref: 唯一性索引扫描，对于每一个索引键，表中只有一条记录与之匹配。常见于主键或者唯一索引扫描。 const: 表示通过索引一次就找到了，const 用于比较为 primary key(主键索引)或者是 unique 索引，因为只匹配一行，所以很快，若将主键作为 where 条件，MySQL 就会把该查询作为一个常量 system ：表中只有一条记录(等同于系统表) 这是 const 特例，平时不会出现。 1234# 最好达到 ref OR range 级别system&gt;const&gt;eq_ref&gt;ref&gt;range&gt;index&gt;all extra： Using where, Using index， Using filesort 最重要的 extra 的取值是前三个 filesort、 using temporary(性能差的sql语句) 、use index(性能好的 sql语句)； 是查询优化器进行选择索引的一个参数，及排序的规则；extra 中出现下面两项意味着 MySQL 不能使用索引，效率会有很大的影响，需尽早优化 Using filesort: 外部索引排序，不是从表中按索引次序读取相关内容，可能在内存或磁盘上排序，MySQL 无法利用索引完成的排序。 Using temporary: 使用临时表，在 order by 和 group by 中常见 select_type: 查询的类型 有以下六种取值 simplye: 表示简单查询 ，不包含子查询以及 union primary: 若查询中包含了任何的子查询，最外层的主查询标识为 primary subquery: 标识为子查询 derived: 派生的，在 from 子查询的结果会被放入为衍生虚表(临时表) union: 若第二个 select 出现在 union 之后，则会标记为 union(若 union 包含在 from 子句的子查询中，外层的的 select 标识为 derived) union result：从 union 表中获取数据的 select 标识 key:实际上使用的索引,为 null 表示为索引失效 possiable_keys: 理论上可能使用到的索引，若在查询的时候使用了覆盖索引，那么该索引就不会出现在 possible_keys 中，而只会出现在 key 列中。 key_len：表示索引在使用的字节数，可以通过该列计算查询中使用的索引的长度，长度越小越好 key_len 显示的值为索引字段的最大可能长度，而非使用长度，及key_len 是根据表定义计算而得，不是通过表内检索出来的。 ref: 表示索引的哪一列被使用，如果可能的话是一个常数，哪些列或者常量被用于索引列上的查找。 rows: 根据表信息统计，估算出大约要扫描的行数。 优化： &amp;手动优化 ① 修改SQL: 在业务允许的情况下使得语句走对应的索引； 1EXPLAIN SELECT evaluator_no, course_id from evaluator; ② 添加索引：对于无法通过修改 SQL 满足业务的情况下，而此 SQL 又进行多次的查询，对其进行添加索引处理 1alter table &lt;table&gt; add index idx_name(&lt;col&gt;); &amp;查询优化器优化 不使用密集索引，稀疏索引为二级索引不存放对应的全行信息； 查询的不需要整体信息； 记住抽样统计，同时查询是否排序、是否使用临时表进行索引的选择； 123EXPLAIN SELECT COUNT( id ) FROM person_info_large;-- 测试使用什么索引所以更好&lt;sql&gt; FORCE INDEX(&lt;index&gt;); mysqldumpslow mysql 自带的工具，较为简单 按序显示执行的 SQL 情况 1mysqldumpslow --verbose slow-query.log -c: 总次数 -t: 时间 l: 锁的时间 r: 总数据行 at,al,ar: 平均数 按照时间排序的前10个查询 1234mysqldumpslow -s t -t 10 slow-query.logmysqldumpslow -s c -t 10 slow-query.logmysqldumpslow -s l -t 10 slow-query.logmysqldumpslow -s r -t 10 slow-query.log pt-query-digest percona toolkit 中提供 功能增强的慢查询分析工具，具体使用见 这里 123pt-query-digest \\\\ --type slowlog \\\\ slow-query.log 根据 STDIN 进行分析 1pt-query-digest --query &quot;select * from mysql.user&quot; 配置配置项： slow_query_log=1： 开启慢查询； long_query_time=0.2： 设置慢查询的时间阈值，设置为 200 毫秒； slow_query_log_file：设置慢查询日志文件目录； log_queries_not_using_indexes=1： 显示没有使用索引的 SQL 语句； 1234SHOW VARIABLES LIKE &#x27;%quer%&#x27;; --慢查询日志开启、位置、时长，查询缓冲、SHOW STATUS LIKE &#x27;%slow_queries%&#x27;; -- 当前慢查询数-- Set slow querySET GLOBAL slow_query_log=on;SET GLOBAL long_query_time=1; -- 当前会话有效, 修改 my.ini 永久 Binlog概述 逻辑日志。为归档日志；记录了完整的逻辑记录；属于 Server 层的日志，可作用于任何存储引擎； 包含了一些事件，这些事件描述了数据库的改动，如建表、数据改动等，主要用于备份恢复、回滚操作等。 binlog 有三种格式：Statement, Row 和 Mixed. Statement: 基于 SQL 语句的复制（statement-based replication, SBR） ： 对一些函数如 now() 在不同主机上执行结果不同会出现不一致的问题 Row: 基于行的复制（row-based replication, RBR): 不会出现某些特定情况下的存储过程，或 function，以及 trigger 的调用和触发无法被正确复制的问题。 基于 Row 的，数据恢复更快 Mixed: 混合模式复制（mixed-based replication, MBR），混合 statement 和物理文件，减少 binlog 的大小 生成新的 binlog 1flush logs 生成新的 binlog 的时机 MySQL 服务器停止或重启时执行； 使用 flush logs 命令； 当 binlog 文件大小超过 max_binlog_size 系统变量配置的上限时； 查看相关 查看 binblog 12show binary logs;show master logs;; 查看 binlog 文件的内容 1show binlog events in &quot;mysql-bin.000005&quot;; 两阶段提交为了保证 binlog 和 redo log 的一致性使用，如果不使⽤“两阶段提交”，那么数据库的状态就有可能和⽤它的⽇志恢复出来的库的状态不⼀致； 分为 prepare 和 commit 两个阶段； 对于 prepare 状态的事务，参考 binlog，若该事务在 binlog 中存在，则将其提交，不存在，则将其回滚，这样保证主从之间的一致性。 不只是误操作后需要⽤这个过程来恢复数据。当需要扩容的时候，也就是多搭建⼀些备库来增加系统的读能⼒的时候，常⻅的做法是⽤全量备份加上应⽤ binlog 来实现的，这个“不⼀致”就会导致你的线上出现主从数据库不⼀致的情况。 简单说，redo log 和 binlog 都可以⽤于表示事务的提交状态，⽽两阶段提交就是让这两个状态保持逻辑上的⼀致。 用途数据库恢复 借助 binlog 配合一次全量备份实现指定时间点数据的恢复 一些参数 --start-position: 开始位置 --stop-porition: 结束位置 --start-datetime: 开始时间 --stop-datetime: 结束时间 --database: 指定数据库 -no-defaults: 处理默认字符集问题 123456mysqlbinlog mysql-bin.000001 | mysql -uroot -prootmysqlbinlog mysql-bin.000002 | mysql -uroot -proot.....mysqlbinlog \\\\ --start-datetime=&quot;2005-12-25 11:25:56&quot;\\\\ binlog.000003 多个 binlog 的恢复 1mysqlbinlog binlog.[0-9]* | mysql -u root -p 更改一内容再恢复 123456mysqlbinlog binlog.000001 &gt; tmpfile... edit tmpfile ...mysql -u root -p &lt; tmpfilemysqlbinlog --no-defaults \\\\ -v --base64-output=DECODE-ROWS \\\\ mysql-bin.000009 指定位置进行重新执行 123mysqlbinlog --start-position=27284 \\\\ binlog.001002 binlog.001003 binlog.001004 | mysql --host=host_name -u root -p 与 redo log 比较binlog 与 redo log 日志的区别： redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使⽤。 redo log 是物理⽇志，记录的是“在某个数据⻚上做了什么修改”；binlog是逻辑⽇志，记录的是这个语句的原始逻辑，⽐如“给ID=2这⼀⾏的c字段加1”。 redo log 空间固定会⽤完；binlog是可以追加写⼊的。“追加写”是指binlog ⽂件写到⼀定⼤⼩后会切换到下⼀个，并不会覆盖以前的⽇志。 日志比较 实时监控 binlog适用场景： 通过实时对 binlog 进行监控分析，将 binlog 中的数据按照业务进行分开，控制拆分的逻辑 通过实时监控 binlog，根据事件的类型，删除或更改基于数据库的倒排索引，以此来保证索引的有效性 通过实时对 binlog 进行读取，将数据写入到 Kafka 中，交由流式处理工具(如Flink) 做实时的分析 实现方案： 通过第三方库操作(阿里的 canal)，因为 mysql 支持通过远程方式下载指定 mysql-server 上的 binlog，从而能够实现借助端口对 MySQL 进行运行情况监控和更改信息的获取。 binlog 清理12345678910111213-- 删除指定日期以前的日志索引中 binlog 日志文件purge master logs before &#x27;2016-09-01 17:20:00&#x27;; -- 删除指定日志文件的日志索引中binlog日志文件-- 将 bin.000022 之前的binlog清掉purge master logs to &#x27;mysql-bin.000022&#x27;; -- 清除master.info文件、relay-log.info文件，以及所有的relay log文件,并重新启用一个新的relaylog文件-- 使用reset slave之前必须使用stop slave 命令将复制进程停止reset slave-- 将删除日志索引文件中记录的所有binlog文件，创建一个新的日志文件，起始值从000001开始。不要轻易使用该命令，这个命令通常仅仅用于第一次用于搭建主从关系的时的主库reset master: 配置配置项 log-bin：指定 binlog 的文件名 innodb_flush_log_at_trx_commit： expire_logs_days：保留 binlog 的天数 max_binlog_size： binlog 单个文件的大小，默认 1G，一个事务所产生的所有事件必须记录在同一个 binlog 文件中，所以即使 binlog 文件的大小达到 max_binlog_size 参数指定的大小，也会写入到 binlog 后才能切换。 配置更改 1234567[mysqld] log-bin &#x3D; mysql-binbinlog_format &#x3D; ROW # can be mixed, decreasebinlog_row_image &#x3D; minimalexpire_logs_days &#x3D; 30sync_binlog &#x3D; 1 # default 0 affect performance， safe to guarantee replicationinnodb_flush_log_at_trx_commit &#x3D; 2 # defalut 1, per second trx flush 2&#x2F;0 &#x3D; perf, 1 &#x3D; ACID 会话级别更改 123# modifySET SQL_LOG_BIN&#x3D;0 SET GLOBAL expire_log_days&#x3D;3; redolog (物理) 为物理日志。重做日志。InnoDB 在处理更新语句的时候，只做了写⽇志这⼀个磁盘操作。这个⽇志叫作 redo log，在更新内存写完 redo log 后，就返回给客户端，本次更新成功。 作用： 确保事务的持久性 防止在发生故障的时间点，尚有脏页未写入磁盘，在重启 MySQL 服务的时候，根据 redo log 进行重做，从而达到事务的持久性这一特性 只有 InnoDB 有，其他引擎没有； redolog 确保事务的持久性。 由来： 如果每⼀次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很⾼。 包含两部分，一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。 WAL**WAL(Write-Ahead Logging)**： 预写日志。先写⽇志，再写磁盘。利⽤ WAL 技术，数据库将随机写转换成了顺序写，⼤⼤提升了数据库的性能。 但是，由此也带来了内存脏⻚的问题。脏⻚会被后台线程⾃动 flush，也会由于数据⻚淘汰⽽触发 flush，⽽刷脏⻚的过程由于会占⽤资源，可能会让更新和查询语句的响应时间⻓⼀些。 刷新脏页Q： MySQL “抖” 了一下的原因 A：当内存数据⻚跟磁盘数据⻚内容不⼀致的时候，我们称这个内存⻚为“脏⻚”。 内存数据写⼊到磁盘后，内存和磁盘上的数据⻚的内容就⼀致了，称为“⼲净⻚”。 平时执⾏很快的更新操作，其实就是在写内存和⽇志，⽽ MySQL 偶尔“抖”⼀下的那个瞬间，可能就是在刷脏⻚(flush)。 几种可能的原因： ① InnoDB 的 redo log 写满了。这时候系统会停⽌所有更新操作，把 checkpoint 往前推进，redo log留出 空间可以继续写。 ② 系统内存不⾜。当需要新的内存⻚，⽽内存不够⽤的时候，就要淘汰⼀些数据⻚，空出内存给别的数据⻚使⽤。如果淘汰的是“脏⻚”，就要先将脏⻚写到磁盘。 ③ MySQL 认为系统“空闲”的时候，即使是“⽣意好”的时候，也要⻅缝插针地找时间，只要有机会就刷⼀点“脏⻚” ④ MySQL正常关闭的情况，这时候，MySQL 会把内存的脏⻚都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。 对性能的影响： 对于 ① 出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。 对于 ② 这种情况其实是常态。InnoDB ⽤缓冲池(buffer pool)管理内存，缓冲池中的内存⻚有三种状态：第⼀种是，还没有使⽤的； 第⼆种是，使⽤了并且是⼲净⻚； 第三种是，使⽤了并且是脏⻚。 InnoDB 刷脏页的控制策略 要正确地告诉 InnoDB 所在主机的 IO 能⼒，这样 InnoDB 才能知道需要全⼒刷脏⻚的时候，可以刷多快。 可能的问题： MySQL 的写⼊速度很慢，TPS 很低，但是数据库主机的 IO 压⼒并不⼤ 1innodb_io_capacity # 会告诉 InnoDB 磁盘能⼒,建议设置成磁盘的 IOPS 如果你来设计策略控制刷脏⻚的速度，会参考哪些因素呢？ InnoDB 的刷盘速度就是要参考这两个因素：⼀个是脏⻚⽐例，⼀个是 redo log 写盘速度。 参数 innodb_max_dirty_pages_pct 是脏⻚⽐例上限，默认值是 75%。InnoDB 会根据当前的脏⻚⽐例(假设为M)，算出⼀个范围在 0 到 100 之间的数字，计算这个数字的伪代码类似这样： 根据上述算得的F1(M)和F2(N)两个值，取其中较⼤的值记为R，之后引擎就可以按照innodb_io_capacity定义的能⼒乘以R%来控制刷脏⻚的速度。 配置 innodb_flush_log_at_trx_commit 123456789101112131415161718192021222324252627282930313233343536 ：指定何时将事务日志刷到磁盘，默认为1。 - 0： 事务提交时不会将 log buffer 中日志写入到 os buffer，而是每秒写入 os buffer 并调用fsync() - 系统崩溃，会丢失 1 秒钟的数据。 - 1：每次 commit 都会把 redo log 从 redo log buffer 写入到 system，并 fsync 刷新到磁盘文件中。 - 即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO 的性能较差。 - 2： 每次事务提交时 MySQL 会把日志从 redo log buffer 写入到 system，但只写入到 file system buffer，由系统内部来 fsync 到磁盘文件。- &#96;innodb_log_buffer_size&#96;: redo 日志的缓冲区，默认为 8M，延迟事务日志写入磁盘- &#96;innodb_log_files_in_group&#96;： redo 日志的个数，默认为2，命名为 ib_logfile&lt;N&gt;- &#96;innodb_log_file_size&#96;： 事务日志的大小- &#96;innodb_log_group_home_dir&#96;： 事务日志组路径，当前目录表示数据目录## undo 日志&gt; 属于 InnoDB 存储引擎特有的日志，做事务的处理。**提供回滚和多个行版本控制(MVCC)**。为逻辑日志，默认存放在共享表空间中，如果配置了 innodb_file_per_table，将会存放在 &lt;table-name&gt;.ibd 中。相关的一些问题### 配置- innodb_max_undo_log_size:- innodb_undo_tablespaces:- innodb_undo_log_truncate:- innodb_purge_rseg_truncate_frequency:&#96;&#96;&#96;sqlshow global variables like &#39;%undo%&#39;; 其他relay log 中继日志，是复制过程中产生的日志。 relay log 是从库服务器 I/O 线程将主库服务器的二进制日志读取过来记录到从库服务器本地文件，然后从库的 SQL 线程会读取 relay-log 日志的内容并应用到从库服务器上。 配置 relay_log： max_relay_log_size： relay_log_recovery 错误日志查找 MySQL 错误日志，查看 MySQL 普通的日志 通过在 mysql.cnf 中配置错误日志的地址 log_error：on|文件路径 是否启用错误日志,on表示开启,文件路径表示指定自定义日志路径 log_warnings： 1|0 是否记录warnings信息到错误日志中 1show variables like &quot;log_error&quot;; 查询日志 general_log： on / off general_log_file：文件保存地址 1234-- 查看show global variables like &quot;%genera%&quot;;-- 开启set global general_log = on; RefsMySQL :: MySQL 8.0 Reference Manual :: 4.6.8 mysqlbinlog - Utility for Processing Binary Log Files 工具 mysqlbinlog 官方文档 [玩转MySQL之八]MySQL日志分类及简介 【MySQL （六） | 详细分析MySQL事务日志redo log】 【MySQL （六） | 详细分析MySQL事务日志redo log】 MySQL实战45讲_MySQL_数据库-极客时间 极客时间-MySQL实战45讲 MySQL中的重做日志（redo log），回滚日志（undo log），以及二进制日志（binlog）的简单总结 - MSSQL123 - 博客园","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"MySQL-结构索引与SQL优化","date":"2021-04-08T17:06:14.000Z","path":"2021/04/09/MySQL-结构索引与SQL优化/","text":"MySQL 结构优化结构设计 过分的反范式化为表建立太多的列 过分的范式化造成太多的表关联 在 OLTP 环境中使用不恰当的分区表 使用外键保证数据的完整性 性能优化顺序 数据库结构设计和SQL语句 数据库存储引擎的选择和参数配置 系统选择及优化 硬件升级 知道常用的数据类型，数据库的范式和反范式，各种字段类型占据的大小，更改字段类型是否锁表，如何处理分布式系统下字段的更改。 1、数据库优化的目的 减少数据冗余，节约数据存储空间 提高查询效率 避免数据维护中的异常： 插入异常： 必须有什么才能有什么 更新异常： 如果更改表中的某个实体的单独属性时，需要对多行进行更新 删除异常： 如果删除表中的某一实体则会导致其他实体的消失 2、数据库结构设计步骤 (1) 需求分析： (2) 逻辑设计: 确定数据实体之间的逻辑关系，逻辑存储结构 (3) 物理设计： 跟据所使用的数据库特点进行表结构设计 (4) 维护优化： 维护好索引 范式与反范式1、数据库设计范式 (1) 1NF (2) 2NF： 要求一个表中只具有一个业务主键，符合第二范式的表中不存在非主键列，只对部分主键的依赖关系 复合主键 进行表的拆分实现 (3) 3NF： 指每一个非主属性既不部分依赖于也不传递依赖于业务主键，也就是在第二范式的基础上消除了非主属性对主键的传递依赖 范式化优点： 可以尽量的减少数据冗余； 范式化的更新操作比反范式化更快； 范式化的表通常比反范式化更小 范式化缺点： 对于查询需要对多个表进行关联；更难进行索引优化 2、反范式化设计 是为了性能和读取效率的考虑而适当的对数据库设计范式的要求进行违反，而允许存在少量的数据冗余，反范式化就是使用空间来换取时间 反范式化优点： 可以减少表的关联，可以更好的进行索引优化 反范式化缺点： 存在数据冗余及数据维护异常，对数据的修改需要更多的成本 字段选择当一个列可以选择多种数据类型时， 考虑顺序： 数字类型 ⇒ 日期 / 二进制类型 ⇒ 字符类型 对于相同级别的数据类型，应该优先选择占用空间小的数据类型 == 加载的页(16k) 整数类型 共五种类型 int(2) 不影响占用的字节，使用 tinyint 进行存储 @Q: int(x) x 是什么? @A: 11 代表的并不是长度，而是字符的显示宽度,navicat 进行格式化显示了 实数类型 共三种类型 FLOAT 4B DOUBLE 8B DECIMAL: 每 4 个字节存 9 个数字，小数点占一个字节 @Q: DECIMAL（18，9）占用几个字节 @A: 需要 9 个字节来存储, 表示 9 位整数，9 位小数, 小数点占一个字节， 2*4+1=9 字符串类型 常用的两种，还支持 blog, text 类型 1、varchar 类型 varchar 特点 varchar 用于存储变长字符串，只占用必要的存储空间列的 最大长度小于 255 则只占用一个额外字节用于记录字符串长度 列的最大长度大于 255 则要占用两个额外字节用于记录字符串长度 更改 varchar 小于 255 不会锁表，大于 255 会锁表 使用时需要确定 varchar 的长度 varchar 使用场景： 字符串列的最大长度比平均长度大很多 字符串列很少被更新 使用了多字节字符集存储字符串 2、char 类型 char 类型的特点： CHAR 类型是定长的 字符串存储在 CHAR 类型的列中会删除末尾的空格 CHAR 类型的 最大宽度为255 char 的适用场景： CHAR 类型适合存储所长度近似的值，如 MD5 加密的密码 CHAR 类型适合存储短字符串，限制 255 CHAR 类型适合存储经常更新的字符串列，不会锁表，内存占用固定 日期类型 Untitled 共支持四种类型,分别占8B,4B,3B,xB (1) DATATIME 类型 以格式存储日期时间 DATATIME 类型与时区无关，占用8个字节的存储空间时间范围 12345YYYY-MM-DD HH:MM:SS[.fraction]datetime=YYYY-MM-DD HH:MM:SSdatetime(6)=YYYY-MM-DD HH:MM:SS.fraction-- 支持的范围1000-1-1 0:0:0~9999-12-31 23:59:59 (2) TIMESTAMP 类型 由格林尼治时间 1970 年 1 月 1 日到当前时间的秒数以]的格式显示 占用 4个字节 默认使用 第一个 timestamp 进行自动更新 1YYYY-MM-DD HH:MM:SS.[L.fraction 比较 timestamp 类型显示依赖于所指定的时区 在行的数据修改时可以自动修改 timestamp 列的值 时区比较 存储微秒值 123set time_zone=&#x27;+10:00&#x27;;# timestamp 与时区相关ALERT TABLE t MODIFY d1 DATETIME(6), MODIFY d2 TIMESTAMP(6); (3) Date 类型 为实现 Date，原来使用 int, datetime 存储 占用的字节数比使用字符串、datetime、int 存储要少，使用 date 类型只需要3个字节 Date 类型还可以利用日期时间函数进行日期之间的计算 (4) time 类型 time 类型用于存储时间数据 日期类型使用注意事项 不要使用字符串类型来存储日期时间数据日期时间类型 通常比字符串占用的存储空间小日期时间类型在进行查找过滤时可以利用日期来进行对比 日期时间类型还有着丰富的处理函数，可以方便的对时期类型进行日期计算 使用 Int 存储日期时间不如使用 Timestamp 类型 使用 int 时间戳保存 12select UNIX_TIMESTAMP(&#x27;2020-01-11 09:53:32&#x27;); select FROM_UNIXTIME(1578707612); Recommand使用 TIMESTAMP(4 个字节) 或 DATETIME 类型 (8 个字节) 存储时间 TIMESTAMP 存储的时间范围 1970-01-01 00:00:01 ~ 2038-01-19-03:14:07 TIMESTAMP 占用 4 字节和 INT 相同，但比 INT 可读性高 超出 TIMESTAMP 取值范围的使用 DATETIME 类型存储 尽量做到冷热数据分离,减小表的宽度 MySQL 限制每个表最多存储 4096 列，并且每一行数据的大小不能超过 65535 字节。 减少磁盘 IO, 保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的 IO）； 更有效的利用缓存，避免读入无用的冷数据； 经常一起使用的列放到一个表中（避免更多的关联操作）。 尽量控制单表数据量的大小, 建议控制在 500 万以内。 500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。 可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小。 临时库表必须以 tmp_ 为前缀并以日期为后缀，备份表必须以 bak_ 为前缀并以日期 (时间戳) 为后缀。 日期相关 timestamp 与时区相关，占用 4个字节 datetime, 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 12345678910111213# 查看当前会话时区SELECT @@session.time_zone;# 设置当前会话时区SET time_zone = &#x27;Europe/Helsinki&#x27;;SET time_zone = &quot;+00:00&quot;;# 数据库全局时区设置SELECT @@global.time_zone;# 设置全局时区SET GLOBAL time_zone = &#x27;+8:00&#x27;;SET GLOBAL time_zone = &#x27;Europe/Helsinki&#x27;; 索引优化索引是在存储引擎层实现的, 部分存储引擎不支持索引 B+ 树索引B+树索引： 1、特点： B-tree 索引能够加快数据的查询速度 B-tree 索引更适合进行范围查找，叶子节点指向的是主键 2、适合使用 B+ 树的索引 全值匹配 最左前缀 匹配列前缀 范围匹配 精确匹配 只访问索引，覆盖索引 3、B+ 树使用限制 查询优化器判定。。。 非最左列开始查找，。。。 不能跳过左边的 Not in 和 &lt;&gt; 无法使用 如果查询中有某个列的范围查询，则其右边所有列都无法使用索引 Hash 索引Memory 支持，且为默认的 InnoDB 存储引擎支持自适应 Hash 索引 1、特点 精确匹配使用，只用在等值查询 所有列，每一行计算一个Hash码 2、限制 需要两次查找，先找到行，之后读取值 无法进行排序 只支持等值查找，不支持索引查找、范围查找 Hash 冲突可能导致性能问题，不适合选择性差的列 索引概述1、使用索引的好处： 减少存储引擎需要扫描的数量，16K 每页，内存中存放更多的索引 帮助排序，避免使用临时表，索引存储结构为 B 树，按序存储 将随机 I/O 转化成顺序的 I/O，扫描的行变少 2、索引带来的损耗： 写操作成本，需要对应的索引控制 多个索引会增加查询优化器的选择时间 3、建立索引的策略： 安装演示数据库： 123&lt;http://downloads.mysql.com/docs/sakila-db.tar.gztar-zxf&gt; sakila-db.tar.gzmysql -uroot -p &lt; sakila-schema.sqlmysql-uroot -p &lt; sakila-data.sql 索引优化策略1、索引列上不能使用函数或表达式 2、索引长度有限，针对字符串 3、通过索引的选择性确定前缀索引的长度(字符串) 4、选取索引列的顺序： 经常使用的放到列的左边(选择性差的例外) 选择性高的优先 宽度小的列优先，I/O 小 5、覆盖索引直接获取： 优点： 可以优化缓存，减少磁盘I/O 减少随机I/O，将磁盘I/O改为内存的顺序 I/O 可避免对 Innodb 主键索引的二次查询， 可以避免 MyISAM 表进行系统调用 缺点： memory 不支持覆盖索引 查询中太多的列。。。 使用双 % 号的 LIKE 查询 123456789101112-- using index，覆盖索引使用expalin select id from &lt;mytab&gt; where id=1\\\\G-- using where, 非覆盖所以不explain select * from &lt;mytab&gt; where id=1\\\\G-- idx_name name 建立索引查询， using where,using index, 自动增加上主键索引的信息-- 高版本优化 using indexexplain select id,name from &lt;mytab&gt; where name=&#x27;joe&#x27;-- 1. 表达式剔除: out_date 为索引列, 查找近一个月内添加的商品select ... from productwhere to_days(out_date)-to_days(current_date)&lt;=30-- 优化后的select ... from productwhere out_date &lt;= date_add(current_date，interval 30 day)-- 2. 前缀索引长度确定 索引优化优化排序优化排序： 通过排序操作 按照索引顺序扫描数据 优化的限制： 索引的列顺序和 Order By 子句的顺序完全一致 索引中所有列的方向（升序，降序）和 Order by 子句完全一致 Order by 中的字段全部在关联表中的第一张表中 仿 Hash 索引优化模拟 Hash 索引优化 (1) 使用流程 新增 title_hash 列 设置值 创建索引 使用限制 只能处理键值的全值匹配查找 所使用的Hash函数决定着索引键的大小 123456789alter table &lt;mytab&gt; add title_hash varchar(32)update &lt;mytab&gt; set title_name=md5(title);create index idx_title_hash on &lt;mhytab&gt;(title_hash);-- using condition index,...explain select *from &lt;mytab&gt;where title_hash=md5(&#x27;sss&#x27;) and title=&#x27;sdfsfds&#x27;\\\\G 优化锁索引优化锁 避免对表的全部锁定 123456-- session1begin;select * from actor where name=&#x27;ddd&#x27; for update;-- session 2, 未使用锁住，使用索引不会锁住begin;select * from actor where name=&#x27;eee&#x27;; 索引自身问题4、删除重复和冗余的索引 单列的索引类型不同的重复 联合索引的最左匹配原则，形成冗余 12-- todo 工具下载pt-duplicate-key-checker h=127.9.0.1 5、查找未使用的索引 定期清理 通过 performance_schema,information 数据库查询出信息 123456789-- 查看所有数据中对应的表，对应的索引名称，索引使用的次数SELECT CONCAT(object_schema, &quot;.&quot;, object_name) AS TABLE_NAME, index_name AS INDEX_NAME, b.`TABLE_ROWS` AS TABLE_ROWSFROM performance_schema.table_io_waits_summary_by_index_usage a JOIN information_schema.tables b ON a.`OBJECT_SCHEMA`=b.`TABLE_SCHEMA` AND a.`OBJECT_NAME`=b.`TABLE_NAME`WHERE index_name IS NOT NULL AND count_star = 0ORDER BY object_schema, object_name; 6、更新索引统计信息及减少索引碎片 123analyze table &lt;mytab&gt;-- 可能锁表optimize table &lt;mytab&gt; SQL 查询优化SQL 性能优化的目标：至少要达到 range 级别，要求是 ref 级别，如果可以是 consts 最好。 获取慢查询的方式： 最终用户、测试人员获取存在性能问题的 SQL, 被动，常用 慢查询日志获取，服务层的日志 实时获取存在性能问题的 SQL SQL 语句执行流程查询语句的执行流程 优化器的作用：选择索引是优化器的⼯作。⽽优化器选择索引的⽬的，是找到⼀个最优的执⾏⽅案，并⽤最⼩的代价去执⾏语句。在数据库⾥⾯，扫描⾏数是影响执⾏代价的因素之⼀。扫描的⾏数 越少，意味着 访问磁盘数据的次数 越少，消耗的CPU资源越少。 当然，扫描⾏数并不是唯⼀的判断标准，优化器还会结合 是否使⽤临时表、是否排序 等因素进⾏综合判断。 1权限校验---&gt;查询缓存---&gt;分析器---&gt;优化器---&gt;权限校验---&gt;执行器---&gt;引擎 Q: MySQL是怎样得到索引的基数的呢？ MySQL采样统计的⽅法，采样统计的时候，InnoDB 默认会选择 N 个数据⻚，统计这些⻚⾯上的不同值，得到⼀个平均值，然后乘以这个索引的⻚⾯数，就得到了这个索引的基数。 ⽽数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据⾏数超过 1/M 的时候，会⾃动触发重新做⼀次索引统计。 执行更新语句的流程 MySQL可以恢复到半个⽉内任意⼀秒的状态； 涉及到两个日志文件 redo log 和 binlog； 两阶段提交，以及 Insert Buffer 插入缓冲 12UPDATE T SET c=c+1 WHERE ID=2;分析器----&gt;权限校验----&gt;执行器---&gt;引擎---redo log prepare---&gt;binlog---&gt;redo log commit SQL 解析及执行计划 1、SQL 执行过程 (1) 客户端发送 SQL 请求给服务器 (2) 服务器检查是否可以在查询缓存中命中该 SQL (3) 服务器端进行 SQL 解析，预处理，再由优化器生成对应的执行计划 (4) 跟据执行计划，调用存储引擎 API 来查询数据将结果返回给客户端 查询缓存 查询缓存： 缓存加锁 对于一个读写频繁的系统使用查询缓存很可能会降低查询处理的效率 所以在这种情况下建议大家不要使用查询缓存 查询缓存的配置参数 123456query_cache_type# 所使用的的大小query_# 缓存结果的最大值# 锁住，是否返回缓存中的数据# 查询缓存内存块的最小 查询优化器 1、可能导致失败的情况： (1) 统计信息不准确，如 Innodb 中的总条数为抽样的数据 (2) 执行计划中的成本估算不等同于实际的执行计划的成本，无法知道顺序读取与随机读取，是否在内存中 (3) MySQL 基于其成本模型进行。。。 (4) 从不考虑其他并发的查询 (5) 不会考虑不受控制的成本，如存储过程、用户自定义的函数 2、查询优化器的作用 (1) 优化 count(), min() 和 max(), B+树的。。。 (2) 将表达式转换成一个常数，MyISAM中的 Selelct Count(*) 子查询优化： 转化成关联查询 提前终止查询： 对 in() 条件进行优化，对 in 中的数据进行排序，之后通过二分查找方式确定是否满足条件 ### 查询耗时 1、通过 profile 高版本已经不建议使用，建议使用方式二 开启与执行 123456789-- 开启set profiling=1;select count(*) from &lt;mytab&gt;-- 查看整体信息show profiles;-- 查看执行的每个阶段信息show profile for query &lt;query_id&gt;;-- 查看 CPU 的信息show profile cpu for query &lt;query_id&gt;; 结果数据 2、通过 performance_schema(建议) 在 MySQL5.6 之后建议使用 对数据全局有效 (1) 开启与使用 12345678910111213141516171819-- 1. 处理的先决条件，开启 performance_schemaUPDATE `setup_instruments`SET enabled=&#x27;YES&#x27;,TIMED=&#x27;YES&#x27;WHERE NAME LIKE &#x27;stage%&#x27;;UPDATE setup_consumersSET enabled=&#x27;YES&#x27;WHERE NAME LIKE &#x27;events%&#x27;;-- 2. 查询使用SELECT a.THREAD_ID, SQL_TEXT,c.EVENT_NAME,(c.TIMER_END-c.TIMER_START)/1000000000 AS &#x27;DURATION(ms)&#x27;FROM events_statements_history_long a JOIN threads b ON a.THREAD_ID=b.THREAD_IDJOIN events_stages_history_long c ON c.THREAD_ID=b.THREAD_ID AND c.EVENT_ID BETWEEN a.EVENT_ID AND a.END_EVENT_ID WHERE b.PROCESSLIST_ID=CONNECTION_ID() AND a.EVENT_NAME=&#x27;statement/sql/select&#x27;ORDER BY a.THREAD_ID,c.EVENT_ID 信息返回 返回各个阶段的耗时 执行的线程ID 慢查询日志写日志为顺序存储 慢查询配置 动态参数,可配合脚本定时开关 slow_query_log 存放位置。将日志存储与数据存储分开 slow_query_log_file 查询阈值，秒为单位，建议 0.001 秒 long_query_time 记录未使用索引的 SQL log_queries_not_using_indexes 实际使用的SQL 1234SHOW VARIABLES LIKE &#x27;%quer%&#x27;SET GLOBAL slow_query_log=on;SET GLOBAL slow_query_log_file=&#x27;/var/log/mysql/mysql-slow.log&#x27;SET GLOBAL long_query_time=0.001;SET GLOBAL log_queries_not_using_indexes=ON; 2、慢查询记录的内容 用户 查询的时间，精确到毫秒 查询占用的锁时间 返回的数据行数 扫描的行数 执行SQL的时间， UNIX时间戳 对应的SQL语句 12345# Time: 2019-05-30T10:10:02.771744Z# User@Host: root[root] @ localhost [127.0.0.1] Id: 44# Query_time: 0.001503 Lock_time: 0.001002 Rows_sent: 12 Rows_examined: 12SET timestamp&#x3D;1559211002;SELECT * FROM exam; mysqldumpslow 获取 通过自带的工具进行筛选输出 (1) -s order（c，t，l，r，at，al，ar）: 指定按哪种排序方式输出结果 c：总次数 t：总时间 1：锁的时间 r：总数据行 at，al，ar:t，l，r平均数 t top: 指定取前几条作为结束输出 1mysqldumpslow -s &lt;r&gt; -t &lt;10&gt; &lt;slow-mysql.log&gt; pt-query-digest 获取 建议使用 还支持对 bin log等日志的进行查看 1pt-query-digest --explain h=127.0.0.1,u=root,p=password mysql-slow.log 返回结果： 整体的统计信息，total,max,min 执行计划 实时获取 通过 information_schema.proceeslist 表进行查看获取实时数据 12345678910-- 查询出服务器中执行超过 60s 的SQLSELECT id, user, DB, command, time, state, infoFROM information_schema.PROCESSLISTWHERE TIME &gt;= 60; 特定 SQL 的优化大表的数据修改分批处理： 1000 万行记录的表中删除/更新 100 万行记录 一次只删除/更新 5000 行记录，暂停几秒 方式一： 通过存储过程实现 1DELIMITER $$USE `&lt;myDB&gt;`$$DROP PROCEDURE IF EXISTS `p_delete rows`$$CREATE DEFINER=`root`@`127.0.0.1` PROCEDURE `p_delete_rows`()BEGIN DECLARE v_rows INT； SET v_rows=1; WHILE v_roWs &gt;0 DO -- 根据业务修改下面的语句 DELETE FROM sbtest1 WHERE id&gt;=90000 AND id &lt;=19000 LIMIT 5000; SELECT ROW_COUNT() INTO v_rows; -- sleep SELECT SLEEP(5); END WHILE;END$$DELIMITER； 方式二： 程序中执行类似存储过程的逻辑每次获取少量数据，之后执行处理逻辑 修改大表的表结构 对表的列的字段类型进行修改，改变字段的宽度会锁表，无法解决主从数据库延迟问题 方式一： 主从切换 方式二： 手动创建新表进行迁移，减少主从延迟，操作复杂 可使用 pt-online-schema-change 工具 完成方式二的复杂逻辑 123456pt-online-schema-change --alter=&quot;MODIFY C VARCHAR(150) NOT NULL DEFAULT &#x27;&#x27;&quot; --user=root \\\\ --password=PassWord D=&lt;mydb&gt;,t=&lt;mytab&gt; --charset=utf8 \\\\ --execute 优化 not in 和 &lt;&gt; 查询(#) 通过外连接 + NULL 进行处理，即为将子查询转化成表的连接查询； 常用的调整手段； 12345678910-- 原始SQLSELECT customer_id, first_name, last_name, emailFROM customerWHERE customer_id NOT IN (SELECT customer_id FROM payment)-- 通过 Left join 配合 null 的优化SELECT a.customer_id,a.first_name,a.last_name,a.emailFROM customer aLEFT JOIN payment b ON a.customer_id =b.customer_idWHERE b.customer_id IS NULL 使用汇总表优化查询(#) 汇总表概述： 汇总表就是提前以要统计的数据进行汇总并记录到表中以备后续的查询使用。 汇总表的数据可以使非实时的。 实际使用汇总表的策略 使用汇总表记录从该天开始之前的所有统计信息，之后每天进行更新维护； 查询时借助统计信息表的数据和当天的数据汇总返回； 汇总表被当做一种缓存，当天数据类似增量信息； 从原来的表中提取出汇总信息，不会变更原来的表结构，侵入性低，是一种常用的扩展手段。 12345678910111213-- 原始的统计SQLSELECT COUNT(*) FROM product_ comment WHERE productid=999-- 创建汇总表CREATE TABLE product_ comment_cnt(product id INT,cnt INT);-- 修改后的 SQL, UNION ALL 确定SELECT SUM(cnt) FROM(SELECT cnt FROM product_comment_cnt WHERE product_id=999UNION ALL SELECT COUNT(*) FROM product_comment WHERE product_id=999AND timestr&gt;DATE(NOW())) a 只要一行数据时使用 LIMIT 1 已经知道结果只会有一条结果，加上 LIMIT 1 可以增加性能。MySQL 数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据。 用 Not Exists 代替 Not In Not Exists 允许用户使用相关子查询已排除一个表中能够与另一个表成功连接的所有记录。Not Exists 用到了连接，能够发挥已经建好的索引的作用，而 Not In 不能使用索引。Not In 是最慢的方式，要同每条记录比较，在数据量比较大的查询中不建议使用这种方式。 12345Select a.mobileidfrom Log_user awhere not exists (select b.mobileid from magazineitem b where b.mobileid=a.mobileid); RefMySQL实战45讲_MySQL_数据库-极客时间 MySQL实战45讲","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"MySql-索引","date":"2021-04-08T17:06:02.000Z","path":"2021/04/09/MySql-索引/","text":"概述删除长期未使用的索引 不用的索引的存在会造成不必要的性能损耗 MySQL 5.7 可以通过查询 sys 库的 chema_unused_indexes 视图来查询哪些索引从未被使用 避免定义重复的索引 借助 pt-duplicate-key-checker 查找，并生成删除重复索引的 SQL 语句 1pt-duplicate-key-checker -h &lt;host&gt; -u&lt;user&gt; -p&lt;passwd&gt; 索引好处： 提高访问速度； 优化查询； 将随机 IO 改为顺序 IO 索引缺点： 占用空间，索引建立的越多越占用空间； 更改频繁时，每次修改都需要重建索引； 索引的适用场景 选择性较高的场景； 不适合索引的场景： 数据规模小的情况； 选择性较低的列； 索引的底层实现 Hash 索引 适⽤于只有等值查询的场景，⽐如 Memcached 及其他⼀些 NoSQL 引擎。 (2)) 有序数组 有序数组在等值查询和范围查询场景中的性能就都⾮常优秀, 有序数组索引只适⽤于静态存储引擎。 二叉树 B+ 树 索引的创建 index_type： 可选择 BTREE，HASH 12345CREATE [UNIQUE | FULLTEXT | SPATIAL] INDEX index_name [index_type] ON tbl_name (key_part,...) [index_option] [algorithm_option | lock_option] ... Functional Key Parts: MySQL8.0+ 支持，不只是列/列特定的前缀，支持 123456789CREATE TABLE t1 ( col1 VARCHAR(10), col2 VARCHAR(20), INDEX (col1, col2(10)));CREATE TABLE t1 (col1 INT, col2 INT, INDEX func_index ((ABS(col1))));CREATE INDEX idx1 ON t1 ((col1 + col2));CREATE INDEX idx2 ON t1 ((col1 + col2), (col1 - col2), col1);ALTER TABLE t1 ADD INDEX ((col1 * 40) DESC); JSON 格式的索引 12345678910CREATE TABLE employees ( data JSON, INDEX idx ((CAST(data-&gt;&gt;&quot;$.name&quot; AS CHAR(30)) COLLATE utf8mb4_bin)));INSERT INTO employees VALUES (&#x27;&#123; &quot;name&quot;: &quot;james&quot;, &quot;salary&quot;: 9000 &#125;&#x27;), (&#x27;&#123; &quot;name&quot;: &quot;James&quot;, &quot;salary&quot;: 10000 &#125;&#x27;), (&#x27;&#123; &quot;name&quot;: &quot;Mary&quot;, &quot;salary&quot;: 12000 &#125;&#x27;), (&#x27;&#123; &quot;name&quot;: &quot;Peter&quot;, &quot;salary&quot;: 8000 &#125;&#x27;);SELECT * FROM employees WHERE data-&gt;&gt;&#x27;$.name&#x27; = &#x27;James&#x27;; 索引查看12345678910111213-- 查看指定表的索引SHOW INDEX FROM &lt;table-name&gt; FROM &lt;database-name&gt;;-- 查看指定数据库的索引统计SELECT TABLE_NAME ,INDEX_NAME ,SEQ_IN_INDEX ,COLUMN_NAME ,CARDINALITY ,INDEX_TYPE FROM INFORMATION_SCHEMA.STATISTICS WHERE table_schema = &#x27;DatabaseName&#x27; 重复索引的查看，见 pt-duplicate-key-checker 索引分类索引分类 B-Tree: b 树索引 R-tree: 空间索引 hash: 散列索引 full-text: 全文索引 主键索引(聚集)作为表的主键，可以有包含多个列，该索引是唯一索引，在 InnoDB 存储引擎中为聚集索引。 主键⻓度越⼩，普通索引的叶⼦节点就越⼩，普通索引占⽤的空间也就越⼩。 所以，从性能和存储空间⽅⾯考量，⾃增主键往往是更合理的选择。 聚集索引和非聚集索引的区别 聚集索引在叶子节点存储的是表中的数据 非聚集索引在叶子节点存储的是主键和索引列 Q：基于主键索引和普通索引的查询有什么区别？ A：如果语句是 select * from table where id=8888，只需要搜索 ID 这棵 B+ 树； 如果语句是 select * from table where key=5，需要先搜索 key 索引树，得到 id 的值为 500，再到 ID 索引树搜索⼀次。这个过程称为 回表。 也就是说，基于⾮主键索引的查询需要多扫描⼀棵索引树。 普通索引相较于唯一索引，使用了 change buffer 与唯一索引的相比，这两类索引在查询能⼒上是没差别，主要考虑的是对更新性能的影响。 Change buffer 使用场景： 如果所有的更新后⾯，都⻢上伴随着对这个记录的查询，那么应该关闭 change buffer。⽽在其他情况下，change buffer 都能提升更新性能。 唯一索引唯⼀索引⽤不上 change buffer 的优化机制，因此如果业务可以接受，从性能⻆度出发建议优先考虑⾮唯⼀索引。 对于唯⼀索引来说，由于索引定义了唯⼀性，查找到第⼀个满⾜条件的记录后，就会停⽌继续检索。 覆盖索引包含了所有查询字段 (where,select,ordery by,group by 包含的字段) 的索引。 对于频繁的查询优先考虑使用覆盖索引。 无需二次扫表，直接扫描索引中的 B+ 树即可获取全部数据； 覆盖索引的好处： 避免 Innodb 表进行索引的二次查询: Innodb 是以聚集索引的顺序来存储的，对于 Innodb 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询，减少了 IO 操作，提升了查询效率。 可以把随机 IO 变成顺序 IO 加快查询效率: 由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。 创建的注意事项： 选取字符串的前多少位作为索引项()； 阿里巴巴开发手册规定 【强制】在 varchar 字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度即可。 注意 最左前缀 的使用，以及基于此衍生出来的联合索引组合； 能够形成覆盖索引，从而避免二次扫表问题。 联合索引联合索引定义的顺序： 建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。 区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数） 尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好） 使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引） 索引列的选取： 常见索引列建议 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列 包含在 ORDER BY、GROUP BY、DISTINCT 中的字段 并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好 多表 join 的关联列 字符串索引直接创建完整索引，这样可能⽐较占⽤空间； 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使⽤覆盖索引 倒序存储，再创建前缀索引，⽤于绕过字符串本身前缀的区分度不够的问题； 创建 引，查询性能稳定，有额外的存储和计算消耗，跟第三种⽅式⼀样，都不⽀持 。hash字段索范围扫描 前缀索引前缀索引限定索引的长度 不指定前缀长度，默认包含整个字符串； 1234ALTER TABLE SUser ADD INDEX idx1(email);-- only prefixALTER TABLE SUser ADD INDEX idx2(email(6)); 由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节，所以占⽤的空间会更⼩，这就是使⽤前缀索引的优势。 但可能会增加额外的记录扫描次数。 如果使⽤的是 index1(即 email 整个字符串的索引结构)，执⾏顺序是这样的： 从 index1 索引树找到满⾜索引值是 zhangssxyz@xxx.com ’的这条记录，取得ID2的值； 到主键上查到主键值是ID2的⾏，判断email的值是正确的，将这⾏记录加⼊结果集； 取index1索引树上刚刚查到的位置的下⼀条记录，发现已经不满⾜email=’&#x7a;&#104;&#97;&#x6e;&#103;&#115;&#115;&#120;&#121;&#x7a;&#64;&#120;&#x78;&#120;&#x2e;&#x63;&#x6f;&#x6d;’的条件了，循环结束。 这个过程中，只需要回主键索引取⼀次数据，所以系统认为只扫描了⼀⾏。 如果使⽤的是index2(即email(6)索引结构)，执⾏顺序是这样的： 1 . 从index2索引树找到满⾜索引值是’zhangs’的记录，找到的第⼀个是ID1； 2 . 到主键上查到主键值是ID1的⾏，判断出email的值不是’&#x7a;&#x68;&#x61;&#x6e;&#x67;&#x73;&#115;&#x78;&#x79;&#x7a;&#64;&#x78;&#120;&#120;&#x2e;&#99;&#x6f;&#x6d;’，这⾏记录丢弃； 3 . 取index2上刚刚查到的位置的下⼀条记录，发现仍然是’zhangs’，取出ID2，再到ID索引上取整⾏然后判断，这次值对了，将这⾏记录加⼊结果集； 4 . 重复上⼀步，直到在idxe2上取到的值不是’zhangs’时，循环结束。 在这个过程中，要回主键索引取4次数据，也就是扫描了4⾏。 通过这个对⽐，你很容易就可以发现，使⽤前缀索引后，可能会导致查询语句读数据的次数变多。 使⽤前缀索引，定义好⻓度，就可以做到既节省空间，⼜不⽤额外增加太多的查询成本。 根据区分度来选择前缀的长度； 建立索引列的区分度越⾼越好。区分度越⾼，意味着重复的键值越少。可以通过统计索引上有多少个不同的值来判断要使⽤多⻓的前缀。 可以使⽤下⾯这个语句，算出这个列上有多少个不同的值，95% 作为参考； 12345SELECT COUNT(DISTINCT LEFT(email, 4)) AS L4, COUNT(DISTINCT LEFT(email, 5)) AS L5, COUNT(DISTINCT LEFT(email, 6)) AS L6, COUNT(DISTINCT LEFT(email, 7)) AS L7,FROM SUser; 前缀索引对覆盖索引的影响 如果使⽤ index1(即email整个字符串的索引结构)的话，可以利⽤覆盖索引，从index1查到结果后直接就返回了，不需要回到ID索引再去查⼀次。⽽如果使⽤index2(即email(6)索引结构)的话，就不得不回到ID索引再去判断email字段的值。 即使你将index2的定义修改为email(18)的前缀索引，这时候虽然index2已经包含了所有的信息，但InnoDB还是要回到id索引再查⼀下，因为系统并不确定前缀索引的定义是否截断了完整信息。 也就是说，使⽤前缀索引就⽤不上覆盖索引对查询性能的优化了，这也是你在选择是否使⽤前缀索引时需要考虑的⼀个因素。 12ALTER TABLE SUser ADD INDEX idx_email(eamil(20));--SELECT id, name, email FROM SUserWHERE email=&#x27;zhangssxyz@xxx.com&#x27;; 区分度不足的处理前缀的区分度不够时如何处理 比如国家的身份证号、电话号码 方式一： 倒序存储 由于身份证号的最后6位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了⾜够的区分度，先使⽤ count(distinct) ⽅法做验证 12345-- MySQL 函数 revere 操作，插入处理INSERT INTO T(col.., id_card) VALUES (xxx, revere(&#x27;input_id_card_string&#x27;));-- 查询的处理SELECT &lt;field_list&gt; FROM t WHERE id_card=reverse(&#x27;input_id_card_string&#x27;); 方式二： 使用 Hash 字段 在表上再创建⼀个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。 之后每次插⼊新记录的时候，都同时⽤ crc32() 函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。 这样，索引的⻓度变成了 4 个字节，⽐原来⼩了很多。 12345678-- 新增加一列，4byte 存放索引 hash 后的值ALTER TABLE t ADD id_card_crc INT UNSIGNED, ADD index(id_card_crc);-- 插入逻辑， crc32 hash 值以及原始的值INSERT INTO T(co1..., id_card_crc, id_card) VALUES (xxx, crc32(&#x27;input_card_string&#x27;), &#x27;input_id_card_string&#x27;); -- INDEX can duplication-- 对应的查询语句，先对 hash 进行查询后对原始字符串查询SELECT * FROM t WHERE id_card_crc=crc32(&#x27;input_id_card_string&#x27;) AND id_card=&#x27;input_id_card_string&#x27;); 倒序存储和 hash 存储两种方式的比较： 相同点是，都不⽀持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的⽅式排序的，已经没有办法利⽤索引⽅式查出身份证号码在[ID_X, ID_Y]的所有市⺠了。同样地，hash 字段的⽅式也只能⽀持等值查询。 它们的区别，主要体现在以下三个⽅⾯： ① 从占⽤的额外空间来看，倒序存储⽅式在主键索引上，不会消耗额外的存储空间，⽽ hash 字段⽅法需要增加⼀个字段。当然，倒序存储⽅式使⽤ 4 个字节的前缀⻓度应该是不够的，如果再⻓⼀点，这个消耗跟额外这个 hash 字段也差不多抵消了。 ② 在CPU消耗⽅⾯，倒序⽅式每次写和读的时候，都需要额外调⽤⼀次 reverse 函数，⽽ hash 字段的⽅式需要额外调⽤⼀次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更⼩些。 ③ 从查询效率上看，使⽤ has h字段⽅式的查询性能相对更稳定⼀些。因为 crc32 算出来的值虽然有冲突的概率，但是概率⾮常⼩，可以认为每次查询的平均扫描⾏数接近 1。⽽倒序存储⽅式毕竟还是⽤的前缀索引的⽅式，也就是说还是会增加扫描⾏数。 索引的使用修改 SQL 语句尽量使其走索引； 对于查询优化器选择索引错误，通过修改 SQL 引导其进行选择正确的索引，如通过 FORCE INDEX() 来指定使用特定的索引进行查询； 为查询较多的字段添加索引，可考虑使用覆盖索引； 要避免编写使索引失效的 SQL 语句； 最左匹配原则 全值匹配我最爱，最左前缀要遵守； 带头大哥不能死，中间兄弟不能断； 原因： B+ 树的索引结构导致 原因： 复合索引(组合)，先对最左边的字段进行排序，在第一个字段排序的基础上再对后面的字段排序。 类似 orderby ，只保证第一个字段有序，通常对于第二个字段用不到索引； B+ 树这种索引结构，可以利⽤索引的“最左前缀”，来定位记录 只要满⾜最左前缀，就可以利⽤索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。 如何控制索引的顺序： 如果通过调整顺序，可以少维护⼀个索引，那么这个顺序往往就是需要优先考虑采⽤的。 考虑的原则就是空间了。⽐如上⾯这个市⺠表的情况，name 字段是⽐ age 字段⼤的，那我就建议你创建⼀个(name,age)的联合索引和⼀个(age)的单字段索引 索引失效 索引列上少计算，范围之后全失效； LIKE 百分写最右，覆盖索引不写星； 不等空值还有 OR, 索引失效要少用； VAR 引号不可丢，SQL 高级也不难！ 条件字段函数及计算操作 如果对字段做了函数计算，就⽤不上索引了。 SQL语句条件⽤的是 where t_modified=‘2018-7-1’ 的话，B+ 树提供的这个快速定位能⼒，来源于同⼀层兄弟节点的有序性。 显示调用函数，在 t_modified 字段加了 month() 函数操作，导致了全索引扫描 123456789101112CREATE TABLE `tradelog` ( `id` int(11) NOT NULL, `tradeid` varchar(32) DEFAULT NULL, `operator` int(11) DEFAULT NULL, `t_modified` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `tradeid` (`tradeid`), KEY `t_modified` (`t_modified`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;-- Query，对索引列使用了函数SELECT COUNT(*) FROM tradelog WHERE month(t_modified)=7; 按照业务进行修改，使其走索引： 12345-- 更改索引列中使用的函数成为索引列的范围比较查询SELECT COUNT(*) FROM tragelogWHERE (t_modified &gt;= &#x27;2016-7-1&#x27; AND t_modified&lt;&#x27;2016-8-1&#x27;) OR (t_modified &gt;= &#x27;2017-7-1&#x27; AND t_modified&lt;&#x27;2017-8-1&#x27;) OR (t_modified &gt;= &#x27;2018-7-1&#x27; AND t_modified&lt;&#x27;2018-8-1&#x27;); 隐式类型转换 字符串隐式的转换成数字进行操作； 1234567select * from tradelog where tradeid=110717;select “10” &gt; 9; -- 1, String ⇒ numberSELECT * FROM tradelog WHERE CAST(tradid AS signed int)=110717;-- 修改后的 SQLSELECT * FROM tradelog WHERE tradeid=&#x27;110717&#x27;; 隐式字符编码转换 123456789101112CREATE TABLE `trade_detail` ( `id` int(11) NOT NULL, `tradeid` varchar(32) DEFAULT NULL, `trade_step` int(11) DEFAULT NULL COMMENT &quot;操作步骤&quot;, `step_info` varchar(32) DEFAULT NULL COMMENT &quot;步骤信息&quot;, PRIMARY KEY (`id`), KEY `tradeid` (`tradeid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- log 和 业务的详情表字符集不同select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /* 语句 Q1 */ 两个字符集不同： 1234select * from trade_detail where tradeid=$L2.tradeid.value;-- 等同于，对列粒度的字符进行编码转换比较select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; 字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做⽐较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做⽐较。 方案一： 把 trade_detail 表上的 tradeid字 段的字符集也改成 utf8mb4，这样就没有字符集转换的问题了。 1ALTER TABLE trade_detail MODIFY tradeid varchar(32) character SET utf8mb4 DEFAULT NULL; 方案二： 在无法修改字符集的情况下，或者表中的数据很多的情况下 12select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; 简单的计算 1SELECT * FROM trade_detail WHERE trade_step=trade_step + 1; 索引下堆(5.6)// TODO 索引问题重建索引@Q: 为什么要重建索引? 索引可能因为删除，或者⻚分裂等原因，导致数据⻚有空洞，重建索引的过程会创建⼀个新的索引，把数据按顺序插⼊，这样⻚⾯的利⽤率最⾼，让索引更紧凑、更省空间。 通过两个 alter 语句重建索引 k，以及通过两个 alter 语句重建主键索引是否合理。 重建索引 k 的做法是合理的，可以达到省空间的⽬的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执⾏这两个语句的话，第⼀个语句就⽩做了。这两个语句，可以⽤这个语句代替 ： alter table Tengine=InnoDB。 记录⽇志⽤的表, 会定期删除过早之前的数据。 最后这个表实际内容的⼤⼩ 10G, 索引却有 30G.. 是 InnoDB 这种引擎导致的,虽然删除了表的部分记录,但是它的索引还在, 并未释放. 只能是重新建表才能重建索引. 索引选择异常@Q: 索引选择异常和处理？ 处理查询优化器选择错误索引？ 查询优化器选择的不是最优的索引情况的处理。 ⼤多数时候优化器都能找到正确的索引，但偶尔还是会碰到我们上⾯举例的这两种情况：原本可以执⾏得很快的SQL语句，执⾏速度却⽐你预期的慢很多 方式一：采⽤ force index() 强⾏选择⼀个索引 MySQL 会根据词法解析的结果分析出可能可以使⽤的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少⾏。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执⾏代价。 12345-- FORCE INDEX 的使用SELECT * FROM t FORCE INDEX(a) WHERE a BETWEEN 1 AND 1000 AND b BETWEEN 50000 AND 100000ORDER BY bLIMIT 1; 但其实使⽤ force index 最主要的问题还是变更的及时性。因为选错索引的情况还是⽐较少出现的，所以开发的时候通常不会先写上 force index。⽽是等到线上出现问题的时候，你才会再去修改 SQL 语句、加上 force index。但是修改之后还要测试和发布，对于⽣产系统来说，这个过程不够敏捷。 方法二：可以考虑修改语句，引导 MySQL 使⽤期望的索引 ⽐如，在这个例⼦⾥，显然把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。 现在 order by b,a 这种写法，要求按照b,a排序，就意味着使⽤这两个索引都需要排序。因此，扫描⾏数成了影响决策的主要条件，于是此时优化器选了只需要扫描 1000 ⾏的索引 a。 当然，这种修改并不是通⽤的优化⼿段，只是刚好在这个语句⾥⾯有 limit 1，因此如果有满⾜条件的记录， order by b limit 1 和 order by b,a limit 1 都会返回 b 是最⼩的那⼀⾏，逻辑上⼀致，才可以这么做。 123456789101112SELECT * FROM t FORCE INDEX(a)WHERE a BETWEEN 1 AND 1000 AND b BETWEEN 50000 AND 100000ORDER BY b,a -- modifyLIMIT 1;-- 另一种引导我们⽤limit 100让优化器意识到，使⽤b索引代价是很⾼的。其实是我们根据数据特征诱导了⼀下优化器，也不具备通⽤性。SELECT * FROM (SELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (B BETWEEN 50000 AND 100000) ORDER BY b LIMIT 100) alias LIMIT 1; 方法三：在有些场景下，可以新建⼀个更合适的索引，来提供给优化器做选择，或删掉误⽤的索引 这种情况其实⽐较少，尤其是经过 DBA 索引优化过的库，再碰到这个 bug，找到⼀个更合适的索引⼀般⽐较难。 如果我说还有⼀个⽅法是删掉索引 b，你可能会觉得好笑。但实际上我碰到过两次这样的例⼦，最终是 DBA 跟业务开发沟通后，发现这个优化器错误选择的索引其实根本没有必要存在，于是就删掉了这个索引，优化器也就重新选择到了正确的索引。 B 树与索引B+ 树特点： 关键字分布在整棵树的所有节点。 任何一个关键字，出现且只出现在一个节点中。 搜索有可能在非叶子节点结束。 其搜索性能等价于在关键字全集内做一次二分查找。 B+树基本特点 非叶子节点的子树指针与关键字个数相同。 非叶子节点的子树指针 P[i]，指向关键字属于 [k[i],K[i+1]) 的子树（注意：区间是前闭后开)。 为所有叶子节点增加一个链指针。 所有关键字都在叶子节点出现。 B 树与 B+ 树的区别 关键字与孩子节点的个数不同； B+树的磁盘读写代价更低：B+ 树的内部没有指向关键字具体信息的指针，其内部节点相对 B 树更小，把所有关键字存放在同一块盘中，B+ 树比 B 树所能容纳的关键字数量也越多； 查询的稳定性： B+ 树所欲数据都存放在叶子节点，B+ 树无论如何都要扫表到叶子节点才能返回数据， 所有关键字查询的路径长度相同；B 树可以中途跳出，查询效率不够稳定； B+ 树适合用于遍历和范围的选择，底层叶子节点是双向链表，只需要去遍历叶子节点就可以实现整棵树的遍历； MongoDB 的索引为什么选择 B 树，而 MySQL 的索引是 B+树 MongoDB 非传统的 RDBMS，是以 Json 格式作为存储的 NoSQL，目的就是高性能、高可用、易扩展。摆脱了关系模型，所以范围查询和遍历查询的需求就没那么强烈。 RefMySQL :: MySQL 8.0 Reference Manual :: C Indexes MySQL 的索引官方文档 深入理解MySQL索引-InfoQ 深入理解 MySQL 索引","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"MySQL 事务","date":"2021-04-08T17:04:36.000Z","path":"2021/04/09/MySQL-事务/","text":"概述 事务是数据库区别于文件系统的一个关键特性。 事务的分类 ① 扁平事务，使用最频繁； ② 带有保存点的扁平事务； ③ 链事务，下一个事务将能够看到上一个事务的结果，只能恢复到最近一个的保存点； ④ 嵌套事务； 任何子事务都在顶层事务提交后才真正的提交；是一棵树状的结构； 只有叶子节点的事务才能访问数据库、发送消息、获取其他类型的资源； ⑤ 分布式事务；需要根据数据所在位置访问网络中的不同节点；保存点在事务内部是递增的；可以借助消息队列实现分布式事务。 相关的 SQL // TODO 关联 Spring 提供的几个事务级别 1SHOW VARIABLES LIKE &#x27;ios%&#x27;; 四大特性 原子性(Atomic)： 所有操作要么全部成功，要么全部失败 一致性(Consistency)： 数据从一个一致性状态转移到另一个一致性状态，一致指的是 数据的完整性约束 没有被破坏 **隔离性(Isolation)**： 并发执行事务时，一个事务应该不影响其他事务的执行 持久性(Duration)： 对 DB 的修改永久，恢复性能 事务的实现方式实现的原理： InnoDB 中的 undo.log, redo.log 日志文件。 隔离性： 通过锁实现 原子性和持久性： 通过 redo 物理日志实现； 事务的一致性： 通过 undo log 实现； redo log blog 可通过参数调节控制 redo log 刷新到磁盘的策略； log block： redo log 的块大小与磁盘扇区大小一样都是 512 字节，保证了原子性，不需要 doublewrite 技术； 为物理日志，恢复速度比逻辑日志快，是幂等的。 重做日志记录了事务的行为，可以很好地通过其对也进行 “重做” 操作 undo log 帮助事务回滚； 帮助实现 MVCC； 是实现快照读的一种必要机制； 存放在数据库内部的一个特殊字段上； 功能一： 是逻辑日志，将数据库逻辑地恢复到原来的样子； 功能二： 当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过 undo 读取之前的行版本信息，以此实现非锁定读取。 分类： insert undo log update undo log delete 操作不直接删除记录，而只是将记录标记为已删除。 undo 信息的数据字典： 真正删除这行记录的操作其实被 “延时” 了，最终在 purage 操作中完成。 两阶段提交第一阶段： 所有参与全局事务的节点都开始准备(PREPARE) ，告诉事务管理器准备好了； 第二阶段： 事务管理器告诉资源管理器质性 ROLLBACK 还是 COMMIT，分布式事务需要多一次的 PREPARE 操作，待收到所有节点的统一信息后，再进行 COMMIT 或是 ROLLBACK 操作。 事务相关的 SQL 语句 一条语句失败并抛出异常，不会导致先前已经执行的语句自动会馆， 1234567891011121314-- salfpoint ROLLBACK-- 删除一个保存点RELEASE SAVEPOINT t1;-- 定义一个保存点SAVEPOINT t2;-- 回滚到某个保存点, 此时事务没有结束ROLLBACK TO SAVEPOINT t2;-- 设置级别SET [GLOBAL | SESSION] TRANSACTION ISOLATION LEVEL &#123;...&#125; 分布式事务 XA XA 事务由一个或多个资源管理器、一个事务管理器以及一个应用程序组成。 Serializable 级别 长事务 执行时间较长的事务； 进行的优化：在 1 亿用户表中，这个操作被封装在一个事务中完成，通过为其转化成小批量的事务进行处理； 好处一： 便于回滚每完成一个小事务，将完成的结果存放在 batchcontext 表中，表示已完成批量事务的最大账号 ID。 在发生错误时，可以从这个已完成的最大事务 ID 继续进行批量的小事务，重新开启事务的代价就显得比较低。 好处二： 用户可以知道现在大概已经执行到了哪个阶段 1UPDATE account SET account_total=account_total+1 + (1+interest_rate); 并发问题更新丢失： Dirty Read 读取到未提交的数据，之后回滚 ，修改成 READ UNCOMMITTED 隔离级别可以处理 1SELECT @@tx_isolation; 二级封锁协议 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 . 不可重复读 session1 执行事务期间，另一个 session2 事务对session1 读取的数据修改并提交 将事务隔离级别升级为 REPEATABLE READ 即可处理该问题 幻读 侧重于删除和增加 Transaction A 读取与搜索条件相匹配的若干行， Transaction B 插入或删除行修改 Transaction A 的结果集。 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插⼊的数据的。因此，幻读在“当前读”下才会出现。 上⾯session B的修改结果，被session A之后的select语句⽤“当前读”看到，不能称为幻读。幻读仅专指“新插⼊的⾏”。 幻读有什么问题？ ⾸先是语义上的。session A在T1时刻就声明了，“我要把所有d=5的⾏锁住，不准别的事务进⾏读写操作”。⽽实际上，这个语义被破坏了。 其次，是数据⼀致性的问题。 我们知道，锁的设计是为了保证数据的⼀致性。⽽这个⼀致性，不⽌是数据库内部数据状态在此刻的⼀致性，还包含了数据和⽇志在逻辑上的⼀致性。 原因很简单。在T3时刻，我们给所有⾏加锁的时候，id=1这⼀⾏还不存在，不存在也就加不上锁。 也就是说，即使把所有的记录都加上锁，还是阻⽌不了新插⼊的记录，这也是为什么“幻读”会被单独拿出来解决的原因。 到这⾥，其实我们刚说明完⽂章的标题 ：幻读的定义和幻读有什么问题。 隔离级别隔离得越严实，效率就会越低。 READ UNCOMMITTED: ⼀个事务还没提交时，它做的变更就能被别的事务看到。 READ COMMIT: ⼀个事务提交之后，它做的变更才会被其他事务看到。 REPEATABLE READ: ⼀个事务执⾏过程中看到的数据，总是跟这个事务在启动时看到的数据是⼀致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可⻅的。 SERIALIZABLE: 对于同⼀⾏记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前⼀个事务执⾏完成，才能继续执⾏。主要用于实现 InnoDB 的分布式事务。 InnoDB 在 REPEATABLE READ 级别下，使用 Next-Key Lock 锁算法，避免幻读的产生。 隔离级别与事务问题 事务隔离的实现 read view 算法 在 MySQL 中，实际上每条记录在更新的时候都会同时记录⼀条回滚操作。记录上的最新值，通过回滚操作，都可以得到前⼀ 个状态的值。 回滚⽇志什么时候删除呢？ 在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要⽤到这些回滚⽇志时，回滚⽇志会被删除。 什么时候才不需要了呢？ 当系统⾥没有⽐这个回滚⽇志更早的 read-view 的时候。 为何尽量不使用长事务？ ⻓事务意味着系统⾥⾯会存在很⽼的事务视图。由于这些事务随时可能访问数据库⾥⾯的任何数据，所以这个事务提交之前，数据库⾥⾯它可能⽤到的回滚记录都必须保留，这就会导致⼤量占⽤存储空间。 除此之外，⻓事务还占⽤锁资源，可能会拖垮库。 其他开启事务的方式 显式启动事务语句： begin 或者 start transaction, 提交 commit，回滚 rollback； set autocommit=0： 该命令会把这个线程的⾃动提交关掉。这样只要执⾏⼀个 select 语句，事务就启动，并不会⾃动提交，直到主动执⾏ commit 或 rollback 或断开连接。 建议使⽤⽅法⼀，如果考虑多⼀次交互问题，可以使⽤ commit work and chain 语法。在 autocommit=1 的情况下⽤ begin 显式启动事务，如果执⾏ commit 则提交事务。如果执⾏ commit work and chain 则提交事务并⾃动启动下⼀个事务。 快照InnoDB⾥⾯每个事务有⼀个 唯⼀的事务ID，叫作transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。 ⽽每⾏数据也都是有多个版本的。每次事务更新数据的时候，都会⽣成⼀个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。 也就是说，数据表中的⼀⾏记录，其实可能有多个版本(row)，每个版本有⾃⼰的row trx_id。 InnoDB利⽤了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能⼒。 更新数据都是先读后写的，⽽这个读，只能读当前的值，称为“当前读”(currentread)。 InnoDB的⾏数据有多个版本，每个数据版本有⾃⼰的row trx_id，每个事务或者语句有⾃⼰的⼀致性视图。普通查询语句是⼀致性读，⼀致性读会根据row trx_id和⼀致性视图确定数据版本的可⻅性。 对于可重复读，查询只承认在事务启动前就已经提交完成的数据； 对于读提交，查询只承认在语句启动前就已经提交完成的数据； ⽽当前读，总是读取已经提交完成的最新版本。你也可以想⼀下，为什么表结构不⽀持“可重复读”？这是因为表结构没有对应的⾏数据，也没有row trx_id，因此只能遵循当前读的逻辑。 RR 下解决幻读表象：快照读(非阻塞读)–伪MVCC 内在：是因为事务对数据加了next-key锁(行锁+gap锁) -gap锁会用在非唯一索引或者不走索引的当前读中 RC、RR 下的 InnoDB 的非阻塞读实现 RR 下可能读取到老的版本 RR 创建快照的时机决定了事务的版本 123456session1:UPDATE ... -- 1session2:SELECT -- 3SELECT ... LOCK IN SHARE MODE; -- 2 数据行中三个行隐藏参数： DB_TRX_ID: 最近一次对本行数据进行修改的数据 ID DB_ROW_PTR: 回滚指针， 指向 undo 日志 DB_ROW_ID: 无主件时隐式的 ID (2) undo 日志： 老版本 针对 Insert undo log, 针对 update undo log (3) read view: 可见性算法 MVCC: 读不加锁，读写不冲突，读多写少 伪 MVCC： 无法多版本共存 RR 避免 幻读 产⽣幻读的原因是，⾏锁只能锁住⾏，但是新插⼊记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引⼊新的锁，也就是间隙锁(Gap Lock)。 但是间隙锁不⼀样，跟间隙锁存在冲突关系的，是“往这个间隙中插⼊⼀个记录”这个操作。间隙锁之间都不存在冲突关系。 间隙锁和 next-key lock 的引⼊，帮我们解决了幻读的问题，但同时也带来了⼀些“困扰”。 间隙锁的引⼊，可能会导致同样的语句锁住更⼤的范围，这其实是影响了并发度的。 ⾏锁确实⽐较直观，判断规则也相对简单，间隙锁的引⼊会影响系统的并发度，也增加了锁分析的复杂度，但也有章可循 next-key 锁 行锁： Gap 锁： 锁定一个范围，不包含当前 () GAP 锁出现的时机 出现的场景： WHERE + INDEX where 条件全部命中，不会加 Gap Lock, 只会加 Record Lock where 条件部分命中，或全部不命中，加 Gap Lock; Gap 锁会用在非唯一索引或者不走 index 的当前读中： 非唯一索引 不走索引的当前读，尽量避免 MVCC Multiversion concurrency control 多版本并发控制。 并发访问（读或者写）数据库时，对正在事务内处理的数据做多版本的管理，用来避免由于写操作的堵塞，而引发读操作失败的并发问题。 Ref 《MySQL技术内幕：InnoDB存储引擎(第二版)》姜承尧","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"Java-Map类源码","date":"2021-04-08T16:59:34.000Z","path":"2021/04/09/Java-Map类源码/","text":"HashMap(JDK7)Hash 表结构几个重要的通用操作， hash 函数、hash 冲突、rehash 及扩容； 存储结构与初始化（1） 结构 底层结构中为每一个 Node 添加指向 prev, next 的引用 1transient Entry[] table; Entry 存储着键值对，为链表结构，数组每个位置相当于一个桶，桶中存放链表。借助其来处理 Hash 冲突。 123456class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash;&#125; （2） 初始化 ① 无参初始化； ② Map 传入初始化； ③ 指定初始化容量； ④ 执行初始化容量和负载因子； 1Map&lt;Obejct, Object&gt; map = new HashMap&lt;&gt;(x * 4/3); // loadFactor to prevent grow 操作1、hash 函数 | 元素定位 ① 整体的定位 12int hash = hash(key);int i = indexFor(hash, table.length); ② 具体的 hash 确定 通过多次移位和异或进行 hash 扰动，使其尽量不依赖于传入的 hashCode 的不均匀性； 123456789101112final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125;final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value);&#125; ③ 根据 hash 确定桶下标 123static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 2、get() 查找需要分成两步进行： 计算键值对所在的桶； 在链表上顺序查找，时间复杂度和链表的长度成正比； 1234567public V get(Object key) &#123; if (key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125; 3、put (1) 总体实现流程 ①判断初始化，未初始化则做对应的初始化 ②Null 值特殊处理，Null 无法调用 hashCode()，防止 NullPointerException ③确定桶下标 ④遍历链表，若重复直接覆盖并返回 ⑤为新加入元素，插入 &lt;K,V&gt; ⑥根据情况看是否需要扩容处理 1234567891011121314151617181920212223242526public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 键为 null 单独处理 if (key == null) return putForNullKey(value); int hash = hash(key); // 确定桶下标 int i = indexFor(hash, table.length); // 先找出是否已经存在键为 key 的键值对，如果存在的话就更新这个键值对的值为 value for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 插入新键值对 addEntry(hash, key, value, i); return null;&#125; （2） 对于 NULL 的插入处理 无法调用 null 的 hashCode() 方法，也就无法确定该键值对的桶下标，只能通过强制指定一个桶下标来存放。HashMap 使用第 0 个桶存放键为 null 的键值对。 12345678910111213private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; /*0 bucket*/ if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(0, null, value, 0); return null;&#125; （3） 处理 Hash 碰撞 头插法处理； 在容量阈值达到时，进行 2 倍扩容操作； 是一种添加之后，再进行扩容的行为，依赖的是上次添加完毕的情况； 12345678910111213141516void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; // 头插法，链表头部指向新的键值对 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 4、扩容 | rehash （1） 影响的变量 ① loadFactor： 负载因子时间上和空间上的一种平衡: ↑ 查找性能差, 空间利用率高； ↓ 查找性能高, 空间利用率低； ② size | threshold： size/capacity 达到负载因子时进行对应的扩容 ③ modCount：用来处理扩容时出现并发访问造成数据不一致，从而 fail-fast 1234567static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;transient int size;int threshold;final float loadFactor;transient int modCount; （2） 扩容实现 在负载因子达到给定值的情况下进行扩容； 扩容为原来数组的两倍； 需要将原来的 Entry 重新插入到新建的表中； 1234567void addEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); if (size++ &gt;= threshold) resize(2 * table.length); ...&#125; （3） rehash | 计算桶下标 在进行扩容时，需要把键值对重新放到对应的桶上。HashMap 使用了一个特殊的机制，可以降低重新计算桶下标的操作。 根据 hash 值在当前的高位上是否为 0，进行不同的处理。 为 0： 不需要移动 为 1： 移动偏移 原来容量对应的桶上； 123456789101112131415161718192021222324252627282930void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);&#125;void transfer(Entry[] newTable) &#123; Entry[] src = table; int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; src[j] = null; do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125; &#125;&#125; 其他（1） JDK7 与 JDK8 中 HashMap 的比较 ① 底层结构上： JDK8 采用 数组 + 链表 + 红黑树实现，长度过长转换成红黑树有效防范了 Hash 碰撞攻击； 将原来的 Entry 改为 Node，表示红黑树节点、链表节点； ② hash 函数： JDK8 只需要一次移位和异或即可，既能有效处理冲突上还保证了执行效率； ③ 处理 hash 冲突上： 在为链表时，通过尾插法进行处理，避免出现逆序且链表死循环问题； （2） 不安全体现 扩容时因为头插法而形成环形引用，造成无限循环，CPU 100%； put 操作可能造成丢失修改； HashMap(JDK8)底层结构与初始化（1） 整体结构 ① table： 存储节点类型，用于多态扩展 ② loadFactor： 负载因子，控制扩容的时机 ③ modCount： 控制迭代访问， fail-fast 12345transient Node&lt;K,V&gt;[] table; transient int size;transient int modCount;int threshold;final float loadFactor; （2） 节点与树化 ① 控制树化的时机： TREEIFY_THRESHOLD(8)： 链表元素大于该值的时候进行树化 UNTREEIFY_THRESHOLD(6)： TreeNode 中元素删除到该值时，将结构退化为链表，一般比 TREEIFY_THRESHOLD(8) 小，避免复杂度震荡 MIN_TREEIFY_CAPACITY(64): 在整个 HashMap 的容量小于该值的时候，即使单个桶中的元素达到 TREEIFY_THRESHOLD(8)，不会进行树化，会直接进行 rehash。 123static final int TREEIFY_THRESHOLD = 8;static final int UNTREEIFY_THRESHOLD = 6; /* prevent complexity oscillation */static final int MIN_TREEIFY_CAPACITY = 64; /* prevent resize and treeify conflict */ ② 链表节点结构： 123456class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next;&#125; ③ 红黑树节点结构： 继承 LinkedHashMap.Entry，便于从 tree 回退到 listNode 1234567static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red;&#125; 操作1、hash 函数 | 元素定位 一次异或一次移位进行 hash 扰动，避免依赖于原来 hashCode 处理键冲突，提高 hash 值的扩散性； 对于 null 的 KEY，直接使其 hash 值为 0，从而避免 NullPointerException； 1234int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 2、get() 执行过程： 定位到对应的桶看是否有该 KEY 首个节点为该 KEY，则直接返回 若为 TreeNode，进行红黑树的查找逻辑 若为 ListNode 进行链表的迭代遍历查找 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 3、put （1） 执行流程： ① 如果 HashMap 未被初始化过，则初始化； ② 对 Key 求 Hash 值，然后再计算下标； ③ 如果没有碰撞直接放入桶中； ④ 如果碰撞了，以链表的方式链接到后面； ⑤ 如果链表长度超过阀值，就把链表转成红黑树； ⑥ 如果链表长度低于 6，就把红黑树转回链表； ⑦ 如果节点已经存在就替换旧值； ⑧ 如果桶满了（容量 16 *加载因子 0.75 ），就需要 resize（扩容 2 倍后重排） （2） 额外功能： null 值处理： 直接通过 hash(key) 给 NULL KEY 为 0 的值； onlyIfAbsent： 实现 putIfAbsent() 方法逻辑，保留旧的值； afterNodeAccess，afterNodeInsertion： hook 钩子函数进行特殊处理，可用于 LinkedHashMap 实现 LRU； 123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) /* 初始情况 */ n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) /* 插入的桶无元素 */ tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; /* 第一个位置与插入的重复 */ ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) /* 是否树化 */ e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); /* 树化 */ break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) /* 总体的容量扩容 */ resize(); afterNodeInsertion(evict); return null;&#125; （3） Hash 冲突处理 对于链表的 hash 冲突 部分 putVal() 方法： 为了实现树化，需要统计链表中的个数，直接遍历到链表尾部，进行插入； 123456789101112for (int binCount = 0; ; ++binCount) &#123; // binCount 记录链表中的个数 if ((e = p.next) == null) &#123; /* 迭代到链表尾部 */ p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); /* 树化 */ break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e;&#125; 3、 扩容 | rehash 两种可能情况： 仍然在原来的位置 在原来的位置上偏移原来的容量 （1） 链表拆分 将原来的链表拆成两条链表，低位链表的数据将会到新数组的当前下标位置，高位链表的数据将会到新数组的当前下标+当前数组长度的位置； 12345678910111213141516171819202122232425262728Node&lt;K,V&gt; loHead = null, loTail = null;Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next;do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125;&#125; while ((e = next) != null);if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead;&#125;if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead;&#125; 4、 树化 （1） 链表转为红黑树 在挂接的链表大于 TREEIFY_THRESHOLD 时进行树化逻辑； 容器整体大于 MIN_TREEIFY_CAPACITY 时才允许树化，否则进行 resize； 1234567891011121314151617181920void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); /* 当前容量太小，直接扩容，防 resize 和 treeify 频繁性能损耗 */ else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; （2） 红黑树转变成链表 在红黑树节点数少于 UNTREEIFY_THRESHOLD(6) 时，进行结构转变； 12345678910111213141516171819// TreeNode.splitif (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125;&#125;if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125;&#125; ConcurrentHashMap(JDK7) ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。 底层结构与初始化（1） 全局结构 segmentShift | segmentMask： 用于快速定位到 Segment 的位置 1234final int segmentShift;final int segmentMask;final Segment&lt;K,V&gt;[] segments; // keep objectstatic final int DEFAULT_CONCURRENCY_LEVEL = 16; （2） Segment 结构 相当于一个带有锁的 HashMap(7) ① 继承自 ReentrantLock 从而实现并发加分段锁访问； ② 保存了 count 用于整个容器的统计，以及作为扩容的参考值； 默认情况下并发级别为 16； 123456789static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; // use for size() transient int modCount; transient int threshold; final float loadFactor;&#125; （3） HashEntry 结构 123456static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;&#125; 操作1、hash &amp; 定位 先整体进行了多次异或操作，进行 hash 扰动，将每位都用上。 通过 hash 借助 sementShift 和 segmentMask 来定位到对应的段上。 123final Segment&lt;K,V&gt; segmentFor(int hash) &#123; return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];&#125; 定位到 Entry，定位 Segment 使用的是元素的 hashcode 通过再散列后得到的值的高位，而定位 HashEntry 直接使用的是再散列后的值。其目的是避免两次散列后的值一样，虽然元素在 Segment 里散列开了，但是却没有 HashEntry 里散列开。 12hash &gt;&gt;&gt; segmentShift) &amp; segmentMask // 定位Segment所使用的hash算法int index = hash &amp; (tab.length - 1); // 定位HashEntry所使用的hash算法 2、get() 无锁获取值实现： 基于 volatile 来替代锁实现，由 JMM 提供的 happen before 原则保证可见性； 通过 hash 得出对应的散列值，之后通过 hash 定位到对应的段； 在桶中再进行 hash 得到对应的桶，只有在读取到 NULL 值时才进行加锁； 12345678910public V get(Object key) &#123; int hash = hash(key.hashCode()); return segmentFor(hash).get(key, hash);&#125;// Segment 中的总数transient volatile int count;// HashEntry 中的值volatile V value; 3、put() 判断是否需要扩容，不是添加之后进行判断的，在插入前进行判断，避免无效的扩容。 扩容仅仅是对当前的 Segment 进行扩容，无需对整个容器扩容。 4、size() 在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。 可能的两步操作： ① 先尝试通过 RETRIES_BEFORE_LOCK(2) 次借助 segment 中 volatile 保存的 count 相加，基于 modCount 来实现的； ② 若无法则对整个容器进行加锁统计所有 Segment 的大小； 12345678910111213141516171819202122232425262728293031323334353637383940static final int RETRIES_BEFORE_LOCK = 2;public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn&#x27;t retry try &#123; for (;;) &#123; // 过多 CAS 转换成对所有 Segment 加锁获取 if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; // 连续两次得到的结果一致，则认为这个结果是正确的 if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125; 其他（1） JDK7 与 JDK8 中 ConcurrentHashMap 的比较 ① 底层结构： 链表过长转换成红黑树 ② 同步机制： JDK7 采用分段锁实现，而 JDK8 可以有两种方案 尝试通过 CAS 来支持更高的并发度； 在 CAS 失败时通过内置锁 synchronized 锁住链表 | 红黑树的头结点； ConcurrentHashMap(JDK8) 五十几个内部类，Guava 中的 Cache 基于此实现。 无法存放 NULL。 底层结构与初始化（1） 底层结构 ① nextTable： 用于并发下的扩容操作 ② transferIndex： 在 rehash 情况下的标记索引 ③ counterCells： 用于并发下获取容量，不精确，与 LongAdder 类似 1234567transient volatile Node&lt;K,V&gt;[] table;transient volatile Node&lt;K,V&gt;[] nextTable;transient volatile long baseCount;transient volatile int sizeCtl;transient volatile int transferIndex;transient volatile int cellsBusy;transient volatile CounterCell[] counterCells; （2） 初始化 五种初始化方式： 前四种同 HashMap 初始化方式； ⑤ 初始容量、负载因子、并发级别： 含有并发级别控制； 并发级别基本不用，初始化用于与 initialCapacity 进行比较取最大值； 与 JDK7 进行兼容的处理逻辑； 操作1、hash 函数|定位 通过传入对象的 hashCode 来进行对应的处理 123static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125; 2、get() 12345678910111213141516171819public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 3、put() ① 判断 Node[] 数组是否初始化，没有则进行初始化操作 ② 通过 hash 定位数组的索引坐标，是否有 Node 节点，如果没有则使用 CAS 进行添加（链表的头节点），添加失败则进入下次循环。 ③ 检查到内部正在扩容，就帮助它一块扩容。 ④ 如果 f != null 则使用 synchronized 锁住 f 元素（链表/红黑二叉树的头元素） 4.1如果是Node（链表结构）则执行链表的添加操作。 4.2如果是TreeNode（树型结构）则执行树添加操作。 ⑤ 判断链表长度已经达到临界值 8 (default)节点数超过这个值就需要将链表转换为树结构。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; // may enter this loop many times Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) /* P1. not init */ tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; /* P2. 第一个桶位置为空, CAS添加 */ if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) /* P3. 其他线程正在扩容 */ tab = helpTransfer(tab, f); else &#123; /* 发生 hash 碰撞, 处理 listnode OR treenode, 只有此时才加锁, 其他情况都 CAS 循环尝试 */ V oldVal = null; synchronized (f) &#123; /* 使用第一个元素作为锁, 粒度比 Segment 分段锁更加细 */ if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; /* 链表的计数器 */ for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; /* 遍历到链表的结尾，在链表尾部添加节点 */ pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; /* 为树形结构的处理 */ Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) /* 判断是否需要树化, 在方法中还需处理当前是否到达树化的最小容量，否则进行扩容操作 */ treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125;&#125;addCount(1L, binCount); return null;&#125; 3、扩容 // todo HashTable 与 JDK7 的 HashMap 基本一致； 线程安全的同步容器； 底层结构与初始化（1） 底层结构 123456class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Entry&lt;K,V&gt; next;&#125; （2） 初始化容量为 11 123public Hashtable() &#123; this(11, 0.75f);&#125; 操作1、hash | 定位 直接通过取模实现； 效率较 HashMap 低； 12int hash = key.hashCode();int index = (hash &amp; 0x7FFFFFFF) % tab.length; 2、 扩容 | rehash 容量为 2*oldCapacity+1； 初始容量和扩容机制都与 HashMap 不同； 1int newCapacity = (oldCapacity &lt;&lt; 1) + 1; 3、 迭代方式 通过 Enumerator 实现，而非 Iterator。 1234567&lt;T&gt; Iterator&lt;T&gt; getIterator(int type) &#123; if (count == 0) &#123; return Collections.emptyIterator(); &#125; else &#123; return new Enumerator&lt;&gt;(type, true); &#125;&#125; 其他（1） 与 HashMap的区别 ① HashTable 设计上基于 Dictionary 实现，线程安全，执行效率低下，而 HashMap 基于 AbstractMap 实现，线程不安全，执行效率比 HashTable 高； ② NULL 值： HashMap 允许 NULL 值， HashTable 不允许； ③ 初始化与 hash 定位： HashTable 初始容量为 11，HashMap 初始容量为 16，HashTable 通过 % 的方式进行定位，HashMap 通过移位异或进行定位； ④ 迭代访问上： 两者实现的迭代不同，一个基于 Iterator，一个基于 Enumerator； LinkedHashMap默认保持元素插入属性的 Map； 可先通过 HashMap 来进行统计一些必要的数据，之后通过对 HashMap 的 KEY, VALUE 进行一些排序，将其变为有序的，使用 LinkedHashMap 来将这些顺序串联起来，之后进行对应的逻辑处理； 底层结构（1） 全局属性 ① accessOrder： 控制开启访问作为次序，可借助 LinkedHashMap 实现 LRU Cache; ② head|tail： 控制按照插入 | 访问顺序迭代； 123transient LinkedHashMap.Entry&lt;K,V&gt; head;transient LinkedHashMap.Entry&lt;K,V&gt; tail;final boolean accessOrder; （2） 节点 before | after 用于将节点连接起来方便遍历； HashMap.TreeNode 扩展此节点； 123456static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; 应用（1） LRU Cache 通过 HashMap 的 putVal() 中提供的两个 hook 钩子函数实现特有的功能； 根据 assessOrder 值不同，迭代出不同的结果。为 true，执行 LRU 顺序，访问过后移到链表尾部，头部为最近最久未使用节点； 为 false，执行插入顺序，与 List 语义相同； 123456789101112131415161718192021222324void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125;&#125; 在 put 等操作之后执行，当 removeEldestEntry() 方法返回 true 时会移除最晚的节点，也就是链表首部节点 first。 evict 只有在构建 Map 的时候才为 false，在这里为 true。 1234567void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125; removeEldestEntry() 默认为 false，如果需要让它为 true，需要继承 LinkedHashMap 并且覆盖这个方法的实现，这在实现 LRU 的缓存中特别有用，通过移除最近最久未使用的节点，从而保证缓存空间足够，并且缓存的数据都是热点数据。 123protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; （1-2） LinkedHashMap 实现的线程安全的 LRUCache 1234567891011121314151617181920212223private static final float DEFAULT_LOAD_FACTOR = 0.75f;private int capacity;private LinkedHashMap&lt;K,V&gt; cache;public LRUCache(int capacity) &#123; this.capacity = capacity; cache = new LinkedHashMap((int) Math.ceil(capacity/DEFAULT_LOAD_FACTOR) + 1, DEFAULT_LOAD_FACTOR, true)&#123; private static final long serialVersionUID = 223232L; @Override protected boolean removeEldestEntry(Map.Entry eldest) &#123; return cache.size() &gt;= capacity; &#125; &#125;;&#125;public synchronized V get(K key) &#123; return cache.get(key);&#125;public synchronized V put(K key, V val) &#123; return cache.put(key, val);&#125; （2） 借助多态将 HashMap 中的数据按照一定的规则进行排序 如 HashMap 存放的是词频，可以根据词频进行排序，之后迭代访问时就是词频从高到低的序列； 其他（1） 与 HashMap 的区别 ① 设计层面上： LinkedHashMap 是 HashMap 的子类； ② 底层结构及功能扩展上： LinkedHashMap 节点中添加了 before, after 用于保证顺序； ③ put 操作： LinkedHashMap 在继承的基础上重写 HashMap 中的 hook(钩子) 方法，在 LinkedHashMap 中向哈希表中插入新 Entry 的同时，还会通过 Entry 的 addBefore 方法将其链入到双向链表中。 ④ get 操作： LinkedHashMap 中重写了 HashMap 中的 get 方法，通过 HashMap 中的 getEntry 方法获取 Entry 对象。 在此基础上，进一步获取指定键对应的值。 ⑤ 在扩容操作上： 虽然 LinkedHashMap 完全继承了 HashMap 的 resize 操作，但是鉴于性能和 LinkedHashMap 自身特点的考量， LinkedHashMap 对其中的重哈希过程(transfer 方法)进行了重写。 TreeMap红黑树的实现 // todo X、其他 与 HashMap 的区别 ① 顺序性： TreeMap 可对按照 Key 的自然顺序或是传入的比较器进行排序； ② 存取效率上： O(1) VS O(logN)； ThreadLocalMap对于 ThreadLocal： 当使用 ThreadLocal 维护变量时，ThreadLocal 为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本； 是一种无锁同步方案； 是一种用空间换取时间来保证线程安全的方案； 多线程情况下，对应的子线程的 ThreadLocal 无法获取到父线程的 ThreadLocal，需要第三方工具包支持，可选择 alibaba 的 transmittable-thread-local 包； 1、底层结构 （1） 全局结构 1234static final int INITIAL_CAPACITY = 16;Entry[] table;int size = 0;int threshold; （2） Entry 继承自 WeakReference ，在无活跃线程或栈中持有时，在 GC 时就会被回收； 节点只保存值，ThreadLocalMap 不是使用链地址法来解决 Hash 冲突； 多个线程，只设置一个 ThreadLocal 变量，在这个线程中的 ThreadLocal 变量的值始终是只有一个的，即以前的值被覆盖了的。这里是因为 Entry 对象是以该 ThreadLocal 变量的引用为 key 的，所以多次赋值以前的值会被覆盖。 1234567static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; /* ThreadLocal as key */ super(k); value = v; &#125;&#125; （3） 定位 通过此来进行 hash 桶的定位； 1final int threadLocalHashCode = nextHashCode(); （4） 负载因子 0.66 空间利用率相较于 HashMap 的 0.75 较低，但加快查询； 同时配合开放地址法来快速定位到空闲的桶； 123private void setThreshold(int len) &#123; threshold = len * 2 / 3;&#125; 操作1、hash() 没有扰动函数，通过 ThreadLocal 中保存的 threadLocalHashCode 来实现； threadLocalHashCode 根据维护的 AtomicInteger nextHashCode 获取； 12345678// ThreadLocalprivate final int threadLocalHashCode = nextHashCode();private static AtomicInteger nextHashCode = new AtomicInteger();private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125;// ThreadLocalMap.getEntryint i = key.threadLocalHashCode &amp; (table.length - 1); 2、get() 12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125; 3、set() ① 先获取到 ThreadLocal 键的 thresholdLocalHashCode ，以此来确定对应的桶下标； ② 如果在该位置正好与当前进行重合，直接覆盖； ③ 如果该位置无元素，则将其放入该位置； ④ 上面两个都不满足的情况下，使用线性探测法不断寻找到对应的满足上述两个条件的位置； ⑤ 上述都不满足，创建一个节点，并清理一些桶位，之后进行重新 hash ； 1234567891011121314151617181920212223242526272829303132private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don&#x27;t use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; // bucket position e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) // add node need to clean some object rehash();&#125; 4、扩容 | rehash （1） rehash 123456void rehash() &#123; expungeStaleEntries(); // Use lower threshold for doubling to avoid hysteresis if (size &gt;= threshold - threshold / 4) resize();&#125; （2） resize 扩容为原来的两倍 123456789101112131415161718192021222324252627void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125; 其他（1）与 HashMap 的比较 ① 底层结构： ThreadLocalMap 只有数组，HashMap 通过数组 + 链表(Tree) 方式 节点引用类型： ThreadLocalMap 节点为弱引用，会下一次 GC 被回收 ② hash： 并发下通过 AtomicInteger 实现 ③ hash 冲突处理： ThreadLocalMap 通过线性探测法实现的，HashMap 通过链地址法实现； WeakHashMap底层结构（1）节点 与 Entry 继承 WeakReference，当前 Entry 需要引用队列来进行处理； 1234567891011121314151617// 成员ReferenceQueue&lt;Object&gt; queue = new ReferenceQueue&lt;&gt;();// 单独的 Entryprivate static class Entry&lt;K,V&gt; extends WeakReference&lt;Object&gt; implements Map.Entry&lt;K,V&gt; &#123; V value; final int hash; Entry&lt;K,V&gt; next; Entry(Object key, V value, ReferenceQueue&lt;Object&gt; queue, int hash, Entry&lt;K,V&gt; next) &#123; /* must use reference queue */ super(key, queue); this.value = value; this.hash = hash; this.next = next; &#125;&#125; 操作1、hash | 定位 通过四次异或来进行 hash 扰动，使其少依赖于原始的 hashCode() 12345678final int hash(Object k) &#123; int h = k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125;int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 2、put NULL 值： 对 NULL 的 KEY 处理机制，将 NULL 作为指向一个对象进行存储 1234static final Object NULL_KEY = new Object();private static Object maskNull(Object key) &#123; return (key == null) ? NULL_KEY : key;&#125; Ref 《Java并发编程的艺术》方腾飞 / 魏鹏 / 程晓明","tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"源码","slug":"源码","permalink":"http://example.com/tags/%E6%BA%90%E7%A0%81/"}]},{"title":"Java-集合类源码","date":"2021-04-08T15:18:17.000Z","path":"2021/04/08/Java-集合类源码/","text":"ListArrayList基本性质： 底层基于数组保存； 增删慢、随机查询快； 线程不安全； 底层结构与初始化（1） 结构 123transient Object[] elementData; int size;transient int modCount = 0; （2） 加载和初始化 懒加载形式，在 add() 时进行对应的初始化； 共支持三种初始化方式： ① 无参构造： 默认不进行数据的初始化； ② 给定容量： 程序中通过给定容量来优化； ③ 通过放入 Collection 接口进行初始化； 123456789101112131415161718192021222324252627282930313233static final int DEFAULT_CAPACITY = 10;private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125;public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); &#125;&#125;public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125;import com.google.common.collect.Lists;// 使用 Guava 创建指定容量的 ListList&lt;String&gt; list = Lists.newArrayListWithCapacity(oldList.size()); 操作1、add ① 默认插入尾部，O(1) 实现； ② 任意位置插入 将插入位置后的所有元素右移一位，之后在插入位置赋值； 插入的开销与插入的位置有关； 123456789101112131415public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); /* 右移一位 */ elementData[index] = element; size++;&#125; 2、remove 需要调用 System.arraycopy() 将 index + 1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，开销大； 同 add() 操作，删除与位置紧密相关； 12345678910public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; 3、 扩容 扩容后的大小为 oldN * 1.5 + 1； 通过 Arrays.copyOf() 复制到新数组中； 可通过指定初始容量的方式，来减少扩容的次数，减少不必要的开销； 12345678910111213141516171819202122232425262728293031public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); /* init capacity */ &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); /* copy to impl. */ elementData = Arrays.copyOf(elementData, newCapacity);&#125; 4、 迭代访问 采用快速失败模式实现； 通过成员变量 modCount 与 expectedModCount 比较实现； 主要用在序列化获得迭代操作时进行判断，对应抛出 ConcurrentModificationException； 5、序列化 只序列化数组中存放值的这些部分。 ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。 1transient Object[] elementData; // not serialize 通过 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。 1234567891011121314151617181920212223242526272829303132333435363738private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; int expectedModCount = modCount; /* keep to compare */ s.defaultWriteObject(); /* only have space */ s.writeInt(size); for (int i=0; i&lt;size; i++) &#123; /* only write have element */ s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; /* use for fail-fast */ throw new ConcurrentModificationException(); &#125;&#125;private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; s.defaultReadObject(); s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125;// 将 list 序列化到指定文件ArrayList list = new ArrayList();ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file));oos.writeObject(list); 其他（1） ArrayList 与 Array 的比较 ① 存储类型： Array 可以存放基本和对象类型， ArrayList 只能存放对象类型； ② 存放元素的大小： ArrayList 动态可变，Array 不可变; ③ 其他方法和特性： ArrayList 提供 addAll()，removeAll()，iterator() 等方法; 对于基本类型数据，集合使用自动装箱来减少编码工作量。但当处理固定大小的基本数据类型的时候，这种方式相对比较慢。 （2）ArrayList 与 LinkedList 的比较 都是线程不安全的容器，都实现了 List 接口具备 List 的特性。 ① 底层结构： ArrayList 基于索引的数据接口，底层是动态数组实现，LinkedList 以元素列表的形式存储数据，是双向链表实现； ② 操作性质： 随机访问： ArrayList 支持随机访问，LinkedList 不支持； 元素删除： LinkedList 在任意位置添加删除元素更快； 操作是否与元素位置的影响： 比较插入和删除是否受元素位置影响，ArrayList 插入和删除受元素位置影响，add(e) 默认追加到末尾，在指定位置 i 插入和删除时复杂度为 O(n-i)，而 LinkedList 链表存储，插入和删除不受位置影响； ③ 内存占用上： LinkedList 存放两个指针，相同数据量下占用更多的空间； （3） ArrayList 与 Vector 的比较 同步性： Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。 扩容： Vector 每次扩容请求其大小的 2 倍空间，而 ArrayList 是 1.5 倍。且 Vector 可以设置增长空间的大小。 LinkedList基本性质： 基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。 线程不安全； LinkedList 可以用作栈、队列和双向队列。 底层结构与初始化（1） 结构 通过记录 first, last, size 便于边界操作（注：用于队列、栈、双端队列） 队列中每个节点都存放元素，存在初始化情况； 12345678transient int size = 0;transient Node&lt;E&gt; first;transient Node&lt;E&gt; last;class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev;&#125; （2） 初始化 不支持初始情况下给定对应的容量，即基于链表都为无界队列； 123456public LinkedList() &#123;&#125;public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 操作1、add 添加元素, 最后元素与中间元素, 可处理头结点位置。 12345678910111213141516171819202122232425262728293031public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) /* init 处理 */ first = newNode; else pred.next = newNode; size++; modCount++;&#125; 2、remove 操作不受指定位置的影响； 为双向链表中指定节点的删除； 1234567891011121314151617181920212223242526272829public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125; Vector基本性质： 底层基于数组保存元素； 随机查询快，增删慢； 线程安全； Java 中的 Stack 通过继承 Vector 实现的； 底层结构与初始化（1） 结构 ① elementCount：初始容量为 10，非懒加载实现； ② capacityIncrement；可以设置每次容量的增长数量； ③ 无 modCount： 同步容器； 123Object[] elementData;int elementCount;int capacityIncrement; （2） 初始化 支持 ArrayList 的各种初始化； 支持设置每次的扩容时的容量增长； 1234567891011public Vector() &#123; this(10);&#125;public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement;&#125; 操作1、add / get 对修改底层结构的函数进行加锁同步访问。 12345678910111213public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125;public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);&#125; 2、扩容机制 默认扩容为 oldN * 2； 可以通过用户设置的正常数量进行控制扩容大小； 1234567891011void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? /* 默认扩容 1 倍 */ capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);&#125; 其他替代方案 因为 Vector 通过加锁实现，粒度大效率低。 （1） 获得对应线程不安全容器的同步容器 12List&lt;String&gt; list = new ArrayList&lt;&gt;();List&lt;String&gt; synList = Collections.synchronizedList(list); （2） 使用并发容器，如 CopyOnWriteArrayList 1List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); CopyOnWriteArrayList基本性质： 易引起 YongGC, FullGC 不可用于实时的数据， 写操作复制防止并发修改不一致 适合读多写少的情景 读操作无需加锁，写操作加锁 三个设计思想： 读写分离 最终一致性 新开辟空间，解决并发冲突 底层结构与初始化（1） 结构 ① ReentrantLock： 通过此来实现并发访问 1234final transient ReentrantLock lock = new ReentrantLock();transient volatile Object[] array;static final long lockOffset;static final sun.misc.Unsafe UNSAFE; （2） 初始化 三种初始化方式： LinkedList 的初始化方式 支持泛型数组初始化 123public CopyOnWriteArrayList(E[] toCopyIn) &#123; setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class));&#125; 操作(1) add 并发下安全的容器，需要处理并发访问问题、处理复制问题。 包含 lock 加锁获取与释放： ① 获取原数组 ② 复制出 len+1 的数组 ③ 为新数组末尾复制 ④ 修改内部数组指向 123456789101112131415161718boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); /* 获取原数组, volatile 保证可见性 */ int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); /* 复制数组 */ newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125;final void setArray(Object[] a) &#123; array = a;&#125; (2) get 无需加锁直接访问, 在 add 操作的同时可访问旧有的数据 ⇒ 实时性得不到保证 。 123456E get(int index) &#123; return get(getArray(), index);&#125;E get(Object[] a, int index) &#123; return (E) a[index];&#125; 3、迭代方式 通过安全失败实现，将当前数组放入到 Iterator 实现类中作为快照访问。 123public Iterator&lt;E&gt; iterator() &#123; return new COWIterator&lt;E&gt;(getArray(), 0);&#125; 迭代器中保存某个时间点下底层数组的快照，通过 cursor 来进行向前迭代访问。 1234567891011final Object[] snapshot;int cursor;COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements;&#125;E next() &#123; if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++];&#125; 其他（1） 读写分离 写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响； 写操作需要加锁，防止并发写入时导致写入数据丢失； 写操作结束之后需要把原始数组指向新的复制数组； （2）适用场景 CopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。 （3） 缺陷 内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右； 数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中。 所以 CopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景。 SetHashSet底层结构与初始化通过一个 HashMap 实现，对应的 Value 为指定的一个 Object 12private transient HashMap&lt;E,Object&gt; map;private static final Object PRESENT = new Object(); 操作1、add 123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 2、remove 123public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; LinkedHashSet基于 LinkedHashMap 实现, HashSet 的子类。 1234567891011SetHashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125;public class LinkedHashSet&lt;E&gt; extends HashSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; public LinkedHashSet() &#123; super(16, .75f, true); &#125;&#125; TreeSet与 HashSet 的区别 ① 底层结构：HashSet 基于 hash 表实现，元素无序， 一些方法 add(), remove(), contains() 复杂度为 O(1)； ② 有序性： TreeSet 基于红黑树实现，元素有序， add(), remove(), contains() 复杂度为 O(logN)； QueuePriorityQueue基本性质： 有序的优先队列； 不可以存放 NULL，NULL 无自然顺序； 非线程安全，入队和出队的时间复杂度为 O(logN)； 基于堆结构实现，默认情况下为最小堆； 底层结构与初始化（1） 底层结构 数组保存的完全二叉树，首元素存放元素值。 堆顶元素有序，默认情况下为最小堆。 comparator： 默认自定义比较器优先于存入对象的自然排序进行比较 1234transient Object[] queue; int size = 0;final Comparator&lt;? super E&gt; comparator;transient int modCount = 0; （2） 初始化 可指定初始容量与比较器； 1234567static final int DEFAULT_INITIAL_CAPACITY = 11;PriorityQueue(Comparator&lt;? super E&gt; comparator) &#123; this(DEFAULT_INITIAL_CAPACITY, comparator);&#125;PriorityQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator); 操作（1） offer 实现： 先将元素放到完全二叉树的尾节点 之后不断上浮调整结构使其符合堆特性 辅助-shiftUp 上浮函数，用于维护最小堆的结构。 赋值替换交换优化； 找出正确位置并放入； 123456789101112void siftUpComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;) x; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = queue[parent]; if (key.compareTo((E) e) &gt;= 0) break; queue[k] = e; k = parent; &#125; queue[k] = key;&#125; （2） poll 弹出当前堆顶元素。 实现： 保存堆顶元素； 将堆顶与最末叶子节点交换，之后通过堆顶下沉实现结构的维护； siftDown，下沉函数，最小堆的结构； 通过赋值来替换掉交换操作； 找到元素应该放入的正确位置放入； 1234567891011121314151617void siftDownComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;)x; int half = size &gt;&gt;&gt; 1; // loop while a non-leaf while (k &lt; half) &#123; int child = (k &lt;&lt; 1) + 1; // assume left child is least Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; ((Comparable&lt;? super E&gt;) c).compareTo((E) queue[right]) &gt; 0) c = queue[child = right]; if (key.compareTo((E) c) &lt;= 0) break; queue[k] = c; k = child; &#125; queue[k] = key;&#125; （3） remove remove(o) 删除一个对象，为 Collection 中的方法，需要先进行向下调整后进行向上调整； 实现： 最末叶子节点赋值到当前删除的位置； 让原来的最末叶子节点向下调整； 若结构不合法则向上调整； 123456789101112131415161718E removeAt(int i) &#123; // assert i &gt;= 0 &amp;&amp; i &lt; size; modCount++; int s = --size; if (s == i) // removed last element queue[i] = null; else &#123; E moved = (E) queue[s]; /* 最末叶子节点赋值到当前删除的位置 */ queue[s] = null; siftDown(i, moved); /* 让原来的最末叶子节点向下调整 */ if (queue[i] == moved) &#123; /* 结构不合法向上调整 */ siftUp(i, moved); if (queue[i] != moved) return moved; &#125; &#125; return null;&#125; （4） heapify 初始传入为 Collection 进行堆化处理，借助原始结构，从中间处向上不断下沉处理，相比较每次插入到最末叶子节点进行向上调整效率更高； 完全二叉树中间节点位置 size / 2 - 1； 12345678void initFromCollection(Collection&lt;? extends E&gt; c) &#123; initElementsFromCollection(c); heapify();&#125;void heapify() &#123; for (int i = (size &gt;&gt;&gt; 1) - 1; i &gt;= 0; i--) /* 完全二叉树从上层节点不断向下调整实习 */ siftDown(i, (E) queue[i]);&#125; 3、扩容 小数据量快速 2 * oldCapacity + 2 扩容，容量大于 64 后进行 1.5 * oldCapacity 扩容； 1234567891011void grow(int minCapacity) &#123; int oldCapacity = queue.length; // Double size if small; else grow by 50% int newCapacity = oldCapacity + ((oldCapacity &lt; 64) ? (oldCapacity + 2) : (oldCapacity &gt;&gt; 1)); // overflow-conscious code if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); queue = Arrays.copyOf(queue, newCapacity);&#125; 4、迭代访问 通过双向队列 ArrayDeque 实现 1234567class Itr implements Iterator&lt;E&gt; &#123; int cursor = 0; int lastRet = -1; ArrayDeque&lt;E&gt; forgetMeNot = null; E lastRetElt = null; int expectedModCount = modCount;&#125; 其他使用场景 贪心算法选择局部最优； 图论中使用进行优化； 实现哈夫曼树等结构； ArrayDeque基于数组实现的双向队列； 可使用 Stack 的 API; 底层结构与初始化(1) 底层结构 一个数组，两个索引指向队列的头节点和尾部节点。 1234transient Object[] elements;transient int head;transient int tail;private static final int MIN_INITIAL_CAPACITY = 8; (2) 初始化 12345678910public ArrayDeque() &#123; elements = new Object[16];&#125;public ArrayDeque(int numElements) &#123; allocateElements(numElements);&#125;public ArrayDeque(Collection&lt;? extends E&gt; c) &#123; allocateElements(c.size()); addAll(c);&#125; UtilArrays1、sort JDK 中的排序都为稳定排序 算法的执行逻辑： 小数据量使用 INSERT 排序 一定规模数据量使用 QUICK 排序 大数据量使用 MERGE 排序 并非所有大数据量都是 Merge Sort，在不具备结构性时转换成 Quick Sort； （1） 归并排序 ① 小数据量转快速排序 ② 通过分配当前大小进行 merge ③ 判断排序数组的结构，不具有时使用快速排序 1234567891011121314151617181920212223static void sort(int[] a, int left, int right, int[] work, int workBase, int workLen) &#123; // Use Quicksort on small arrays if (right - left &lt; QUICKSORT_THRESHOLD) &#123; sort(a, left, right, true); return; &#125; int[] run = new int[MAX_RUN_COUNT + 1]; /* aux space to merge */ int count = 0; run[0] = left; // Check if the array is nearly sorted for (int k = left; k &lt; right; run[count] = k) &#123; // ... /* * The array is not highly structured, * use Quicksort instead of merge sort. */ if (++count == MAX_RUN_COUNT) &#123; sort(a, left, right, true); return; &#125; &#125; // ...&#125; （2） 快速排序 ① 小数据量插入排序 1234567static void sort(int[] a, int left, int right, boolean leftmost) &#123; int length = right - left + 1; // Use insertion sort on tiny arrays if (length &lt; INSERTION_SORT_THRESHOLD) &#123; if (leftmost) &#123; &#125; ② 逻辑实现 通过双枢纽元分割实现； 类似 BFPRT 算法中对于枢纽元的选取，将原来期望的复杂度转换成确定的复杂度； 12345678910111213141516171819202122232425262728left part center part right part +--------------------------------------------------------------+ | &lt; pivot1 | pivot1 &lt;= &amp;&amp; &lt;= pivot2 | ? | &gt; pivot2 | +--------------------------------------------------------------+ ^ ^ ^ | | | less k great left part center part right part +----------------------------------------------------------+ | == pivot1 | pivot1 &lt; &amp;&amp; &lt; pivot2 | ? | == pivot2 | +----------------------------------------------------------+ ^ ^ ^ | | | less k great Partitioning degenerates to the traditional 3-way (or &quot;Dutch National Flag&quot;) schema: left part center part right part +-------------------------------------------------+ | &lt; pivot | == pivot | ? | &gt; pivot | +-------------------------------------------------+ ^ ^ ^ | | | less k great （3） 插入排序 为快速排序中的子过程实现； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960if (length &lt; INSERTION_SORT_THRESHOLD) &#123; if (leftmost) &#123; /* * Traditional (without sentinel) insertion sort, * optimized for server VM, is used in case of * the leftmost part. */ for (int i = left, j = i; i &lt; right; j = ++i) &#123; int ai = a[i + 1]; while (ai &lt; a[j]) &#123; a[j + 1] = a[j]; if (j-- == left) &#123; break; &#125; &#125; a[j + 1] = ai; &#125; &#125; else &#123; /* * Skip the longest ascending sequence. */ do &#123; if (left &gt;= right) &#123; return; &#125; &#125; while (a[++left] &gt;= a[left - 1]); /* * Every element from adjoining part plays the role * of sentinel, therefore this allows us to avoid the * left range check on each iteration. Moreover, we use * the more optimized algorithm, so called pair insertion * sort, which is faster (in the context of Quicksort) * than traditional implementation of insertion sort. */ for (int k = left; ++left &lt;= right; k = ++left) &#123; int a1 = a[k], a2 = a[left]; if (a1 &lt; a2) &#123; a2 = a1; a1 = a[left]; &#125; while (a1 &lt; a[--k]) &#123; a[k + 2] = a[k]; &#125; a[++k + 1] = a1; while (a2 &lt; a[--k]) &#123; a[k + 1] = a[k]; &#125; a[k + 1] = a2; &#125; int last = a[right]; while (last &lt; a[--right]) &#123; a[right + 1] = a[right]; &#125; a[right + 1] = last; &#125; return;&#125; 2、binarySearch 计算 mid mid = (low + high) &gt;&gt;&gt; 1 12345678910111213141516171819202122// Like public version, but without range checks.private static int binarySearch0(Object[] a, int fromIndex, int toIndex, Object key) &#123; int low = fromIndex; int high = toIndex - 1; while (low &lt;= high) &#123; int mid = (low + high) &gt;&gt;&gt; 1; // @SuppressWarnings(&quot;rawtypes&quot;) Comparable midVal = (Comparable)a[mid]; @SuppressWarnings(&quot;unchecked&quot;) int cmp = midVal.compareTo(key); if (cmp &lt; 0) low = mid + 1; else if (cmp &gt; 0) high = mid - 1; else return mid; // key found &#125; return -(low + 1); // key not found.&#125; 3、asList / subList 不推荐使用，返回的 List 修改会有问题。 Collections1、提供一些容器的空实现：作为容器为空的情况下的返回值，规避空指针问题。 1234public static final List EMPTY_LIST = new EmptyList&lt;&gt;();public static final &lt;T&gt; List&lt;T&gt; emptyList() &#123; return (List&lt;T&gt;) EMPTY_LIST;&#125; 2、提供单个元素的集合： 方便传递方法的参数 123public static &lt;T&gt; List&lt;T&gt; singletonList(T o) &#123; return new SingletonList&lt;&gt;(o);&#125; 3、sort JDK8 中借助 List 中自带的 sort() 函数调用实现； 4、binarySearch 对 List 进行二分搜索 根据底层是数组还是链表采用不同的处理： ① 数组： 数组随机访问定位实现 ② 链表： 接着 ListIterator 实现二分查找 在 binarySearch（）⽅法中，它要判断传⼊的list 是否 RamdomAccess 的实例，如果是，调⽤ indexedBinarySearch() ⽅法，如果不是，那么调⽤ iteratorBinarySearch() ⽅法 1234567public static &lt;T&gt; int binarySearch(List&lt;? extends Comparable&lt;? super T&gt;&gt; list, T key) &#123; if (list instanceof RandomAccess || list.size()&lt;BINARYSEARCH_THRESHOLD) return Collections.indexedBinarySearch(list, key); else return Collections.iteratorBinarySearch(list, key);&#125; 5、提供将不安全的容器转换为同步容器 1public static &lt;T&gt; List&lt;T&gt; synchronizedList(List&lt;T&gt; list)","tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"源码","slug":"源码","permalink":"http://example.com/tags/%E6%BA%90%E7%A0%81/"}]},{"title":"Hive-优化","date":"2021-03-09T13:33:13.000Z","path":"2021/03/09/Hive-优化/","text":"[TOC] 影响 Hive 效率的几乎从不是数据量过大，而是数据倾斜、数据冗余、Job / IO过多、MapReduce 分配不合理等。 架构优化执行引擎选择通过参数 hive.execution.engine 控制，可选 MapReduce, Tez, Spark, Flink 作为执行引擎，在离线数仓中，批处理方面主要使用 Spark 优化器的使用在真正执行计算之前，生成和优化逻辑执行计划与物理执行计划。 Vectorize 矢量化查询执行 Cost-Based Optimization: CBO 成本优化器 矢量化查询执行 要求执行引擎为Tez, 执行通过一次批量执行1024行而不是每行一行来提高扫描，聚合，过滤器和连接等操作的性能, 可一显着缩短查询执行时间。 需要使用 orc 格式存储数据 123-- 开启 set hive.vectorized.execution.enabled = true;set hive.vectorized.execution.reduce.enabled = true; 成本优化器 基于apache Calcite的，Hive的CBO通过查询成本(有analyze收集的统计信息)会生成有效率的执行计划，最终会减少执行的时间和资源的利用 可定期执行表的分析，分析后数据存放在元数据库中 123456789-- 从 v0.14.0默认SET hive.cbo.enable=true; true-- 默认falseSET hive.compute.query.using.stats=true; -- 默认falseSET hive.stats.fetch.column.stats=true; -- 默认trueSET hive.stats.fetch.partition.stats=true; 文件格式Parquet 和 ORC 都是 Apache 旗下的开源列式存储格式。列式存储比起传统的行式存 储更适合批量 OLAP 查询，并且也支持更好的压缩和编码。 选择 Parquet 的原因主要是它支持 Impala 查询引擎，并且对 update、delete 和事务性操作需求很低。 选择 ORCFile 支持事务操作。 数据压缩压缩的配置可以在hive的命令行中或者hive-site.xml文件中进行配置。 1SET hive.exec.compress.intermediate=true DEFLATE GZIP: 扩展名 .gz Bzip2: 支持分割, 扩展名 .gz LZO： LZ4： Snappy: 不支持分割 可在mapred-site.xml, hive-site.xml 配置，命令行配置 12345SET hive.intermediate.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;SET hive.exec.compress.output=true;SET mapreduce.output.fileoutputformat.compress.codec =org.apache.hadoop.io.compress.SnappyCodc 分区、分桶表设计成分区表可以提升查询的性能，对于一个特定分区的查询，只会加载对应分区路 径的文件数据 尽量避免层级较深的分区 日期或时间。如year、month、day或者hour， 地理位置。如国家、省份、城市 业务逻辑。如部门、销售区域、客户 分桶表 分桶表的组织方式是将HDFS上的文件分割成多个文件。 分桶可以加快数据采样，也可以提升join的性能(join的字段是分桶字段)，因为分桶可 以确保某个key对应的数据在一个特定的桶内(文件)，巧妙地选择分桶字段可以大幅 度提升join的性能。 分桶字段可以选择经常用在过滤操作或者join操作的字段。 参数优化本地模式支持将作业动态地转为本地模式, 当Hive处理的数据量较小时，启动分布式去处理数据会有点浪费。 一个作业只要满足下面的条件，会启用本地模式 输入文件的大小小于 hive.exec.mode.local.auto.inputbytes.max 配置的大小 map 任务的数量小于 hive.exec.mode.local.auto.input.files.max 配置的大小 reduce 任务的数量是1或者0 123SET hive.exec.mode.local.auto=true; -- 默认 falseSET hive.exec.mode.local.auto.inputbytes.max=50000000;SET hive.exec.mode.local.auto.input.files.max=5; -- 默认 4 严格模式强制不允许用户执行3种有风险的HiveQL语句，一旦执行会直接失败。 查询分区表时不限定分区列的语句； 两表 join 产生了笛卡尔积的语句； 用 order by 来排序，但没有指定 limit 的语句。 12-- DEFAULT strictset hive.mapred.mode=nostrict JVM 重用Hadoop可以重用 JVM，通过共享 JVM 以串行而非并行的方式运行 map 或者 reduce。 避免 JVM 启动进程所耗费的时间会比作业执行的时间还要长。 JVM的重用适用于同一个作业的 map 和 reduce，对于不同作业的 task 不能够共享 JVM。 开启JVM重用将一直占用使用到的 task 插槽，以便进行重用，直到任务完成后才能释放。 如果某个“不平衡的”job中有某几个reduce task执行的时间要比其他Reduce task消耗的时间多的多的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的task都结束了才会释放。 12-- 代表同一个MR job中顺序执行的5个task重复使用一个JVM，减少启动和关闭的开销SET mapreduce.job.jvm.numtasks=5; 并行执行Hive 将查询转换成一个或多个阶段，MapReduce 阶段、抽样阶段、合并阶段、Limit 阶段.. 默认情况下一次只执行一个阶段，对于特定 Job 有多个阶段，阶段间非完全相互依赖，并行执行，可以缩短 job 的执行时间。 1234-- 默认falseSET hive.exec.parallel=true; -- 默认8SET hive.exec.parallel.thread.number=16; 推测执行在分布式集群环境下，因为程序Bug、负载不均衡、资源分布不均、网络情况等原因，会造成同一个作业的多个任务之间运行速度不一致，有些任务的运行速度可能明显慢于其他任务, 这些任务会拖慢作业的整体执行进度。 Hadoop采用了推测执行机制，它根据一定的规则推测出 “拖后腿” 的任务，并为这样的任务启动一个备份任务，让该任务与原始任务同时处理同一份数据，并最终选用最先成功运行完成任务的计算结果作为最终结果。 123set mapreduce.map.speculative=trueset mapreduce.reduce.speculative=trueset hive.mapred.reduce.tasks.speculative.execution=true 合并小文件在map执行前合并小文件，减少map数 12-- 缺省参数set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat 在Map-Reduce的任务结束时合并小文件 1234567891011-- 在 map-only 任务结束时合并小文件，默认trueSET hive.merge.mapfiles = true;-- 在 map-reduce 任务结束时合并小文件，默认falseSET hive.merge.mapredfiles = true;-- 合并文件的大小，默认256MSET hive.merge.size.per.task = 268435456;-- 当输出文件的平均大小小于该值时，启动一个独立的 map-reduce 任务进行文件mergeSET hive.merge.smallfiles.avgsize = 16777216; Fetch 模式Fetch 模式是指 Hive 中对某些情况的查询可以不必使用 MapReduce 计算 在开启 fetch 模式之后，在全局查找、字段查找、limit 查找等都不启动 MapReduce 123-- Default Value: minimal in Hive 0.10.0 through 0.13.1, -- more in Hive 0.14.0 and laterhive.fetch.task.conversion=more SQL 优化列裁剪和分区裁剪列裁剪： SELECT 只查需要的列。少用 SELECT * 分区裁剪: 只读取需要的列。在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where 后面，那么就会先全表关联，之后再过滤。 1234# 列裁剪优化相关的配置项, default truehive.optimize.cp=true# 分区裁剪优化, default truehive.optimize.pruner=true 谓词下推在 RDBMS 中，如 MySQL 也有 Predicate Pushdown(PPD) 的概念，将 SQL 语句中的 where 谓词逻辑尽可能提前执行，减少下游处理的数据量。 如下的 SQQ， forum_topic 表过滤的 where 语句卸载子查询内部，而不是外部，Hive 谓词下推逻辑优化器是 PredicatePushDown，该优化器将 OperatorTree 中的 FilterOperator 向上提。 123456789select a.uid,a.event_type,b.topic_id,b.titlefrom calendar_record_log aleft outer join (select uid,topic_id,title from forum_topicwhere pt_date = 20190224 and length(content) &gt;= 100) b on a.uid = b.uidwhere a.pt_date = 20190224 and status = 0;# 谓词下推优化的配置项, default truehive.optimize.ppd = true sort by 代替 order by为了控制 map 端数据分配到 reducer 的 key, 需要配置 distribute by 一起使用，如果不加 distribute by 的话，map 端数据就会随机分配到 reducer。 123456-- 以UID为key，以上传时间倒序、记录类型倒序输出记录数据select uid,upload_time,event_type,record_datafrom calendar_record_logwhere pt_date &gt;= 20190201 and pt_date &lt;= 20190224distribute by uidsort by upload_time desc,event_type desc; group by 代替 count(distinct)去重计算数据量大时不好处理，数据量大的时候用一个 ReduceTask 来完成，导致整个 Job 很难完成 。 一般 COUNT DISTINCT 使用先 GROUP BY 再 COUNT 的方式替换。使用 group by 替换后， SQL 如下，会启动两个 MR Job，确保启动 Job 开销远小于计算耗时的时候使用。 12345select count(1) from ( select uid from calendar_record_log where pt_date &gt;= 20190101 group by uid) t; group by 配置调整并不是所有的聚合操作都需要在 Reduce 端完成，可现在 Map 端进行部分聚合，最后在 Reduce 端得出最终结果 hive.map.aggr=true: 是否在 Map 端进行聚合 hive.groupby.napaggr.checkinterva=10000: 在 Map 端进行聚合操作的条目数目 hive.groupby.skewindata=true: 有数据倾斜的时候进行负载均衡，默认 false 当选项设定为 true，生成的查询计划会有两个 MR Job。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。 join 基础优化map join 分桶 join 大表 join 大表处理空值或无意义值(1) 空 key 过滤 大表 Join 大表时，key 有大量的异常数据，相同的 key 发送到相同的 reducer 上，从而导致内存不够，结果 Join 的时候耗时长，可先通过 SQL 对其进行过滤。 (2) 空 key 转化 空 Key 转化，key 非异常数据，必须包含在 join 的结果中，可对为空的 key 设置随机值，使数据随机均匀分到不同的 reducer 上，防止数据的倾斜问题 … 单独处理倾斜 key调整 Map 数通常情况下，作业通过 Input 目录产生一个/多个 map 任务 input 文件总个数、文件大小，集群设置的文件快大小。 Q: 是不是map数越多越好？ 答案是否定的。如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。 Q: 是不是保证每个map处理接近128m的文件块，就高枕无忧了？ 答案也是不一定。比如有一个127m的文件，正常会用一个 map 去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果 map 处理的逻辑比较复杂，用一个 map 任务去做，肯定也比较耗时。 增加 Map 的方法： 调整 maxSize 最大值，使 maxSize 小于 blockSize 增加 map 个数 // TODO maxSize 对应的配置参数… 1computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))&#x3D;blocksize&#x3D;128M 调整 Reduce 数过多的 reduce 问题 过多的 reduce， 会过多启动、初始化 reduce 消耗时间和资源 有多少个 reduce 就会有多少个输出文件，生成很多小文件，如果这些小文件作为下一个任务的输入，会出现小文件过多的问题 hive.exec.reducers.bytes.per.reducer=256000000: 每个 reduce 处理的数据量默认为 256MB hive.exec.reducers.max=1009: 每个任务最大的 reduce 数，默认 1009 mapreduce.job.reduces： 设置每个 job 的 reduce 个数 12-- 设置每个 job 的 reduce 个数set mapreduce.job.reduces=15 优化小结 Hadoop/Hive 处理数据过程，有几个显著特征： 不怕数据多，就怕数据倾斜 对 job 数比较多的作业运行效率相对比较低 对 sum、count 等聚合操作而言，不存在数据倾斜问题 count(distinct) 效率较低，数据量大容易出问题 优化可以从几个方面着手： 好的模型设计，事半功倍 解决数据倾斜问题。根据配置和业务进行处理 减少 job 数 设置合理的map、reduce task 数 对小文件进行合并，是行之有效的提高 Hive 效率的方法 优化把握整体，单一作业的优化不如整体最优 RefHive 自带的序列化与反序列化 https://cwiki.apache.org/confluence/display/Hive/DeveloperGuide#DeveloperGuide-HiveSerDe Hive 参数说明的官方文档：https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties Hive SQL的编译过程 Hive/HiveSQL常用优化方法全面总结","tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"}]},{"title":"Hive 中的函数","date":"2021-03-09T13:30:52.000Z","path":"2021/03/09/Hive-函数/","text":"函数分类 标准函数： 一列或多列作为参数传入，返回值是一个值的函数 如 to_date(string timestamp), sqrt(double a) 聚合函数： 接收0行、多行的列，返回单一的值 表生成函数： 接收 0 、 多个输入，产生多列 、 多行输出 如 explode 123show functions;desc function upper;desc function extended upper; 基础函数日期函数基础日期函数： current_date: current_timestamp： year(string date) month(string date) hour(string date) minute(string date) second(string date) datediff(string enddate, string startdate): 计算时间差 from_unixtime(bigint unixtime[, string format])：转换从 1970-01-01 00:00:00 UTC 开始的秒为日期 date_format(date/timestamp/string ts, string fmt)： 日期、时间戳、字符串类型格式化输出标准时间格式 to_date(string timestamp)： 字符串转日期，2.1.0- 返回 String 类型，2.1.0+ 返回 date 类型 day(string date) / dayofmonth(date): 查询当月第几天 weekofyear(string date): 如weekofyear(“1970-11-01 00:00:00”) = 44, weekofyear(“1970-11-01”) = 44. 相对日期相关的函数： last_day(string date)：查询月末的最后一天 date_add(date/timestamp/string startdate, tinyint/smallint/int days)： 增加指定多少天 date_sub(date/timestamp/string startdate, tinyint/smallint/int days) 1234567891011 ： 减少指定多少天 - date_sub(current_date, dayofmonth(current_date)-1)：当月第一天- add_months(string start_date, int num_months, output_date_format)， - add_months(date_sub(current_date, dayofmonth(current_date)-1), 1)： 下月第一天- &#96;&#96;&#96; next_day(string start_date, string day_of_week) ： 返回第一个日期，该日期晚于 start_date 并命名为day_of_week。 - day_of_week 为两个或三个字符，如 &quot;Mo&quot;, &quot;tue&quot;, &quot;FRIDAY&quot; - next_day(&#39;2021-03-26&#39;, &#39;mo&#39;) = 2021-03-29： 指定日期的下一个周一 - date_add(next_day(&#39;2021-03-26&#39;, &#39;mo&#39;), -7) = 2021-03-22： 指定日期的上一个周一日期 1234567891011121314151617181920212223242526SELECT current_date;SELECT CURRENT_TIMESTAMP();-- unix 时间戳转换成日期SELECT FROM_UNIXTIME(11111111);SELECT FROM_UNIXTIME(11111, &#x27;yyyyMMdd&#x27;);SELECT FROM_UNIXTIME(1111111, &#x27;yyyy-MM-dd HH:mm:ss&#x27;);-- 日期转成时间戳SELECT UNIX_TIMESTAMP(&#x27;2019-09-15 14:23:00&#x27;);-- 时间差, 返回日期相差的天数SELECT datediff(&#x27;2020-04-18&#x27;, &#x27;2019-11-21&#x27;);SELECT abs(datediff(&#x27;2020-04-18&#x27;, &#x27;2019-11-21&#x27;));-- 日期为所处月的第几天SELECT dayofmonth(current_date);-- 日期所处月的最后一天日期SELECT last_day(current_date);-- 当月第一天SELECT DATE_SUB(current_date, dayofmonth(current_date) - 1);-- 下月第一天SELECT add_months(date_sub(current_date, dayofmonth(current_date) - 1), 1);-- must 字符串转换成 date yyyy-MM-ddSELECT to_date(&#x27;2020-01-01&#x27;);SELECT to_date(&#x27;2020-01-01 12:12:12&#x27;);-- 日期格式化成指定的字符串SELECT date_format(current_timestamp(), &#x27;yyyy-MM-dd HH:mm:ss&#x27;);SELECT date_format(current_date(), &#x27;yyyyMMdd&#x27;);SELECT date_format(&#x27;2020-06-01&#x27;, &#x27;yyyy-MM-dd HH:mm:ss&#x27;); 常用的日期处理 1234567-- 近3天的-- 近一周的where dt &gt;= date_add(next_day(&#x27;$do_date&#x27;, &#x27;mo&#x27;), -7) and dt &lt;= &#x27;$do_date&#x27;-- 近一月的where dt &gt;= date_format(&#x27;$do_date&#x27;, &#x27;yyyy-MM-01&#x27;) and dt &lt;= &#x27;$do_date&#x27; 条件函数 IF .. else case when.. end &lt;column-name&gt;: 多个条件的时候使用 nvl(T value, T default_value): value 为空的时候返回默认值 COALESCE(T v1, T v2, ...): 返回参数中第一个非空值 nullif(x, y): 相等为空，否则为x isnull / isnull( a ): assert_true(boolean condition): 不满足抛出异常 12345678910111213141516171819202122232425262728293031323334353637383940414243444546-- 测试表定义create table if not exists emp( empno int comment &#x27;员工号&#x27;, ename string comment &#x27;员工姓名&#x27;, job string comment &#x27;工作名称&#x27;, mgr int comment &#x27;&#x27;, hiredate date comment &#x27;雇佣日期&#x27;, sal int comment &#x27;薪水&#x27;, comm int, deptno int comment &#x27;部门号&#x27;) row format delimited fields terminated by &quot;,&quot;;select * from emp;-- if (boolean testCondition, T valueTrue, T valueFalseOrNull)-- 将 emp 表的员工工资等级分类：0-1500、1500-3000、3000以上SELECT sal, if(sal &lt;= 1500, &#x27;primary&#x27;, if(sal &lt;= 3000, &#x27;middle&#x27;, &#x27;advanced&#x27;))FROM emp;-- case when 判断SELECT ename, deptno, CASE WHEN deptno = 10 THEN &#x27;accounting&#x27; WHEN deptno = 20 THEN &#x27;research&#x27; WHEN deptno = 30 THEN &#x27;sales&#x27; ELSE &#x27;unknown&#x27; END deptnameFROM emp;-- 返回参数中的第一个非空值；如果所有值都为 NULL，那么返回NULLselect sal, coalesce(comm, 0)from emp;-- null 判断select *from empwhere isnotnull(comm);-- 空值转换函数 nvl(T value, T default_value)select empno, ename, job, mgr, hiredate, deptno, sal + nvl(comm, 0) sumsalfrom emp;-- nullif(x, y) 相等为空，否则为x SELECT nullif(&quot;b&quot;, &quot;b&quot;), nullif(&quot;b&quot;, &quot;a&quot;); 字符串函数 lower： length: concat / || ：字符拼接 concat_ws(separator, [string | array(string)]+): 可指定分隔符进行拼接 substr： 求子串, 指定开始和结束索引 split： . 需要进行正则转义 instr(string str, string substr)： 返回substr在str中第一次出现的位置 parse_url(string urlString, string partToExtract [, string keyToExtract])： 从 url 中抽取值，可抽取的值包括 HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO. 如 parse_url(‘http://facebook.com/path1/p.php?k1=v1&amp;k2=v2#Ref1&#39;, ‘HOST’) returns ‘facebook.com‘。 regexp_extract(string subject, string pattern, int index)： 按照正则匹配值 如 regexp_extract(‘foothebar’, ‘foo(.*?)(bar)’, 2)， Index 参数为 Java 的 group regexp_replace(string INITIAL_STRING, string PATTERN, string REPLACEMENT):正则替换 如 regexp_replace(“foobar”, “oo|ar”, “”) returns ‘fb.’ get_json_object(string json_string, string path)： 从 JSON 字符串中获取特定路径值 JSON 路径只能为 [0-9a-z_], 没有大写或特殊字符, keys 不可以以 数字开头 str_to_map(text[, delimiter1, delimiter2])： 返回 map 123456789-- 子串截取SELECT split(&quot;www.janhen.com&quot;, &quot;\\\\\\\\.&quot;);select empno || &quot; &quot; || ename idname-- 字符串拼接 指定分割符拼接 concat_ws(separator, [string | array(string)]+)SELECT concat_ws(&#x27;.&#x27;, &#x27;www&#x27;, array(&#x27;janhen&#x27;, &#x27;com&#x27;));SELECT substr(&#x27;www.janhen.com&#x27;, 5);SELECT substr(&#x27;www.janhen.com&#x27;, -5);SELECT substr(&#x27;www.janhen.com&#x27;, 5, 5); get_json_object 获取 JSON 字符串信息 1234567891011121314151617181920212223242526272829&#123; &quot;store&quot;: &#123; &quot;fruit&quot;:[ &#123; &quot;weight&quot;: 8, &quot;type&quot;: &quot;apple&quot; &#125;, &#123; &quot;weight&quot;: 9, &quot;type&quot;: &quot;pear&quot; &#125; ], &quot;bicycle&quot;: &#123; &quot;price&quot;: 19.95, &quot;color&quot;: &quot;red&quot; &#125; &#125;, &quot;email&quot;: &quot;amy@only_for_json_udf_test.net&quot;, &quot;owner&quot;: &quot;amy&quot;&#125;-- 获取值SELECT get_json_object(src_json.json, &#x27;$.owner&#x27;) FROM src_json;amy-- 获取数组值SELECT get_json_object(src_json.json, &#x27;$.store.fruit\\\\[0]&#x27;) FROM src_json;&#123;&quot;weight&quot;:8,&quot;type&quot;:&quot;apple&quot;&#125;-- 获取不存在的值SELECT get_json_object(src_json.json, &#x27;$.non_exist_key&#x27;) FROM src_json;NULL 数学函数 round: round x to d decimal places，可用于控制小数保留几位 ceil: 向上取整 floor: 向下取整。 exp(DOUBLE a), exp(DECIMAL a): 指数函数 log10(DOUBLE a), log10(DECIMAL a) log(DOUBLE base, DOUBLE a) abs(DOUBLE a) 1234select round(314.15926, 2);select round(314.15926, -2);select ceil(3.1415926);select floor(3.1415926); 集合函数 size(Map&lt;K.V&gt;) / size(Array&lt;T&gt;)： 返回元素个数 map_keys(Map&lt;K.V&gt;) / map_values(Map&lt;K.V&gt;): 将 Map 所有的 key、value 进行返回 array_contains(Array&lt;T&gt;, value): 数组中是否包含某个值 sort_array(Array&lt;T&gt;)： 对数组元素进行排序 concat_ws： 将集合通过字符拼接起来 类型转换函数 binary(string|binary)： 转换成二进制 cast(expr as )： 类型转换，无法转换时，返回 NULL 1SELECT CAST(&#x27;23232&#x27; AS INT); UDTF 聚集函数(UDAF) count / sum / avg / min / max collect_set(col): 将制定列聚集为一个 set，自动去重 collect_list(col) ntile(INTEGER x): 将有序分区划分为x个称为存储桶的组，并为该分区中的每一行分配存储桶编号。 123456-- 按照设备聚合用户，将 set 转换成一个 string 字段保存select device_id, concat_ws(&#x27;|&#x27;, collect_set(uid))from start_log where dt=&#x27;2021-01-01&#x27; group by device_id; 表生成函数(UDTF) 一行输入，多行输出 配合 lateral view 进行使用，解决 UDTF 不能添加额外列的问题。 explode(ARRAY a) explode(MAP&lt;Tkey,Tvalue&gt; m) posexplode (array)： 带有原始位置的炸裂函数 json_tuple(string jsonStr,string k1,…,string kn) parse_url_tuple(string urlStr,string p1,…,string pn) explode 炸裂数组/Map值 1234567891011121314151617181920-- lateral view 常与表生成函数 explode 结合使用，处理上述问题-- ==&gt; 解决 UDTF 不能添加额外列的问题-- lateral view udtf(expression) tableALias as ...with t1 as ( select &#x27;OK&#x27; cola, split(&#x27;www.janhen.com&#x27;, &#x27;\\\\\\\\.&#x27;) colb)select cola, colcfrom t1 lateral view explode(colb) t2 as colc;lateral view udtf(expression) tableALias as &lt;col1&gt;, &lt;col2&gt; ...-- 炸裂 map 并给定别名select explode(map(&#x27;A&#x27;,10,&#x27;B&#x27;,20,&#x27;C&#x27;,30)) as (key,value);key valueA 10B 20C 30select posexplode(array(&#x27;A&#x27;,&#x27;B&#x27;,&#x27;C&#x27;)) as (pos,val);pos val2 C1 B0 A json_tuple 获取 JSON 多个值拆开 12select a.timestamp, b.*from log a lateral view json_tuple(a.appevent, &#x27;eventid&#x27;, &#x27;eventname&#x27;) b as f1, f2; parse_url_tuple 获取 URL 中的多个信息 123SELECT b.*FROM src LATERAL VIEW parse_url_tuple(fullurl, &#x27;HOST&#x27;, &#x27;PATH&#x27;, &#x27;QUERY&#x27;, &#x27;QUERY:id&#x27;) b as host, path, query, query_id LIMIT 1; 其他脱敏函数： 对姓名、电话号码进行脱敏，不显示全部内容 mask(string str[, string upper[, string lower[, string number]]]): 如 mask(“abcd-EFGH-8765-4321”, “U”, “l”, “#”) results in llll-UUUU-####-####. collect_list： 列出该字段的所有值，不去重 current_user()： 当前用户 md5(string/binary) version() 窗口与分析函数 和聚合函数的不同之处是：对于每个组返回多行，而聚合函数对于每个组只返回一行。数据窗口大小可能会随着行的变化而变化。 窗口函数 使用之前一般要通过 over() 进行开窗 针对每一行数据的，若 over 中没有参数，默认是全部的结果集 partition by 子句 在 over 窗口中进行分区，对某一列进行分区统计，窗口的大小就是分区的大小 order by 子句 对输入的数据进行排序，有 order by 缺少 window 子句，默认窗口为 range between unbounded preceding and current row over 子句 后面可指定标准的聚集函数， count, sum, min, max, avg 使用 PARTITION BY 语句，具有任何原始数据类型的一个或多个分区列 带有 PARTITION BY 和 ORDER BY 以及任何数据类型的一个或多个分区和/或排序列， 带有窗口规格，Windows 可以在 WINDOW 子句中单独定义。 Window 子句 窗口规范支持以下格式： 指定 order by 并缺少 window 子句时，window 默认被指定为 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW 当同时缺少 order by 和 window 子句时，默认窗口指定为 ROW BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING 不支持 Rank 函数， rank、ntile、denseRank、cusmeDis、percentRank，不支持 Lead 和 Lag 函数 123(ROWS | RANGE) BETWEEN (UNBOUNDED | [num]) PRECEDING AND ([num] PRECEDING | CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING)(ROWS | RANGE) BETWEEN CURRENT ROW AND (CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING)(ROWS | RANGE) BETWEEN [num] FOLLOWING AND (UNBOUNDED | [num]) FOLLOWING 窗口范围 unbounded preceding: 组内第一行数据 n preceding: 组内当前行的前n行数据 current row: 当前行数据 n following: 组内当前行的后 n 行数据 unbounded following: 组内最后一行数据 123456789101112131415161718192021222324252627282930-- 查询员工姓名、薪水、部门薪水总和、占部门薪水的百分比select ename, sal, deptno, sum(sal) over (partition by deptno) depsalsum, round(sal / sum(sal) over(partition by deptno) * 100, 2) || &#x27;%&#x27; salofdeptsumpercentfrom emp;select ename, sal, deptno, sum(sal) over (partition by deptno order by ename)from emp;-- 等价。组内，第一行 ~ 当前行的和select ename, sal, deptno, sum(sal) over (partition by deptno order by ename rows between unbounded preceding and current row )from emp;-- 组内，第一行 ~ 最后一行的和select ename, sal, deptno, sum(sal) over (partition by deptno order by ename rows between unbounded preceding and unbounded following )from emp;-- 组内，按照分区前后两行和当前行的总和，前一行 + 当前行 + 后一行select ename, sal, deptno, sum(sal) over (partition by deptno order by ename rows between 1 preceding and 1 following )from emp; 排名函数 row_number(): 排名顺序增加不会重复 RANK(): 排名相等会在名次中留下空位；如 1、2、2、4、5、… DENSE_RANK(): 排名相等会在名次中不会留下空位 ；如1、2、2、3、4、… 1234567891011121314151617CREATE TABLE IF NOT EXISTS t2( cname string comment &#x27;课程名&#x27;, sname string COMMENT &#x27;学生名&#x27;, score int COMMENT &#x27;课程分数&#x27;) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27; &#x27;;-- 求每个班级前3名的学员 with tmp as ( SELECT cname, sname, score, dense_rank() over (partition by cname order by score) rank FROM t2)select cname, sname, score, rankfrom tmpwhere rank &lt;= 3; 序列函数 lag: 返回当前数据行的上一行数据 常用 lead: 返回当前数据行的下一行数据 常用 first_value: 取分组内排序后，截止到当前行，第一个值 last_value: 分组内排序后，截止到当前行，最后一个值 ntile: 将分组的数据按照顺序切分成n片，返回当前切片值 12345678910111213141516171819202122232425262728293031create table userpv ( cid string comment &#x27;&#x27;, ctime date comment &#x27;时间&#x27;, pv int COMMENT &#x27;页面访问次数&#x27;) row format delimited fields terminated by &#x27;,&#x27;;-- 上两行数据， 下三行数据select cid, ctime, pv, lag(pv, 2) over (partition by cid order by ctime) lagpv, lead(pv, 3) over (partition by cid order by ctime) leadpvfrom userpv;-- first_value 分组排序截止到当前行第一个值 / last_value 分组排序后截止到当前行最后一个值select cid, ctime, pv, first_value(pv) over (partition by cid order by ctime rows between unbounded preceding and unbounded following) firstpv, last_value(pv) over (partition by cid order by ctime rows between unbounded preceding and unbounded following) lastpvfrom userpv;-- ntile 按照cid进行分组并按照 ctime 排序，将分组内的数据平均分成 2 份select cid, ctime, pv, ntile(2) over (partition by cid order by ctime) ntilefrom userpv;-- LAG specifying a lag of 3 rows and default value of 0SELECT a, LAG(a, 3, 0) OVER (PARTITION BY b ORDER BY C)FROM T; UDF临时性添加函数 1234-- hive add jaradd jar /home/hadoop/udf.jarcreate temporary function myconcat as &#x27;con.janhen.hive.udaf.ConcatUDAF&#x27;;SHOW FUNCTIONS; 永久添加到 Hive 中 1234567# jar ==&gt; hdfs hdfs dfs -put hiveudf.jar /user/hadoop/jar/-- 加载函数create function mynvl2 as &#x27;com.janhen.bigdata.hive.nvl&#x27; using jar &#x27;hdfs:/user/hadoop/jar/hiveudf.jar&#x27;;show functions;drop function mynvl2; Ref Built-in Functions Windowing and Analytics Functions","tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"}]},{"title":"Hive-HQL","date":"2021-03-09T13:28:56.000Z","path":"2021/03/09/Hive-HQL/","text":"HQL 的特点： 并不是所有的 HQL 都会被 Hive 转换成 MR 作业执行，对于简单不需要聚合的操作，如 SELECT .. FROM xx LIMIT n，直接通过 FetchTask 获取数据 HQL 是一种 SQL 方案，支持绝大部分的 SQL-92 标准 DML数据导入从本地或 HDFS 中装载数据 LOCAL： LOAD DATA LOCAL …：从本地文件系统加载数据到 Hive 表中 LOAD DATA …：从HDFS加载数据到 Hive 表中 INPATH：加载数据的路径 OVERWRITE：覆盖表中已有数据，否则表示追加数据，用于幂等 PARTITION：将数据加载到指定的分区 一旦该表存在分区，那么在数据在加载时必须加载进入指定分区中，如下： 1234567891011121314-- 加载数据并指定分区，HDFS 文件，已经被转移LOAD DATA INPATH &#x27;/user/hadoop/data&#x27; INTO student_info PARTITION(province=&#x27;sichuan&#x27;, city=&#x27;chengdu&#x27;);-- 加载数据覆盖表中已有数据LOAD DATA INPATH &#x27;data/sourceA.txt&#x27; OVERWRITE INTO TABLE tabA;-- 加载数据，覆盖表的数据，到指定的分区LOAD DATA INPATH &#x27;/user/hadoop/o&#x27; OVERWRITE INTO TABLE test3 PARTITION (part = &quot;a&quot;);-- 添加分区并指定存储位置ALTER TABLE test ADD PARTITION (x = x1, y = y2) SET LOCATION &#x27;/user/test/x1/y1&#x27;; 插入数据 12345-- 插入数据insert into table tabC partition(month=&#x27;202001&#x27;) values (5, &#x27;wangwu&#x27;, &#x27;BJ&#x27;), (4, &#x27;lishi&#x27;, &#x27;SH&#x27;), (3, &#x27;zhangsan&#x27;, &#x27;TJ&#x27;);-- 插入查询的结果数据到指定分区中 insert into table tabC partition(month=&#x27;202002&#x27;) select id, name, area from tabC where month=&#x27;202001&#x27;; 创建表并插入数据 1create table if not exists tabD as select * from tabC; 多表（多分区）插入模式 一次查询，产生多个不相交的输出 可以通过一次查询，产生多个不相交的输出。 这样只通过对 source 表的一次查询，就将符合条件的数据插入 test 表的各个分区，非常方便 12345678910-- 多个查询差生多个不相交的输出FROM sourceINSERT OVERWRITE TABLE test PARTITION (part = &#x27;a&#x27;)SELECT id, name WHERE id &gt;= 0 AND id &lt; 100INSERT OVERWRITE TABLE test PARTITION (part = &#x27;b&#x27;)SELECT id, name WHERE id &gt;= 100 AND id &lt; 200INSERT OVERWRITE TABLE test PARTITION (part = &#x27;c&#x27;)SELECT id, name WHERE id &gt;= 200 AND id &lt; 300 import 导入数据 1import table student2 partition(month=&#x27;201709&#x27;) from &#x27;/user/hive/warehouse/export/student&#x27;; 数据导出 将结果导出到本地 将查询结果格式化到本地 将结果导出到 HDFS 通过 DataX、Sqoop 等工具将结果导出到 HBase、MySQL 等其他地方 修改表1234567891011121314151617181920212223-- 修改列alter table course_common1 change column id cid int;-- 增加字段alter table course_common1 add columns (common string);-- 删除字段：replace columns-- 在元数据中删除了字段，并没有改动hdfs上的数据文件alter table course_common1 replace columns( id string, cname string, score int);-- 更改序列化的编码格式ALTER TABLE person SET SERDEPROPERTIES (&#x27;serialization.encoding&#x27;=&#x27;GBK&#x27;);-- 更改序列化反序列化的属性分割alter table test.tmp1 set serdeproperties(&#x27;field.delim&#x27;=&#x27;,&#x27;);-- 更改编码alter table COLUMNS_V2 modify column COMMENT varchar(256) character set utf8;alter table TABLE_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;-- 创建了分区的话就要再执行两条命令alter table PARTITION_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;alter table PARTITION_KEYS modify column PKEY_COMMENT varchar(4000) character set utf8; DDLDB 与 Table 123456789101112131415161718192021222324-- 查看默认 hive 存放目录下的数据目录dfs -ls /user/hive/warehouse;-- 创建数据库并指定存放位置create database if not exit comment &#x27;test comment&#x27; location &#x27;/usr/hive/mydb2.dbe&#x27;;desc database extended mydb2;-- 连同表一起删除DROP DATABASE IF EXISTS test CASCADE;DESC EXTENDED student;DESC FORMATTED student;-- 根据其他表创建新的表CREATE TABLE IF NOT EXISTS test.student2 LIKE test.student;-- 表的情况查看，文件的大小，文件个数，是否分区,lastAccessTime,lastUpdateTimeshow table extended like &#x27;dwd_start_log&#x27;;-- 查看指定分区的情况show table extended like &#x27;dwd_start_log&#x27; parititon(dt=&#x27;2020-07-22&#x27;);-- desc formatted dwd_start_log;desc formatted dwd_start_log partition (dt=&#x27;2020-07-22&#x27;); Table 建表的方式： 直接建表、查询建表、LIKE 建表 建表的语法： CREATE TABLE [IF NOT EXISTS]：创建表 EXTERNAL： 外部表创建，生产中一般创建的都是外部表，删除表不删除数据 comment： 表注释 partition by： 对表中数据进行分区 clustered by： 建立分桶表 sorted by： 对表中的一个或多个字段进行排序，较少使用 存储子句: 可指定 SerDe, 默认没有使用 ROW FORMAT 或者 ROW FORMAT DELIMITED，会默认使用 SerDe。建表时需要为表指定列在指定列的同时也会指定自定义的 SerDe。hive使用 Serde 进行行对象的序列与反序列化。 stored as SEQUENCEFILE|TEXTFILE|RCFILE LOCATION： 表在 HDFS 上的位置 TBLPROPERTIES：定义表的属性 AS： 接查询语句，根据查询结果建表 LIKE： 复制现有的表结构，不会复制数据 1234567ROW FORMAT DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char] [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)] 使用 JSONSerDe 进行建表 12345678&#123;&quot;id&quot;: 1,&quot;ids&quot;: [101,102,103],&quot;total_number&quot;: 3&#125;&#123;&quot;id&quot;: 2,&quot;ids&quot;: [201,202,203,204],&quot;total_number&quot;: 4&#125;&#123;&quot;id&quot;: 3,&quot;ids&quot;: [301,302,303,304,305],&quot;total_number&quot;: 5&#125;create table jsont2 ( id int, ids array&lt;string&gt;, total_number int) ROW FORMAT SERDE &#x27;org.apache.hive.hcatalog.data.JsonSerDe&#x27;; 内外部表表的类型有两种，分别是内部表、外部表 默认情况下，创建内部表 删除内部表，表的元数据和数据一起删除 删除外部表，删除表的定义，数据保留 生产环境中，多使用外部表 外部表不能执行 TRUNCATE 表类型转换 12345-- 内部表转外部表ALTER TABLE t1 SET tblproperties(&#x27;EXTERNAL&#x27;=&#x27;TRUE&#x27;);-- 外部表转内部表。EXTERNAL 大写，false 不区分大小alter table t1 set tblproperties(&#x27;EXTERNAL&#x27;=&#x27;FALSE&#x27;); 分区表 按照分区字段将表中的数据放置在不同的目录中，提高SQL查询的性能 Hive 没有索引，分区的作用和索引非常类似，可将其看做一种简易索引。对于直接命中分区的查询，Hive 不会执行 MapReduce 作业。 分区字段不是表中已经存在的数据，可以将分区字段看成伪列。 多分区表，在表的目录下有多少分区就有多少级子目录。 分区查看 12345-- 查看分区SHOW PARTITIONS student_info;-- partition counthive --silent -e &quot;show partitions &lt;dbName&gt;.&lt;tableName&gt;;&quot; | wc -lselect count(distinct &lt;partition key&gt;) from &lt;TableName&gt;; 新增分区，加载数据 123456789101112-- 增加分区，不加载数据alter table t3 add partition(dt=&#x27;2020-06-03&#x27;);-- 增加多个分区alter table t3 add partition(dt=&#x27;2020-06-05&#x27;) partition(dt=&#x27;2020-06-06&#x27;);-- 增加分区，加载数据alter table t3 add partition(dt=&#x27;2020-06-07&#x27;) location &#x27;/user/hive/warehouse/mydb.db/t3/dt=2020-06-07&#x27; partition(dt=&#x27;2020-06-08&#x27;) location &#x27;/user/hive/warehouse/mydb.db/t3/dt=2020-06-08&#x27;;-- 单独为外部表的分区键指定值和存储位置：ALTER TABLE student _info ADD PARTITION (province = sichuan, city = chengdu) LOCATION &#x27;hdfs://master:9000/student/sichuan/chengdu&#x27;; 修改分区的hdfs路径 12alter table t3 partition(dt=&#x27;2020-06-01&#x27;) set location &#x27;/user/hive/warehouse/t3/dt=2020-06-03&#x27;; 删除分区 1alter table t3 drop partition(dt=&#x27;2020-06-03&#x27;), partition(dt=&#x27;2020-06-04&#x27;); 动态分区 Hive 会根据 SELECT 语句中的最后一个查询字段作为动态分区的依据，而不是根据字段名来选择。如果指定了 n 个动态分区的字段，Hive 会将 select 语句中最后 n 个字段作为动态分区的依据。 Hive 默认没有开启动态分区。 1234-- 开启自动分区set hive.exec.dynamic.partition = true;INSERT OVERWRITE TABLE test PARTITION(time) SELECT id, modify_time FROM source; 分桶表 分区不能更细粒度的划分数据，就需要使用分桶技术将数据划分成更细的粒度。 使用 cluster by &lt;col-name&gt; into &lt;num&gt; buckets 建表的时候指定。 分桶的原理 MR 中： key.hashCode % reduceTask Hive 中： 分桶字段.hashCode % 分桶个数 分桶表创建 123456create table course( id int, name string, score int ) clustered by (id) into 3 buckets row format delimited fields terminated by &quot;\\\\t&quot;; 分桶表加载数据 12345-- 普通表加载数据 load data local inpath &#x27;/home/hadoop/data/course.dat&#x27; into table course_common;-- 通过 insert ... select ... 给桶表加载数据 insert into table course select * from course_common; 分区表和分桶表的区别 存储格式： 分区表和分桶表的存储格式不同，分区表在多个分区时会有多级目录，分桶表按照字段散列分布。 作用： 分区表细化数据管理，缩小 MR 扫描的数据量；分桶表提高 join 查询效率，在一份数据被经常用作连接 hash 的时候建立分桶，分桶字段为连接字段，提高采样的效率。 数据粒度划分： 分桶表相对分区进行更细粒度的划分。 依据的列： 分桶表指定的分桶依据不是伪列，而是数据表中真实存在的列。 大表 JOIN 分桶的原因 DQLwhere正则匹配过滤 1234-- 正则匹配，使用 rlike。正则表达式，名字以A或S开头select ename, salfrom empwhere ename rlike &#x27;^(A|S).*&#x27;; lateral view lateral view 首先将表生成函数 UDTF 应用于基础表的每一行，然后将结果输出行与输入行连接起来以形成具有提供的表别名的虚拟表。 语法 从 0.12.0 开始列别名可省略，从 UTDF 返回的 StructObjectInspector 的字段名称继承 12lateralView: LATERAL VIEW udtf(expression) tableAlias AS columnAlias (&#x27;,&#x27; columnAlias)*fromClause: FROM baseTable (lateralView)* 使用案例 123456789101112131415161718192021222324252627CREATE TABLE IF NOT EXISTS pageAds( pageid string, adid_list Array&lt;int&gt;);pageid adid_listfront_page [1,2,3]contact_page [3,4,5]-- 页面对应的广告SELECT pageid, adidFROM pageAds LATERAL VIEW explode(adid_list) adTable AS adid;-- 查看特定广告的展示次数SELECT adid, count(1) AS adcntFROM pageAds LATERAL VIEW explode(adid_list) adTable AS adid;pageid(string) adid(int)&quot;front_page&quot; 1&quot;front_page&quot; 2&quot;front_page&quot; 3&quot;contact_page&quot; 3&quot;contact_page&quot; 4&quot;contact_page&quot; 5adid adcnt1 12 13 24 15 1 多个 lateral view from clause 可有多个 lateral view 后续的 LATERAL VIEWS 可以引用 LATERAL VIEW 左侧出现的任何表中的列。 原始数据 ⇒ 建表语句 ⇒ 多个 lateral view 使用 123456789101112131415161718use1;18;male;&#123;&quot;id&quot;: 1,&quot;ids&quot;: [101,102,103],&quot;total_number&quot;: 3&#125;use2;20;female;&#123;&quot;id&quot;: 2,&quot;ids&quot;: [201,202,203,204],&quot;total_number&quot;: 4&#125; use3;23;male;&#123;&quot;id&quot;: 3,&quot;ids&quot;: [301,302,303,304,305],&quot;total_number&quot;: 5&#125;CREATE TABLE IF NOT EXISTS jsont1 ( username string, age int, sex string, json string) row format delimited fields terminated by &#39;;&#39;;-- 解析json串中的数组，并展开select username, age, sex, ids1, id, numfrom jsont1 lateral view explode(janhen_json_array(json, &quot;ids&quot;)) t1 as ids1 lateral view json_tuple(json, &#39;id&#39;, &#39;total_number&#39;) t1 as id, num; join 子句123456-- 内连接 select * from u1 join u2 on u1.id = u2.id;-- 左外连接 select * from u1 left join u2 on u1.id = u2.id;-- 全外连接 select * from u1 full join u2 on u1.id = u2.id; 多表连接 Hive 总是按照从左到右的顺序执行，Hive 会对每对 JOIN 连接对象启动一个 MapReduce 任务。 会首先启动一个 MapReduce job 对表 t 和表 c 进行连接操作；然后再 启动一个 MapReduce job 将第一个 MapReduce job 的输出和表 s 进行连接操作； 然后再继续直到全部操作； 12345select *from techer t left join course c on t.t_id = c.t_id left join score s on s.c_id = c.c_id left join student stu on s.s_id = stu.s_id; 笛卡尔积 满足下列条件 没有连接条件 连接条件无效 所有表中的所有行互相连接 Hive 默认不支持笛卡尔积 12set hive.strict.checks.cartesian.product=false;select * from u1, u2; union 子句union all 不会对合并的数据进行去重， union 会进行去重 可以使用 union all + group by 进行数据去重 使用 union all 要保证两个子查询得到的字段名称一致 排序子句MR 全局排序 排序字段需要出现在 select 字段中 ORDER BY 执行全局排序，只有一个 reduce 输出规模较大时，耗时高 12345678-- 多列排序 select empno, ename, job, mgr, sal + nvl(comm, 0) salcomm, deptno from emp order by deptno, salcomm desc; MR 的内部排序(sort by) sort by 为每个 reduce 产生排序文件，在 reduce 内部进行排序，得到局部有序的结果，保证每个 reducer 的结果有序 123456-- 设置reduce个数set mapreduce.job.reduces=2;-- 按照工资降序查看员工信息 select * from emp sort by sal desc;-- 将查询结果导入到文件中（按照工资降序）。生成两个输出文件，每个文件内部数据按 工资降序排列 insert overwrite local directory &#x27;/home/hadoop/output/sortsal&#x27; select * from emp sort by sal desc; MR 分区排序(distribute by) 将特定的行发送到特定的 reducer 中 distribute by 要写在 sort by 之前 可结合 sort by 操作，使分区数据有序 类似于 MR 中的分区操作 123456789101112131415161718192021-- 先按 deptno 分区，在分区内按照 sal + comm 排序set mapreduce.job.reduces=3;SELECT empno, ename, job, deptno, sal + nvl(comm, 0) salcommFROM emp DISTRIBUTE BY deptno SORT BY sal comm DESC;-- 将数据分到 3 个区中，每个分区都有数据insert overwrite local directory &#x27;/home/hadoop/output/distBy1&#x27; select empno, ename, job, deptno, sal + nvl(comm, 0) salcomm from emp distribute by deptno sort by salcomm desc; Cluster By distribute by 与 sort by 为同一个字段时，使用 cluster by 简化语法 只能是升序，不能指定排序规则 Ref LanguageManual LateralView LanguageManual Joins","tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"},{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"}]},{"title":"Vagrent","date":"2021-03-09T13:17:56.000Z","path":"2021/03/09/Vagrent/","text":"[TOC] Vagrant 快速搭建虚拟机环境，可通过 Vagrantfile 配置文件进行定制，类似 Docker 管理容器。 一些特性： 多种虚拟器支持，如 VirsualBox(默认)、 Vmware、Docker、Hyper-V 方便网络配置，支持端口转发，配置私有、公有网络 方便进行宿主机与虚拟机之间共享文件提供丰富的插件，简化日常使用 环境安装Virtual Box Oracle 开源的虚拟机软件，跨平台 在 winows 上无法同时运行 Hyper-V 和 VisualBox，两者都是基于 CPU 等底层硬件的 Hypervisor 机制来实现的，而他们必须独占管理 Hypervisor。通过开启启动项选择是否加载 Hyper-V 服务，实现伪同时运行。 问题由来： Docker 安装在 win10 上需要开启 Hyper-V，方便进行本地镜像的打包部署，同时需要 VirtualBox 进行模拟集群。 问题处理： 解决Win7/8/10系统中的Hyper-V和VMware虚拟机软件共存问题 Virtualbox “Callee RC: REGDB_E_CLASSNOTREG” (0x80040154)? Hyper-V Win10 自带虚拟化工具，实现在 Win10 上运行 Docker 环境，而无需开启 Docker 的远程访问，开启后无法使用其他虚拟器 对应的 vagrant 设置内存和CPU参数参考文档 12345678910111213141516boxes &#x3D; [ &#123; :name &#x3D;&gt; &quot;docker-kubernetes&quot;, :eth1 &#x3D;&gt; &quot;192.168.205.12&quot;, :mem &#x3D;&gt; &quot;2048&quot;, :cpu &#x3D;&gt; &quot;2&quot; &#125;]... config.vm.provider &quot;hyperv&quot; do |v| v.ip_address_timeout&#x3D;121 v.memory&#x3D;opts[:mem] v.cpus&#x3D;opts[:cpu] endbcdedit &#x2F;set hypervisorlaunchtype offbcdedit &#x2F; set hypervisorlaunchtype auto XShell SSH 命令工具 一些特性 标签化页面管理，方便管理打开的连接 支持连接目录管理，方便进行多种环境管理 支持分屏，方便对集群中的主从进行区分 支持透明图，无需切换窗口查看遗忘的命令 侧栏显示连接信息，方便集群中配置 IP 地址 Vagrant 管理 通过 Vagrantfile 文件设置好一些数值进行控制虚拟机，通过命令管理虚拟机 1234567# 全局管理vagrant global-statusvagrant global-status --prunevagrant destroy &lt;vm_id&gt;vagrant halt &lt;vm_id&gt; &lt;vm_id2&gt;vagrant reload &lt;vm_id1&gt; &lt;vm_id2&gt;..vagrant up &lt;vm_id1&gt; &lt;vm_id2&gt;.. 安装虚拟机环境 快速安装环境，支持从远程获取对应的 Vagrantfile，之后拉取远程镜像；支持导入本地的 box 作为镜像； 12345678# vagrant 命令# 初始化一个安装 centos&#x2F;7 虚拟机的 Vagrantfile# 根据目录下的 Vagrantfile 进行启动# 删除虚拟机# 查案虚拟机运行状态vagrant init centos&#x2F;7vagrant upvagrant status 多种虚拟机支持 支持多种虚拟机，对应的配置memory、Cpu 方式不同 1234# 使用 vmware 虚拟机# 使用 hyper-v，需要管理员权限运行 vagrant，通过 Cmder 默认使用 admin 启动的 powershell 处理vagrant up --provider&#x3D;vmware_fusionvagrant up --provider&#x3D;hyperv Vagrant 插件vagrant-hostmanager 实现多台虚拟机之间直接通过名称访问，原理为更改 host 文件 123456789# 安装并验证插件vagrant plugin install vagrant-hostmanagervagrant plugin list# 在 Vagrantfile 中修改config.hostmanager.enabled &#x3D; trueconfig.hostmanager.manage_guest &#x3D; trueconfig.hostmanager.manage_host &#x3D; true# 执行命令，更新虚拟机上的hosts，同时更新主机上的 hostsvagrant hostmanager vagrant-vbguest 处理 VisualBox 中无法设置共享目录问题 12345vagrant plugin install vagrant-vbguestvagrant vbguest --statusvagrant vbguest --do install node1# 配置 vagrantfileconfig.vbguest.auto_update&#x3D;false vagrant-bindfs 非使用 visualBox 自带的共享目录，自定义使用文件系统 nfs，性能更高 12345678910111213141516171819202122232425vagrant plugin install vagrant-bindfs# 。。。node1. vm. synced_folder &quot;.&#x2F;app&quot;,&quot;&#x2F;mnt&#x2F;app-data&quot;, type:&quot;nfsnode1. bindfs. bind_folder &quot;&#x2F;mnt&#x2F;app-data&quot;,&quot;&#x2F;app&quot;, force_user:&quot;root&quot;, force_group:&quot;root&quot;,o:&quot;nonempty&quot;# 代理设置插件# 在Vagrantfile中的config部分添加代理配置, 全部网络都走主机代理vagrant plugin install vagrant-proxyconfvim Vagrantfile Vagrant.configure(&quot;2&quot;) do |config| if Vagrant.has_plugin?(&quot;vagrant-proxyconf&quot;) config.proxy.http &#x3D; &quot;&lt;http:&#x2F;&#x2F;192.168.0.2:3128&#x2F;&gt;&quot; config.proxy.https &#x3D; &quot;&lt;http:&#x2F;&#x2F;192.168.0.2:3128&#x2F;&gt;&quot; config.proxy.no_proxy &#x3D; &quot;localhost,127.0.0.1,.example.com&quot; end # ... other stuff end# 复用虚拟机环境插件安装vagrant plugin listvagrant plugin install vagrant-scpvagrant scp# 处理虚拟机安装进行目录文件映射权限问题vagrant plugin install vagrant-vbguestvagrant plugin list Vagrantfile 构建虚拟机的硬件情况，实现控制 CPU、内存、Ip 等资源，同时支持虚拟机启动后执行初始化脚本，实现一些必要工具的安装，如 Docker。 通过配置可实现： 进行虚拟机目录与本地目录映射 选择网络 安装成功后执行特定脚本，直接安装要必要的工具以及 Docker 环境 12345678910# config.vm.box 配置使用哪个boxconfig.vm.box &#x3D; &quot;ubuntu16.04_louis&quot;# box ∈ vagrant box listconfig.vm.hostname # 机器应该有的主机名aa.vm.hostname &#x3D; &quot;aa.test.com&quot;config.vm.network # 在机器上配置网络config.vm.network&quot;forwarded_port&quot;,guest:80,host:8080aa.vm.network &quot;private_network&quot;, ip: &quot;192.168.55.100&quot;config.vm.provider # 配置提供程序特定的配置，用于修改特定于某个 提供程序的设置config.vm.provision # 配置置备 在机器上，使软件可以自动安装并创建机器时配置config.vm.synced_folder # 配置 机器上的同步文件夹 配置实例： 参数注入 脚本执行，进行必要软件(vim,git…)、必要环境(如pip,java,docker) 的安装 资源配置，可 CPU、内存…. 等硬件资源 123456789101112131415161718boxes &#x3D; [ &#123; :name &#x3D;&gt; &quot;docker-host&quot;, :eth1 &#x3D;&gt; &quot;192.168.205.10&quot;, :mem &#x3D;&gt; &quot;1024&quot;, :cpu &#x3D;&gt; &quot;1&quot; &#125;]boxes.each do |opts| config.vm.provider &quot;virtualbox&quot; do |v| v.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, opts[:mem]] v.customize [&quot;modifyvm&quot;, :id, &quot;--cpus&quot;, opts[:cpu]] end config.vm.network :private_network, ip: opts[:eth1] # 从主机特定文件读入脚本执行 config.vm.provision &quot;shell&quot;, privileged: true, path: &quot;.&#x2F;setup.sh&quot; endend 网络配置根据需要设置虚拟机网络 IP 地址固定，实现虚拟机中的软件根据名称访问，设置虚拟机可以访问外部的网络。 端口转发 将宿主机的端口与虚拟机的端口绑定，从而让外部通过端口可以访问虚拟机 若 guest_ip 和 host_ip 两项配置为空，则局域网下的所有设备都可以访问该虚拟机 12345678910111213141516Vagrant.configure(2&quot;) do |config|config.vm.network&quot;forwarded_port&quot;(必选) &#x2F;&#x2F;端口转发标示,guest(必选): # 虚拟端口,host(必选): # 宿主机端口，值必须大于1024,gust_ip(可选): # 虚拟机端口绑定虚拟机ip地址,host_ip(可选): # 虚拟机端口绑定宿主机端口ip,protocol(可选): # 指定通信协议，可以使用tcp&#x2F;udp,默认tcp,auto_correct(可选): # ture&#x2F;fasle,开机是否自动检测端口冲突end# 实际配置# 配置2个端口映射，把物理机的8080映射到虚拟机80，物理机的2100映射到虚拟机的22# host_ip 在主机 IP 较为固定情况下配置使用config.vm.network :&quot;forwarded_port&quot;, guest: 80, host: 8060,host_ip: &quot;10.2.11.203&quot;config.vm.network :&quot;forwarded_port&quot;, guest: 22, host: 2100, host_ip: &quot;10.2.11.203&quot; 私有网络 虚拟机之间处在同一网段的地址可相互访问，主机可以访问虚拟机，无法通过虚拟机进行团队合作，不与宿主机的 IP 在同一个网段，防止冲突 配置 vagrant 里面的虚拟机的私有网段的时候，切记不能和企业（公司）内部的 DHCP 分配的 IP 地址在同一网段，否则会发生冲突 1234567891011# 配置 Static IPconfig.vm.network &quot;private_network&quot;, ip: &quot;192.168.50.10&quot;config.vm.network &quot;private_network&quot;, ip: &quot;192.168.55.20&quot;# 配置通过 DHCP 进行获取 IP，之后执行 &#96;vagrant reload&#96;config.vm.network &quot;private_network&quot;, type: &quot;dhcp&quot;# 实际使用Vagrant.configure(&quot;2&quot;) do |config|config.vm.network &quot;private_network&quot;, ip: &quot;192.168.50.10&quot;,auto_config: falseend 公有网络 与宿主机一样的网络配置， vagrant1.3+ 支持设置固定 IP，虚拟机 IP 与主机 IP 处在同一个网段时，实现局域网之间的互通，需要有路由器分配 IP.一般来说开发和测试使用较为封闭的网络模型是比较好的方式，通常不建议 vm 配置有 public_network 的网卡关联 配置虚拟机自动获取公司内部DHCP服务器分配的IP地址，在局域网任何一台电脑上，都可以ssh到虚拟机，或访问虚拟机上提供的服务 12345678910111213141516171819config.vm.network &quot;public_network&quot;, ip: &quot;192.168.1.120&quot;# 配置动态 IP# 配置共有网络，使用主机上可以访问外网的接口(ipconfig)# 配置默认网关config.vm.network &quot;public_network&quot;,bridge: &quot;ens33&quot;config.vm.provision &quot;shell&quot;,run: &quot;always&quot;,inline: &quot;route add default gw 10.2.11.1&quot;# 配置静态 IP# auto_config：关闭自动配置# ifconfig enp0s8 10.2.11.196 netmask 255.255.255.0 up: 配置静态ip（这里的ip不能和公司内部的地址冲突）# route add default gw 10.2.11.1 指定网关（添加默认路由）# bridge： 绑定接口（物理机哪个接口可以上网）config.vm.network &quot;public_network&quot;, auto_config: false ,bridge: &quot;ens33&quot;config.vm.provision &quot;shell&quot;,run: &quot;always&quot;,inline: &quot;ifconfig eth1 10.2.11.196 netmask 255.255.0.0 up&quot;config.vm.provision &quot;shell&quot;,run: &quot;alway&quot;,inline: &quot;route add default gw 10.2.11.1&quot;config.vm.network &quot;public_network&quot;, auto_config: false config.vm.provision &quot;shell&quot;,run: &quot;always&quot;,inline: &quot;ip addr add 172.17.10.51&#x2F;21 dev eth1&quot; config.vm.provision &quot;shell&quot;,run: &quot;alway&quot;,inline: &quot;ip route add 172.17.8.0&#x2F;21 via 172.17.0.49&quot; 共享文件配置宿主机中的数据与虚拟机的数据映射 1234567# src： 是物理机的目录，相对路径，（相对于项目目录（&#x2F;vagrant&#x2F;ubuntu））# &#x2F;srv&#x2F;website: 虚拟机的目录，绝对路径，如果没有，会自动创建config.vm.synced_folder &quot;src&#x2F;&quot;, &quot;&#x2F;srv&#x2F;website&quot;endconfig.vm.synced_folder &quot;.&quot;, &quot;&#x2F;vagrant&quot;, disabled: trueconfig.vm.synced_folder &quot;src&#x2F;&quot;,&quot;&#x2F;srv&#x2F;website&quot;,owner: &quot;root&quot;,group: &quot;root&quot; Q&amp;A 出现的问题以及对应的处理 @Q: 处理本地下载对应镜像慢问题： 直接下载、设置代理 执行 vagrant up --provider=hyperv，在控制台找到下载地址，使用本地下载工具下载(代理) 12345678# 执行下载# 获取地址重新下载# 重命名为指定格式vagrant up --provider&#x3D;hyperv# 将下载的 .box 添加# 使用下载的 .box 进行初始化 vagrant box add centos-7_hyperv hyperv.boxvagrant init centos-7_hyperv @Q: 卸载重装 Vagrant 无法删除之前构建的虚拟机 @Q: 公有网络设置静态 IP 的接口选择问题，无法选择 Wifi、以太网接口?? 待验证 选择不同的连接网卡是否可相互通信？ 选择以太网的桥接可实现内网互通 @Q: 使用以太网接口指定公司网关显示网络不可达? 公司内网的安全性?? 相当于占用内网的一个 IP @Q: 二次使用 vagrantfile 时，报错 chmod: cannot access ‘/etc/systemd/system/docker.service.d/http-proxy.conf’: No such file or directory A： 通过 ssh 进入主机，创建该文件 // todo 搜寻更好的处理方法 1touch &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;http-proxy.conf 原因是修改了网络配置(改成桥接)，重新配置 docker 的代理，需要创建文件的方式来配置代理，而默认情况下无权限访问 @Q: 同步文件夹显示编码问题， ==&gt; Test-Node: Rsyncing folder: /cygdrive/d/develop/Env2/Test-Node/ =&gt; /vagrant D:/ProgramFile/Vagrant/embedded/gems/2.2.5/gems/vagrant-2.2.5/lib/vagrant/util/io.rb:32:in `encode’: “5” from GBK to UTF-8 (Encoding::UndefinedConversionError) 管理员权限编辑对应的 io.rb 文件，更改 vagrant 源码 https://github.com/hashicorp/vagrant/issues/9368 Ref： 多种类型虚拟机支持 使用vagrant和vitrualBox搭建虚拟开发环境 Box-Search: hyperv Vagrant使用指南: 插件、vagrant 代理、对应虚拟机代理 windows 下 使用 vagrant 来管理 linux 虚机开发环境 HyperV - Static Ip with Vagrant 征服诱人的Vagrant！ Vagrant学习文档 VAGRANT 网络配置 ifconfig命令和ip命令及route命令： 配置公有网络设定 IP、掩码、网关","tags":[{"name":"工具","slug":"工具","permalink":"http://example.com/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"Docker-镜像构建-‘最佳实践’","date":"2021-03-09T01:41:21.000Z","path":"2021/03/09/Docker-镜像构建-最佳实践/","text":"构建发布一键构建发布 通过 node 命令合并，maven 插件集成，zsh 终端别名命令定制，Jenkins CICD 操作 Shell 脚本 镜像构建1、构建方式 Dockerfile 一键构建，构建环境为当前运行环境 Dockerfile + Builder 容器进行构建，构建环境为 Builder 指定的容器环境 Jenkins + Agent 配合数据卷容器构建，构建环境为 agent 指定的或是新构建的容器环境 2、常见构建目标 中间件镜像构建，对于 redis、rabbitmq、nginx、haproxy、mysql 对外提供服务，需要更改启动方式为非后台启动，在配置中或是命令运行时进行更改处理 运行环境构建，Centos、Debian、Alpine 操作系统，JRE 、Tomcat、Nginx、Ruby、MySql 程序运行环境 构建工具构建，Maven、Node、Gradle 等工具镜像构建,保存公司私有仓库的账号密码进行打包发布 3、镜像构建与 Git 配合 Docker 提供环境、Git 仓库提供最新的部署脚本，entrypoint 中指定运行特定的脚本(python) 1234git clone &lt;git_url&gt; -b &lt;branch&gt;chmod 777 &lt;git_master&gt;&#x2F;docker-entrypoint.shdocker build -t &lt;&gt; .docker push &lt;&gt; 镜像打包镜像的 Tag 选择 日期 + &lt;short_commid_id&gt;: 持续交付方式的镜像打包，可保留以往的 &lt;mvn_version&gt;: mvn 版本，不断的覆盖，随模块版本稳定而稳定 10.0.0-YYmmddHHMMSS-abddfd Dockerfile 编写合并多个 RUN 减少镜像层数 合并多个 RUN 成一个，因为每次 RUN 都是在原有的镜像上增加一层，可有效减少镜像中的层数 123456FROM debianRUN apt-get update \\ &amp;&amp; apt-get -y install \\ openjdk-8-jdk ssh vim COPY target/app.jar /appCMD [&quot;java&quot;, &quot;-jar&quot;, &quot;/app/app.jar&quot;] 选取合适的基础镜像 使用 alpine 架构的 Linux 一般生成的镜像比较小，根据需要选择可以满足运行条件的最小镜像，自己构建镜像，使用公司内部镜像，借助 Dockerfile 更改部分内容适配需求 1234node:10.16.3-alpin 74Mnode:10.16.3 904Mnode:10.16.3-stretchnode:10.16.3-bruster 可重建性 制作镜像时将源码打包进入镜像中，在镜像提供的环境中进行源码的编译打包，之后运行此种方式配合容器的挂载映射，实现每次运行时的配置都是最新的 123456FROM maven:3.6-jdk-alpineWORKDIR /appCOPY pom.xml .COPY src ./srcRUN mvn -e -B packageCMD [&quot;java&quot;, &quot;-jar&quot;, &quot;/app/app.jar&quot;] 多阶段构建 使用某个镜像作为构建环境，之后引用其中的文件，不会将该辅助镜像打包进最后生成的镜像中; 将编译和运行过程分离开，与通过 Jenkins 的 docker agent 进行编译镜像实现类似 方便控制构建环境的版本，不易出现版本问题 可以使用配有公司 Maven 私服地址的 Maven 镜像作为编译环境，之后在容器中编译打包，从构建包传递到 JDK 环境的运行包中，执行最终的构建 1234567891011121314151617181920212223242526# jar 的打包和运行# As Builder 指定构建过程中的镜像FROM maven:3.6-jdk-8-alpine As builder WORKDIR /app COPY pom.xml .RUN mvn -e -B dependency:resolve COPY src ./src RUN mvn -e -B package # 实际运行的环境FROM openjdk:8-jre-alpine # 从 Builder 中复制COPY --from=builder /app/target/app.jar /CMD [&quot;java&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]# Web 项目的打包和运行FROM node:10.16.3 as builderWORKDIR /usr/src/app/USER rootCOPY package.json ./RUN npm installCOPY ../Doc ./RUN npm run build:dockerFROM nginxWORKDIR /usr/share/nginx/html/COPY ./docker/nginx.conf /etc/nginx/conf.d/default.confCOPY --from=builder /usr/src/app/dist /usr/share/nginx/html/EXPOSE 80 运行参数和动态控制COPY 实现自定义配置 可以实现容器内配置的覆盖，一般配合 WORKDIR 使用 可以实现相对路径下的文件拷贝到容器中，存在时覆盖原有文件 可自动实现文件的重命名 NOTE: 对于可执行文件，需要进行赋权 对于配置文件，特定组件需要文件有指定的权限，如 MySQL 的配置文件 123456789101112131415# 工程文件复制到镜像COPY ../devops ./# 配置覆盖COPY ./docker/nginx.conf /etc/nginx/conf.d/default.conf# 当前目录下文件作为容器中的部分配置COPY nginx.conf /etc/nginx/conf.d/default.conf# 相对路径下的所有文件拷贝到指定目录，不包含该路径文件夹COPY ./dist /usr/share/nginx/html/# Dockerfile_rabbit3.6FROM docker.elastic.co/logstash/logstash:7.2.0# 别名指定RUN alias ll=&#x27;ls -l&#x27;ADD logstash.yml /usr/share/logstash/config/logstash.ymlADD jvm.options /usr/share/logstash/config/jvm.optionsEXPOSE 9600 动态参数和配置 RUN + echo 实现自定义配置 通过 RUN 执行 shell 命令，将需要的配置插入到配置文件的尾部，从而覆盖之前编写的配置，实现自定义配置 只适合使用 key=val 方式的配置文件，对于 json 格式的配置文件无法使用 1234567891011FROM mysql:5.6...RUN echo &quot;lower_case_table_names=1&quot; &gt;&gt; /etc/mysql/mysql.conf.d/mysqld.cnf &amp;&amp; \\ echo &quot;max_allowed_packet=100M&quot; &gt;&gt; /etc/mysql/mysql.conf.d/mysqld.cnf &amp;&amp; \\ echo &quot;innodb_log_file_size=500M&quot; &gt;&gt; /etc/mysql/mysql.conf.d/mysqld.cnf &amp;&amp; \\ echo &quot;wait_timeout=57600&quot; &gt;&gt; /etc/mysql/mysql.conf.d/mysqld.cnf &amp;&amp; \\ echo &quot;interactive_timeout=57600&quot; &gt;&gt; /etc/mysql/mysql.conf.d/mysqld.cnf &amp;&amp; \\ echo &quot;transaction_isolation=READ-COMMITTED&quot; &gt;&gt; /etc/mysql/mysql.conf.d/mysqld.cnf &amp;&amp; \\ echo &quot;event_scheduler=1&quot; &gt;&gt; /etc/mysql/mysql.conf.d/mysqld.cnf &amp;&amp; \\ echo &quot;max_connections=500&quot; &gt;&gt; /etc/mysql/mysql.conf.d/mysqld.cnf &amp;&amp; \\ echo &quot;innodb_lock_wait_timeout=500&quot; &gt;&gt; /etc/mysql/mysql.conf.d/mysqld.cnf COPY + Shell + Sed + ENTRYPOINT 自定义配置 将带有一定模板值的多个配置文件 COPY 进镜像中，将通过 sed 进行配置替换的脚本 COPY 进镜像，将配置替换脚本作为 ENTRYPOINT; 即使配置文件对应的应用不支持传入变量值和环境变量也可以通过此种方式使其支持; 实际使用： 运行在 Nginx 容器中的 web 项目，动态替换框架打包的 umi 中的配置，实现环境的指定； 运行在 tomcat 容器中的 war Java 项目，在运行启动后，对应的 war 包的内容被解压开来，更改配置文件的位置，一般是 xx.properties、xxxx.yml，之后重启整个容器应用更改 ENV 指定实现特定功能 三种语法 配合 Python 脚本将传入的环境变量进行解析成 Ansible 连接的信息 运行时指定环境变量实现动态运行控制 123456789101112# 指定路径、版本...ENV MAVEN_HOME=/apache-maven-3.3.9ENV MYSQL_VERSION 5.6.45-1debian9ENV NODE_VERSION 8.9.4# 指定系统环境变量ENV PATH $&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/bin# 指定一组环境变量参数ENV ANSIBLE_HOSTS=&quot;test1:127.0.0.1&quot; \\ ANSIBLE_PORT=&quot;22&quot; \\ ANSIBLE_USER=&quot;root&quot; \\ ANSIBLE_PASSWORD=&quot;123456&quot; \\ ANSIBLE_FILE=&quot;centos_init_test&quot; 多用途构建文件拆分 通过 Dockerfile、Dockerfile.hub、Dockerfile.dev、Dockerfile.in 增加文件后缀方式区分构建的用途 通过Dockerfile_&lt;iamge_name&gt;&lt;image_version&gt;_&lt;env&gt;_for_&lt;gole&gt; 指明所属环境版本、目的、特定版本 123456Dockerfile Dockerfile.hubDockerfile.devDockerfile_alpine_3.5Dockerfile_mysql5.6_v6Dockerfile_tomcat8539-jre811-for-prod 配合构建工具实现一键发布 对于 Maven 项目，通过 docker-maven-plugin 实现自定义选择阶段，只需在命令后增加 docker:build， docker:push 即可，同时可以将阶段绑定到对应 mvn 命令，如 package、deploy 对于 Node 项目，可以自定义 npm run 命令，在 package.json 中定义好 scripts 指定好某个命令的执行指令，并支持多个命令的合并运行，命令之间顺序任意，以此方便项目的 CI 123456&quot;docker-hub:build&quot;: Dockerfile_jenkins_jdk8-maven3.6.1,&quot;docker:tag&quot;: &quot;docker tag docker.io/project/web&quot;,&quot;docker-registry:login&quot;: &quot;docker login -u &lt;user-name&gt; -p&lt;password&gt;&quot;,&quot;docker:push&quot;: &quot;npm run docker-hub:build &amp;&amp; npm run docker:tag &amp;&amp; npm run docker-registry:login &amp;&amp; docker push &lt;image-name&gt;&quot;,mvn deploymvn clean package docker:push -Pdocker ENTRYPOINT + CMD 参数填充 指定命令参数覆盖 -?，实现指定参数的运行，配合特定运行 jar 包随着 main 类传入参数定制容器的行为 适合 “一次性命令”，启动的容器目的只是依赖于容器内部的工具执行特定的脚本，方便实现数据库的安装、redis-trib 构建集群便是此种方式 12ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;setup.jar&quot;] CMD [&quot;-?&quot;] ENTRYPOINT + docker-entrypoint.sh + 环境变量实现定制化运行 在 docker-entrypoint.sh 中指定多种后缀类型的文件执行不同的处理 通过执行一个初始化脚本，对于 MySQL 环境初始项目需要使用的数据库，并实现权限的分配。 123COPY docker-entrypoint.sh /opt/app/RUN chmod +x /opt/app/docker-entrypoint.shENTRYPOINT [&quot;sh&quot;, &quot;/opt/app/docker-entrypoint.sh&quot;] 不在其中进行修改文件 镜像修改会新增一个层，对于修改文件或目录权限，会将文件复制一份 在 Dockerfile 之前设置好或是通 entrypoint 进行修改 使用 dockerignore 文件 执行 docker build 时忽略特定的路径和文件，加速构建过程 运行时参数指定构建阶段动态配置 常见的编译构建类型 Docker 镜像的编译构建 Java 项目的编译构建成对应的 jar 可运行包 Web 进行编译构建成静态文件 Android 项目的打包构建 Flutter 项目的打包构建 构建过程中的工具 Maven、Gradle、npm。 Profile： 指定 Maven 的 resource 为不同的目录，仅能够支持配置文件和一些 Maven 插件配置 12345resource # 所有的通用配置resource.dev # 开发配置resource.test # 测试配置resource.prod # 生产环境配置resource.docker # docker ... 可等价于 生产环境 3、Git 的分支控制 更改分支上的配置内容实现环境的拆分，可以实现非配置文件的更改，直接修改代码 12345git checkout -b prodgit checkout -b devgit checkout -b testgit checkout -b mockgit checkout -b docker 4、Jenkins 构建变量 在 Jenkins 中添加条件变量，在每次构建的时候选择需要构建的环境，配合 Shell 脚本将源码中的文件进行替换，实现和 Git 分支控制一样的效果 如在 WEB-INFO 下的 db.properties，无法通过 上述1、2处理，可以在对应目录下再建一个 db.prod.properties，Jenkins 判断为 prod 环境时，对 db.properties 删除，db.prod.properties 进行重命名即可 Dockerfile 中的动态配置 通过 COPY, ADD 将自定义配置放入 image 中 运行阶段动态配置 通过 kube 控制 k8s 集群进行运行通过 docker 命令在本机运行通过 ansible 控制机器运行通过 jenkins 的 ssh 工具控制机器运行 关于运行的环境选择，针对 Java 项目当前已知三种方式进行环境区分： Spring 的 profile，更细致的是 Condition + 各种判断控制，控制较为灵活 12application-dev.propertiesapplication-test.properties 构建后运行前阶段的动态配置 1、通过 Docker 的 entrypoint 指定参数拼凑运行的配置或命令 从环境变量中取值，进行环境判断和动态赋值 2、通过 SpringBoot 的 jar 参数控制 SpringBoot 作为可运行 jar，内部调用一个 sh 脚本控制 3、通过 volumn 映射配置执行 将指定的配置文件进行映射 将指定的配置文件夹进行映射 4、镜像中集成 template 更新模板参数，对配置模板渲染生成后重启 运行后配置1、更改配置不重启(重启失效) 一些组件支持在运行过程中更改配置，一般重启后配置失效 redis 的动态配置 连接的主服务器 持久化配置 .. mysql 的动态配置 字符集 信任function - .. 2、更改配置重启 适合容器中的配置文件可见，对于使用 jar 包运行的参数拼接可更改对应的 docker-entrypoint.sh 中的 JVM 和 Springboot 配置文件参数实现 直接在容器中更改配置文件重启 通过 docker cp 方式将更改好的配置复制到容器中后重启 Refdocker:mysql启动时自动执行初始建表脚本_10km的专栏-CSDN博客 docker:mysql启动时自动执行初始建表脚本 https://www.cnblogs.com/han-1034683568/p/6941337.html 让docker中的mysql启动时自动执行sql文件","tags":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"}]},{"title":"Guava使用","date":"2021-03-08T17:24:34.000Z","path":"2021/03/09/Guava使用/","text":"Guava工具Joiner 字符拼接 1、Joiner | JDK8 Stream 字符拼接常见操作： 不带空元素的拼接 对空元素使用默认值拼接 写入文件 12345678910111213141516String result=Joiner.on(&quot;#&quot;).join(stringList);String result =Joiner.on(&quot;#&quot;).userorNull(&quot;DEAULT&quot;).join(stringListwithNull);final StringBuilder builder=new StringBuilder();StringBuilder resultBuilder=Joiner.on(&quot;#&quot;) .useForNull(&quot;DEFAULT&quot;) .appendTo(builder, stringListwithNullval);// Writertry (Filewriter writer = new Filewriter(new File(targetFileName))) &#123; Joiner.on(&quot;#&quot;) .useForNull(&quot;DEFAULT&quot;) .appendTo(writer, stringListwithNullValue);&#125; catch (IOException e) &#123; fail(&quot;append to the writer occur fetal error.&quot;);&#125; JDK8 中的 Join 中的 Stream：跳过 Null 值 12345678910String result=stringListwithNullValue.stream() .filter(item-&gt;item!=null &amp;&amp; !item.isEmpty()).collect(joining(&quot;#&quot;));// null to defalutString result=stringListwithNullValue.stream() .map(item-&gt;item==null || item.isEmpty()?&quot;DEFAULT&quot;:item).collect(joining(&quot;#&quot;));// function inferpublic void testJoiningByStreamwithDefaultyalue()&#123;string result =stringListwithNullValue.stream() .map(this::defaultValue) .collect(joining(&quot;#&quot;)); 2、Map 拼接 将 Map 的键值按照特定分隔符进行拼接 默认 key 和 val 通过 = 进行拼接 12345678910// join mapprivate final Map&lt;String,string&gt; stringMap = of(&quot;Hello&quot;,&quot;Guaga&quot;,&quot;Java&quot;,&quot;Scala&quot;);assertThat(Joiner.on(&#x27;#&quot;).withKeyValueSeparator(&quot;=&quot;).join(stringMap), equalTo(&quot;Hello=Guava#Java=Scala&quot;));try(FileWriter writer=new Filewriter(new File(targetFileNameToMap)))&#123; Joiner.on(&quot;#&quot;).withKeyValueSeparator(&quot;=&quot;).appendTo(writer, stringMap); assertThat(Files.isFile().test(new File(targetFileNameToMap)), equalTo(true));&#125; catch (IOException e)&#123; fail(&quot;append to the writer occur fetal error.&quot;);&#125; Splitter 字符分隔 剔除一些无用的 按照特定分隔符分隔并转化成 List 剔除掉空的字符并转化成 List 指定分隔符 剔除 Blank 字符 剔除剔除 Empty 字符 收集结果成为 List 1、分隔与忽略 12345678// 1.1 普通分隔List&lt;String&gt;result=Splitter.on(&quot;|&quot;).splitToList(&quot;hellolworld&quot;);// 1.2 忽略空串List&lt;string&gt;result=Splitter.on(&quot;|&quot;).omitEmptystrings().splitroList(&quot;hellolworldlll&quot;);// 1.3 忽略空格并忽略空串result=Splitter.on(&quot;I&quot;).trimResults().omitEmptystrings().splitroList(&quot;hel1o I worldlll&quot;); 2、正则分隔 使用 onPattern 替代 on, 参数即为正则 12345// 3.1 传入正则表达式进行分隔List&lt;String&gt;result=Splitter.onPattern(&quot;\\\\\\\\\\\\\\\\l&quot;).trimResults().omitEmptystrings().splitTorist(&quot;hello | worldl&quot;);// 3.2 传入正则PatternList&lt;string&gt;result =Splitter.on(Pattern.compile(&quot;\\\\\\\\l&quot;)).trimResults(). omitEmptystrings().splitToList(&quot;&quot;); 3、结果分隔 通过字符长度截取字符串 截取结果中固定的个数，最后的保存剩余所有的 1234567891011121314// 2.1 分隔固定长度，报文的固定长度截取 aaabbbcccList&lt;string&gt; result = Splitter.fixedtength(4).splitToList(&quot;aaaabbbbccccdddd&quot;);// 2.2 限制返回的结果数，多余的放在最后一个结果中List&lt;String&gt;result=Splitter.on(&quot;#&quot;) .limit(3) .splitToList(&quot;hello# world# java# google# scala&quot;);// 3.3 传入正则Pattern, 返回 MapMap&lt;String, String&gt; result = Splitter.on(Pattern.compile(&quot;\\\\\\\\\\\\\\\\l&quot;)) .trimResults() .omitEmptystrings() .withKeyValueSeparator(&quot;=&quot;) .split(&quot;hello=HELLOl|world=WORLD|||&quot;); String 其他工具 1、Strings 填充字符串 获取公共前缀|后缀 重复指定次数的字符串: 和 python 进行重复类似 123456789101112131415assertlhat(strings.emptytovull(&quot;&quot;) rnullvalue())assertThat(Strings.nullToEmpty(null), equalro(&quot;&quot;)); assertThat(strings.nullToEmpty(&quot;hello&quot;), equalTo(&quot;hello&quot;));assertThat(Strings.commonPrefix(&quot;Hello&quot;,&quot;Hit&quot;), equalTo(&quot;H&quot;));assertThat(Strings.commonPrefix(&quot;Hello&quot;,&quot;Xit&quot;), equalro(&quot;&quot;));assertThat(Strings.commonSuffix(&quot;Hello&quot;,&quot;Echo&quot;), equalTo(&quot;o&quot;));assertThat(Strings.repeat(&quot;Alex&quot;,3), equalTo(&quot;AlexAlexAlex&quot;));assertlhat(btrings.1sNullormpty(nulL), equallo(true))assertThat(Strings.isNullOrEmpty(&quot;&quot;), equalTo(true));assertThat(Strings.padstart(&quot;Alex&quot;,3,&#x27;H&#x27;), equalTo(&quot;Alex&quot;));assertThat(strings.padstart(&quot;Alex&quot;,5,&#x27;H&#x27;), equalTo(&quot;HAlex&quot;));assertThat(Strings.padEnd(&quot;Alex&quot;,5,&#x27;H&#x27;), equalTo(&quot;AlexH&quot;)); 2、CharSet 3、CharMatcher 123456assertThat(CharMatcher. javaDigit(). matches(&#x27;A&#x27;), equalTo(true));assertThat(CharMatcher. javaDigit(). matches(&#x27;x&#x27;), equalTo(false)); assertrhat(CharMatcher. is(&#x27;A&#x27;).countIn(&quot;Alex sharing the Google Guava to Us&quot;), equalTo(1));assertThat(CharMatcher. breakingwhitespace().collapseFrom(&quot;hello Guava &quot;,&#x27;*&quot;), equalro(&quot;* hello Guaval&quot;);assertThat(CharMatcher. javaDigit(). or(CharMatcher. whitespace()). removeFrom(&quot;hello 234 world&quot;), equalTo(&quot;helloworld&quot;);asserThat(CharMatcher. javaDigit(). or(CharMatcher. whitespace()). retainFrom(&quot;hello 234 world&quot;), equalro(&quot;234&quot;)); 类通用工具 1、MoreObjects 1、实战 toString 辅助编写： 支持忽略空值 123456public string tostring()&#123; return Moreobjects.tostringHelper(this).omitNullValues() .add(&quot;manufacturer&quot;, this.manufacturer) .add(&quot;version&quot;, this.version) .add(&quot;releaseDate&quot;, this.releaseDate).tostring();&#125; 2、源码 链表结构 12345678910111213private ToStringHelper(String className) &#123; this.holderHead = new MoreObjects.ToStringHelper.ValueHolder(); this.holderTail = this.holderHead; this.omitNullValues = false; // check and get this.className = (String)Preconditions.checkNotNull(className);&#125;private MoreObjects.ToStringHelper.ValueHolder addHolder() &#123; MoreObjects.ToStringHelper.ValueHolder valueHolder = new MoreObjects.ToStringHelper.ValueHolder(); this.holderTail = this.holderTail.next = valueHolder; return valueHolder;&#125; 2、Objects 深度比较 deepEquals hash: compare(a,b, cmp); requireNonNull template = String.valueOf(template); // null -&gt; “null” 在 JDK7+ 使用 JDK 提供的 Objects 方法替代 3、ComparisonChain 链式的比较规则 JDK8 添加类似的实现在 Comparator 上 1234567@Overridepublic int compareTo(Guava this, Guava o) &#123; return Comparisonchain.start() .compare(this.manufacturer,o.manufacturer) .compare(this.version,o.version) .compare(this.releasepate,o.releaseDate).result();&#125; 2、源码 本身为抽象类 类中持有一个实例化的对象 提供该抽象类的一个继承实现类 针对 float,double,int,long,Object 提供比较，针对 Object 提供 classis 和基于 Comparator 的比较 StopWatch 工厂方式获取，createStarted() 省去创建之后开启的步骤 可控制返回的时间单位 对象可以来回复用记录 1234LOGGER.info(&quot;start process the order [&#123;&#125;]&quot;, orderNo);Stopwatch stopwatch = Stopwatch.createStarted();TimeUnit.MILLISECONDS.sleep(100);LOGGER.info(&quot;The orderNo [&#123;&#125;] process successful and elapsed [&#123;&#125;] min.&quot;, orderNo, stopwatch.stop().elapsed(TimeUnit.MINUTES)); PreConditons 运行时空判断 判断并可给出 message，默认通过 String 自带的格式化字符串实现 通过方法名空值语义： checkState: 判断状态 checkElementIndex: 判断容器的索引 1234Preconditions.checkNotNull(list,&quot;The list should not be null and the size must be %s&quot;,2);Preconditions.checkArgument(type.equals(&quot;B&quot;));Preconditions.checkState(state.equals(&quot;B&quot;), &quot;The state is illegal.&quot;);Preconditions.checkElementIndex(10, list.size()); CollectionsFluentIterable 类似网络中的数据流处理 1、将其当做链表操作： 链表的头结点、尾节点获取 两条链表的合并 链表中是否含有满足特定条件的值 链表中是否全部满足特定条件 链表中满足特定条件的第一个值 将链表按照特定的长度进行分割 从数组中构建链表 从迭代器中构建链表 链表的循环读取，先连接成环，之后扫描限定个数的节点 链表元素的转换(transform)，通过 Function 接口实现 链表元素进行转换，单个元素转化后是一个 迭代器，重新进行连接 1234FluentIterable&lt;String&gt; fit = build();boolean result = fit.allMatch(e -&gt; e != null &amp;&amp; e.length() &gt;= 4);result = fit.anyMatch(e -&gt; e != null &amp;&amp; e.length() == 5);Optional&lt;String&gt; optional = fit.firstMatch(e -&gt; e != null &amp;&amp; e.length() == 5); Lists | Sets List 构造 通过工厂提供方便的构造方式, 同时语义明确 主要提供三种 List 的构造： ArrayList 原始方式 提供根据迭代器构造 提供根据可变数组构造 提供容量构造，包含限定长度、给出期望长度 LinkedList 构造仅提供两种方式： 底层链表无法指定大小 原始方式 迭代器构造 CopyOnWriteArrayList： 构造方式同 LinkedList Set 构造 HashSet: 方式和 ArrayList 方式类似 LinkedHashSet： 方式与 LinkedList 类似 增加限定容量，底层基于数组。。。 TreeSet： 普通构建，(), (comparator) 传入迭代器 EnumSet： Set 集合性质(&amp;) 笛卡尔积 组合选取 两个集合不同的部分， difference(set1, set2) 返回在 set1 中的元素而不再 set2 中的元组 交集、并集 MultiSet 记录重复元素的个数 Maps | BiMap | MultiMap 构造方式 转换成不可变Map 根据 Set 转变成可变 Map 根据 Map 转换对应的值 BiMap 严格的一对一映射，通过接口声明通用的操作 Table | Range ArrayTable TreeBaseTable HashBaseTable ImmutableTable 表名、列明、列值 Range 提供实现了自然排序类的范围： &gt;= &lt;=, [) 范围映射，Key 为一个给定的范围，放入的为泛型 K 的一个 Range，支持按照某个具体的值获取到对应范围端的一个值 Range | RangeMap | Ording Sorted 判断是否已经按照自然排序完成 给出相反的比较。。。 Getting Started with Google Guava.pdf 不可变设计： 提供工厂方式， of 提供构建器方式 CacheBuilder.newBuilder().build() 提供原型方式构建 copyOf Range 存放在其中的元素必须是 Comparable 的 提供多种符合语义的工厂构造： 根据枚举值确定两端的开闭 RangeMap 另一种存在有序性的 Map Ording 支持对 null 的特殊处理，将其放在第一位或者最后一位 与当前 JDK8 中 Comparator 中的 nullFirst 一致，配合 thenXXX 进行控制比较规则 Guava 缓存原始缓存实现 1、LinkedHashMap 通过 JDK 自带的实现 2、LinkedList 借助 LinkedList 实现 3、通过 SoftReference 实现 容量： 初始容量、最大容量 过期策略： 设置的大小、按照权重、访问、写入、更新、GC 并发等级： 并发使用 KV收集机制： 软引用、弱引用进行 GC 过期策略(5) 1、大小 限定缓存的个数，内存大小 2、LRU 限定大小的情况下，模式通过 LRU 算法进行淘汰 3、Time(W,R) 在访问命中某个元素多长时间后过期； 在更新某个元素多长时间后过期； 4、引用生命周期控制(GC) .softValues() .softKeys() 借助 GC 控制何时回收，何时保留 5、权重 通过为每个缓存的数据设定一定的权重进行控制是否过期 通过实体，给出计算规则： 入参为 key, values，返回的值为对应的权重 其他特性(4) 1、不存在的默认值(LoadingCache) 在获取不到的情况下给出的值 类似缓存雪崩情况下的熔断 通过 CacheLoader 抽象类实现： 给类提供根据 Function，Supplier 进行创建的工厂 是 LoadingCache 实现必须要指定的参数 12CacheLoader&lt;K, V&gt; from(Function&lt;K, V&gt; function)CacheLoader&lt;Object, V&gt; from(Supplier&lt;V&gt; supplier) 2、统计功能 .recordStats() 记录缓存的命中率，执行情况 3、监听缓存移除事件 可设置缓存移除监听器，监听到删除事件进行处理 封装成通知实体控制移除策略 1void onRemoval(RemovalNotification&lt;K, V&gt; notification); 4、灵活的构造方式 支持根据特定的字符串构造 CacheBuilder： 类似读取配置文件实现缓存 根据函数式接口构造 CacheLoader 1234String spec = &quot;maximumSize=5,recordStats&quot;;CacheBuilderSpec builderSpec = CacheBuilderSpec.parse(spec);CacheLoader&lt;String, String&gt; loader = CacheLoader.from(String::toUpperCase);LoadingCache&lt;String, String&gt; cache = CacheBuilder.from(builderSpec).build(loader); 源码分析 通过 ConcurrentHashMap 实现 Entry 中各种引用的获得： 有限的几个 每个实现都不同 有一定的规律(存在是否) ⇒ 定义Enum, 将所有Enum放入数组中，定义工厂获取方法，按照将boolean作为参数进行掩码控制获得 EventBus消息的 pull 和 push 进程级别，内部 Listener 对其进行 subscribe 只能有一个参数： 实战 1、多种类型 同种类型的多个订阅方法会被调用 2、Listener 继承特性 都会被调用 3、Event继承 都会被调用 4、异步总线 设计 自己实现一个消息总线，实现与 Guava 中 EventBus 类似的功能 并发Monitor LockCondition 的一个封装 可替换 synchronized 的实现，语义更加明确，同时更加方便编程 1、阻塞队列设计 (1) synchronized 方式设计 (2) Reentrant + Condition 方式设计 (3) Monitor 方式设计 限流 rateLimiter Semaphore 通过 Semaphore 进行获取并释放令牌的方式进行控制访问的速率 令牌桶 Refhttps://github.com/google/guava/wiki Github Guava Wiki","tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"Guava","slug":"Guava","permalink":"http://example.com/tags/Guava/"}]},{"title":"Java 并发学习笔记","date":"2020-12-17T14:53:30.000Z","path":"2020/12/17/Java-并发学习笔记/","text":"线程 Java 代码首先会编译成Java字节码，字节码被类加载器加载到JVM里，JVM执行字节码，最终需要转化为汇编指令在CPU上进行执行。 Java中所使用的并发机制依赖于 JVM 的实现和 CPU 的指令。 创建方式(1) extends Thread 当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。 12MyThread t1 = new MyThread();t1.start(); (2) Runnable (3) Callable 与 Runnable 相比，Callable 可以有返回值，且可以跑出异常，返回值通过 FutureTask 进行封装。 (4) ThreadPool 继承与实现接口的比较 优先实现接口 ① Thread 只能够通过单继承来实现； ② Thread 创建开销大，Runnable 创建的开销小； ③ Runnable 实现解耦； 可以配合线程池使用 生命周期 12345678public enum State &#123; NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED;&#125; (1) 新建(NEW) 创建后尚未启动。 当程序使用 new 关键字 创建了一个线程之后，该线程就处于新建状态，此时仅由JVM为其分配内存，并初始化其成员变量的值。 (2) 可运行(Runnable)可能正在运行，也可能正在等待 CPU 时间片。 包含了操作系统线程状态中的 Running 和 Ready。 当线程对象调用了start()方法之后，该线程处于就绪状态。Java虚拟机会为其创建方法调用栈和程序计数器，等待调度运行。 (3) 阻塞(Blocked)等待获取一个排它锁，如果其线程释放了锁就会结束此状态。 主要分为三种阻塞方式： ① 同步阻塞： 等待获取锁，获取同步锁时该同步锁被别的线程占用，JVM 将线程放入到锁池 (lock pool) 中。 ② 等待阻塞 执行 o.wait() ，JVM会把该线程放入等待队列(waitting queue)中。 ③ 其他阻塞 I/O 阻塞： 等待 I/O 操作完成； 执行 Thread.sleep() ； 执行 t.join() 方法； (4) 无限期等待(Waiting)等待其它线程显式地唤醒，否则不会被分配 CPU 时间片； 都是交互性质的方法； Object.wait()、Thread.join()、LockSupport.part() 进入方法 退出方法 没有设置 Timeout 参数的 Object.wait() 方法 Object.notify() / Object.notifyAll() 没有设置 Timeout 参数的 Thread.join() 方法 被调用的线程执行完毕 LockSupport.park() 方法 LockSupport.unpark(Thread) (5) 限期等待(Timed Waiting) 无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。 调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。 睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。 阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用 Thread.sleep() 和 Object.wait() 等方法进入。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 / Object.notify() / Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 / 被调用的线程执行完毕 LockSupport.parkNanos() 方法 LockSupport.unpark(Thread) LockSupport.parkUntil() 方法 LockSupport.unpark(Thread) (6) 死亡(Terminated) 可以是线程结束任务之后自己结束，或者产生了异常而结束。 线程的终止(1) 正常终止 运行结束，正常终止； (2) 退出标志 定义了一个退出标志exit，当exit为true时，while循环退出，exit的默认值为false.在定义exit时，使用了一个Java关键字volatile，这个关键字的目的是使exit同步，也就是说在同一时刻只能由一个线程来修改exit的值。 volatile 无锁同步的应用场景之一； 123456class MyThread extends Thread &#123; public volatile boolean exit = false; // volatile public void run() &#123; // ... &#125;&#125; (3) Interrupt 方法结束 ① 阻塞下的结束 在线程处于阻塞状态下，调用 interrupt() 会抛出 InterrupteException，一定要先捕获InterruptedException异常之后通过break来跳出循环，才能正常结束run方法。 死循环中的退出，只有在捕获后进行显示的 break 才能实现； ② 未阻塞下的结束 使用 isInterrupted() 判断线程的中断标志来退出循环。当使用 interrupt() 方法时，中断标志就会置 true，和使用自定义的标志来控制循环是一样的道理。 1234567891011class MyThread implements Runnable &#123; public void run() &#123; while (!isInterrupted()) &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; break; // NOTE: after catch exception must break to skip loop &#125; &#125; &#125;&#125; (4) stop 方法终止 程序中可以直接使用thread.stop()来强行终止线程，但是stop方法是很危险的，就象突然关闭计算机电源，而不是按正常程序关机一样，可能会产生不可预料的结果，不安全主要是：thread.stop()调用之后，创建子线程的线程就会抛出ThreadDeatherror的错误，并且会释放子线程所持有的所有锁。一般任何进行加锁的代码块，都是为了保护数据的一致性，如果在调用thread.stop()后 导致了该线程所持有的所有锁的突然释放(不可控制) ，那么被保护数据就有可能呈现不一致性，其他线程在使用这些被破坏的数据时，有可能导致一些很奇怪的应用程序错误。因此，并不推荐使用stop方法来终止线程。 (5) Callable 通过 Future.camcel 来进行终止 Interrupt()一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。 (1) InterruptedException 该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。 Thread.sleep()； synchronized； join()； (2) interrupted() 无限循环不跳出，只有在该循环中执行 sleep() 等会抛出 InterruptedException 操作， 可通过其返回值来防止无线循环，作为一种退出标志； 调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。 (3) Executor 的中断操作 ① 关闭池子操作 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。 ② 关闭指定的线程(Future) 只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。 方法(1) join 进行线程之间的流程控制，进行线程通信的一种方式； (2) yield() 让出当前 CPU，之后重新进行竞争； (3) sleep() 不释放锁，在等待一定时间后自动唤醒； sleep() 与 wait() 的区别 想到对应在阻塞队列中、以及延时双删策略中的场景； ① 设计|定义： sleep() 是 Thread 的静态方法，wait() 是 Object 的成员方法； ② 锁的占用： sleep() 导致程序暂停执行指定的时间，它的监控状态依然保持着，不释放锁， 而 wait() 释放对象锁，进入等待此对象的等待池中； ③ 使用范围： sleep() 可以用在任何地方， wait() 只能够用在同步控制方法或同步控制块中使用； ④ 唤醒方式： sleep() 给定时间内自动唤醒，wait() 需要调用 notify 显视唤醒； start() 与 run() 的区别 start() 方法来启动线程，真正实现了多线程运行。这时无需等待 run 方法体代码执行完毕，可以直接继续执行下面的代码。 通过调用 Thread 类的 start() 方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行。 run ⽅法只是 thread 的⼀个普通 ⽅法调⽤，直接运行。 方法 run() 称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运行 run 函数当中的代码。 Run方法运行结束， 此线程终止。然后CPU再调度其它线程。 其他性质 (1) 进程与线程的比较 进程是 OS 资源分配的单位，有自己独立的寻址空间； 线程是 OS 独立运行的单元，其共享同一个进程内的所有数据； 线程相较于进程更加轻量； ⼀个进程中可以有多个线程，多个线程共享进程的堆和⽅法区 (JDK1.8 之后的元空间)资源，但是每个线程有⾃⼰的程序计数器、虚拟机栈 和 本地⽅法栈。 (2) 实现多线程的方式 Java 中通过将每个线程映射为一个进程实现的； 线程的实现3种模型:内核线程；用户线程；两者结合。 (3) 守护线程 是个服务线程，准确地来说就是服务其他的线程，这是它的作用——而其他的线程只有一种，那就是用户线程。所以java里线程分2种。 ① 停止执行情况 专门用于服务其他的线程，如果其他的线程(即用户自定义线程)都执行完毕，连main线程也执行完毕，那么jvm就会退出(即停止运行)——此时，连jvm都停止运行了，守护线程当然也就停止执行了。 ② 优先级 优先级较低 ③ 设置 通过 setDaemon(true) 在 Thread 未 start() 之前显视设置 Daemon 线程产生的新线程也是 Daemon 的 ④ 性质 为 JVM 级别的线程，即使你停止了Web应用，这个线程依旧是活跃的。 (4) 线程派生的联系 继承对应的优先级、daemon等属性； (5) 并发和并行 并发： 同⼀时间段，多个任务都在执⾏ (单位时间内不⼀定同时执⾏)； 并⾏： 单位时间内，多个任务同时执⾏。 线程间通信while 循环监测 线程B是一直执行着while(true) 循环的，直到长度为5才终止执行，显然这种方式是很消耗资源的。所以，就需要一种机制能避免上述的操作又能实现多个线程之间的通信，这就是接下来需要学习的“wait/notify线程间通信”。 通信方式(1) 进程间的通信方式 ① 管道(pipe)、有名管道(named pipe) ② 信号量(semophore) ③ 消息队列(message queue) ④ 信号(signal) ⑤ 共享内存(shared memory) ⑥ 套接字(socket) (2) 线程间的通信方式 1、锁机制： 1.1 互斥锁：提供了以排它方式阻止数据结构被并发修改的方法。 1.2 读写锁：允许多个线程同时读共享数据，而对写操作互斥。 1.3 条件变量：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。2、信号量机制：包括无名线程信号量与有名线程信号量3、信号机制：类似于进程间的信号处理。线程间通信的主要目的是用于线程同步，所以线程没有像进程通信中用于数据交换的通信机制。 等待/通知机制 Object.wait, notify 机制，需要配合 synchronized 一起使用 1、wait()/notify 方法 (1)wait() 和 notify() 方法要在同步块或同步方法中(synchronized 关键字) 调用，即在调用前，线程也必须获得该对象的对象级别锁。(2)wait方法是释放锁，notify方法是不释放锁的；(3)notify 每次唤醒 wait 等待状态的线程都是随机的，且每次只唤醒一个；(4)notifAll 每次唤醒 wait 等待状态的线程使之重新竞争获取对象锁，优先级最高的那个线程会最先执行；(5)当线程处于 wait() 状态时，调用线程对象的 interrupt() 方法会出现 InterruptedException 异常； 通过 等待通知模式实现阻塞队列 (1) 结构 1234Queue&lt;Object&gt; queue = new LinkedList&lt;&gt;();AtomicInteger count = new AtomicInteger();int capacity = 5;Object lock = new Object(); // use for thread communication (2) 入队 1234567891011121314void put(Object task) &#123; synchronzied(lock) &#123; while (count.get() == capacity) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; log.error(&quot;&quot;, e); &#125; &#125; queue.offer(task); count.getAndIncrement(); lock.notify(); // not empty conditon &#125;&#125; (2) 出队 12345678910111213141516Object take() &#123; Obejct oldFront = null; synchronized(lock) &#123; while (count.get() == 0) &#123; try &#123; lock.wait()； &#125; catch (Exception e) &#123; log.error(&quot;Error&quot;, e); &#125; &#125; oldFront = queue.poll(); count.getAndDecrment(); lock.notify(); // not full condition &#125; return oldFront;&#125; 应用 (1) MyBatis 中 在数据库连接这个地方使用到的：org.apache.ibatis.datasource.pooled.PooledDataSource 类中，所以不用花太多的时间去深究。1、获取连接的时候，如果数据库连接池没有空闲的连接，那么当前线程就会进入等待，直到被通知，这个地方就是popConnection()方法 *ThreadLocal 实现每⼀个线程都有⾃⼰的专属本地变量。 如果你创建了⼀个 ThreadLocal 变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是 ThreadLocal 变量名的由来。 如果使用 ThreadLocal 管理变量，则每一个使用该变量的线程都获得该变量的副本， 副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。 (1)概述 原理： 为每个使用该变量的线程都提供独立的变量副本，从而不会影响到其他线程所对应的副本。 是一种多线程间并发访问变量的解决方案，不使用锁来保证并发访问，本质是以空间换时间的方式，为每个线程提供变量的独立副本，以保证线程的安全。 (2) 作用 ThreadLocal 的作用是提供线程内的局部变量 ，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。 底层结构 一个Thread中只有一个ThreadLocalMap， 一个ThreadLocalMap中可以有多个ThreadLocal对象， 其中一个ThreadLocal对象对应一个ThreadLocalMap中一个的Entry实体 (也就是说：一个Thread可以依附有多个ThreadLocal对象)。 (1) Thread 中持有的结构 线程局部变量 ，那么理所当然就应该存储在自己的线程对象中 线程局部变量存储在 Thread 对象的 threadLocals 属性中 12345public class Thread implements Runnable &#123; ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ...&#125; (2) ThreadLocal.ThreadLocalMap 是实现 ThreadLocal 的原理，用于存储每一个线程的变量副本，Map中元素的键为线程对象，而值对应线程的变量副本。 KEY: 线程对象； VALUE: 对应线程的变量副本； 12ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; ......&#125; 一些操作 (1) ThreadLocal 4 大 public 方法 根据当前线程获取到对应的 ThreadLocalMap，借助该 Map 操作实现； get()、 set()、 remove()、 withInitial()。 最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上， ThreadLocal 可以理解为只是 ThreadLocalMap 的封装，传递了变量值。 1234567891011121314151617181920212223242526272829public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125;public static &lt;S&gt; ThreadLocal&lt;S&gt; withInitial(Supplier&lt;? extends S&gt; supplier) &#123; return new SuppliedThreadLocal&lt;&gt;(supplier);&#125; 与同步机制的比较 a.ThreadLocal与同步机制都是为了 &lt;u&gt;解决多线程中相同变量的访问冲突问题&lt;/u&gt;。 b.前者采用以&quot;空间换时间&quot;的方法，后者采用以&quot;时间换空间&quot;的方式 对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 Thread 造成的内存溢出问题 (1) 与线程池协作引发的内存溢出问题 ThreadLocal变量是维护在Thread内部的，线程不退出，对象的引用就会一直存在。 当我们使用线程池的时候，就意味着当前线程未必会退出(比如固定大小的线程池，线程总是存在的)。如果这样的话，将一些很大的对象设置到ThreadLocal中(这个很大的对象实际保存在Thread的threadLocals属性中)，这样的话就可能会出现内存溢出的情况。 一种场景就是说如果使用了线程池并且设置了固定的线程，处理一次业务的时候存放到ThreadLocalMap中一个大对象，处理另一个业务的时候，又一个线程存放到ThreadLocalMap中一个大对象，但是这个线程由于是线程池创建的他会一直存在，不会被销毁，这样的话，以前执行业务的时候存放到ThreadLocalMap中的对象可能不会被再次使用，但是由于线程不会被关闭，因此无法释放Thread 中的ThreadLocalMap对象，造成内存溢出。 也就是说，ThreadLocal在没有线程池使用的情况下，正常情况下不会存在内存泄露，但是如果使用了线程池的话，就依赖于线程池的实现，如果线程池不销毁线程的话，那么就会存在内存泄露。所以我们在使用线程池的时候，使用ThreadLocal要格外小心！ (2) 原因 ThreadLocal内存泄漏的根源是：由于 ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏 ，而不是因为弱引用。 弱引用与内存泄漏 弱引用被回收了只是回收了Entry的key引用，但是Entry应该还是存在的吧？ ThreadLocal的get(),set(),remove() 的时候都会清除线程ThreadLocalMap里所有key为null的value。 1234567static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 这里我们就需要重新认识一下，什么是：当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象，这里的重点是：只被弱引用关联的对象 上述过程尽管 GC 执行了垃圾收集，但是弱引用还是可以访问到结果的，也就是没有被回收，这是因为除了一个弱引用 userWeakReference 指向了User实例对象，还有 user 指向 User 的实例对象，只有当user和User实例对象的引用断了的时候，弱引用的对象才会被真正的回收 并不是所有弱引用的对象都会在第二次GC回收的时候被回收，而是 回收掉只被弱引用关联的对象 。因此，使用弱引用的时候要注意到！希望以后在面试的时候，不要上来张口就说，弱引用在第二次执行GC之后就会被回收！ 应用场景 (1) 解决数据库连接 避免方法中总是出现 Connection 参数，每个线程每次使用的都是用一个 Connection； (2) MyBatis 中用于 Session 管理 123456789101112private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s; &#125; *线程池(1) new Thread 弊端： 每次new Thread新建对象，Thread 为大对象，性能差 ； 线程缺乏统一管理，可能无限制的新建线程，相互竞争，有可能占用过多系统资源导致死机或 OOM； 缺少更多功能，如更多执行、定期执行、线程中断； (2) 线程池好处 重用性： 重用存在的线程，减少对象创建、消亡的开销，性能佳 ； 可控性： 可有效控制最大井发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞 ； 功能性： 提供定时执行、定期执行、单线程、井发数控制等功能； 线程池参数 corePoolSize: &lt;= x maximumPoolSize: 最大线程数 workQueue: 工作队列，为BlockingQueue threadFactory: 默认非守护，同优先级，名称 rejectHandler: BlockingQueue 满，无空闲的线程池，拒绝cel，默认直接抛出 exception keepAliveTime，unit: corePoolSize –&gt;&gt; maximumPoolSize 123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 四种拒绝策略： ThreadPoolExecutor 类中提供 AbortPolicythrows exception DiscardPolicy： 直接丢弃 CallerRunPolicy： 使用调用者 thread 执行 DiscardOldestPolicy： 丢弃 BlockingQueue 中最靠前的 task，执行当前 task 方法 (1) 主要方法 生命周期及 ExecutorService： - execute() - submit(): execute + Future - shutdown() : handle BlockingQueue in - shutdownNow() : BlockingQueue not handler (2) 监控方法： getTaskCount()：线程池已执行和未执行的任务总数 getCompIetedTaskCount()：已完成的任务数量 getPoolSize()：线程池当前的线程数量 getActiveCount()：当前线程池中正在执行任务的线程数量 Executors① Executors.newCachedThreadPool 创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute 将重用以前构造的线程(如果线程可用)。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源。 ② Executors.newFixedThreadPool 创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大多数 nThreads 线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线程将代替它执行后续的任务(如果需要)。在某个线程被显式地关闭之前，池中的线程将一直存在。 ③ Executors.newSingleThreadExecutor Executors.newSingleThreadExecutor()返回一个线程池(这个线程池只有一个线程),这个线程池可以在线程死后(或发生异常时)重新启动一个线程来替代原来的线程继续执行下去！ ④ Executors.newScheduIedThreadPool 创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。 1ScheduledExecutorService scheduledThreadPool= Executors.newScheduledThreadPool(3); scheduledThreadPool.schedule(newRunnable()&#123; @Override public void run() &#123; System.out.println(&quot;延迟三秒&quot;); &#125; &#125;, 3, TimeUnit.SECONDS); scheduledThreadPool.scheduleAtFixedRate(newRunnable()&#123; @Override public void run() &#123; System.out.println(&quot;延迟1秒后每三秒执行一次&quot;); &#125; &#125;,1,3,TimeUnit.SECONDS); ⑤ 线程池配置 CPU 密集型任务，就需要尽量压榨 CPU，参考值可以设为 NCPU + 1IO 密集型任务，参考值可以设置为 2 * NCPU； 选用基础： - 小型应用不适合 - 线程调度时间开销大 @@计算密集型与IO密集型 密集型： CPU 核 + 1IO 密集： CPU 核数 / (1-阻塞系数) 一般0。8~0.9 @@如何正确的使用线程池 设置线程池，比设置界限； hook 机制嵌入行为，由 beforeMethod, afterMethod 记录线程执行前和后做日志，异常结果； 优雅的关闭，hook 机制，推荐使用 JavaBean 创建线程池，在 destoryMethod 里面在销毁时调用 shutdown； JMM(1) 概述 Java 并发采用的是共享内存模型，线程之间的通信总是隐式执行。 定义： Java 线程之间的通信由 JMM 控制， JMM 决定一个线程对共享变量的写入何时对另一个线程可见。 Java内存模型(JMM)解决了可见性和有序性的问题，而锁解决了原子性的问题，理想情况下我们希望做到“同步”和“互斥” 主内存与工作内存 主内存副本拷贝，非对整个obj拷贝。 Java借助共享内存实现线程间的通信 内存间的交互操作 8中操作, 主内存，保证原子性； 对于long和double的特殊规则(了) 64位 对于volatile变量的特殊规则 语义： 可见性, 实现对于其修改立即写回主内存中, 非保证原子性; 有序性, 禁止指令重排序, 是一种同步机制, 轻量, 与DCL实现安全的单例. 原子性、可见性与有序性volatile：finale: this 引用逃逸(读初始化一般的data)；synchronized: “万能”, 重量, 阻塞 硬件的效率与一致性:缓存一致性协议 关键字*volatile 能够在线程之间保持可见性，能够被 多线程同时读，并且保证不会读到过期的值，但 只能被单线程写。基于 happens-before 原则，对 volatile 字段的写入操作先于读操作，即使两个线程同时修改和获取 volatile 变量。 volatile是轻量级的synchronized，他的意思是：当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。如果volatile变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度 (1) 特性 a.volatile关键字为域变量的访问提供了一种免锁机制， b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新， c.因此每次使用该域就要重新计算，而不是使用寄存器中的值 d.volatile不会提供任何原子操作，它也不能用来修饰final类型的变量 volatile 保证可见性 有volatile变量修饰的共享变量进行写操作的时候会引发了两件事情：(1)将当前处理器缓存行的数据写回到系统内存；(2)这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效； 底层实现细节(了)： ① 发生 volatile W， JVM 向处理器发送 Lock 前缀的汇编命令，将该变量缓存行写到系统内存； ② 为了保证写回到的数据被其他线程立即可见，借助 缓存一致性协议 实现，每个处理器 嗅探总线 上传播的数据检查自己是否过期，过期强制从系统内存中把数据读到处理器缓存中。 volatile 如何禁止指令重排序 借助内存屏障和禁止指令重排实现 对 volatile 变量写操作时，会在写操作之后加上一条 store 屏障指令，将本地内存中的共享变量刷新到主内存； 对 volatile 变量的读操作，会在读操作之前加上一条 load 屏障指令，从主内存中读取共享变量。 使用volatile关键字修饰共享变量可以禁止重排序。若用volatile修饰共享变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序volatile禁止指令重排序的一些规则： 1.当第二个操作是voaltile写时，无论第一个操作是什么，都不能进行重排序 2.当地一个操作是volatile读时，不管第二个操作是什么，都不能进行重排序 3.当第一个操作是volatile写时，第二个操作是volatile读时，不能进行重排序 涉及到内存屏障(Memory Barrier)，它是让一个CPU处理单元中的内存状态对其它处理单元可见的一项技术。 一些应用 无锁读取数据： ConcurrencyHashMap 的 get 操作，通过 volatile 替换锁，AQS 中 state 变量； 作为终止标识，exit 来进行终止，类似 interrupt 终止； 那么在禁止重排序时是一个较好的使用场景，否则我们不需要再使用它，如 DCL 中通过 volatile 修饰； 热部署的变量： 通过线程修改之后立即被其他线程可见； 适用场景： (1) 对变量的写操作不依赖于当前值(比如 i++)，或者说是单纯的变量赋值(boolean flag = true)。 (2)该变量没有包含在具有其他变量的不变式中，也就是说，不同的 volatile 变量之间，不能互相依赖。只有在状态真正独立于程序内其他内容时才能使用 volatile。 synchronized字解决的是多个线程之间访问资源的同步性。 (1) 一些性质： 提供原子性，实现同步功能； 是 JVM 提供的同步工具，使用 lock 和 unlock 字节码指令，保证被它修饰 的⽅法或者代码块在任意时刻只能有⼀个线程执⾏； 与 CAS 比较： 相比于 CAS 可以保证 一块 而非一个变量的原子性； 与 Lock 比较： 相比于 JDK Lock 可以保存 程序运行信息 ，便于解决死锁和异常； (2) 使用的位置： code bloker： 显视锁住当前调用对象 synchronized(this)，通过监视器锁实现； method: 锁住调用对象，通过访问标识位实现； static method: 锁住该类的所有对象； class: 显视锁住类对象 synchronized(xxx.class)； 适用同一个对象调用锁住 obj 的可以实现同步，使其中的一个线程阻塞等待另一个线程执行完毕；不同对象调用时不适用； synchronized 保证可见性原理 通过 javap -v xxx.class 获取字节码指令分析 关键字synchronized可以修饰方法或者以同步块的形式来进行使用，它主要确保多个线程在同一个时刻，只能有一个线程处于方法或者同步块中，它保证了线程对变量访问的可见性和排他性。 JMM 对 synchronized 的规定： 线程解锁前，必须把共享变量的最新值刷新到主内存； 线程加锁时，将清空工作内存 中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值(注意，加锁与解锁是同一把锁)； 本质是对一个对象的监视器(monitor) 进行获取，而这个获取过程是排他的，也就是说同一时刻只有一个线程获取到由 synchronized 所保护对象的监视器。 (1) 对代码块同步 monitorenter 和 monitorexit 指令 Synchronized 每个对象有一个 内置的监视器锁(monitor) 。当 monitor 被占用时就会处于锁定状态，线程执行monitorenter 指令时尝试获取monitor的所有权，过程如下：1、如果 monitor 的进入数为0，则该线程进入 monitor，然后将进入数设置为1，该线程即为 monitor 的所有者。2、如果线程己经占有该 monitor，只是重新进入，则进入monitor 的进入数加1．3．如果其他线程巳经占用了 monitor ,则该线程进入阻塞状态，直到 monitor 的进入数为0，再重新尝试获取monitor的所有权。 (2) 同步方法 调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了， 执行线程将先获取 monitor，获取成功之后才能执行方法体 ，方法执行完后再释放 monitor Synchronize和lock都属于同步阻塞。 synchronized 其他性质 (1) 作为锁 见下部分锁相关 (2) 原子性 @Q: CAS 机制与 synchronized 保证原子性的区别？ ① CAS 仅能够保证一个变量的原子性，而 synchronized 可用于方法、类、字段等多处； ② CAS 通过不断循环重试实现，存在不必要的开销，但是是一种无锁的实现； ③ CAS 存在 ABA 问题； Q: JDK1.6+ 的 synchronized 关键字做了哪些优化? 对锁的实现引⼊了⼤量的优化，如偏向锁、轻量级锁、⾃旋锁、适应性⾃旋锁、锁消除、锁粗 化等技术来减少锁操作的开销。 锁主要存在四种状态，依次是：⽆锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈⽽逐渐升级。锁可以升级不可降级，提⾼获得锁和释放锁的效率。 三大特性原子性 提供了互斥访问，同一时刻只能有一个线程对它进行操作。 (1) 实现方式： 锁的同步机制： synchronized | Lock CAS 机制： 包括 AtomicInteger 等原子类 可见性 一个线程对主内存中共享变量的修改，能够及时地被其他线程观察到。 (1) 不可见的原因： 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主存间及时更新 (2) 实现方式 volatile 关键字可以保证共享变量的可⻅性。 有序性： 代码在执⾏的过程中的先后顺序。 Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性，导致代码的执⾏顺 序未必就是编写代码时候的顺序。 volatile、synchronized、Lock *happen-before 原则 单一线程原则 Single Thread Rule 一个线程内，程序前面的操作先于后面的操作。也叫程序次序原则。 管程锁定原则 Monitor Lock Rule 一个 unlock option 先于后面同一个锁的 lock option。 volatile 变量规则 Volatile Variable Rule 对一个 volatile 变量的写操作先于后面对这个变量的读操作。 传递性原则 Transitivity A –&gt; B, B –&gt; C ==&gt;&gt; A –&gt; C 线程启动规则 Thread Start Rule丶。 入 Thread 对象的 start() 先于此线程的每一个动作 线程中断规则 Thread Interruption Rule 对线程 interrupt() 的调用先于被中断线程的代码检测到中断事件的发生，即 isInterrupt(). 线程加入规则 Thread Join Rule Thread 对象的结束先于 join() 方法返回 对象终结规则 Finalizer Rule 一个对象的初始化完成(构造函数结束)先于它的 finalize() 方法的开始 线程同步的实现说明： 需要使用线程同步的根本原因在于对普通变量的操作不是原子的。 1、 互斥同步 (1) 同步方法 、同步代码块 (2) 使用重入锁实现线程同步 (3) 使用阻塞队列实现线程同步 2、 非阻塞同步 主要是 CAS 不断尝试实现 (1) 使用原子变量实现线程同步 3、 无同步方案 (1) 使用局部变量实现线程同步 如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本， 副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。 (2) 使用特殊域变量(volatile)实现线程同步 注：多线程中的非同步问题主要出现在对域的读写上，如果让域自身避免这个问题，则就不需要修改操作该域的方法。 锁与锁优化线程安全 Java语言中的线程安全绝对线程安全相对线程安全线程兼容线程对立 2. 线程安全的实现方法1)同步互斥Synchronized：存在挂起、恢复，是阻塞 实现的，且java线程直接映射到OS原生线程上的，存在用户态到内核态的_转换_，因而性能较差。 Lock：可重用锁 2)非阻塞基于CAS+Loop实现 3)无同步 可重入代码 TLC，线程本地， 是消息队列架构模式 锁乐观锁 乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是 在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作 (比较跟上一次的版本号，如果一样则更新)，如果失败则要重复读-比较-写的操作。 java中的乐观锁基本都是通过CAS操作实现的，CAS是一种更新的原子操作， 比较当前值跟传入值是否一样，一样则更新，否则失败。 悲观锁 悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block直到拿到锁。java中的悲观锁就是 Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如RetreenLock。 JVM 锁优化锁有四种状态，无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁 通过 对象头实现 (1) 原理： 基于对象头的Mark Word， 23位表示偏向的线程ID 偏向锁 偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入(CAS)的开销，看起来让这个线程得到了偏护 而偏向锁只需要在置换 ThreadID 的时候依赖一次CAS原子指令 如果一个线程获得了锁，那么锁就进入了偏向模式。当这个线程再次请求锁时，无需再做任何同步操作 (1) 设计原因 为什么会出现这种设计的方式那？这是因为根据HotSpot的作者研究，他发现 锁不仅不存在多线程竞争，而且总是由同一线程多次获得 ，为了让线程获得锁的代价更低而引入了的偏向锁这个概念。 (2) 锁的升级 在锁竞争比较激烈的场景，最有可能的情况是每次不同的线程来请求相同的锁，这样的话偏向锁就会失效，倒不如不开启这种模式，幸运的是Java虚拟机提供了参数可以让我们有选择的设置是否开启偏向锁。如果偏向锁失败，虚拟机并不会立即挂起线程，而是使用轻量级锁进行操作。 (3) 性质： 线程获取到锁之后，消除这个线程的重入开销； 1-XX:+UseBiasedLocking 轻量级锁 轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。 如果偏向锁失败，虚拟机并不会立即挂起线程，而是使用轻量级锁进行操作。轻量级锁他只是简单的将对象头部作为指针，指向持有锁的线程堆栈的内部，来判断一个线程是否持有对象锁。 如果线程获得轻量级锁成功，则可以顺利进入临界区。如果轻量级锁加锁失败，则表示其他线程抢先夺到锁，那么当前线程的轻量级锁就会膨胀为重量级锁。 轻量级锁所适应的场景是 线程交替执行同步块 的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。 (1) 说明： 嵌入在线程栈中的对象使用 Displaced Mark Word 复制对象头到堆栈中，借助CAS实现同步。还是需要进行 CAS , 出现竞争时，会尝试自旋 (2) 原理： 绝大部分锁在整个同步周期内都是不存在竞争的 自旋锁(无锁) (1) 原理 自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等(自旋)，等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。 (2) 优缺点 (3) 时间阈值 在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是 由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。 (4) 一些实现 在通过一定的自旋失败后，通常转化为加悲观锁实现，如 ConcurrentHashMap 中对于 put 在尝试 3 次失败后进行转换成对链表头进行加锁； 1-XX:+UseSpinning 自适应锁原来默认是10，现在可以实现自适应自旋 自适应，由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 如ConcurrentHashMap的tryLock() -XX:+UseSpinning 1.7默认开启-XX:PreBlockSpin 默认为10，代表 锁消除不存在共享数据竞争，需要对其进行逃逸分析，从而减少不必要的锁。 锁粗化防止在循环中加锁，进行资源的浪费 锁的对比 程序锁优化1.减少锁粒度 将大对象(这个对象可能会被很多线程访问)，拆成小对象，大大增加并行度，降低锁竞争。降低了锁的竞争，偏向锁，轻量级锁成功率才会提高。 () 应用 ① 最最典型的减小锁粒度的案例就是ConcurrentHashMap。进而提高并发程度如将 HashMap –&gt; ConcurrentHashMap使用Segment(16)增加并行度。 2. 减少锁持有时间 只用在有线程安全要求的程序上加锁 只在有必要的时候进行同步，这样就明显减少了线程持有锁的时间，从而提高系统的性能。 12345public synchronized void syncMethod()&#123; method1(); // cost much time mutextMethod(); // 实际需要进行同步的方法 method2();&#125; 3. 锁分离如根据功能进行锁分离(1) 应用 ① ReadWriteLock，即保证了线程安全，又提高了性能。 在读多写少的情况下，通过 ReentrantReadWriteLock 替换 ReentrantLock，实现对于 Read 的不加锁实现； ② 读写分离思想可以延伸， 只要操作互不影响，锁就可以分离 。比如LinkedBlockingQueue 从头部取出，从尾部放数据。 如果使用独占锁的话，则要求两个操作在进行时首先要获取当前队列的锁，那么take和put就不是先真正的并发了，因此，在JDK中正是实现了两种不同的锁，一个是takeLock一个是putLock。 4. 锁粗化不在循环中加锁，来回加和释放的开销大 12345678910111213public void syncMethod() &#123; synchronized (lock) &#123; //第一次加锁 method1(); &#125; method3(); synchronized (lock) &#123; //第二次加锁 mutextMethod(); &#125; method4(); synchronized (lock) &#123; //第三次加锁 method2(); &#125;&#125; 如果第一次和第二次加锁和线程上下文切换的时间超过了method1()、method2()method3()、method4() 的时间. 改进后的代码的执行时间可能小于上述分别加锁的时间，这就是锁粗化，也是一种锁优化的方式，但是要根据具体的场景； 5. 锁消除 锁消除是在 编译器级别的事情。在即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作。 引发原因： ① 多数是因为程序员编码不规范引起。 ② 有时这些锁并不是程序员所写的，有的是JDK实现中就有锁的，比如Vector和StringBuffer 这样的类，它们中的很多方法都是有锁的。当我们在一些不会有线程安全的情况下使用这些类的方法时，达到某些条件时，编译器会将锁消除来提高性能。 **6. JVM 锁优化(volatile, synchronized) ** 见上部分 *synchronized(1) 作用范围 (2) 核心组件 Wait Set：哪些调用wait方法被阻塞的线程被放置在这里； Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck； Owner：当前已经获取到所资源的线程被称为Owner； !Owner：当前释放锁的线程。 () 底层实现 是非公平锁，等待的线程会先尝试自旋获取锁，如果获取不到就进入 ContentionList； 每个对象后有个 monitor 对象， 加锁就是在竞争 monitor 对象 ， 代码块加锁是在前后分别加上monitorenter和monitorexit指令来实现的，方法加锁是通过一个标记位来判断的。 与 ReentrantLock 对比 相同点： 都是可重入锁。 ① 底层实现：ReentrantLock 是 API 级别的，synchronized 是 JVM 级别的，为关键字，能够在出现异常时打印出对应的错误堆栈用于分析问题，同时 JVM 对 synchronized 提供了锁升级的优化； ② 锁的实现方式： ReentrantLock 是同步非阻塞，采用的是乐观并发策略，而 synchronized 是同步阻塞，使用的是悲观并发策略。 ③ 锁的使用的安全性： ReentrantLock 需要显视加锁解锁，可能因为忘记解锁而陷入死锁，而 synchronized 为隐式加锁，不会因为忘记解锁而陷入死锁。 ④ 功能灵活性： ReentrantLock 可尝试获取锁； RentrantLock 可中断获取锁，提供了⼀种能够中断等待锁的线程的机制，lock.lockInterruptibly() ； RentrantLock 能够支持公平锁, synchronized 只能实现非公平锁； RentrantLock 可实现选择性通知： synchronizedf 使用 notify / notifyAll 进行通知时，通知的线程由 JVM 选择，ReentrantLock 更加灵活的绑定多个 Condition, 进行选择性通知。 1 ReentrantLock显示的获得、释放锁，synchronized隐式获得释放锁2 ReentrantLock可响应中断、可轮回，synchronized是不可以响应中断的，为处理锁的不可用性提供了更高的灵活性3 ReentrantLock是API级别的，synchronized是JVM级别的4 ReentrantLock可以实现公平锁5 ReentrantLock通过Condition可以绑定多个条件6 底层实现不一样， synchronized是同步阻塞，使用的是悲观并发策略，lock是同步非阻塞，采用的是乐观并发策略7 Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现。8 synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁。9 Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断。10 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。11 Lock可以提高多个线程进行读操作的效率，既就是实现读写锁等。 synchronized 与volatile 的比较 ① 实现与性能：volatile关键字是线程同步的 轻量级实现，所以 volatile性能肯定⽐synchronized关键字要好。 但是 volatile关键字只能⽤于变量⽽synchronized关键字可以修饰⽅法以及代码块。 synchronized关键字在JavaSE1.6之后进⾏了主要包括为了减少获得锁和释放锁带来的性能消耗 ⽽引⼊的偏向锁和轻量级锁以及其它各种优化之后执⾏效率有了显著提升，实际开发中使⽤ synchronized 关键字的场景还是更多⼀些。 ② 阻塞： 多线程访问volatile关键字不会发⽣阻塞，⽽synchronized关键字可能会发⽣阻塞 ③ 三特性的： volatile关键字能保证数据的可⻅性，但不能保证数据的原⼦性。synchronized关键字两者都能 保证。 ④ 使用场景： volatile关键字主要⽤于解决变量在多个线程之间的可⻅性，⽽ synchronized关键字解决的是 多个线程之间访问资源的同步性。 死锁两个进程都在等待对方执行完毕才能继续往下执行的时候就发生了死锁。结果就是两个进程都陷入了无限的等待中。 (1) 死锁的四个必要条件： 互斥条件：该资源任意⼀个时刻只由⼀个线程占⽤。 持有和等待条件： ⼀个进程因请求资源⽽阻塞时，对已获得的资源保持不放。 不可剥夺条件：线程已获得的资源在末使⽤完之前不能被其他线程强⾏剥夺，只有⾃⼰使⽤完毕后 才释放资源。 循环等待条件：:若⼲进程之间形成⼀种头尾相接的循环等待资源关系。 (2) 避免线程死锁 ① 破坏互斥条件 ：这个条件我们没有办法破坏，因为我们⽤锁本来就是想让他们互斥的（临界资源需要互斥访问）。 ② 破坏请求与保持条件 ：⼀次性申请所有的资源。 ③ 破坏不剥夺条件 ：占⽤部分资源的线程进⼀步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 ④ 破坏循环等待条件 ：靠按序申请资源来预防。按某⼀顺序申请资源，释放资源则反序释放。 相关问题 (1) 如何确保N个线程可以访问N个资源同时又不导致死锁？ ① 指定获取锁的顺序，并强制线程按照指定的顺序获取锁。因此，如果所有的线程都是以同样的顺序加锁和释放锁，就不会出现死锁了； ② 使用带有超时时间的锁； ③ 通过死锁的检测和恢复机制进行规避； (2) 写一个发生死锁的程序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 class DeadLock1 implements Runnable &#123; private static Object resource1 = new Object(); private static Object resource2 = new Object(); private int flag = 0; public DeadLock1(int flag) &#123; this.flag = flag; &#125; @Override public void run() &#123; if (flag == 1) &#123; synchronized (resource1) &#123; try &#123; Thread.sleep(500); System.out.println(&quot;flag1 one level&quot;); synchronized (resource2) &#123; System.out.println(&quot;flag 1&quot;); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; if (flag == 2) &#123; synchronized (resource2) &#123; try &#123; Thread.sleep(500); System.out.println(&quot;flag2 one level&quot;); synchronized (resource1) &#123; System.out.println(&quot;flag 2&quot;); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(new DeadLock1(1)); Thread t2 = new Thread(new DeadLock1(2)); t1.start(); t2.start(); &#125;&#125; 其他锁无锁 CAS算法的过程是这样：它包含三个参数CAS(V,E,N): V表示要更新的变量，E表示预期值，N表示新值。仅当V值等于E值时，才会将V的值设为N，如果V值和E值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。最后，CAS返回当前V的真实值。 可重入锁(递归锁) 可重入锁，也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。 偏向锁对于偏向的线程没有重入的开销。 公平锁和非公平锁 公平锁(Fair) 加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得。 非公平锁(Nonfair) 加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待。 非公平锁性能比公平锁高5~10倍，因为公平锁需要在多核的情况下维护一个队列 Java中的synchronized是非公平锁，ReentrantLock 默认的lock()方法采用的是非公平锁。 读写锁 读读不互斥，读写互斥，写写互斥 为了提高性能，Java提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的,在一定程度上提高了程序的执行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm自己控制的，你只要上好相应的锁即可。 (1) 读锁 如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁 (2) 写锁 如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！ Java中读写锁有个接口java.util.concurrent.locks.ReadWriteLock，也有具体的实现ReentrantReadWriteLock。 共享锁和独占锁 java并发包提供的加锁模式分为独占锁和共享锁。 (1) 独占锁 独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock就是以独占方式实现的互斥锁。独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。 (2) 共享锁 共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。 AQS的内部类Node定义了两个常量 SHARED 和 EXCLUSIVE ，他们分别标识 AQS队列中等待线程的锁获取模式。 java的并发包中提供了ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问，或者被一个 写操作访问，但两者不能同时进行。 重量级锁(Mutex Lock) Synchronized是通过对象内部的一个叫做监视器锁(monitor)来实现的。但是监视器锁本质又是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。 因此，这种 依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”。JDK中对Synchronized做的种种优化，其核心都是为了减少这种重量级锁的使用。JDK1.6以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。 分段锁 是一种思想ConcurrentHashMap是学习分段锁的最好实践 活锁 因为活跃性而引入的问题 并发中的设计模式单例模式保证全局唯一，并发情况下使用安全 见设计模式单例 7 种单例模式： 饿汉式； 双重监测懒汉式； 线程安全懒汉式； 静态内部类持有懒汉式； 枚举式； 变种的饿汉式； 变种的懒汉式； Future 模式Future模式的核心思想：异步调用 不仅可以在子线程完成后收集其结果，还可以设定子线程的超时时间，避免主任务一直等待。 () 性质Future模式不会立即返回你需要的数据，但是，他会返回一个契约 ，以后在使用到数据的时候就可以通过这个契约获取到需要的数据。 在广义的Future模式中，虽然获取数据是一个耗时的操作，但是服务程序不等数据完成就立即返回客户端一个伪造的数据(就是上述说的“契约”)，实现了Future模式的客户端并不急于对其进行处理，而是先去处理其他业务，充分利用了等待的时间，这也是Future模式的核心所在，在完成了其他数据无关的任务之后，最后在使用返回比较慢的Future数据。这样在整个调用的过程中就不会出现长时间的等待，充分利用时间，从而提高系统效率。 () JDK 中的 Future 模式 FutureTask实现了 Callable，Future接口，RunnableFuture接口继承了Future和Runnable接口。因为RunnableFuture实现了Runnable接口，因此FutureTask可以提交给Executor进行执行，FutureTask有两个构造方法，如下： Runnable 与 Callable 的区别 (1) Callable规定的方法是call()，Runnable规定的方法是run()；(2) Callable的任务执行后可返回值，而Runnable的任务是不能返回值得；(3) call()方法可以抛出异常，run()方法不可以；(4) 运行Callable任务可以拿到一个Future对象，Future 表示异步计算的结果 () 异常 Future 的 get() 可能会阻塞当前线程的执行，会抛出 InterruptedExcpeiton、ExecutionException，若线程已经取消，抛出 CancellationException，取消由cancel 方法来执行。isDone确定任务是正常完成还是被取消了。 () 可取消性 一旦计算完成，就不能再取消计算。如果为了可取消性而使用Future 但又不提供可用的结果，则可以声明Future&lt;?&gt; 形式类型、并返回 null 作为底层任务的结果。 生产者消费者使用生产者消费者模式实现的一个例子；模仿分布式爬虫； 单生产者单消费者 单生产者多消费者 多生产者单消费者 多生产者多消费者 Refs 《Java 并发编程的艺术》 《深入理解Java虚拟机(第二版)》","tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"Docker 学习笔记","date":"2020-12-17T14:41:19.000Z","path":"2020/12/17/Docker-学习笔记/","text":"Docker 基础 类似精简的 Linux 环境，含 root 权限、进程空间、用户空间和网络空间，以及运行在其中的应用程序 Client： 客户端通过 CLI 命令与 Docker 交互Docker daemon： 宿主机的守护进程，通过 RESTful 接口处理 Client 的命令，连接 Registry 进行镜像的拉取的推送，具体配置见 [Daemon配置](#Daemon 配置)Registry： 保存 image 的地方，实现 image 的维护、复用Image： 静态的镜像，可根据 Image 运行 containerContainer： 依据 Image 生成的具体的容器，实际运行的程序 Docker 底层实现原理： Namespaces：做隔离pid，net，ipc，mnt，uts Control groups(cgroups)：做资源限制 Union file systems: Container和image的分层，分层文件系统 镜像 一个特殊的文件系统，提供容器运行时所需的程序，同时包含一些为运行时准备的配置参数，无法更改 镜像的获取 根据 Dockerfile 构建镜像，配合 sh 脚本实现一些定制的初始化和参数判断逻辑，可重建 根据容器构建镜像，在只读镜像上操作可写容器重新打包成镜像，Docker 无状态，volume 不会打包进镜像，较少使用 从远程 Registry 拉取镜像 123456# 从远程 registry 拉取docker commit wonderful_mendeleev janhen/centos-vim-gcc:1.0.0# 从 Dockerfile 构建docker build -t janhen/myimage:1.0 .# 从容器创建docker pull &lt;registry_host&gt;/&lt;username OR project_name&gt;/&lt;image_name&gt;:&lt;image_tag&gt; 镜像 tag 1234# image 的查、交互docker imagesdocker history &lt;image_id&gt;docker tag &lt;image_old_name&gt; &lt;image_new_name&gt; 镜像清理 处理同一个版本多次覆盖，默认查找顺序为 Local -&gt; Registry 的问题 1234567# 删除指定的 imagedocker rmi &lt;image_id OR image_name&gt;# 强制删除指定|全部 imagedocker rmi -f $(docker images)# 删除 &lt;none&gt; 的镜像(#)docker rmi $(docker images -f &quot;dangling=true&quot; -q)docker images | grep none | awk &#x27;&#123;print $3&#125;&#x27; | xargs docker rmi 容器 是镜像运行时的实体，构建在镜像上，可对容器进行写操作 Container 的启动并运行 单机上使用最多，控制部署时候的各种参数，包含网络、存储、密码、变量… 常用的启动指定： 指定网络，根据需要选择端口转发、单机桥接网络、多机网络、主机网络 指定文件映射，将程序中的配置文件、数据文件隔离出来，避免应容器销毁而丢失 指定命令，内部运行的程序自带的命令，如 Redis 中的命令控制持久化方式… 指定变量，通过命令方式、环境变量方式指定，让运行容器更加定制化 1234567891011121314151617181920212223242526# 容器的运行# --name: 按照特定名称启动，作为容器标识# -d: 后台运行# -i: 交互式运行容器，打开STDIN，用于控制台交互 # -t: 终端方式交互, 通过 bash、shell... 进行命令式交互# -p: 映射宿主机与容器的端口号# --network=&lt;value&gt;: 指定网络连接类(#)# -v: 进行宿主机文件与容器文件的映射(#)# --&lt;param&gt;=&lt;value&gt;: 进行特定参数指定，传入中的参数，在容器中的文件处可引用# -e: 指定环境变量, 对应镜像提供，与 Dockerfile 中指定的 ENV 等同，可进入容器使用 env 查看(#)# --privileged=true: 给容器扩展的权限# --rm: 在容器终止运行后自动删除容器文件，避免磁盘浪费，常用于测试# --restart=&lt;strategy&gt;: 重启策略，与 --rm 参数冲突，提供多种策略# --entrypoint: 覆盖默认镜像的 ENTRYPOINT# --link: 添加链接到另一个 container, 不建议使用# -w: 指定工作目录，等价于 Dockerfile 中的 WORKDIR# 启动过后执行一段 Shell 脚本, 用于测试环境类镜像使用docker run ubuntu:18.04 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;# 以命令行方式进入容器，查看镜像具体情况docker run -it --entrypoint bash openjdk:7-jre # Dockerfile 中环境变量配合运行指定 JVM 运行参数、运行端口，参数名仿照 spring-boot maven 插件docker run -d -p 7070:7070 -e JVM_OPTS=&quot;-Xms1024m -Xmx2048m&quot; -e PROGRAM_ARGS=&quot;--server.port=7070&quot; com.blinkfox/web-demo:1.0.0docker run -e &quot;JAVA_OPTS=-agentlib:jdwp=transport=dt_socket,address=5005,server=y,suspend=n&quot; -p 8080:8080 -p 5005:5005 -t springio/gs-spring-boot-dockerdocker run -d --name test1 \\ -e MYENV=AAAA \\ busybox /bin/sh -c &quot;while true;do sleep 3600;done&quot; 容器的信息查看 1234567891011121314151617181920# 容器整体信息查询docker infodocker info | grep &quot;Docker Root Dir&quot;docker ps [(-a)|(-aq)]?# 配置信息docker inspect &lt;container&gt;docker inspect -f &#123;&#123;xx.yy&#125;&#125; &lt;container&gt;# 交互，调试# 日志， -f ： follow log output，持续实时显示日志， -t:......# 命令交互# 在容器中执行特定命令# 日志查看docker logs &lt;contain_id OR container_name&gt;docker logs -f &lt;container_id OR container_name&gt;# 容器内部执行docker exec -it &lt;container_id&gt; bashdocker exec &lt;container_id&gt; ip adocker exec -it &lt;container_id OR container_name&gt; env# 运行信息docker stat &lt;container&gt; 容器基础命令 123456789# 容器的启、停docker container start|stop|restart &lt;container_id OR contaienr_name&gt;# 导入导出# 导出容器成指定的 tar 包# 容器快照文件导入为*镜像*# URL/目录导入docker export 7691a814370e &gt; ubuntu.tarcat ubuntu.tar | docker import - test/ubuntu:v1.0docker import http://example.com/exampleimage.tgz example/imagerepo 容器的清理 12345678# 删除|强制删除指定的容器docker container rm &lt;container_id OR container_name&gt;docker contaienr rm -f &lt;container_id OR container_name&gt;# 删除所有容器docker rm $(docker ps -aq)docker rm -f $(docker ps -aq)# 删除已停止运行的容器(#)docker rm $(docker ps -f &quot;status=exited&quot; -q) Container 交互 容器内部可执行的命令，特定目录存储的配置内容，可以通过 CLI 的监控命令 支持更改 /etc/hosts， /etc/hostname，/etc/resolv.conf ，只针对运行时，临时的更改 几种交互方式： 运行时直接进入交互、运行时直接执行命令交互，包含对文件的操作、内部命令执行 运行后按特定终端进入交互、运行后按特定命令交互，同上 日志交互，logs，支持最后几行、最近的时间点、实时显示 基本情况，inspect，返回运行情况 JSON 字符串，可通过 Go Templete 获取特定情况 运行的资源情况，stats，实时显示 CPU、内存、网络、磁盘情况 1234567891011121314151617181920212223242526272829303132# 进入容器内部docker exec -it -u root jenkins sh# 执行特定命令# 创建之后执行# 在已运行的容器中执行命令docker run -it --rm ubuntu:18.04 ip adocker run -it --rm ubuntu:18.04 --hostname=test.com --dns=172.16.3.3 ip adocker run -it --rm ubuntu:18.04 cat /etc/resolv.confdocker exec -it gitlab cat /etc/resolv.confdocker exec -it gitlab cat /etc/hostnamedocker exec -it gitlab cat /etc/hosts# 容器内部执行# 查看挂载情况# 查看定义的环境变量# 查看 dns 情况, 与在宿主机上的 /etc/docker/daemon.json 上配置 dns 类似?# 查看容器IP地址配置# 查看路由情况mountenvcat /etc/resolv.confip addr show eth0ip route# logs 查看# 特定时间偏移, 特定时间段docker logs -f -t --since=40m --tail=10 jenkinsdocker logs -t --since=&quot;2019-08-01T13:23:37&quot; --until &quot;2018-08-31T12:23:37&quot; jenkins# inpect 查看docker inspect -f &#x27;&#123;&#123;.State.Pid&#125;&#125;&#x27; 1f1f4c1f931a# stat 查看docker stats &lt;container_id OR container_name&gt;# 拷贝文件，作为 Dockerfile 中 COPY 的...docker cp &lt;host_machine file OR dir&gt; &lt;container_name&gt;:&lt;container_dir&gt; Registry Docker 的私有仓库，实现容器的复用共享 发布镜像到 Registry 的方式： 发布镜像到仓库 直接将本地已经构建好的镜像发布到仓库中 根据指定 Dockerfile 由 Docker hub 进行构建形成镜像 自动在 git 发生变化的时候拉取数据进行构建重新发布到仓库上，自动构建发布，CICD 保证镜像的可再生性 私有 Registry 搭建： 官方提供的 registry Vmware 开源的 harbor，见 工具与环境 123456789# 登录 docker hub 账号和密码# 推送镜像到 docker hub# docker hub 关联 github or bitbucketdocker login 172.17.11.29:5111 -u admin -p Harbor12345# 重命名镜像的名称(tag)docker push 172.17.11.29:5111/centos-vim-gcc:1.0.0docker tag janhen/centos-vim-gcc:1.0.0 172.17.11.29:5111/study-docker/centos-vim-gcc:1.0.0docker push 172.17.11.29:5111/study-docker/centos-vim-gcc:1.0.0 Docker 网络 进行容器之间的访问，包含单机上的访问，多台机器之间的访问； 含端口映射、容器互联 关联文档: 使用网络 | 高级网络配置 Linux 上网络访问 Linux 网络命名空间，进行网络的隔离 Veth pair： 进行网络命名空间的连接，实现两个 net namspce 连接通信 12345678910# 网络命名空间# ip link# 给命名空间分配 ip 地址, 默认情况下只有 mac 地址# 启动接口# 连接双方使其网络互通ip netns listip netns delete test1ip netns exec test2 ip linkip netns exec testl ip link set dev veth-testl upip netns exec testz ip link set dev veth-test2 up Docker 网络访问 通过link 方式实现容器之间的访问，直接通过名称而非 IP，适用于单台机器 一个容器对应一个网络空间 类似局域网连接，通过中间的交换机实现两个容器之间的通信， docker0 的内网指定默认为 172.17.0/16，自定义为 172.17.18.0/16… 访问外部网络，需要经过 NAT 转换 12345678910# 查看容器网络， bridge 网络docker network lssudo docker network inspect &lt;network_id OR network_name&gt;ip ayum install bridge-utils# 展示系统当前桥接brctl showip a# 创建指定类型的网络docker network create -d bridge net-my Docker link 网络连接 通过命名 Docker 进行相连，类似网络命名空间中的 Veth pair，目前不推荐使用 命令格式： –link : 替代方案： docker-compose.yml 中使用 depends_on，使用 overlay 网络 123456789101112# 类似给 net-test2 添加 DNS 记录# link 方向性; 使用少docker run -d --name net-test2 \\ --link net-test1 busybox \\ /bin/sh -c &quot;while true; do sleep 3600; done&quot;docker exec -it net-test2 /bin/sh ip a ping net-test1# -d 指定网络类型， bridge|overlaydocker network create -d bridge net-mydocker run -it --rm --name busybox1 --network my-net busybox shdocker run -it --rm --name busybox2 --network my-net busybox sh 12345678910111213# --link &lt;name&gt; 支持通过名称访问容器 docker run -d --name flask-redis \\ -p 5000:5000 \\ --link redis \\ -e REDIS_HOST=redis \\ janhen/flask-redis docker run -d --name test1 \\ -e PENG=testt1 \\ busybox docker run -d --name test2 \\ -e PENG=testest \\ busybox \\ /bin/sh -c &quot;while true; do sleep 3600; done&quot; 自定义网络连接 避免使用 –link 进行容器之间网络的连接 1dockernetwork create -d bridge net-demo Docker 单机网络Docker bridge 网络 可以创建自己的桥接网络，进行区分，docker-compose 默认管理的容器共享同一个 bridge 网络 12345678# 创建自己的桥接网络docker network create -d bridge my-bridgedocker network lsbrctl showdocker run -d \\ -- name net-test3 \\ --network my-bridge busybox /bin/sh -c &quot;while true; do sleep 3600; done&quot;docker network connect mybridge net-test2 bridge 性能一般，对性能要求较高，可使用个 SR-IOV 网卡嵌入容器内。 Docker host 和 none网络 none 网络： 不会有网络信息，孤立的网络，用来做私有的工具，如保存密码??，使用场景少 host 网络：无网络信息，与主机共享网络命名空间，存在端口冲突问题 1docker run -d -p 80:80 nginx Docker 多机网络 实现多个不同机器之间的容器进行通信 Overlay 网络 依赖一个分布式存储，保存对应的 IP，防止网络(172.18.0.0/16)、容器名称等的冲突 实现 Docker 的多机网络，见 [Internel 访问](#Internel 访问) 两台机器之间可以相互通信，为了实现不同容器之间的通信需要借助第三方的分布式存储 使用etcd 建立的 cluster 中容器名称不允许重复、Ip 地址不允许重复 1234567891011121314151617# 创建 overlay 网络，实现多态主机之间的同步创建 overlay 网络docker network lsdocker netword create -d overlay net-overlay-demo# 查看网络情况，子网范围，容器情况docker network inspect net-overlay-demo# 启动容器指定到 overlay 网络docker run -d --name node1-test1 \\ --net net-overlay-demo \\ busybox sh -c &quot;while true; do sleep 3600; done&quot;docker run -d --name node2-test1 \\ --net net-overlay-demo \\ busybox sh -c &quot;while true; do sleep 3600; done&quot;# 查看节点上容器的地址# 查看 cluster 中网络的情况docker exec node1-test1 ip adocker exec node2-test1 ip adocker network inspect net-overlay-demo Etcd 分布式存储 存储分布式系统中的 key-val，开源免费，保证 overlay 网络中分配的容器与容器对应的IP地址在整个网络中唯一 关联： GitHub 1234567891011121314151617# 在对应的两台机器上安装 etcd，容器安装/binary 安装# 通过命令指定好集群启动# 验证 cluster 的运行情况# 进入 etcd 文件夹执行健康检查，两台机器同时执行./etcdctl cluster-health# 关闭 Docker 服务# 使用 etcd 作为分布式存储启动 docker， 手动启动 dockerd 守护进程# 验证systemctl stop dockersudo /usr/bin/dockerd -H tcp://0.0.0.0:2375 \\ -H unix://var/run/docker.sock \\ --cluster-store=etcd://192.168.xx.xx:2379 \\ --cluster-advertise=192.168.xx.xx:2375 &amp; docker version Docker 持久化 将容器与数据存储隔离开，如 Mysql 运行程序与数据保存位置 两种持久化的方式： 本地 FS 的 Volumn 基于 plugin 的 Volume， 如 NAS 本机上三种持久化实现, -mount 选项选择数据卷： bind :挂载在 Linux FS 中任意位置 volume：统一挂载在 daemon 设置的 docker 目录下，默认为 /var/lib/docker/volumes/&lt;unique_str_id OR volume_name&gt; tmpfs： 只挂载在内存中，易丢失 使用命令: 12345678docker volume create -d local testdocker volume inspect &lt;contaienr&gt;# 清理docker volume prune &lt;&gt;docker volume rm &lt;&gt;docker run -d --mount type=bind, source=/data, destination=/redis/data xxxx# 指定 :ro 容器无法对挂载数据卷内的数据进行修改docker run -d -v /webapp:/opt/webapp:ro 数据卷容器 实现多个容器操作数据，任意容器修改都可被其他容器看到 –volumes-from 参数所挂载的数据卷容器无需处在运行状态 1docker run -d --volumes-from dbdata xxx Volume 通过 Dockerfile 中的 Volumn 控制，在宿主机上 docker 文件下建立目录存放文件 建议 -v 参数指定在 docker 目录下 volume 的名称，默认为 /var/lib/docker/volumes/&lt;-v_name OR long_str&gt; 针对官方镜像，到 Docker Hub 上查看对应的 volume 挂载目录位置 1234567891011121314# 创建 volume，查看所有|指定|删除volumedocker volume create volume1docker volume lsdocker volume inspect volume1docker volume rm volume2# 运行-&gt;删除-&gt;验证docker run -d -v mysql1:/var/lib/mysql \\ --name mysql1 \\ -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql docker rm -f mysql1 mysql2docker run -d -v mysql1:/var/lib/mysql --name mysql1 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql docker exec -it mysql2 /bin/bash mysql -u root show databases; Bind Mouting 指定容器目录与宿主机目录绑定，宿主机文件更改影响到容器中的运行 可以实现本台电脑 –&gt; 虚拟机 –&gt; 容器三者的目录映射 1234# -v: &lt;宿主机目录&gt;:&lt;容器目录&gt; 进行一一映射docker run -d -v $(pwd):/usr/share/nginx/html -p 80:80 --name web janhen/my-nginx# 使用 Docker 作为本地开发环境docker run -d -p 80:5000 --name flask janhen/flask-skeleton Dockerfile 编写 用于生成 Docker Image 的文件，一般只用于 docker build -t janhen/xx:99 . 命令执行使用 关联： Dockerfile 指令 语法Dockerfile 的基本语法 FROM,WORKDIR,ENV,COPY,ADD RUN,CMD,ENTRYPOINT VOLUME,EXPOSE FROM： 根据特定的镜像制作，从头制作、 根据指定环境制作、某个镜像作为构建阶段使用 RUN ： 运行命令脚本, 可以通过此安装一些环境并对环境进行配置，如安装 Node 环境，每运行一个命令增加一层 ==&gt; 建议将多个命令合并成一个命令使用 WORKDIR： 设定当前工作目录, 类似 cd 改变目录, 没有目录自动创建(#) 直接通过绝对路径定位 通过绝对路径+相对路径定位目录 ADD and COPY： 将本地文件添加到 docker image 中,常 配合 WORKDIR 使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748FROM python:3.7# LABEL 镜像的 metadata，帮助信息LABEL maintainer=&quot;janhen &lt;ipaam414@gmail.com&gt;&quot;RUN yum update &amp;&amp; yum install -y vim \\ python-devRUN apt-get update &amp;&amp; apt-get install -y perl \\ pwgen --no-install-recommends &amp;&amp; rm -rf \\ /var/lib/apt/lists/*RUN /bin/bash -c &#x27;source $HOME/.bashrc;echo $HOME&#x27;WORKDIR /rootWORKDIR /testWORKDIR demoRUN pwdADD hello /ADD test.tar.gz /WORKDIR /rootADD hello test/COPY hello test/# ENV 设定环境变量, 建议使用ENV MYSQL_VERSION 5.6RUN apt-get install -y mysql-server = &quot;$&#123;MYSQL_VERSION&#125;&quot; \\ &amp;&amp; rm -rf /var/lib/apt/lists/*# CMD# 设置容器启动后默认执行的命令和参数# docker run 指定其他命令, CMD 被忽略# 定义多个 CMD，只运行最后一个docker run [image] # CMD 会被执行docker run -it [image] /bin/bash # CMD 不会执行CMD [&quot;mongod&quot;]# ENTRYPOINT# 设置容器启动时运行的命令# 容器以应用程序/服务的形式运行# 不会被忽略, 一定会执行# 最佳实践: 通过 shell 脚本作为 entrypoint COPY docker-entrypoint.sh /usr/local/bin/ # 添加到容器中ENTRYPOINT [&quot;docker-entrypoint.sh&quot;] # 指定入口脚本EXPOSE 27017ENTRYPOINT [&quot;scripts/dev.sh&quot;]# 进行宿主机与容器中文件的映射# 映射容器中的 /tmp 到宿主机上，默认在 /var/lib/docker/volumes/&lt;long_id OR name&gt; 下建立对应的映射VOLUME /tmp 命令格式 不同的命令执行写法，以及对应的区别 Shell 格式, 默认通过 shell 执行 Exec 格式, ENTRYPOINT [“/bin/bash”, “-c”, “echo”, “hello $name”] 针对 Exec 无法映射变量问题的处理： 通过命令方式编写语句 12ENV name DockerENTRYPOINT [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo&quot;, &quot;hello $name&quot;] 命令区别 1、RUN、CMD和ENTRYPOINT命令区别 RUN 运行在 image 的构建阶段执行，执行结果会被打包进 image 文件 CMD 在容器启动后执行，可用于在容器内启动某个服务、进程，只可使用一次，与 run 中年执行命令冲突 ENTRYPOINT 在容器启动后执行，出现多行不会忽略，一定执行，通常配合 COPY 到容器中的 sh 脚本使用 2、COPY 与 ADD 命令区别 ADD 可以获取网络资源，可以直接解压缩 注意事项 1、CMD 的最后一次有效性 官方镜像中大多最后运行 CMD，方便覆盖实现定制化的参数的启动 2、目录 COPY . /app 与 COPY . /app/ 映射不同 Docker Compose 多容器管理，通过 yml 配置管理容器之间的依赖关系，底层 python 编写，前身为开源的 Fig 项目。主要用于本地开发使用。 关联文档：Compose 模板文件 | Doc 管理 docker-compose 的启动、停止、交互 123456789101112131415161718# compose 后台启动# 启动并查看日志docker-compose updocker-compose up -ddocker-compose -f &lt;compose_name&gt; up -d # 停止服务# 停止并删除 容器、网络、volumesdocker-compose stop &lt;service&gt;docker-compose down &lt;service&gt;docker-compose build# compose 查看运行情况，状态、端口情况# 查看 compose 中定义容器使用的 imagesdocker-compose psdocker-compose images# 进入 compose 中的 servicedocker-compose exec mysql bash# 扩展docker-compose scale &lt;service_name&gt;=&lt;count&gt; service 的扩展 实现水平扩展，负载均衡，在不存在端口冲突的情况下通过 haproxy 进行负载均衡，在 Docker Swarm 运行时可直接通过 deploy 中的参数指定复制扩展的个数 通过 docker-compose scale 命令进行扩展 处理 scale 中端口映射重复问题 在 docker-compose 中增加 dockercloud/haproxy 进行负载均衡 12345678docker-compose up -d# 启动时指定扩展docker-compose up --scale web=3 -d# 运行后进行扩展docker-compose scale web=4# 验证扩展情况docker-compose psfor i in `seq 10`; do curl 127.0.0.1:8080; done 语法 对应 docker-compose.yml 文件的语法 三大实体： service: 服务 networks: 网络指定，指定网络类型，一般为 bridge、overlay，根据需要指定多个网络，进行一定的隔离 volumes: 进行数据卷的映射 image 获取方式： 通过 image 获取本地的或是拉取远程的，或者通过 build 进行构建，传入 Dockerfile 的目录以及对应的 Dockerfile 名称 ports: 进行宿主端口与容器端口的映射 depends_on: 解决容器的依赖，启动先后问题 links: 服务之间的依赖关系，在容器内部可以直接使用依赖服务名称对应的 IP 地址，不建议使用 deploy: 进行部署，控制集群中的各种情况，用于 Docker swarm，version 3 支持 12345678910111213141516# 特定片段参考# 设置网络, 可多个# frontend, backend 前后端设置networks: - frontend - backend# 端口设置# 直接引号设置# 宿主机与容器端口映射ports: - &quot;6379&quot;ports: - 5000:80# 依赖depends_on: - mysql Docker Swarm Docker 自带的服务编排框架，大多数都由其中的 Manager 做管理，较难定制，不适合太多节点的部署 Docker Swarm 特点： 符合传统IT的管理模式 平台本身集成性好，可当成云管平台使用 内置太多不易进行定制化，不好 Debug，不易干预 不提供存储选项：Docker Swarm不提供将容器连接到存储的无障碍方式，其数据量需要在主机和手动配置上进行大量即兴创作 监控不良：Docker Swarm提供有关容器的基本信息，如果您正在寻找基本的监控解决方案，那么Stats命令就足够了。如果您正在寻找高级监控，那么Docker Swarm永远不是一个选择。虽然有像CAdvisor这样的第三方工具可以提供更多监控，但使用Docker本身实时收集有关容器的更多数据是不可行的。 Swarm 架构 Raft consensus group： 进行控制分布式场景下的协商: 内置的分布式的存储数据库，通过 Raft 协议进行同步，包含 Leader 选举、Log 复制 Internel distributed state store： 分布式存储数据库，功能如保证分布式场景下 Ip 等唯一，类似 etcd Manager: 可以保存 Raft 关联的文件，用于 Secret 实现 Worker: 主要运行容器，通过 Gossip network 进行通信，保证分布式下的一致性 Gossip network： 各个 Worker 之间同步实现的协议 扩展： Service: 通过 swam manager 进行控制，具体 service 部署到哪个 node 上 Replicas： 一个 Service 对应多个 Replicas，用于扩展 集群搭建管理 让几台服务器搭建成一个 Swarm Cluster 1234567891011# 配置 Manager Nodedocker swarm init --advertise-addr=192.169.xx.xx# 配置 Worker Node 加入到特定的 Manager Nodedocker swarm join --token xxxfsdfsdf &lt;ip&gt;:&lt;port&gt;# 查看当前 Node 情况# 节点查看# 节点降级docker node ls docker node inspect &lt;node_name&gt;docker node demote &lt;node_name&gt;docker node ps Swarm管理Swarm Services 管理 单个 Service 的管理，一个 Service 可扩展到多个 cluster node 上的 Container 运行 123456789101112131415161718192021222324# 创建容器，运行位置有 mananger 进行控制运行在哪个节点上# 类似 docker run 命令，在本地创建 container# 查看 service 情况# MODE: replicated# REPLICAS: 1/1 支持水平扩展，类似 docker compose 中的 scale# 查看具体的 service 情况# 运行在哪个节点上# 扩展servie，通过复制的方式(#) docker service create --name demo busybox \\ sh -c &quot;while true; do sleep 3600; done&quot;docker service lsdocker service ps demodocker service scale demo=5docker service ps demo # 本机查看 docker 容器运行# 强制删除某个正在运行中的容器# 集群自动恢复，确保一定数目的 scale 扩展有效，系统稳定运行时# 显示节点中容器运行情况# 删除服务，对应的集群节点容器删除docker psdocker rm -f e64432docker service lsdocker service ps demodocker service rm demo RoutingMesh Swarm 网络通信原理，管理集群服务间的通信，访问集群中任何一个节点特定端口都会被重定向到实际运行服务的节点上 DNS 服务发现，单机情况下可以通过 service 的名称进行相互访问，多机情况下通过 swarm 进行相互访问 VIP： 非真实机器的IP地址，避免多个IP地址变化问题，造成系统运行不稳定，一个 service 对应一个 LVS： 根据虚拟 IP 找出容器中的具体的 IP 地址 两种体现： Internel：容器之间通过 overlay 网络访问 Ingress ：服务绑定接口的情况，此服务通过任意 Swarm 节点对应接口访问 Internel 访问 容器间实现相互访问，通过 overlay 网络实现，实现 service 与 service 之间的通信 whoami 镜像： 提供 web 服务，访问 8000 端口，返回 container 的 hostname 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# 创建 overlay 网络# 创建 whoami 服务# 后台运行# 端口映射# 网络指定# 查看所有 service # 查看 whoami 服务运行位置# 到对应机器上验证docker network create -d overlay net-demodocker service create -d \\ --name whoami \\ -p 8000:8000 \\ --network net-demo jwilder/whoamidocker service lsdocker service ps whoamidocker pscurl 127.0.0.1:8000# 创建 busybox 的容器# 连接到同一个 overlay 网络# 查看所有服务，当前 busybox service 是否启动完成# 查看服务 client 服务具体位置# 进入对应的机器查看对应运行的 container# 进入容器# 10.0.0.7 IP 地址，为虚拟 IP， 将 whoiam 通过 scale 扩展# 通过 scale 进行扩展 whoami # 查看 whoami 位置，并进入# 进入对应 client contaienr 中# 连接 whoami # 查询 dns，只有一个虚拟IP 10.0.0.7# 进入容器 whoami 查看网络地址# 进入容器 whoami(另一) 查看网络地址# 进入容器 client# 查看 task.whoami，返回对应的多个节点，为真实的 IP 地址（#）docker service create -d \\ --name client \\ --network net-demo busybox \\ sh -c &quot;while true; do sleep 3600; done&quot;docker service lsdocker service ps clientdocker psdocerer exec -it &lt;container_id&gt; sh ping whoami docker service scale whoami=2 docker service ps whoamidocker service ps clientdocker exec -it &lt;container_client_id&gt; sh ping whoami nslookup whoamidocker exec 5b79 ip adocker exec df9 ip adocerk exec -it &lt;container_client_id&gt; sh nslookup task.whoami# 扩展 whoami 服务# 查案 client 对应的 task.whoami，显示三个对应的(whoami)IP 地址# ==&gt; 虚拟IP: 不会随 service 的扩展而变化, 包括增加、减少、机器之间的迁移不会变化(#)# 访问多次服务 whoami，相应的对应机器上的容器会因为负载均衡而不同，通过 LVS 实现docker service scale whoami=3docker service ps whoami--- nslookup task.whoami wget whoami:8000 more index.html rm -rf index.html wget whoami:8000 两种体现： Internal: 容器键通过 overlay 网络(VIP)访问 Ingress: 服务绑定接口, 通过任意 swarm 节点的接口访问’ DNS + VIP + iptables + LVS 实现的过程图： // todo 具体 Swarm 网络中数据的流动情况 小结： 容器之间连接到 overlay 网络进行通信，service 之间的通信通过 VIP + LVS 实现 Ingress 负载均衡 绑定端口实现的容器之间的访问，通过 : 直接访问服务 作用体现：集群中的 Node 对应的端口提供相同的服务，即使 Node 本地无服务也支持访问 Ingress Network 的数据包走向图 在 IPTables + IPVS 发往目的网络 12345678910111213141516# 常看网络桥接情况# 查看机器的网络命令空间# 进入 ingress_sbox 网络命名空间iptablesbrctl showsudo ls /var/run/docker/netnssudo nsenter --net=/var/run/docker/netns/ingress_sboxip aiptables -nL -t mangle# 安装 LVS 管理工具# # 查看 LVS 情况，展示可选的服务 IP 地址，展示机器的 weight, yum install ipvsadmsudo nsenter --net=/var/run/docker/netns/ingress_sboxiptables -nL -t mangleipvsadm -l Docker Stack 部署 进行多服务部署，可以使用 docker-compose.yml ，只能用于 swarm cluster，无法用于其他的服务编排框架 docker-compose.yml 文件更改 compose file version 3: 增加 deploy 命令，具体参数如下 1234567891011121314151617181920212223242526# deploy# endpoint_mode: vip 模式(默认), dnsrr 模式 循环访问(少用)# labels: 帮助描述信息# mode: global, replicated， global 全局唯一, 无法通过 scale 横向扩展，一般外部服务使用此种方式，如 mysql,nginx,redis等； replicated 默认，可通过复制来进行扩展# placement: # constraint: # - node.role == manager # 限制部署到 manager 节点上# preferences: 优先喜好# -# replicas: 在 mod 是 replicated 的时候定义初始化时候需要的 replicas# resources: 进行资源的限制# limits:# cpus: &#x27;0.50&#x27; # CPU 使用限制# memeory: 50M # 内存使用限制# reservations: # 优先保留，最小的情况# cpus: &#x27;0.25&#x27;# memory: 20M# restart_policy: # 容器宕机后的处理# conditon: on-failure # 什么情况下重启# delay: 5s # 延迟# max_attempts: 3 # 最大重试次数# window: 120s# update_config: # service 更新的配置# parallelism: 2# delay: 10s# order: stop-first 部署的过程： 更改单机的 docker-compose.yml 为对应 cluster 部署(deploy) 按条件执行命令： 如下 验证： 通过访问任意一个 cluster 中的地址即可访问 12345678910# 整个 application 定义为一个 stack 为 wordpress# 可通过 -c=docker-compose.yml 进行简化# 查看运行情况# mysql: 限制只运行一个，只能运行在 manager 节点# 通过 stack 查看服务情况docker stack deploy wordpress --compose-file=docker-compose.ymldocker stack lsdocker stack ps wordpressdocker stack services wordpressdocker stack rm wordpress Docker Secret 管理 对一些密码进行管理， 处理 docker-compose.yml 中存储密码不安全问题，借助内部分布式存储数据库控制，只作用于 Docker Swarm 关联： Doc-CLI Secret 类型： username password， SSH key, TLS 认证，不想让人看到的数据 生产环境至少要两个 Manager，分布式存储的天然加密环境 Secret 的管理： 将 Secret 存储在 Manager 中的分布式存储中的 Raft Database Secret 给某个 service 指派 Service 基本使用 Secret 的创建方式：文件方式、输入方式。 存放在容器中的 /run/secrets/&lt;secret_file_name&gt; 文件中 123456789101112131415161718192021222324252627282930313233# 按文件方式进行创建# 删除文件，保证安全性# 查看 secret# 借助管道按照输入方式创建 secretvim passworddocker secret create my-file-pw passwordrm -rf passworddocker secret lsecho &quot;mypassword&quot; | docker secret create my-input-pwdocker secret rm my-input-pw# 通过 swarm service 创建过程中指定 secret 进行使用# 进入容器查看指定目录，找到 manager 通过 Raft Database 保存的 secretdocker service create -d --name client \\ --secret my-file-pw busybox \\ sh -c &quot;while true; do sleep 3600; done&quot;docker service ls docker service ps clientdocker psdocker exec -it &lt;client_container_id&gt; sh cd /run/secrets/ ls cat my-file-pw # 原文# 实际使用# 在创建 service 的时候指定好 secret，并在环境变量中指定在容器中的位置docker service create -d --name db \\ --secret my-file-pw \\ -e MYSQL_ROOT_PASSWORD_FILE=/run/secrets/my-file-pw mysqldocker service ps db--docker exec -it &lt;db_container_id&gt; shls /run/secretscat /run/secrets/my-file-pwmysql -u root -p 在 Stack 中的使用 在服务配置下增加 secrets，指定对应的 Secret 对应的密码参数使用指定的 secrets 在容器中的位置 可以连通创建 secret 一起使用，不建议 12345# -c 简化 --compose-file # 查看服务是否全部启动完成docker stack deploy wordpress \\ -c=docker-compose.ymldocker stack services wordpress Docker Service 更新 在运行过程中对 service 依赖的镜像进行升级，实现升级过程中不会中断原来的服务 单 Service 更新进行 service 的更新，不会暂停运行的项目 @Q: 存在一段时间有 1.0和2.0并存的情况，如何处理?? 12345678910111213141516171819# 创建 overlay 网络，启动服务# 等待服务启动完毕docker network create -d overlay net-demodocker network lsdocker service create -d --name web \\ --publish 8080:5000 \\ --network net-demo janhen/python-flask-demo:1.0.0docker service ps web# 扩展服务# 检查服务运行情况# 编写测试脚本方便验证docker service scale web=2docker service ps webcurl 127.0.0.1:8080sh -c &quot;while true; do curl 127.0.0.1:8080&amp;&amp;sleep 1; done&quot;# 更新镜像，一般通过 Dockerfile 进行构建，指定对应更新的版本，发布到私有 registry# 运行环境拉取镜像，执行更新命令docker service update --image janehn/python-plask-demo:2.0.0 web 12345# 更新镜像并设置参数, 覆盖 docker-compose.ymldocker service update --image westos.org/game2048 \\ --update-parallelism 10 \\ --update-delay 10s \\ nginx 端口更新 对 service 与宿主机的端口映射进行更改 删除掉原来的端口映射，无法做到更新时业务不中断，通过 VIP + 端口实现原理导致的 12docker service update --publish-rm 8080:500 \\ --publish-add 8088:5000 web Stack 更新 更改 Swarm Cluster 中多个容器中对于镜像、网络、部署配置的更新，关联 .deploy.update_config 下的配置 可更改 docker-compose.yml 中 deploy 下的 update_config 控制更新时的细节，允许几个 scale 进行更新，延迟信息。。。 第一次通过 deploy 进行启动进行了多 service 的部署 第二次通过 deploy 部署时，自动检测到 docker-compose.yml 的变化，进行更新 1docker stack deploy wordpress --compose-file docker-compose.yml Docker Swarm 监控 实现对 Docker Swarm Cluster 中运行节点上容器的监控 CAdvisor+InfluxDB+Grafana docker swarm集群的监控方案，开源免费 cAdvisor：数据收集模块，需要部署在集群中的每一个节点上，当然前提条件是节点接受task。 InfluxDB：数据存储模块 Grafana：数据展示模块 Docker Universal Control Plane(UCP) docker原厂的可视化集群管理GUI，企业级的，只支持docker EE portainer 在集群中部署portainer的service，只能被调度给manager角色的节点 关联： Web 其他Daemon 配置 对容器的 dockerd 守护线程进行配置 关联： Configure the daemon dameon.json 配置文件编写： 源镜像地址配置 私有源非 Https 配置 Debug 模式开启 /etc/docker/daemon.json ip: 永久绑定到某个固定的 IP 地址 bridge： 将 Docker 默认桥接到创建的网桥上 1234567891011121314151617181920&#123; &quot;registry-mirrors&quot;: [ &quot;https://dockerhub.azk8s.cn&quot;, &quot;https://reg-mirror.qiniu.com&quot; ], &quot;insecure-registries&quot;: [ &quot;172.17.11.29:80&quot;, &quot;172.17.11.29:5111&quot;, &quot;192.168.205.23:80&quot;, &quot;192.168.205.23:5111&quot;, &quot;172.17.10.150:80&quot; ], &quot;debug&quot;: false, &quot;dns&quot; : [ &quot;114.114.114.114&quot;, &quot;8.8.8.8&quot; ], &quot;ip&quot;: &quot;0.0.0.0&quot;, &quot;bridge&quot;: &quot;bridge-my&quot;&#125; 12345# 更改后使其生效sudo systemctl daemon-reloadsudo systemctl restart docker.servicesudo systemctl status docker -lsudo docker info 设置运行时目录，存储驱动 设置 Http/Https 代理 加快拉取国外访问、处理国内制作镜像无法访问国外资源问题 123456789101112131415161718# 添加配置mkdir -p /etc/systemd/system/docker.service.dvim /etc/systemd/system/docker.service.d/http-proxy.conf[Service] Environment=&quot;HTTP_PROXY=https://172.17.10.18:5720/&quot; &quot;NO_PROXY=localhost,127.0.0.1&quot;# 配置生效systemctl daemon-reloadsystemctl restart dockersystemctl show --property=Environment docker# 重置rm -f /etc/systemd/system/docker.service.d/http-proxy.confsystemctl daemon-reloadsystemctl restart dockersystemctl show --property=Environment docker Docker systemd http-proxy 监控与管理 人工进行容器的管理、监控、资源调整、故障排除，包括日志查看、容器实时运行情况、资源重分配，在无法使用或没有监控方案情况下使用 dockerd 支持 在发生故障后，通过设置 Docker 守护线程的一些参数方便调试 123456# 开启守护线程的 debug 模式，给出更多的信息提示dockerd --debug \\ --tls=true \\ --tlscert=/var/docker/server.pem \\ --tlskey=/var/docker/serverkey.pem \\ --host tcp://192.169.9.2:2376 容器的运行日志查看 使用 Go 模板尽心格式化日志输出 可使用日志驱动程序插件，企业版支持统一格式查看远程的日志，默认双重日志 Format command and log output 1234567docker container inspect --format &#x27;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&#x27; $&#123;CID&#125;# 获取某个镜像对应的全部容器docker container ls | grep &lt;image&gt; | awk &#x27;&#123;print $1&#125;docker inspect -f &#x27;&#123;&#123;.HostConfig.LogConfig.Type&#125;&#125;&#x27; &lt;CONTAINER&gt;docker logs -f &lt;container_id&gt;# 通过 Go 的模板语法进行格式化展示数据docker image ls --format &quot;&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;&quot; 容器日志 在 daemon 中的日志配置，根据实际需要进行优化，可选择日志插件 指定容器日志最大大小 20M 最大的文件个数 5 压缩， 开 容器的运行情况 通过 stats 实时查看容器的资源信息 123# 实时查看容器统计信息，CPU、内存、网络、磁盘docker stats 13b9203f9f0b d42877298134 44fb90cd2f2cdocker container stats --format &quot;table &#123;&#123;.Name&#125;&#125;\\t&#123;&#123;.CPUPerc&#125;&#125;\\t&#123;&#123;.MemUsage&#125;&#125;&quot; 容器的资源分配 容器使用多少宿主机的资源，可以通过 docker-compose.yml 中设置 123# 通过参数限定容器访问内存、CPUdocker run --help | grep cpu docker run --help | grep memory 容器可用性 容器支持重启，可以通过 --restart 指定重启策略，保证可用性 容器网络 1234# 查看所有网络docker network ls# 查看容器网络映射docker port nostalgic_morse 5000 .dockerignore 针对非 SpringBoot 项目，如前端项目需要忽略一些文件。 123.gitnode_modulesnpm-debug.log 默认的重要文件： /var/run/docker.sock /var/lib/docker/volumes/ Docker 卸载1234567891011121314151617181920212223# 停止并删除容器docker rm -f `docker ps -aq`# 删除安装yum list installed|grep docker yum -y remove docker-ce.x86_64 yum -y remove docker-ce-cli.x86_64 yum -y remove containerd.io.x86_64 # 所有镜像、Volume删除 # 删除 docker-compose rm -rf /var/lib/docker rm -rf /hdapp rm -rf /etc/docker rm -f /usr/local/bin/docker-compose # 测试卸载情况 yum list installed|grep docker # 删除 docker0 网卡 yum install bridge-utils ip link set dev docker0 down brctl delbr docker0 RefsDocker-guide: 中文的 GitBook 官方镜像示例： Docker Hub 中一些镜像的开源示例 play-with-docker ： 方便环境搭建， 保存 docker 4h，在网站上创建多个网络，进行互通访问 10分钟看懂Docker和K8S： 快速入门 docker学习笔记： 他人博客笔记 Docker – 从入门到实践 如何调试 Docker： 总结调试方法 关于对docker run –link的理解： Docker 桥接网络理解 工具和示例： Docker 相关工具 Dockerfile 最佳实践： 编写 Dockerfile 的一些建议 CentOS7.4—构建LVS+Keepalived高可用群集： LVS docker镜像操作： 容器制作、本地导入、镜像导出","tags":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"}]},{"title":"Arthas","date":"2020-12-17T13:10:57.000Z","path":"2020/12/17/Arthas/","text":"概述 Arthas 是Alibaba开源的Java诊断工具。 Github 当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决： 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到JVM的实时运行状态？ 怎么快速定位应用的热点，生成火焰图？ JVM 信息JVM 相关命令的 1.dashboard -&gt; thread -&gt; 3.jvm -&gt; 4.sysprop -&gt; 查看和修改JVM的系统属性 5.getstatic -&gt; 查看类的静态属性 dashboard 当前系统的实时数据面板 线程、内存、运行信息 thread 当前JVM 线程堆栈信息 -b: 找出持有锁的 -n: 根据 cpu 使用排序 -i: 指定时间间隔 –state : 过滤线程状态 使用最繁忙的 5个线程 1thread -i 2000 -n 5 查看指定线程堆栈 1thread &lt;id&gt; 查看特定状态的线程: RUNNABLE, TIMED_WAITING, WAITING, BLOCKED.. 12thread -i 2000 --state TIMED_WAITINGthread -i 2000 --state RUNNABLE jvm 查看当前JVM 的信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182 RUNTIME ------------------------------------------------------------------------------------------------------------------------------------ MACHINE-NAME 8@e57d77f3ad01 JVM-START-TIME 2020-12-10 19:38:01 MANAGEMENT-SPEC-VERSION 1.2 SPEC-NAME Java Virtual Machine Specification SPEC-VENDOR Oracle Corporation SPEC-VERSION 1.8 VM-NAME Java HotSpot(TM) 64-Bit Server VM VM-VENDOR Oracle Corporation VM-VERSION 25.11-b03 INPUT-ARGUMENTS -Xmx4096M -Xms4096M -Xmn1536M ... CLASS-PATH ... BOOT-CLASS-PATH ... ------------------------------------------------------------------------------------------------------------------------------------ CLASS-LOADING ------------------------------------------------------------------------------------------------------------------------------------ LOADED-CLASS-COUNT 34980 TOTAL-LOADED-CLASS-COUNT 46897 UNLOADED-CLASS-COUNT 11917 IS-VERBOSE false ------------------------------------------------------------------------------------------------------------------------------------ COMPILATION ------------------------------------------------------------------------------------------------------------------------------------ NAME HotSpot 64-Bit Tiered Compilers TOTAL-COMPILE-TIME 549939(ms) ------------------------------------------------------------------------------------------------------------------------------------ GARBAGE-COLLECTORS ------------------------------------------------------------------------------------------------------------------------------------ ParNew 5889/191768(ms) [count/time] ConcurrentMarkSweep 18/12942(ms) [count/time] ------------------------------------------------------------------------------------------------------------------------------------ MEMORY-MANAGERS ------------------------------------------------------------------------------------------------------------------------------------ CodeCacheManager Code Cache ... ------------------------------------------------------------------------------------------------------------------------------------ MEMORY ------------------------------------------------------------------------------------------------------------------------------------ HEAP-MEMORY-USAGE 4133945344(3.85 GiB)/4294967296(4.00 GiB)/4133945344(3.85 GiB)/289171584(275.78 MiB) [committed/init/max/used] NO-HEAP-MEMORY-USAGE 398196736(379.75 MiB)/2555904(2.44 MiB)/1862270976(1.73 GiB)/340835576(325.05 MiB) [committed/init/max/used] PENDING-FINALIZE-COUNT 0 ------------------------------------------------------------------------------------------------------------------------------------ OPERATING-SYSTEM ------------------------------------------------------------------------------------------------------------------------------------ OS Linux ARCH amd64 PROCESSORS-COUNT 6 LOAD-AVERAGE 0.35 VERSION 3.10.0-957.el7.x86_64 ------------------------------------------------------------------------------------------------------------------------------------ THREAD ------------------------------------------------------------------------------------------------------------------------------------ COUNT 99 DAEMON-COUNT 75 PEAK-COUNT 99 STARTED-COUNT 70889 DEADLOCK-COUNT 0 ------------------------------------------------------------------------------------------------------------------------------------ FILE-DESCRIPTOR ------------------------------------------------------------------------------------------------------------------------------------ MAX-FILE-DESCRIPTOR-COUNT 1048576 OPEN-FILE-DESCRIPTOR-COUNT 298 Affect(row-cnt:0) cost in 19 ms. sysprop 查看当前JVM的系统属性(System Property) 查看日志匹配，方便进行日志的收集查看日志文件位置，方便日志的查看查看执行的参数，SpringBoot 之后拼接的参数，方便定位自定义参数的实际指定情况查看 JVM 运行的时区，方便处理日志的时间问题查看运行时的版本，方便查看已知的 JDK bug 修复情况 123456sysprop FILE_LOG_PATTERNsysprop CONSOLE_LOG_PATTERsysprop LOG_FILEsysprop sun.java.commandsysprop user.timezonesysprop java.runtime.version getstatic 查看类的静态属性 , 推荐直接使用 ognl 命令 -c: 类加载器的 hash id -E: 开启正则表达式匹配，默认通配符匹配 &lt;class-pattern&gt; Class name pattern, use either ‘.’ or ‘/‘ as separator &lt;field-pattern&gt; Field name pattern &lt;express&gt; the content you want to watch, written by ognl 123456789getstatic com.janhen.SapConstants JOB_RUNNING_INTERVALfield: JOB_RUNNING_INTERVAL@Integer[2]Affect(row-cnt:1) cost in 331 ms.[arthas@8]$ getstatic com.janhen.SapConstants ALCNTC_INTERFACE_NOfield: ALCNTC_INTERFACE_NO@String[MD038]Affect(row-cnt:1) cost in 33 ms. 查看私有的静态变量 1getstatic org.springframework.amqp.rabbit.connection.CachingConnectionFactory DEFAULT_CHANNEL_CACHE_SIZE 查看集合信息 1getstatic org.springframework.amqp.rabbit.connection.CachingConnectionFactory txStarts 指定的 classloader 加载的类查看 12getstatic -c 73ad2d6 io.netty.channel.nio.NioEventLoop logger &#x27;getClass().getName()&#x27;field: logger 类加载sc 查看JVM已加载的类信息 各个字段的类型，以及访问标识符 父类信息、接口信息、类加载器信息、加载的来源文件 search-class -d, –details: Display the details of class -f, –field: Display all the member variables Class name pattern, use either ‘.’ or ‘/‘ as separato 1sc -df org.springframework.amqp.rabbit.connection.CachingConnectionFactory* sm 查看已加载类的方法信息 声明的类、 构造器、注解、参数、异常、类加载器 -c, –classloader The hash code of the special class’s classLoader -d, –details Display the details of method&lt;class-pattern&gt; Class name pattern, use either ‘.’ or ‘/‘ as separator&lt;method-pattern&gt; Method name pattern 1sm -d org.springframework.amqp.rabbit.connection.CachingConnectionFactory 查看具体的方法信息 1sm -d org.springframework.amqp.rabbit.connection.CachingConnectionFactory toString classloader 查看classloader的继承树，urls，类加载信息 12345678910111213 classloader name numberOfInstances loadedCountTotal org.springframework.boot.loader.LaunchedURLClassLoader 1 15617 java.net.URLClassLoader 1060 5560 BootstrapClassLoader 1 4535 java.net.FactoryURLClassLoader 2 1666 sun.reflect.DelegatingClassLoader 1406 1406 com.taobao.arthas.agent.ArthasClassloader 1 1116 sun.misc.Launcher$AppClassLoader 1 47 com.alibaba.fastjson.util.ASMClassLoader 1 13 sun.misc.Launcher$ExtClassLoader 1 10 org.apache.cxf.common.util.ASMHelper$TypeHelperClassLoader 1 6 Affect(row-cnt:10) cost in 330 ms. redefine 载入外部 .class，直接修改线上的代码，不能恢复 -c, –classloader classLoader hashcode .class file paths *ognl 执行ognl表达式， ognl命令实际上包含了getstatic的功能 查看Spring的配置 -c, –classLoader The hash code of the special class’s classLoader, default classLoader is SystemClassLoader. 查看 Spring 中运行时指定属性的值，先找到持有 ApplicationContext 的类对应的类加载器 12sc -df com.janhen.SpringContextUtil | grep classLoaderHashognl -c b1bc7ed &#x27;#spCtx=@com.janhen.SpringContextUtil@context,#spCtx.getEnvironment().getProperty(&quot;spring.redis.sentinel.nodes&quot;)&#x27; 设置静态属性值 一般由配置中心修改，防止 setstatic 不知道什么时候因为什么修改的应该无法更改 final 的静态变量 1ognl &#x27;#field=@demo.MathGame@class.getDeclaredField(&quot;random&quot;), #field.setAccessible(true), #field.set(null,null)&#x27; 替换方式实现： 可以写一个新的类，里面设置 static field的值。然后用 classloader 命令把这个新的类 load到JVM里再执行。 上传class到服务器上 redefine https://github.com/WangJi92/arthas-idea-plugin/issues/1 tt 记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测 -n &lt;count&gt;: 指定次数, 通过 -n 参数指定需要记录的次数，当达到记录次数时 Arthas 会主动中断tt命令的记录过程，避免人工操作无法停止的情况 1tt -t org.springframework.amqp.rabbit.connection.CachingConnectionFactory toString 监控与执行获取运行时的方法信息、返回信息、执行过程的耗时通过字节码增强技术实现，使用完成之后需要执行shutdown 或者 将增强过的类执行reset 命令。 monitor -c, –cycle The monitor interval (in seconds), 60 seconds by default Path and classname of Pattern Matching Method of Pattern Matching watch 查看方法参数 -n, –limits Threshold of execution times -b, –before Watch before invocation -x, –expand Expand level of object (1 by default) 查看入参对象(Object)以及返回对象(Set) 123456watch com.janhen.ConsumingRtnProcessor getBinAlreadyExistContainerBarcodes &quot;&#123;params, returnObj&#125;&quot; -b -x 2watch com.janhen.ConsumingRtnProcessor verifyContainer &quot;&#123;params, returnObj&#125;&quot; -bwatch -E .*ConsumingRtnProcessor verify|verifyContainer &quot;&#123;params, returnObj&#125;&quot; -b -x 3watch -E .*ConsumingRtnProcessor verify|verifyBin|verifyContainer &quot;&#123;params,returnObj&#125;&quot; -b -x 3watch -E .*ReceiveBillDao update &quot;&#123;params,returnObj&#125;&quot; -b -x 3watch com.janhen.StockServiceImpl query &quot;&#123;params,target&#125;&quot; -x 3 trace 跟踪方法耗时 跟踪方法的耗时情况，包含各个阶段的 1trace com.janhen.OrderBillServiceImpl getByBillNumber|query 匹配特定类的所有方法 1trace -E .*OrderServiceImpl .* 1trace -E com.janhen.OrderServiceImpl query RefConfigure logging drivershttps://docs.docker.com/config/containers/logging/configure/ Java线上诊断神器Arthas-2https://kamzhuyuqing.github.io/2018/12/20/Java%E7%BA%BF%E4%B8%8A%E8%AF%8A%E6%96%AD%E7%A5%9E%E5%99%A8Arthas-2/ 技术征文 | 那些年，我用 Arthas 排查过的问题https://mp.weixin.qq.com/s/gJ4ZVvFBuiXbirjTxjwGeQ 是否可以考虑支持setstatichttps://github.com/alibaba/arthas/issues/641","tags":[{"name":"工具","slug":"工具","permalink":"http://example.com/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"Percona-Toolkit-数据库工具","date":"2020-12-17T11:20:54.000Z","path":"2020/12/17/Percona-Toolkit/","text":"概述 perl 语言编写, 不同的 linux 发行版不同的安装 DSN 语法 h: host P: 端口 u: 用户 p: 密码 S: mysql_socket D: 数据库 A: charset t: table F: mysql_read_default_file 1h&#x3D;172.17.10.233,P&#x3D;3306,u&#x3D;root,p&#x3D;root,D&#x3D;testdb3,t&#x3D;testtable1 分类 这些工具主要包括开发、性能、配置、监控、复制、系统、实用六大类 PT 工具分类 工具类别 工具命令 工具作用 备注 开发类 pt-duplicate-key-checker 列出并删除重复的索引和外键 优化使用，实用 pt-online-schema-change 在线修改表结构 pt-query-advisor 分析查询语句，并给出建议，有bug 已废弃 pt-show-grants 规范化和打印权限 分析使用 pt-upgrade 在多个服务器上执行查询，并比较不同 性能类 pt-index-usage 分析日志中索引使用情况，并出报告 索引查看，实用 pt-pmp 为查询结果跟踪，并汇总跟踪结果 pt-visual-explain 格式化执行计划 pt-table-usage 分析日志中查询并分析表使用情况 pt 2.2新增命令 配置类 pt-config-diff 比较配置文件和参数 pt-mysql-summary 对mysql配置和status进行汇总 整体信息，实用 pt-variable-advisor 分析参数，并提出建议 监控类 pt-deadlock-logger 提取和记录mysql死锁信息 死锁信息，实用 pt-fk-error-logger 提取和记录外键信息 pt-deadlock-logger pt-mext 并行查看status样本信息 pt-query-digest 分析查询日志，并产生报告 常用命令 pt-trend 按照时间段读取slow日志信息 已废弃 复制类 pt-heartbeat 监控mysql复制延迟 pt-slave-delay 设定从落后主的时间 pt-slave-find 查找和打印所有mysql复制层级关系 pt-slave-restart 监控salve错误，并尝试重启salve pt-table-checksum 校验主从复制一致性 实用 pt-table-sync 高效同步表数据 实用 系统类 pt-diskstats 查看系统磁盘状态 pt-fifo-split 模拟切割文件并输出 pt-summary 收集和显示系统概况 pt-stalk 出现问题时，收集诊断数据 pt-sift 浏览由pt-stalk创建的文件 pt 2.2新增命令 pt-ioprofile 查询进程IO并打印一个IO活动表 pt 2.2新增命令 实用类 pt-archiver 将表数据归档到另一个表或文件中 pt-find 查找表并执行命令 pt-kill Kill掉符合条件的sql 常用命令 pt-align 对齐其他工具的输出 pt 2.2新增命令 pt-fingerprint 将查询转成密文 pt 2.2新增命令 信息查看pt-summary 可查看挂载情况、网络情况、进程情况 –sleep: 通过 vmstat 收集的 sleep 时间, 默认 5 –summarize-mounts: 挂载的文件系统、磁盘使用, 默认 TRUE –summarize-network: 网络收集、配置, 默认 TRUE –summarize-processes: top process vmstat 输出, 默认 TRUE 1pt-summary pt-mysql-summary 精细地对 mysql 的配置和 sataus 信息进行汇总, 优先执行各种类型字段在对应数据库中的数量btree 在对应 db 中的数量连接的 host 当前连接情况, Process list主从连接情况 –all-databases: 默认 false –databases: 查看指定的数据库 12345678910# 查看所有数据库pt-mysql-summary \\ --host=127.0.0.1 --port=3306 \\ -u root -p root \\ --all-databases# 查看指令数据库pt-mysql-summary \\ --host=127.0.0.1 --port=3306 \\ -u root -p root \\ --databases testdb 1234567891011121314151617181920212223状态统计:Aborted_clients: 取消的连接Com_change_db: 更改 db 命令?Com_commit: 事务提交的个数Com_insert: 插入语句Com_select: 查询语句Com_show_engine_status: 查看存储引擎情况Com_show_table_status: 查看表状态Com_show_variables: 查看变量Connections: 连接数Created_tmp_disk_tables: 创建的临时表Handler_commitHandler_rollbackHandler_updateHandler_writeInnodb_buffer_pool_bytes_data: 缓存池数据Innodb_row_lock_time: 行锁的时间Innodb_row_lock_waits: 锁等待Innodb_rows_deletedInnodb_rows_insertedSelect_full_join: 全表连接Select_full_range_join: 范围连接Sort_rows: 排序的行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107pt-mysql-summary \\ --host=127.0.0.1 --port=3306 \\ -u root -p root \\ --databases testdb1,testdb2# Note Processlist, Schema, InnoDB, Binary Logging Server_id: 315 Master_id: 391 Slave_UUID: 7f80892a-650a-11ea-bb0f-0242ac110002 Version | 5.6.47-log MySQL Community Server (GPL) Started | 2020-07-01 19:35 (up 43+14:06:36) Databases | 9 Datadir | /var/lib/mysql/ Processes | 60 connected, 4 running Replication | Is not a slave, has 1 slaves connected# Processlist ################################################ Command COUNT(*) Working SUM(Time) MAX(Time) ------------------------------ -------- ------- --------- --------- Binlog Dump 1 1 8000 8000 Daemon 1 1 20000 20000 Query 1 1 0 0 Sleep 60 0 22500 3500 User COUNT(*) Working SUM(Time) MAX(Time) ------------------------------ -------- ------- --------- --------- event_scheduler 1 1 20000 20000 user1 45 1 0 0 user2 1 1 8000 8000 user3 15 0 0 0 Host COUNT(*) Working SUM(Time) MAX(Time) ------------------------------ -------- ------- --------- --------- 127.0.0.1 1 1 0 0 172.17.0.1 2 0 0 0 192.168.199.116 1 1 8000 8000 ... localhost 1 1 20000 20000 db COUNT(*) Working SUM(Time) MAX(Time) ------------------------------ -------- ------- --------- --------- NULL 3 3 30000 20000 testdb1 6 0 0 0 testdb2 10 0 0 0 testdb3 15 0 0 0 testdb4 30 0 0 0 testdb5 1 0 0 0 State COUNT(*) Working SUM(Time) MAX(Time) ------------------------------ -------- ------- --------- --------- 60 0 0 0 Master has sent all binlog to 1 1 8000 8000 Waiting for next activation 1 1 20000 20000 init 1 1 0 0# Schema ##################################################### Database Tables Views SPs Trigs Funcs FKs Partn testdb1 35 4 testdb3 223 1 4 Database InnoDB testdb1 35 testdb3 223 Database BTREE testdb1 112 testdb3 653 v d b s t i c d d t a a i m e n h e a i r t g a x t a c t n c e i l t r i e y h t n l m i a i t i a n r m n l t e t Database === === === === === === === === === === testdb1 209 34 13 3 4 17 5 testdb3 3482 283 88 1 2 132 37 433 73 4# InnoDB ##################################################### Version | 5.6.47 Buffer Pool Size | 18.0G Buffer Pool Fill | 100% Buffer Pool Dirty | 0% File Per Table | ON Page Size | 16k Log File Size | 2 * 500.0M = 1000.0M Log Buffer Size | 8M Flush Method | Flush Log At Commit | 2 XA Support | ON Checksums | ON Doublewrite | ON...# Binary Logging ############################################# Binlogs | 15 Zero-Sized | 0 Total Size | 14.2G binlog_format | ROW expire_logs_days | 7 sync_binlog | 0 server_id | 391 binlog_do_db | binlog_ignore_db | pt-deadlock-logger 死锁检测, 收集和保存 mysql 上最近的死锁信息，可以直接打印死锁信息和存储死锁信息到数据库中，死锁信息包括发生死锁的服务器、最近发生死锁的时间、死锁线程 id、死锁的事务 id、发生死锁时事务执行了多长时间等信息。 –columns=A: 控制输出的列 –daemonize: 后台运行 –log=s: 后台运行将输出到处到指定文件 –tab: 使用 tab 进行分割 1234pt-deadlock-logger \\ --h 127.0.0.1 \\ -u root -p root \\ --tab pt-duplicate-key-checker 找出重复的索引和外键，并生成删除重复索引的 SQL 语句 1234pt-duplicate-key-checker \\ -h 127.0.0.1 \\ -u root -p root \\ -d testdb3,testdb1 1234567891011121314151617181920212223# ######################################################################### testdb3.testtable1 # ######################################################################### idx_testtable1_06 is a left-prefix of id_testtable1_unique_01# Key definitions:# KEY &#96;idx_testtable1_06&#96; (&#96;dcUuid&#96;)# UNIQUE KEY &#96;id_testtable1_unique_01&#96; (&#96;dcUuid&#96;,&#96;billNumber&#96;),# Column types:# &#96;dcuuid&#96; varchar(38) not null comment &#39;配送中心uuid&#39;# &#96;billnumber&#96; varchar(30) not null comment &#39;单号&#39;# To remove this duplicate index, execute:ALTER TABLE &#96;testdb3&#96;.&#96;testtable1&#96; DROP INDEX &#96;idx_testtable1_06&#96;;...# ######################################################################### Summary of indexes # ######################################################################### Size Duplicate Indexes 30832348# Total Duplicate Indexes 23# Total Indexes 707 pt-show-grants 查看授权情况 –flush: 刷新权限 1234# Show all grantspt-show-grants \\ -h 127.0.0.1 -P3306 \\ -u root -p $MYSQL_ROOT_PASSWORD 1234# Show database grantspt-show-grants \\ -u root -p root \\ -D testdb4 pt-variable-advisor 分析 mysql 的参数变量，并对可能存在的问题提出建议 12345678pt-variable-advisor --h 172.17.10.233 --u root --p root pt-variable-advisor --h localhost --u root --p root \\ --source-of-variables /etc/mysql/mysql.conf.d/mysqld.cnf pt-variable-advisor \\ h=172.17.10.233,P=3306,u=root,p=root, \\ S=/var/run/mysqld/mysqld.sock \\ --source-of-variables=mysql pt-table-checksum 校验 MySQL 主从复制的完整性，存在锁表问题。 参数： –databases=：指定需要被检查的数据库，多个则用逗号隔开 –tables=：指定需要被检查的表，多个用逗号隔开 -h=127.0.0.1 ：Master的地址 -u=xiaoml：用户名 -p=123456：密码 -P=3306：端口 –tables-regex=s： 表正则匹配 –ignore-tables-regex=s： 忽略的表 –replicate=s: 将校验结果保存到表中 percona.checksums –replicate-database=s: 指定数据库复制校验 123pt-table-checksum -u root -p root \\ --databases testdb5 \\ --tables=QRTZ_TRIGGERS 使用依赖： 需要一个既能登录主库，也能登录从库，而且还能同步数据库的账号 生产环境使用 pt-table-checksum 检查MySQL数据一致性https://segmentfault.com/a/1190000004309169 pt-diskstats 为 GUN/LINUX 打印磁盘 io 统计信息,可以分析从远程机器收集的数据 分析pt-index-usage 从 log 文件中读取查询语句，并用 explain 分析他们是如何利用索引。 完成分析之后会生成一份关于索引没有被查询使用过的报告。 1234pt-index-usage /var/lib/mysql/slow.log \\ --h localhost --u root --p 123456 \\ -d testdb3 \\ --no-report --create-save-results-database *pt-query-digest 分析查询执行日志，并产生一个查询报告，为 MySQL、PostgreSQL、 memcached 过滤、重放或者转换语句。pt-query-digest --database=s: 连接的数据库, 非分析的数据库 --limit=A: 限制输出的百分比/数量， (default 95%:20) --report-all： 所有的查询输出 --ignore-attributes=a: 忽略收集的属性 --timeline: 展示时间线的事件 --review type: DSN 保存查询结果供之后 review, 默认数据库和表为 percona_schema.query_review --report-histogram=s: 属性的直方图，默认为 Query_time --type tcpdump: 类型, 分析多种不同类型的日志 binlog: 分析 binlog genlog: slowlog: 分析慢查询 tcpdump: --order-by: 默认根据查询时间排序， Query_time:sum ，attribute:aggregate 参数的语法 sum Sum/total attribute value min Minimum attribute value max Maximum attribute value cnt Frequency/count of the query 12# 按照总耗时排序--order-by Query_time:sum --since=s: 过滤开始时间 --until=s 过滤结束时间 --limit=A: 限制输出的百分比/数量， (default 95%:20) --filter: 过滤指定的事件, 不同的扫描条件 12# 过滤语句 select：--filter &#x27;$event-&gt;&#123;arg&#125; =~ m/^select/i&#x27;， 12# 过滤指定用户：--filter &#x27;($event-&gt;&#123;user&#125; || &quot;&quot;) =~ m/^dba/i&#x27; ， 12# 过滤全表扫描：--filter &#x27;(($event-&gt;&#123;Full_scan&#125; || &quot;&quot;) eq &quot;yes&quot;) ||(($event-&gt;&#123;Full_join&#125; || &quot;&quot;) eq &quot;yes&quot;)&#x27; 12# 过滤指定数据库--filter &#x27;$event-&gt;&#123;db&#125; &amp;&amp; $event-&gt;&#123;db&#125; =~ /testdb3/ &amp;&amp; $event-&gt;&#123;user&#125; =~ /root/&#x27; 使用案例分析所有慢查询日志 1pt-query-advisor /var/lib/mysql/slow-query.log 指定的查询分析 1pt-query-digest --query &quot;select * from mysql.user&quot; 1234567891011121314151617pt-query-digest \\ -h127.0.0.1 -P3306 \\ -uroot -proot \\ --since &#x27;2020-07-25 00:00:00&#x27; \\ --until &#x27;2020-07-26 00:00:00&#x27; \\ --limit 20 \\ /var/lib/mysql/mysql-slow.log.200725 pt-query-digest \\ -uroot -pimws \\ --since &#x27;2020-07-25 00:00:00&#x27; \\ --until &#x27;2020-07-26 00:00:00&#x27; \\ --order-by Query_time:cnt \\ --limit 20 \\ /var/lib/mysql/mysql-slow.log.200725 \\ &gt; slow-analyse-2.log 更改相关*pt-online-schema-change 在线更改表结构，适用于大表结构的更改 --host: 连接mysql的地址 -P=3306: 连接mysql的端口号 --user: 连接mysql的用户名 --password: 连接mysql的密码 --database=s / D: 连接mysql的库名 t: 连接mysql的表名 --alter: 修改表结构的语句 --charset=utf8: 使用utf8编码，避免中文乱码 --no-version-check: 不检查版本，在阿里云服务器中一般加入此参数，否则会报错 --execute: 执行修改表结构 --new-table-name=s: 新创建的表，默认为 &lt;old-table-name&gt;_new --dry-run: 常见并更改表, 不会创建触发器、复制数据.. --print: 打印 SQL 执行语句 --statistics： 打印内部计数器的统计信息 123456alert_sql=&quot;ADD COLUMN addColumn varchar(30) DEFAULT &#x27;QTY&#x27; COMMENT &#x27;增加列备注&#x27;,ADD COLUMN addColumn2 varchar(30) DEFAULT 0 COMMENT &#x27;增加列2备注&#x27;,CHANGE COLUMN modColumn varchar(100)&quot;pt-online-schema-change \\ --user=root --password=root --host=127.0.0.1 \\ --alter &quot;$alert_sql&quot; \\ D=testdb3,t=testtable1 \\ --print --dry-run -pt-heartbeat 监控 mysql 复制延迟，测量复制落后主 mysql 或者主 PostgreSQL 多少时间，可以使用这个脚本去更新主或者监控复制 通过 show slave status\\G 命令中的 Seconds_Behind_Master 值来判断主从延迟并不靠谱。 原理：pt-heartbeat 通过真实的复制数据来确认 mysql 和 postgresql 复制延迟，避免了对复制机制的依赖，能得出准确的落后复制时间。 包含两部分： 第一部分在主上 pt-heartbeat 的 --update 线程会在指定的时间间隔更新一个时间戳， 第二部分是 pt-heartbeat 的 --monitor 线程或者 --check 线程连接到从上检查复制的心跳记录（前面更新的时间戳），并和当前系统时间进行比较，得出时间的差异。 可以手工创建 heartbeat 表或者添加 –create-table 参数。 -D / –database=s: 指定数据库, 必须的参数 –update, –monitor, –check: 互斥参数 –daemonize, –check: 互斥参数 –config: 指定配置文件的位置， key 必须为全称 –create-table： 创建heartbeat表如果该表不存在，该表由–database和–table参数来确认 –file： 将最新的–monitor信息输出到文件中，新的信息会覆盖旧的信息，通常和–daemonize参数一起使用 –frames： 统计的时间窗口，默认为1m,5m,15m -master-server-id： 指定master的server_id，在检测从的延迟时，必须指定该参数 1234567891011121314151617181920212223# 新建 heartbeat 表, 保存主从执行情况master_server_id=$( mysql -uroot -proot \\ -e &quot;SHOW VARIABLES LIKE &#x27;server_id&#x27;\\G&quot; \\ | grep Value \\ | sed -n -e &#x27;s/^.*: //p&#x27;)slave_server=192.168.199.116pt-heartbeat \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --create-table \\ --update mysql -uroot -proot -e &quot;SELECT * FROM testdb3.heartbeat &quot;;pt-heartbeat \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --update &amp; 查看主从延迟 12345678910111213pt-heartbeat \\ -h $slave_server \\ --monitor \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --print-master-server-idpt-heartbeat \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --check 123#实时延迟，1分钟延迟，5分钟延迟，15分钟延迟0.00s [ 0.00s, 0.00s, 0.00s ] 3910.00s [ 0.00s, 0.00s, 0.00s ] 391 守护线程方式执行， 2s 执行一次 1234567pt-heartbeat \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --update --daemonize --interval=2pt-heartbeat --stop 监控从库并输出日志 1234567pt-heartbeat \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --monitor --print-master-server-id \\ --daemonize --interval=2 \\ --log=/var/lib/mysql/slave-lag.log 使用pt-heartbeat监控主从复制延迟https://cloud.tencent.com/developer/article/1183713pt-heartbeathttps://www.cnblogs.com/ivictor/p/5901853.html -pt-table-sync 主从过程中不同步的表进行同步, 解决主从数据不一致的问题。 注意事项：使用 --dry-run 和 --print 选项总是先测试同步。 无法同步表结构，和索引等对象，只能同步数据 使用该工具来解决主从数据不一致的问题，也可以用来对两个不在一个主从拓扑实例，进行数据 sync –[no]check-slave: 检查目标服务器是否是从数据库，默认为 Yes –sync-to-master and/or –replicate: 只有当需要sync的表都有唯一键(主键或唯一索引)，才能使用–sync-to-master and/or –replicate。(没有唯一键，则只能在desitination上直接修改，而指定–sync-to-master and/or –replicate时只能在主库上修改)，如果sync主从时没有指定–replicate或者–sync-to-master则所有修改都在从库上执行(不论表上是否有唯一键) 123456789# 查看数据不一致pt-table-sync --print \\ h=127.0.0.1,P=3306,u=root,p=root h=127.0.0.1,P=3307 \\ --database=testdb5 --tables=testtable1 # 修复pt-table-sync --execute \\ h=127.0.0.1,P=3306,u=root,p=root h=127.0.0.1,P=3307 \\ --database=testdb5 --tables=testtable2 pt-archiver 将 mysql 数据库中表的记录归档到另外一个表或者文件，也可以直接进行记录的删除操作 只是归档旧的数据，不会对线上数据的 OLTP 查询造成太大影响，可以将数据插入另外一台服务器的其他表中，也可以写入到一个文件中，方便使用 load data infile 命令导入数据。还可以用来执行 delete 操作, 默认的会删除源中的数据。使用的时候请注意 12345678910# create tablemysql -uroot -proot \\ -e &quot;CREATE TABLE IF NOT EXISTS testdb4.bak_mis_wm_testtable1 LIKE testdb4.mis_wm_testtable1&quot;# archive data to bak table and filept-archiver \\ --source h=172.17.10.233,u=root,p=root,D=testdb4,t=mis_wm_testtable1 \\ --dest h=172.17.10.233,u=root,p=root,D=testdb4,t=bak_mis_wm_testtable1 \\ --file &#x27;/var/lib/mysql/%Y-%m-%d-%D.%t&#x27; \\ --where &quot;dispatchState = &#x27;FINISHED&#x27;&quot; \\ --limit 1000 --commit-each Refspercona-toolkit工具的使用Percona-Toolkit 示例说明https://blog.csdn.net/kk185800961/article/details/85016523 pt-query-digest（percona toolkit）小解https://www.cnblogs.com/shengdimaya/p/7063204.html","tags":[{"name":"工具","slug":"工具","permalink":"http://example.com/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"旋转数组类问题","date":"2020-11-09T17:03:57.000Z","path":"2020/11/10/旋转数组类问题/","text":"数组旋转 k 位 189. Rotate Array 123456Input: [1,2,3,4,5,6,7] and k = 3Output: [5,6,7,1,2,3,4]Explanation:rotate 1 steps to the right: [7,1,2,3,4,5,6]rotate 2 steps to the right: [6,7,1,2,3,4,5]rotate 3 steps to the right: [5,6,7,1,2,3,4] 123456789public void rotate(int[] nums, int k) &#123; if (nums.length == 1) return ; int n = nums.length; k = k % n; // prevent unnecessary rotate reverse(nums, 0, n-k-1); reverse(nums, n-k, n-1); reverse(nums, 0, n-1);&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"Leetcode","slug":"Leetcode","permalink":"http://example.com/tags/Leetcode/"}]},{"title":"二分查找及变种","date":"2020-11-09T16:56:19.000Z","path":"2020/11/10/二分查找/","text":"二分查找（1） 算法 （2） 复杂度 O(logN) （3）性质 适用于处理 ceil、floor 等操作； 配合索引相当于是实现了跳表结构； 1、 普通二分查找 12345678910111213int binarySearch(int[] arr, int target) &#123; int lo = 0, hi = arr.length - 1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (arr[mid] == target) return mid; if (arr[mid] &lt; target) lo = mid + 1; else hi = mid - 1; &#125; return -1;&#125; 2、 带有重复元素的二分查找-最先&amp;最后 （1） 查找含有重复元素的数组集合中元素第一次出现的位置 在相等的情况下，进行判断决定是否进行缩小范围或找到对应的值； 12345678910111213int binarySearchFirst(int[] nums, int lo, int hi, int aim) &#123; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (nums[mid] == aim) &#123; if (mid == 0 || nums[mid-1] != nums[mid]) return mid; else hi = mid - 1; &#125; else if (nums[mid] &lt; aim) &#123; lo = mid + 1; &#125; else hi = mid - 1; &#125; return -1;&#125; （2） 查找含有重复元素的数组集合中元素最后一次出现的位置 1234567891011121314int binarySearchLast(int[] nums, int key, int lo, int hi) &#123; while (lo &lt;= hi) &#123; int mid = (hi - lo) / 2 + lo; if (nums[mid] == key) &#123; if (mid == nums.length - 1 || nums[mid] != nums[mid + 1]) return mid; else lo = mid + 1; &#125; else if (nums[mid] &lt; key) &#123; lo = mid + 1; &#125; else &#123; hi = mid - 1; &#125; &#125; return -1;&#125; 3、 二分查找-大于&amp;小于 （1） 查找小于等于给定元素的最小元素在数组中的位置 123456789101112public int binarySearchFloor(int[] nums, int key, int lo, int hi) &#123; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (nums[mid] &lt;= key) &#123; if (mid == nums.length-1 || nums[mid+1] &gt; key) return mid; else lo = mid + 1; &#125; else &#123; hi = mid - 1; &#125; &#125; return -1;&#125; （2） 查找大于等于给定元素的最小元素在数组中的位置 123456789101112public int binarySearchCeil(int[] nums, int key, int lo, int hi) &#123; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (nums[mid] &gt;= key) &#123; if (mid == 0 || nums[mid-1] &lt; key) return mid; else hi = mid - 1; &#125; else &#123; lo = mid + 1; &#125; &#125; return -1;&#125; 4、 带偏移的二分查找 用于旋转数组的查找，偏移后数据有序； 1234567891011121314int binarySearchOffset(int[] nums, int key, int offset) &#123; int lo = 0, hi = nums.length - 1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; int realMid = (mid + offset) % nums.length; if (nums[realMid] == key) &#123; return mid; &#125; else if (nums[mid] &lt; key) &#123; lo = mid + 1; &#125; else hi = mid - 1; &#125; return -1;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"基础排序及变种","date":"2020-11-09T16:51:39.000Z","path":"2020/11/10/基础排序/","text":"基本的排序算法，以及变种 排序比较 选择排序（1） 算法: 选择数组中最小的元素, 将它与数组的第一个元素交换, 之后开始次小元元素… （2） 复杂度 比较: N²/2, 交换: N 最坏: O(n²) 最好: O(n²)， 平均: O(n²) （3） 性质: 运行时间与输入无关； 不稳定； 原地排序； 1234567891011void selectSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = 0; i &lt; arr.length; i ++) &#123; int minIndex = i; for (int j = i + 1; j &lt; arr.length; j ++) &#123; if (arr[j] &lt; arr[minIndex]) minIndex = i; &#125; swap(arr,i, minIndex); &#125;&#125; 冒泡排序（1） 算法: 从左到右不断交换相邻逆序的元素, 经过一次循环确定最后一个元素到达最右侧 存在传入数组已经有序的情况 （2） 复杂度分析: 最坏: O(n²) 最好: O(n), 集合有序, 需要进行一次冒泡 平均: O(n²) （3） 性质： 元素交换的次数为固定值, 原始数据的逆序度 需要三次赋值操作； 稳定； 原地排序； 1、基础冒泡 1234567void bubbleSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = arr.length - 1; i &gt; 0; i --) // insure N-1~1 position, 0 must in correct position for (int j = 0; j &lt; i; j ++) if (arr[j] &gt; arr[j + 1]) swap(arr, j, j + 1);&#125; 有序性优化对于已经有序的数据，不进行元素交换。 12345678910111213void bubbleSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; boolean hasSorted = false; for (int i = arr.length - 1; i &gt; 0 &amp;&amp; !hasSorted; i --) &#123; // except bad condtion hasSorted = true; for (int j = 0; j &lt; i; j ++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; // when equal not modify original order hasSorted = false; swap(arr, j, j + 1); &#125; &#125; &#125;&#125; 插入排序（1）算法: 将数组分为两部分，将后部分元素逐一与前部分元素比较，如果前部分元素比 array[i] 小，就将前部分元素往后移动。当没有比 array[i] 小的元素，即是合理位置，在此位置插入 array[i]。 （2） 复杂度分析 最坏: O(n²), 数组逆序, 需要 N²/2 比较 N²/2 交换 最好: O(n), 正序, 需要 N-1 比较 0 次交换 平均: O(n^2) N²/4 比较 N²/4 交换 （3） 性质: 复杂度取决于数组的初始顺序， 移动次数为逆序对的数量； 稳定； 原地排序； 基础插入排序 1234567public static void insertSortB(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = 1; i &lt; arr.length; i++) for (int j = i; j &gt; 0 &amp;&amp; arr[j] &lt; arr[j - 1]; j --) swap(arr, j, j - 1);&#125; 赋值优化1234567891011void insertSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = 1; i &lt; arr.length; i ++) &#123; int e = arr[i], j; // e current element, j should put position for (j = i; j &gt; 0; j --) &#123; if (e &lt; arr[j-1]) arr[j] = arr[j-1]; &#125; arr[j] = e; &#125;&#125; 链表实现插入排序leetcode 123456789101112131415161718192021222324public ListNode insertionSortList(ListNode head) &#123; if (head == null) &#123; return head; &#125; ListNode first = new ListNode(0); ListNode cur = head; //the node will be inserted ListNode pre = first; //insert node between pre and pre.next ListNode next = null; //the next node will be inserted while (cur != null) &#123; next = cur.next; //find the right place to insert while (pre.next != null &amp;&amp; pre.next.val &lt; cur.val) &#123; pre = pre.next; &#125; //insert between pre and pre.next cur.next = pre.next; pre.next = cur; pre = first; cur = next; &#125; return first.next;&#125; 希尔排序 希尔排序可视轨迹 （1） 算法：使用插入排序对间隔 h 的序列进行排序。通过不断减小 h，最后令 h=1，就可以使得整个数组是有序的。 （2） 复杂度分析： 希尔排序的运行时间达不到平方级别，使用递增序列 1, 4, 13, 40, … 的希尔排序所需要的比较次数不会超过 N 的若干倍乘于递增序列的长度。 （3） 性质： 交换不相邻元素，将逆序数量减少大于1； 基于原来的插入排序； 不稳定； 原地排序； 1234567891011121314void shellSort(int[] arr) &#123; int N = arr.length; int h = 1; while (h &lt; N/3) h = 3 * h + 1; while (h &gt; 0) &#123; for (int i = h; i &lt; N; i += h) &#123; for (int j = i; j &gt;= h; j -= h) &#123; if (arr[j] &lt; arr[j-h]) swap(arr, j, j - h); else break; &#125; &#125; h /= 3; &#125;&#125; 快速排序（1） 思想: 分治, 分区 （2） 复杂度: 由每次选取的分割点控制 最好: 每次分割点都为中间的元素， O(logN) 最坏: 每次分割点都为最后元素 O(n²) （3） 性质: 每趟排序就有一个元素排在了最终的位置上，第n趟结束，至少有n个元素已经排在了最终的位置上； 非稳定 原地排序 （4） 归并 VS 快排: 归并由下到上, 先处理子问题之后合并，快排由上到下, 先进行分区然后处理子问题； 归并非原地排序，需要辅助空间，快排通过原地分区函数实现原地排序； 归并排序为稳定的排序，保留原来相同值的顺序； （5） 优化: 三数取中法 随机选取法 随机取枢纽元 小数据集使用插入排序； 随机选择枢纽元比较； 12345678910111213void quickSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; quickSort(arr, 0, arr.length);&#125;void quickSort(int[] arr, int lo, int hi) &#123; if (hi - lo &lt; INSERTION_SORT_THRESHOLD) &#123; insertSort(arr, lo, hi); return; &#125; int j = partition(arr, lo, hi); quickSort(arr, lo, j - 1); quickSort(arr, j +1, hi);&#125; 快速选择； 123456789101112int partition(int[] arr, int lo, int hi) &#123; swap(arr,lo,lo +(int) Math.random() * (hi-lo+1); int pivot = arr[lo]; int i = lo, j = hi + 1; while (true) &#123; while (arr[++ i] &lt; pivot) if (i == hi) break; while (arr[-- j] &gt; pivot) if (j == lo) break; if (i &gt;= j) break; swap(arr, i, j); &#125; swap(arr, j, lo);&#125; 三路快排优化 三向切分快排可视轨迹 对重复元素较多的情形优化； 函数返回重复元素第一次和最后一次出现位置； 类似荷兰国旗问题的处理； 相关： 75. Sort Colors 1234567891011121314int[] partition(int[] arr, int lo,int hi) &#123; int pivot = arr[lo]; int lt = lo - 1, gt = hi + 1; int i = lo; while (i &lt; gt) &#123; // 各个区间的语义 if (arr[i] == pivot) i ++; else if (arr[i] &lt; pivot) swap(arr, i ++, ++ lt); else swap(arr, i, -- gt); &#125; return new int[]&#123;lt+1, gt-1&#125;;&#125; 三数取中值确定枢纽元优化枢纽元的选取上进行优化； 选取边界和中间数将三处进行排序，选择中间元素作为枢纽元，并放入 [hi-1] 位置； 之后 [lo], [hi] 可以作为快排内循环的哨兵； 123456789101112131415161718192021222324252627282930// sort three element AND put hi-1 positionint medianOf3(int[] arr, int lo, int hi) &#123; int mid = lo + (hi - lo) / 2; if (arr[lo] &gt; arr[mid]) swap(arr, lo, mid); if (arr[lo] &gt; arr[hi]) swap(arr, lo, hi); if (arr[mid] &gt; arr[hi]) swap(arr, mid, hi); swap(arr, mid, hi - 1); return arr[hi - 1]; // pivot is mid value, and position is hi-1&#125;int partition(int[] arr, int lo, int hi, int pivot) &#123; // pivot original position hi - 1 int i = lo, j = hi - 1; while (true) &#123; while (arr[++ i] &lt; pivot); // NOTE: [hi-1] as sentinel while (arr[-- j] &gt; pivot); // [lo] as sentinel if (i &gt;= j) break; swap(arr, i, j); &#125; swap(arr, i, hi - 1); // put pivot as correct position return i;&#125;void quickSort(int[] arr, int lo, int hi) &#123; if (hi - lo &lt;= INSERTITION_SORT_THRESHOLD) &#123; insertSort(arr, lo, hi); return; &#125; int median = medianOf3(arr, lo, hi); int i = partition(arr, lo, hi, median); quickSort(arr, lo, i - 1); quickSort(arr,i +1, hi);&#125; 归并排序（1） 算法 （2） 复杂度 大部分为 O(NlogN) 1234T(n) = 2T(n/2) + n = 2(2T(n/4) + n/2) + n = 4T(n/4) + 2n = 4(2T(n/8) + n/4) + 2n = 8T(n/8) + 3n = 8(2T(n/16) + n/8) + 3n = 16T(n/16) + 4n …… = 2^k T(n/2^k) + k * n （3） 性质 大数据量情况下出现无法分配空间情况； 稳定的排序； 非原地排序； 基础归并排序 自顶向下归并排序可视轨迹 ① 对排序的两个子数组 [lo,mid], [mid+1, hi]，在 [mid] &gt;= [mid+1] 数组整体有序情况下跳过合并； ② 分配当前两个数组对应的数组空间作为辅助； 1234567891011121314151617181920212223void mergeSort(int[] arr, int lo, int hi) &#123; if (hi - lo &lt; INSERTITION_SORT_THRESHOLD) &#123; insertSort(arr, lo, hi); return; &#125; int mid = lo + (hi - lo) / 2; mergeSort(arr, lo, mid); mergeSort(arr, mid + 1, hi); if (arr[mid] &gt; arr[mid + 1]) loopArrQueue merge(arr, lo, mid, hi);&#125;void merge(int[] arr, int lo, int mid, int hi) &#123; int[] aux = new int[hi - lo + 1]; int i = lo, j = mid + 1; for (int k = 0; k &lt; aux.length; k ++) &#123; if (i &gt; mid) aux[k] = arr[j ++]; else if (j &gt; hi) aux[k] = arr[i ++]; else if (arr[i] &lt; arr[j]) aux[k] = arr[i ++]; else aux[k] = arr[j ++]; &#125; for (int k = 0; k &lt; aux.length; k ++) arr[k + lo] = aux[k];&#125; 自底向上的归并排序 自底向上的归并排序可视轨迹 考虑处理两种情况： 12P1 __ __ | __ __ | __ __ | _ i + sz &lt; arr.length to controlP2 __ __ | __ __ | __ __ | __ _ min&#123;i + sz + sz - 1, arr.length - 1&#125; to control sz 为两个子数组的区间大小 123456789void mergeSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; int N = arr.length; for (int sz = 1; sz &lt; N; sz += sz) &#123; for (int i = 0; i + sz &lt; N; i += sz + sz) &#123; loopArrQueue merge(arr, i, i + sz - 1, Math.min(i + sz + sz - 1, N-1)); &#125; &#125;&#125; 使用链表进行归并排序执行过程： ① 找出中间节点，分割链表； ② 对分割的链表分别进行归并排序； ③ 将链表合并； 相关： leetcode | leetcode-cn 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ListNode implements Cloneable &#123; public int val; public ListNode next; public ListNode(int val) &#123; this.val = val; &#125; public ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;&#125;public ListNode sortList(ListNode head) &#123; if (head == null || head.next == null) &#123; return head; &#125; // 1. find mid node and cut two list ListNode preMid = preMidNode(head); ListNode mid = preMid.next; preMid.next = null; // 2. handle two sub problem ListNode l1 = sortList(head); ListNode l2 = sortList(mid); // 3. merge result return merge(l1, l2);&#125;private ListNode preMidNode(ListNode head) &#123; ListNode pre = null, fast = head, slow = head; while (fast != null &amp;&amp; fast.next != null) &#123; pre = slow; slow = slow.next; fast = fast.next.next; &#125; return pre;&#125;private ListNode merge(ListNode l1, ListNode l2) &#123; if (l1 == null) return l2; if (l2 == null) return l1; if (l1.val &lt; l2.val) &#123; l1.next = merge(l1.next, l2); return l1; &#125; else &#123; l2.next = merge(l1, l2.next); return l2; &#125;&#125; 合并 k 个已经排序的链表leetcode-cn | leetcode 12345678910111213141516171819202122232425262728293031323334public ListNode mergeKLists(ListNode[] lists) &#123; return mergeSortList(lists, 0, lists.length - 1); &#125; private ListNode mergeSortList(ListNode[] lists, int lo, int hi) &#123; if (lo &gt; hi) &#123; return null; &#125; if (lo == hi) &#123; return lists[lo]; &#125; int mid = lo + (hi - lo) / 2; ListNode left = mergeSortList(lists, lo, mid); ListNode right = mergeSortList(lists, mid + 1, hi); return merge(left, right); &#125; // 合并两个排序的链表 private ListNode merge(ListNode l1, ListNode l2) &#123; if (l1 == null) &#123; return l2; &#125; if (l2 == null) &#123; return l1; &#125; if (l1.val &lt; l2.val) &#123; l1.next = merge(l1.next, l2); return l1; &#125; else &#123; l2.next = merge(l1, l2.next); return l2; &#125; &#125; 堆排序 堆排序可视轨迹 （1） 算法 （2） 复杂度 O(logN) （3） 性质 无法利用到现代处理器的缓存局部性原理，一般不使用； 不稳定； 原地排序，适用于嵌入式系统中内存小的情况； 基础堆排序 先通过向堆中不断插入元素，向上调整形成堆结构； 之后不断删除堆顶元素实现排序； 12345678910111213141516171819202122232425262728void heapSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = 0; i &lt; arr.length; i ++) heapify(arr, i); // heapInsert int N = arr.length; while (N &gt; 0) &#123; // heapify: delete and adjust heap structure swap(arr, -- N, 0); sink(arr, N, 0); &#125;&#125;void heapify(int[] arr, int k) &#123; while (arr[k] &gt; arr[(k - 1) / 2]) &#123; swap(arr, k, (k - 1) / 2); k = (k - 1) / 2; &#125;&#125;void sink(int[] arr, int N, int k) &#123; while (2 * k + 1 &lt; N) &#123; int j = 2 * k + 1; if (j + 1 &lt; N &amp;&amp; arr[j] &lt; arr[j + 1]) j ++; if (arr[k] &gt;= arr[j]) break; swap(arr, k, j); k = j; &#125;&#125; 算法优化与 java.util.ProrityQueue 中实现逻辑相同 ① 通过 sink 向下调整进行优化； ② 下沉操作中使用赋值替代交换，常数级优化； 1234567891011121314151617181920212223void heapSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; int N = arr.length; for (int i = (N - 2) / 2; i &gt;= 0; i --) // build heap sink(arr, i, N); while (N &gt; 0) &#123; // delete max ⇔ put into last position swap(arr, 0, -- N); sink(arr, 0, N); &#125;&#125;void sink(int[] arr, int k, int N) &#123; int val = arr[k]; while (k * 2 + 1 &lt; N) &#123; int j = k * 2 + 1; if (j + 1 &lt; N &amp;&amp; arr[j] &lt; arr[j + 1]) j = j + 1; if (val &gt;= arr[j]) break; arr[k] = arr[j]; k = j; &#125; arr[k] = val;&#125; 合并 k 个已经排序的链表123456789101112131415161718192021222324public ListNode mergeKLists(ListNode[] lists) &#123; if (lists == null || lists.length == 0) &#123; return null; &#125; // 初始化加载所有链表的头节点 PriorityQueue&lt;ListNode&gt; pq = new PriorityQueue&lt;&gt;(lists.length, Comparator.comparingInt(l -&gt; l.val)); // list like each data flow for (ListNode list : lists) &#123; if (list != null) &#123; pq.offer(list); &#125; &#125; // 比较每条链表当前的头节点 ListNode first = new ListNode(-1); ListNode cur = first; while (!pq.isEmpty()) &#123; cur.next = pq.poll(); cur = cur.next; if (cur.next != null) &#123; pq.offer(cur.next); &#125; &#125; return first.next;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"}]}]