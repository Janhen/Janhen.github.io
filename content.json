[{"title":"Java-集合类源码","date":"2021-04-08T15:18:17.000Z","path":"2021/04/08/Java-集合类源码/","text":"ListArrayList基本性质： 底层基于数组保存； 增删慢、随机查询快； 线程不安全； 底层结构与初始化（1） 结构 123transient Object[] elementData; int size;transient int modCount = 0; （2） 加载和初始化 懒加载形式，在 add() 时进行对应的初始化； 共支持三种初始化方式： ① 无参构造： 默认不进行数据的初始化； ② 给定容量： 程序中通过给定容量来优化； ③ 通过放入 Collection 接口进行初始化； 123456789101112131415161718192021222324252627282930313233static final int DEFAULT_CAPACITY = 10;private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125;public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); &#125;&#125;public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125;import com.google.common.collect.Lists;// 使用 Guava 创建指定容量的 ListList&lt;String&gt; list = Lists.newArrayListWithCapacity(oldList.size()); 操作1、add ① 默认插入尾部，O(1) 实现； ② 任意位置插入 将插入位置后的所有元素右移一位，之后在插入位置赋值； 插入的开销与插入的位置有关； 123456789101112131415public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); /* 右移一位 */ elementData[index] = element; size++;&#125; 2、remove 需要调用 System.arraycopy() 将 index + 1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，开销大； 同 add() 操作，删除与位置紧密相关； 12345678910public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; 3、 扩容 扩容后的大小为 oldN * 1.5 + 1； 通过 Arrays.copyOf() 复制到新数组中； 可通过指定初始容量的方式，来减少扩容的次数，减少不必要的开销； 12345678910111213141516171819202122232425262728293031public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); /* init capacity */ &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); /* copy to impl. */ elementData = Arrays.copyOf(elementData, newCapacity);&#125; 4、 迭代访问 采用快速失败模式实现； 通过成员变量 modCount 与 expectedModCount 比较实现； 主要用在序列化获得迭代操作时进行判断，对应抛出 ConcurrentModificationException； 5、序列化 只序列化数组中存放值的这些部分。 ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。 1transient Object[] elementData; // not serialize 通过 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。 1234567891011121314151617181920212223242526272829303132333435363738private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; int expectedModCount = modCount; /* keep to compare */ s.defaultWriteObject(); /* only have space */ s.writeInt(size); for (int i=0; i&lt;size; i++) &#123; /* only write have element */ s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; /* use for fail-fast */ throw new ConcurrentModificationException(); &#125;&#125;private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; s.defaultReadObject(); s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125;// 将 list 序列化到指定文件ArrayList list = new ArrayList();ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file));oos.writeObject(list); 其他（1） ArrayList 与 Array 的比较 ① 存储类型： Array 可以存放基本和对象类型， ArrayList 只能存放对象类型； ② 存放元素的大小： ArrayList 动态可变，Array 不可变; ③ 其他方法和特性： ArrayList 提供 addAll()，removeAll()，iterator() 等方法; 对于基本类型数据，集合使用自动装箱来减少编码工作量。但当处理固定大小的基本数据类型的时候，这种方式相对比较慢。 （2）ArrayList 与 LinkedList 的比较 都是线程不安全的容器，都实现了 List 接口具备 List 的特性。 ① 底层结构： ArrayList 基于索引的数据接口，底层是动态数组实现，LinkedList 以元素列表的形式存储数据，是双向链表实现； ② 操作性质： 随机访问： ArrayList 支持随机访问，LinkedList 不支持； 元素删除： LinkedList 在任意位置添加删除元素更快； 操作是否与元素位置的影响： 比较插入和删除是否受元素位置影响，ArrayList 插入和删除受元素位置影响，add(e) 默认追加到末尾，在指定位置 i 插入和删除时复杂度为 O(n-i)，而 LinkedList 链表存储，插入和删除不受位置影响； ③ 内存占用上： LinkedList 存放两个指针，相同数据量下占用更多的空间； （3） ArrayList 与 Vector 的比较 同步性： Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。 扩容： Vector 每次扩容请求其大小的 2 倍空间，而 ArrayList 是 1.5 倍。且 Vector 可以设置增长空间的大小。 LinkedList基本性质： 基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。 线程不安全； LinkedList 可以用作栈、队列和双向队列。 底层结构与初始化（1） 结构 通过记录 first, last, size 便于边界操作（注：用于队列、栈、双端队列） 队列中每个节点都存放元素，存在初始化情况； 12345678transient int size = 0;transient Node&lt;E&gt; first;transient Node&lt;E&gt; last;class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev;&#125; （2） 初始化 不支持初始情况下给定对应的容量，即基于链表都为无界队列； 123456public LinkedList() &#123;&#125;public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 操作1、add 添加元素, 最后元素与中间元素, 可处理头结点位置。 12345678910111213141516171819202122232425262728293031public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) /* init 处理 */ first = newNode; else pred.next = newNode; size++; modCount++;&#125; 2、remove 操作不受指定位置的影响； 为双向链表中指定节点的删除； 1234567891011121314151617181920212223242526272829public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125; Vector基本性质： 底层基于数组保存元素； 随机查询快，增删慢； 线程安全； Java 中的 Stack 通过继承 Vector 实现的； 底层结构与初始化（1） 结构 ① elementCount：初始容量为 10，非懒加载实现； ② capacityIncrement；可以设置每次容量的增长数量； ③ 无 modCount： 同步容器； 123Object[] elementData;int elementCount;int capacityIncrement; （2） 初始化 支持 ArrayList 的各种初始化； 支持设置每次的扩容时的容量增长； 1234567891011public Vector() &#123; this(10);&#125;public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement;&#125; 操作1、add / get 对修改底层结构的函数进行加锁同步访问。 12345678910111213public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125;public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);&#125; 2、扩容机制 默认扩容为 oldN * 2； 可以通过用户设置的正常数量进行控制扩容大小； 1234567891011void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? /* 默认扩容 1 倍 */ capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);&#125; 其他替代方案 因为 Vector 通过加锁实现，粒度大效率低。 （1） 获得对应线程不安全容器的同步容器 12List&lt;String&gt; list = new ArrayList&lt;&gt;();List&lt;String&gt; synList = Collections.synchronizedList(list); （2） 使用并发容器，如 CopyOnWriteArrayList 1List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); CopyOnWriteArrayList基本性质： 易引起 YongGC, FullGC 不可用于实时的数据， 写操作复制防止并发修改不一致 适合读多写少的情景 读操作无需加锁，写操作加锁 三个设计思想： 读写分离 最终一致性 新开辟空间，解决并发冲突 底层结构与初始化（1） 结构 ① ReentrantLock： 通过此来实现并发访问 1234final transient ReentrantLock lock = new ReentrantLock();transient volatile Object[] array;static final long lockOffset;static final sun.misc.Unsafe UNSAFE; （2） 初始化 三种初始化方式： LinkedList 的初始化方式 支持泛型数组初始化 123public CopyOnWriteArrayList(E[] toCopyIn) &#123; setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class));&#125; 操作(1) add 并发下安全的容器，需要处理并发访问问题、处理复制问题。 包含 lock 加锁获取与释放： ① 获取原数组 ② 复制出 len+1 的数组 ③ 为新数组末尾复制 ④ 修改内部数组指向 123456789101112131415161718boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); /* 获取原数组, volatile 保证可见性 */ int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); /* 复制数组 */ newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125;final void setArray(Object[] a) &#123; array = a;&#125; (2) get 无需加锁直接访问, 在 add 操作的同时可访问旧有的数据 ⇒ 实时性得不到保证 。 123456E get(int index) &#123; return get(getArray(), index);&#125;E get(Object[] a, int index) &#123; return (E) a[index];&#125; 3、迭代方式 通过安全失败实现，将当前数组放入到 Iterator 实现类中作为快照访问。 123public Iterator&lt;E&gt; iterator() &#123; return new COWIterator&lt;E&gt;(getArray(), 0);&#125; 迭代器中保存某个时间点下底层数组的快照，通过 cursor 来进行向前迭代访问。 1234567891011final Object[] snapshot;int cursor;COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements;&#125;E next() &#123; if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++];&#125; 其他（1） 读写分离 写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响； 写操作需要加锁，防止并发写入时导致写入数据丢失； 写操作结束之后需要把原始数组指向新的复制数组； （2）适用场景 CopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。 （3） 缺陷 内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右； 数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中。 所以 CopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景。 SetHashSet底层结构与初始化通过一个 HashMap 实现，对应的 Value 为指定的一个 Object 12private transient HashMap&lt;E,Object&gt; map;private static final Object PRESENT = new Object(); 操作1、add 123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 2、remove 123public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; LinkedHashSet基于 LinkedHashMap 实现, HashSet 的子类。 1234567891011SetHashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125;public class LinkedHashSet&lt;E&gt; extends HashSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; public LinkedHashSet() &#123; super(16, .75f, true); &#125;&#125; TreeSet与 HashSet 的区别 ① 底层结构：HashSet 基于 hash 表实现，元素无序， 一些方法 add(), remove(), contains() 复杂度为 O(1)； ② 有序性： TreeSet 基于红黑树实现，元素有序， add(), remove(), contains() 复杂度为 O(logN)； QueuePriorityQueue基本性质： 有序的优先队列； 不可以存放 NULL，NULL 无自然顺序； 非线程安全，入队和出队的时间复杂度为 O(logN)； 基于堆结构实现，默认情况下为最小堆； 底层结构与初始化（1） 底层结构 数组保存的完全二叉树，首元素存放元素值。 堆顶元素有序，默认情况下为最小堆。 comparator： 默认自定义比较器优先于存入对象的自然排序进行比较 1234transient Object[] queue; int size = 0;final Comparator&lt;? super E&gt; comparator;transient int modCount = 0; （2） 初始化 可指定初始容量与比较器； 1234567static final int DEFAULT_INITIAL_CAPACITY = 11;PriorityQueue(Comparator&lt;? super E&gt; comparator) &#123; this(DEFAULT_INITIAL_CAPACITY, comparator);&#125;PriorityQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator); 操作（1） offer 实现： 先将元素放到完全二叉树的尾节点 之后不断上浮调整结构使其符合堆特性 辅助-shiftUp 上浮函数，用于维护最小堆的结构。 赋值替换交换优化； 找出正确位置并放入； 123456789101112void siftUpComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;) x; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = queue[parent]; if (key.compareTo((E) e) &gt;= 0) break; queue[k] = e; k = parent; &#125; queue[k] = key;&#125; （2） poll 弹出当前堆顶元素。 实现： 保存堆顶元素； 将堆顶与最末叶子节点交换，之后通过堆顶下沉实现结构的维护； siftDown，下沉函数，最小堆的结构； 通过赋值来替换掉交换操作； 找到元素应该放入的正确位置放入； 1234567891011121314151617void siftDownComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;)x; int half = size &gt;&gt;&gt; 1; // loop while a non-leaf while (k &lt; half) &#123; int child = (k &lt;&lt; 1) + 1; // assume left child is least Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; ((Comparable&lt;? super E&gt;) c).compareTo((E) queue[right]) &gt; 0) c = queue[child = right]; if (key.compareTo((E) c) &lt;= 0) break; queue[k] = c; k = child; &#125; queue[k] = key;&#125; （3） remove remove(o) 删除一个对象，为 Collection 中的方法，需要先进行向下调整后进行向上调整； 实现： 最末叶子节点赋值到当前删除的位置； 让原来的最末叶子节点向下调整； 若结构不合法则向上调整； 123456789101112131415161718E removeAt(int i) &#123; // assert i &gt;= 0 &amp;&amp; i &lt; size; modCount++; int s = --size; if (s == i) // removed last element queue[i] = null; else &#123; E moved = (E) queue[s]; /* 最末叶子节点赋值到当前删除的位置 */ queue[s] = null; siftDown(i, moved); /* 让原来的最末叶子节点向下调整 */ if (queue[i] == moved) &#123; /* 结构不合法向上调整 */ siftUp(i, moved); if (queue[i] != moved) return moved; &#125; &#125; return null;&#125; （4） heapify 初始传入为 Collection 进行堆化处理，借助原始结构，从中间处向上不断下沉处理，相比较每次插入到最末叶子节点进行向上调整效率更高； 完全二叉树中间节点位置 size / 2 - 1； 12345678void initFromCollection(Collection&lt;? extends E&gt; c) &#123; initElementsFromCollection(c); heapify();&#125;void heapify() &#123; for (int i = (size &gt;&gt;&gt; 1) - 1; i &gt;= 0; i--) /* 完全二叉树从上层节点不断向下调整实习 */ siftDown(i, (E) queue[i]);&#125; 3、扩容 小数据量快速 2 * oldCapacity + 2 扩容，容量大于 64 后进行 1.5 * oldCapacity 扩容； 1234567891011void grow(int minCapacity) &#123; int oldCapacity = queue.length; // Double size if small; else grow by 50% int newCapacity = oldCapacity + ((oldCapacity &lt; 64) ? (oldCapacity + 2) : (oldCapacity &gt;&gt; 1)); // overflow-conscious code if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); queue = Arrays.copyOf(queue, newCapacity);&#125; 4、迭代访问 通过双向队列 ArrayDeque 实现 1234567class Itr implements Iterator&lt;E&gt; &#123; int cursor = 0; int lastRet = -1; ArrayDeque&lt;E&gt; forgetMeNot = null; E lastRetElt = null; int expectedModCount = modCount;&#125; 其他使用场景 贪心算法选择局部最优； 图论中使用进行优化； 实现哈夫曼树等结构； ArrayDeque基于数组实现的双向队列； 可使用 Stack 的 API; 底层结构与初始化(1) 底层结构 一个数组，两个索引指向队列的头节点和尾部节点。 1234transient Object[] elements;transient int head;transient int tail;private static final int MIN_INITIAL_CAPACITY = 8; (2) 初始化 12345678910public ArrayDeque() &#123; elements = new Object[16];&#125;public ArrayDeque(int numElements) &#123; allocateElements(numElements);&#125;public ArrayDeque(Collection&lt;? extends E&gt; c) &#123; allocateElements(c.size()); addAll(c);&#125; UtilArrays1、sort JDK 中的排序都为稳定排序 算法的执行逻辑： 小数据量使用 INSERT 排序 一定规模数据量使用 QUICK 排序 大数据量使用 MERGE 排序 并非所有大数据量都是 Merge Sort，在不具备结构性时转换成 Quick Sort； （1） 归并排序 ① 小数据量转快速排序 ② 通过分配当前大小进行 merge ③ 判断排序数组的结构，不具有时使用快速排序 1234567891011121314151617181920212223static void sort(int[] a, int left, int right, int[] work, int workBase, int workLen) &#123; // Use Quicksort on small arrays if (right - left &lt; QUICKSORT_THRESHOLD) &#123; sort(a, left, right, true); return; &#125; int[] run = new int[MAX_RUN_COUNT + 1]; /* aux space to merge */ int count = 0; run[0] = left; // Check if the array is nearly sorted for (int k = left; k &lt; right; run[count] = k) &#123; // ... /* * The array is not highly structured, * use Quicksort instead of merge sort. */ if (++count == MAX_RUN_COUNT) &#123; sort(a, left, right, true); return; &#125; &#125; // ...&#125; （2） 快速排序 ① 小数据量插入排序 1234567static void sort(int[] a, int left, int right, boolean leftmost) &#123; int length = right - left + 1; // Use insertion sort on tiny arrays if (length &lt; INSERTION_SORT_THRESHOLD) &#123; if (leftmost) &#123; &#125; ② 逻辑实现 通过双枢纽元分割实现； 类似 BFPRT 算法中对于枢纽元的选取，将原来期望的复杂度转换成确定的复杂度； 12345678910111213141516171819202122232425262728left part center part right part +--------------------------------------------------------------+ | &lt; pivot1 | pivot1 &lt;= &amp;&amp; &lt;= pivot2 | ? | &gt; pivot2 | +--------------------------------------------------------------+ ^ ^ ^ | | | less k great left part center part right part +----------------------------------------------------------+ | == pivot1 | pivot1 &lt; &amp;&amp; &lt; pivot2 | ? | == pivot2 | +----------------------------------------------------------+ ^ ^ ^ | | | less k great Partitioning degenerates to the traditional 3-way (or &quot;Dutch National Flag&quot;) schema: left part center part right part +-------------------------------------------------+ | &lt; pivot | == pivot | ? | &gt; pivot | +-------------------------------------------------+ ^ ^ ^ | | | less k great （3） 插入排序 为快速排序中的子过程实现； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960if (length &lt; INSERTION_SORT_THRESHOLD) &#123; if (leftmost) &#123; /* * Traditional (without sentinel) insertion sort, * optimized for server VM, is used in case of * the leftmost part. */ for (int i = left, j = i; i &lt; right; j = ++i) &#123; int ai = a[i + 1]; while (ai &lt; a[j]) &#123; a[j + 1] = a[j]; if (j-- == left) &#123; break; &#125; &#125; a[j + 1] = ai; &#125; &#125; else &#123; /* * Skip the longest ascending sequence. */ do &#123; if (left &gt;= right) &#123; return; &#125; &#125; while (a[++left] &gt;= a[left - 1]); /* * Every element from adjoining part plays the role * of sentinel, therefore this allows us to avoid the * left range check on each iteration. Moreover, we use * the more optimized algorithm, so called pair insertion * sort, which is faster (in the context of Quicksort) * than traditional implementation of insertion sort. */ for (int k = left; ++left &lt;= right; k = ++left) &#123; int a1 = a[k], a2 = a[left]; if (a1 &lt; a2) &#123; a2 = a1; a1 = a[left]; &#125; while (a1 &lt; a[--k]) &#123; a[k + 2] = a[k]; &#125; a[++k + 1] = a1; while (a2 &lt; a[--k]) &#123; a[k + 1] = a[k]; &#125; a[k + 1] = a2; &#125; int last = a[right]; while (last &lt; a[--right]) &#123; a[right + 1] = a[right]; &#125; a[right + 1] = last; &#125; return;&#125; 2、binarySearch 计算 mid mid = (low + high) &gt;&gt;&gt; 1 12345678910111213141516171819202122// Like public version, but without range checks.private static int binarySearch0(Object[] a, int fromIndex, int toIndex, Object key) &#123; int low = fromIndex; int high = toIndex - 1; while (low &lt;= high) &#123; int mid = (low + high) &gt;&gt;&gt; 1; // @SuppressWarnings(&quot;rawtypes&quot;) Comparable midVal = (Comparable)a[mid]; @SuppressWarnings(&quot;unchecked&quot;) int cmp = midVal.compareTo(key); if (cmp &lt; 0) low = mid + 1; else if (cmp &gt; 0) high = mid - 1; else return mid; // key found &#125; return -(low + 1); // key not found.&#125; 3、asList / subList 不推荐使用，返回的 List 修改会有问题。 Collections1、提供一些容器的空实现：作为容器为空的情况下的返回值，规避空指针问题。 1234public static final List EMPTY_LIST = new EmptyList&lt;&gt;();public static final &lt;T&gt; List&lt;T&gt; emptyList() &#123; return (List&lt;T&gt;) EMPTY_LIST;&#125; 2、提供单个元素的集合： 方便传递方法的参数 123public static &lt;T&gt; List&lt;T&gt; singletonList(T o) &#123; return new SingletonList&lt;&gt;(o);&#125; 3、sort JDK8 中借助 List 中自带的 sort() 函数调用实现； 4、binarySearch 对 List 进行二分搜索 根据底层是数组还是链表采用不同的处理： ① 数组： 数组随机访问定位实现 ② 链表： 接着 ListIterator 实现二分查找 在 binarySearch（）⽅法中，它要判断传⼊的list 是否 RamdomAccess 的实例，如果是，调⽤ indexedBinarySearch() ⽅法，如果不是，那么调⽤ iteratorBinarySearch() ⽅法 1234567public static &lt;T&gt; int binarySearch(List&lt;? extends Comparable&lt;? super T&gt;&gt; list, T key) &#123; if (list instanceof RandomAccess || list.size()&lt;BINARYSEARCH_THRESHOLD) return Collections.indexedBinarySearch(list, key); else return Collections.iteratorBinarySearch(list, key);&#125; 5、提供将不安全的容器转换为同步容器 1public static &lt;T&gt; List&lt;T&gt; synchronizedList(List&lt;T&gt; list)","tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"源码","slug":"源码","permalink":"http://example.com/tags/%E6%BA%90%E7%A0%81/"}]},{"title":"大数据","date":"2021-03-09T15:23:13.000Z","path":"2021/03/09/大数据/","text":"使用 Notion 做笔记，博客为 Notion 的部分导出。","tags":[]},{"title":"Hive-基础","date":"2021-03-09T14:57:00.000Z","path":"2021/03/09/Hive-基础/","text":"Hive [TOC] 基础说明 将 SQL 转换成 MapReduce 任务的工具。 基于 Hadoop 的数据仓库工具，存储和处理海量结构化的数据，可将结构化的数据映射成一张表 FaceBook 开发的海量数据查询工具，基本实现了 SQL-92 标准。 可以与 Druid, Kudu 进行集成 与 HBase 集成 说明 处理 HDFS 中的海量数据 通过 SQL 完成计算 基于Hadoop的数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能. 最适合数据仓库程序 缺点： HQL 表达能力有限： 无法表示迭代计算，数据挖掘方面不擅长 效率低： 自动生成的 MR 效率，调优较困难 Pig: Hive 的替代品，apache 顶级项目 一种数据流语言，不是查询语言 常用语 ETL 中的一部分 HBase: 已经可以结合 Hive 使用 Thrift: 提供了可远程访问其他进程的功能，提供了使用 JDBC, ODBC 访问 Hive 的功能 HWI: 简单的网页界面 HQL： Hive: 解释器: AST 抽象语法树 编译器 优化器 执行期 MetaStore Hive 的元数据默认存储在自带的 derby 数据库中 derby: java 开发、但进程、单用户 架构原理// TODO Client： Hive、Beeline、Hue 元数据库： 存放元数据的地方，数据库、表、分区、列的名称和属性，数据所在位置等信息 Meta store 元数据服务： 提供统一的服务接口，Client 通过 metastore 访问元数据。三种模式，内嵌、本地、远程模式。 。。。 Hive Driver： 解释器、编译器、优化器、执行器 HSQL 转化为 MapReduce 的过程 HiveSQL -&gt; AST 抽象语法树 -&gt; QB 查询块 -&gt; OperatorTree 操作树 -&gt; 优化后的 OperatorTree -&gt; MapReduce 树 -&gt; 优化后的 MapReduce 任务树 Q: Hive 关联表对应 MapReduce 如何实现？ Hive 的优缺点Hive 的优点 学习成本低。Hive提供了类似SQL的查询语言，开发人员能快速上手； 处理海量数据。底层执行的是MapReduce 任务； 系统可以水平扩展。底层基于Hadoop； 功能可以扩展。 Hive允许用户自定义函数； 良好的容错性。某个节点发生故障，HQL仍然可以正常完成； 统一的元数据管理。元数据包括：有哪些表、表有什么字段、字段是什么类型 Hive 的缺点 HQL表达能力有限； 迭代计算无法表达； Hive的执行效率不高(基于MR的执行引擎)； Hive自动生成的MapReduce作业，某些情况下不够智能； Hive的调优困难； Hive 架构 CLI: Hive 命令行 Thrift Server: Hive 可选组件，一个软件框架服务，可通过编程方式访问 Hive MetaStore: 元数据存储在 RDBMS 中，元数据包括数据库名、表名和类型、字段名和数据类型、数据所在的位置等 Driver： 驱动程序 解析器： 第三方工具(antlr) 将 HQL 字符串转换成 AST，对 AST 进行语法分析，如字段是否存在、SQL 语义正确性、表的存在 编译器： 将 AST 编译成逻辑执行计划 优化器： 对逻辑执行计划进行优化，减少不必要的列、使用分区、进行谓词下推等 执行器： 将逻辑执行计划转换成可以运行的物理计划 数据类型数据类型与转换基本数据类型 整数类型： Integer 、TINYINT、SMALINT、INT、BIGINT 浮点数类型： FLOAT、DOUBLE、DECIMAL(17byte) 字符类型： STRING(任意长度)、VARCHAR(1-65535) 日期类型： 类型转换 String 可隐式转换 整形科转换为更广的类型，TINYINT → INT, INT → BIGINT 整数类型、FLOAT、STRING 类型可隐式转换成 DOUBLE cast 进行强制类型转换，失败返回空 1SELECT CAST(&#x27;11111&#x27; AS INT); 集合类型四种集合类型 array: 有序的相同类型集合 map: key 为基本类型 struct: 不同类型字段的集合 union: 不同类型元素存储在统一字段的不同行中 1SELECT NAMED_STRUCT(&quot;name&quot;, &quot;usernamexx&quot;, &quot;id&quot;, 7, &quot;salary&quot;, &quot;111111.23&quot;); 使用案例 原始的 JSON 数据 123456789101112&#123; &quot;name&quot;: &quot;songsong&quot;, &quot;friends&quot;: [&quot;bingbing&quot; , &quot;lili&quot;] , //列表Array, &quot;children&quot;: &#123; //键值Map, &quot;xiao song&quot;: 18 , &quot;xiaoxiao song&quot;: 19 &#125; &quot;address&quot;: &#123; //结构Struct, &quot;street&quot;: &quot;hui long guan&quot; , &quot;city&quot;: &quot;beijing&quot; &#125;&#125; 格式好的行数据 12345678910111213141516songsong,bingbing_lili,xiao song:18_xiaoxiao song:19,hui long guan_beijingyangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing-- 表创建create table test( name string, friends array&lt;string&gt;, children map&lt;string, int&gt;, address struct&lt;street:string, city:string&gt;)row format delimited fields terminated by &#x27;,&#x27;collection items terminated by &#x27;_&#x27;map keys terminated by &#x27;:&#x27;lines terminated by &#x27;\\\\\\\\n&#x27;;-- 测试结构查询SELECT friends[1], children[&#x27;xiao song&#x27;], address.city FROM test WHERE name = &#x27;songsong&#x27;; 表类型 外部表： 指定 external 关键字，元数据 + 数据分开管理，删除表定义，数据不会删除 内部表： 删除表的时候数据会删除 分桶表： 实现 DML 事务时必须 分区表： 123456789CREATE EXTERNAL TABLE emp_bucket ( empno INT, ename STRING, job STRING, mgr INT, hiredate TIMESTAMP, sal DECIMAL(7,2), comm DECIM) Q: 为何分区？ 可避免全表扫描，提高查询效率，通常根据事件、地区等信息进行分区 Q: 为何分桶？ 分区或表数据量过大，分桶降数据划分成更细粒度。 通过 分桶字段.hashCode % 分桶个数。 不能使用 load data local inpath 方式加载数据 在数据仓库中 ODS 外部表，从外部进来 DW 内部表 ADS 内部表 计算过程中使用到的临时表，数据随用随删，使用内部表。 文本文件编码支持自定义文件存储格式 默认的文件分割 行与行 \\\\n 字段之间 ^A 元素之间 ^B k-v 之间： ^C 12# 显示 ^A/^B 特殊的控制字符cat -A emp 读时模式写时模式 -&gt; 写数据检查 -&gt; RDBMS 读时模式 -&gt; 读时检查 -&gt; Hive 写时模式： 在加载时发现数据不符合表的定义，则拒绝加载数据。数据在写入 数据库时对照表模式进行检。 读时模式： 加载数据时不进行数据格 式的校验，读取数据时如果不合法则显示NULL。 元数据管理 通常是独立的 RDBMS 元数据信息包括： 存在的表、表的列、权限 … Thrift 服务开启 hiveserver2，搭配 groovy / maven 使用 默认情况下，管理表在 /usr/hive/warehouse 目录下 hive.start.cleanup.scratchdir 默认为 false 每次重启 Hiveserver 时清理掉历史目录 HiveServer2 管理元数据，生产环境中常使用。 beelinebeeline 可以连接 Hive， MySQL… HCatalogHive 的元数据服务 统一的元数据服务 可不启动 MR 任务执行 主要是 DDL 对元数据的操作 hcat -e “create database tt2”; hcat -f xxx.hql 数据存储格式TEXTFILE（默认格式） 、 SEQUENCEFILE、 RCFILE、 ORCFILE、 PARQUET。 TEXTFILE、SEQUENCEFILE 的存储格式是基于行存储的； ORC和PARQUET 是基于列式存储的。 TEXTFILE 通常先导入到 textfile，之后执行 insert … select 到其他格式的表中 行和列的存储 行存储： insert 与 update 比较容易 select 需要查询大多无用的数据 textfile,sequencefile 行 rcrile, orc, parout 列存储 sequencefile: 可分割 可压缩 record, none, block 压缩 … RCFile: 列式记录文件，结合列和行存储的优势 先按水平划分，后让垂直划分 使用列唯独的压缩，有效提升存储空间利用率 textfile默认格式，数据不压缩 12345678910111213CREATE TABLE student (name STRING,age INT,cource ARRAY&lt;STRING&gt;,body MAP&lt;STRING, FLOAT&gt;,address STRUCT&lt;STREET:STRING, CITY:STRING, STATE:STRING&gt;)ROW FORMAT DELIMITEDFIELDS TERMINATED BY &#x27;\\\\001&#x27;COLLECTION ITEMS TERMINATED BY &#x27;002&#x27;MAP KEYS TERMINATED BY &#x27;\\\\003&#x27;LINES TERMINATED BY &#x27;\\\\n&#x27;STORED AS TEXTFILE; ORCFile 表位 ORC 可支持事务操作 组成 文件脚注(file footer)： postscript： stripe: 条带 ，默认 250M Index Data: 1W行一个, 条带统计信息, 数据在条带中的位置 Row data: 水平 –&gt; 垂直, 列为单位存储数据 Stripe Footer: stripe 元数据信息 三个级别的索引： 文件级别、条带级、行组级 无需指定分割符，自动处理 Parquet apache 顶级项目site 由 Twitter 和 Cloudera 合作开发 支持使用重复级别/定义级别的方法来对数据结构进行编码 通用型强 与语言和平台无关 二进制存储的 文件中包含数据和元数据 Row group: 文件有多个行组组成，写入数据最大的缓存单元，50M ~ 1GB 之间 Column Chunk: 存储当前行组内的某一行数据 最小的 I/O 并发单元 Page: 压缩读取数据的最小单元 8K ~ 1M 之间，越大压缩率越高 Footer: 数据的 schema 信息 每个行组的元数据信息： 每个 column chunk 的元数据信息： 比较压缩比 ORC &gt; Parquet &gt; text 执行查询 ORC 与 Parquet 相当 TextFile文件更多的是作为跳板来使用(即方便将数据转为其他格式) 有update、delete和事务性操作的需求，通常选择ORCFile 没有事务性要求，希望支持 Impala、Spark，多种计算框架/查询引擎，建议选择 Parquet 其他Hive 与 RDBMS 的对比Hive 是基于 Hadoop 的数据仓库分析工具， 可以将 SQL 转换成 MR 任务运行。 查询语言类似， HQL, 与 SQL 高度类似，实现了 SQL-92 的标准。 数据规模，Hive 处理海量数据，RDBMS 只能处理有限的数据集 执行引擎，Hive 的执行引擎可以是 MR / Tex / Spark / Flink, RDBMS使用自己的执行引擎 数据存储，Hive 的数据一般存储在 HDFS 上，RDBMS 通常存储在贝蒂文件系统或者裸设备 执行速度，Hive 执行速度相对比较慢(MR/数据量)，RDBMS 相对快，Hive 没有索引，默认使用 MapReduce 作为执行引擎，会产生较高的延迟。RDBMS 一般会定义索引，执行延迟较低。 可扩展性，Hive 方便进行水平扩展，通常 RDBMS 对水平扩展支持不友好。Hive 建立在 Hadoop 上，可扩展性与 Hadoop 的可扩展性是一致的，RDBMS 优于 ACID 语义的严格限制，扩展行有限。 数据更新，Hive 对数据更新不友好，RDBMS 支持频繁快速的数据更新 Hive 与 RDBMS 对比 Property Hive RMDBMS 查询语言 HQL SQL 数据存储位置 HDFS Raw Device / 本地文件系统 数据格式 用户定义 系统决定 数据更新 不支持 支持 索引 无 有 执行引擎 MapReduce Executor 执行延迟 高 低 可扩展性 高 低 数据规模 大 小 子查询 只可 from 子句中 完全支持 HiveQL 于 SQL 的比较 比较项 SQL HiveQL ANSI SQL 更新 支持 UPDATEVINSERT\\DELETE 。。。 不完全支持 insert OVERWRITEVINTO TABLE 事务 支持 可支持(分桶、ORCFile 文件格式) 模式 写模式 读模式 数据保存 块设备、本地文件系统 HDFS 延时 低 高 多表播入 不支持 支持 子查询 完全支持 只能用在 From 子句中 视图 Updatable Read-only 可扩展性 低 高 数据规模 小 大 Ref Github-Hive LanguageManual","tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"}]},{"title":"Hive-优化","date":"2021-03-09T13:33:13.000Z","path":"2021/03/09/Hive-优化/","text":"[TOC] 影响 Hive 效率的几乎从不是数据量过大，而是数据倾斜、数据冗余、Job / IO过多、MapReduce 分配不合理等。 架构优化执行引擎选择通过参数 hive.execution.engine 控制，可选 MapReduce, Tez, Spark, Flink 作为执行引擎，在离线数仓中，批处理方面主要使用 Spark 优化器的使用在真正执行计算之前，生成和优化逻辑执行计划与物理执行计划。 Vectorize 矢量化查询执行 Cost-Based Optimization: CBO 成本优化器 矢量化查询执行 要求执行引擎为Tez, 执行通过一次批量执行1024行而不是每行一行来提高扫描，聚合，过滤器和连接等操作的性能, 可一显着缩短查询执行时间。 需要使用 orc 格式存储数据 123-- 开启 set hive.vectorized.execution.enabled = true;set hive.vectorized.execution.reduce.enabled = true; 成本优化器 基于apache Calcite的，Hive的CBO通过查询成本(有analyze收集的统计信息)会生成有效率的执行计划，最终会减少执行的时间和资源的利用 可定期执行表的分析，分析后数据存放在元数据库中 123456789-- 从 v0.14.0默认SET hive.cbo.enable=true; true-- 默认falseSET hive.compute.query.using.stats=true; -- 默认falseSET hive.stats.fetch.column.stats=true; -- 默认trueSET hive.stats.fetch.partition.stats=true; 文件格式Parquet 和 ORC 都是 Apache 旗下的开源列式存储格式。列式存储比起传统的行式存 储更适合批量 OLAP 查询，并且也支持更好的压缩和编码。 选择 Parquet 的原因主要是它支持 Impala 查询引擎，并且对 update、delete 和事务性操作需求很低。 选择 ORCFile 支持事务操作。 数据压缩压缩的配置可以在hive的命令行中或者hive-site.xml文件中进行配置。 1SET hive.exec.compress.intermediate=true DEFLATE GZIP: 扩展名 .gz Bzip2: 支持分割, 扩展名 .gz LZO： LZ4： Snappy: 不支持分割 可在mapred-site.xml, hive-site.xml 配置，命令行配置 12345SET hive.intermediate.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;SET hive.exec.compress.output=true;SET mapreduce.output.fileoutputformat.compress.codec =org.apache.hadoop.io.compress.SnappyCodc 分区、分桶表设计成分区表可以提升查询的性能，对于一个特定分区的查询，只会加载对应分区路 径的文件数据 尽量避免层级较深的分区 日期或时间。如year、month、day或者hour， 地理位置。如国家、省份、城市 业务逻辑。如部门、销售区域、客户 分桶表 分桶表的组织方式是将HDFS上的文件分割成多个文件。 分桶可以加快数据采样，也可以提升join的性能(join的字段是分桶字段)，因为分桶可 以确保某个key对应的数据在一个特定的桶内(文件)，巧妙地选择分桶字段可以大幅 度提升join的性能。 分桶字段可以选择经常用在过滤操作或者join操作的字段。 参数优化本地模式支持将作业动态地转为本地模式, 当Hive处理的数据量较小时，启动分布式去处理数据会有点浪费。 一个作业只要满足下面的条件，会启用本地模式 输入文件的大小小于 hive.exec.mode.local.auto.inputbytes.max 配置的大小 map 任务的数量小于 hive.exec.mode.local.auto.input.files.max 配置的大小 reduce 任务的数量是1或者0 123SET hive.exec.mode.local.auto=true; -- 默认 falseSET hive.exec.mode.local.auto.inputbytes.max=50000000;SET hive.exec.mode.local.auto.input.files.max=5; -- 默认 4 严格模式强制不允许用户执行3种有风险的HiveQL语句，一旦执行会直接失败。 查询分区表时不限定分区列的语句； 两表 join 产生了笛卡尔积的语句； 用 order by 来排序，但没有指定 limit 的语句。 12-- DEFAULT strictset hive.mapred.mode=nostrict JVM 重用Hadoop可以重用 JVM，通过共享 JVM 以串行而非并行的方式运行 map 或者 reduce。 避免 JVM 启动进程所耗费的时间会比作业执行的时间还要长。 JVM的重用适用于同一个作业的 map 和 reduce，对于不同作业的 task 不能够共享 JVM。 开启JVM重用将一直占用使用到的 task 插槽，以便进行重用，直到任务完成后才能释放。 如果某个“不平衡的”job中有某几个reduce task执行的时间要比其他Reduce task消耗的时间多的多的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的task都结束了才会释放。 12-- 代表同一个MR job中顺序执行的5个task重复使用一个JVM，减少启动和关闭的开销SET mapreduce.job.jvm.numtasks=5; 并行执行Hive 将查询转换成一个或多个阶段，MapReduce 阶段、抽样阶段、合并阶段、Limit 阶段.. 默认情况下一次只执行一个阶段，对于特定 Job 有多个阶段，阶段间非完全相互依赖，并行执行，可以缩短 job 的执行时间。 1234-- 默认falseSET hive.exec.parallel=true; -- 默认8SET hive.exec.parallel.thread.number=16; 推测执行在分布式集群环境下，因为程序Bug、负载不均衡、资源分布不均、网络情况等原因，会造成同一个作业的多个任务之间运行速度不一致，有些任务的运行速度可能明显慢于其他任务, 这些任务会拖慢作业的整体执行进度。 Hadoop采用了推测执行机制，它根据一定的规则推测出 “拖后腿” 的任务，并为这样的任务启动一个备份任务，让该任务与原始任务同时处理同一份数据，并最终选用最先成功运行完成任务的计算结果作为最终结果。 123set mapreduce.map.speculative=trueset mapreduce.reduce.speculative=trueset hive.mapred.reduce.tasks.speculative.execution=true 合并小文件在map执行前合并小文件，减少map数 12-- 缺省参数set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat 在Map-Reduce的任务结束时合并小文件 1234567891011-- 在 map-only 任务结束时合并小文件，默认trueSET hive.merge.mapfiles = true;-- 在 map-reduce 任务结束时合并小文件，默认falseSET hive.merge.mapredfiles = true;-- 合并文件的大小，默认256MSET hive.merge.size.per.task = 268435456;-- 当输出文件的平均大小小于该值时，启动一个独立的 map-reduce 任务进行文件mergeSET hive.merge.smallfiles.avgsize = 16777216; Fetch 模式Fetch 模式是指 Hive 中对某些情况的查询可以不必使用 MapReduce 计算 在开启 fetch 模式之后，在全局查找、字段查找、limit 查找等都不启动 MapReduce 123-- Default Value: minimal in Hive 0.10.0 through 0.13.1, -- more in Hive 0.14.0 and laterhive.fetch.task.conversion=more SQL 优化列裁剪和分区裁剪列裁剪： SELECT 只查需要的列。少用 SELECT * 分区裁剪: 只读取需要的列。在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where 后面，那么就会先全表关联，之后再过滤。 1234# 列裁剪优化相关的配置项, default truehive.optimize.cp=true# 分区裁剪优化, default truehive.optimize.pruner=true 谓词下推在 RDBMS 中，如 MySQL 也有 Predicate Pushdown(PPD) 的概念，将 SQL 语句中的 where 谓词逻辑尽可能提前执行，减少下游处理的数据量。 如下的 SQQ， forum_topic 表过滤的 where 语句卸载子查询内部，而不是外部，Hive 谓词下推逻辑优化器是 PredicatePushDown，该优化器将 OperatorTree 中的 FilterOperator 向上提。 123456789select a.uid,a.event_type,b.topic_id,b.titlefrom calendar_record_log aleft outer join (select uid,topic_id,title from forum_topicwhere pt_date = 20190224 and length(content) &gt;= 100) b on a.uid = b.uidwhere a.pt_date = 20190224 and status = 0;# 谓词下推优化的配置项, default truehive.optimize.ppd = true sort by 代替 order by为了控制 map 端数据分配到 reducer 的 key, 需要配置 distribute by 一起使用，如果不加 distribute by 的话，map 端数据就会随机分配到 reducer。 123456-- 以UID为key，以上传时间倒序、记录类型倒序输出记录数据select uid,upload_time,event_type,record_datafrom calendar_record_logwhere pt_date &gt;= 20190201 and pt_date &lt;= 20190224distribute by uidsort by upload_time desc,event_type desc; group by 代替 count(distinct)去重计算数据量大时不好处理，数据量大的时候用一个 ReduceTask 来完成，导致整个 Job 很难完成 。 一般 COUNT DISTINCT 使用先 GROUP BY 再 COUNT 的方式替换。使用 group by 替换后， SQL 如下，会启动两个 MR Job，确保启动 Job 开销远小于计算耗时的时候使用。 12345select count(1) from ( select uid from calendar_record_log where pt_date &gt;= 20190101 group by uid) t; group by 配置调整并不是所有的聚合操作都需要在 Reduce 端完成，可现在 Map 端进行部分聚合，最后在 Reduce 端得出最终结果 hive.map.aggr=true: 是否在 Map 端进行聚合 hive.groupby.napaggr.checkinterva=10000: 在 Map 端进行聚合操作的条目数目 hive.groupby.skewindata=true: 有数据倾斜的时候进行负载均衡，默认 false 当选项设定为 true，生成的查询计划会有两个 MR Job。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。 join 基础优化map join 分桶 join 大表 join 大表处理空值或无意义值(1) 空 key 过滤 大表 Join 大表时，key 有大量的异常数据，相同的 key 发送到相同的 reducer 上，从而导致内存不够，结果 Join 的时候耗时长，可先通过 SQL 对其进行过滤。 (2) 空 key 转化 空 Key 转化，key 非异常数据，必须包含在 join 的结果中，可对为空的 key 设置随机值，使数据随机均匀分到不同的 reducer 上，防止数据的倾斜问题 … 单独处理倾斜 key调整 Map 数通常情况下，作业通过 Input 目录产生一个/多个 map 任务 input 文件总个数、文件大小，集群设置的文件快大小。 Q: 是不是map数越多越好？ 答案是否定的。如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。 Q: 是不是保证每个map处理接近128m的文件块，就高枕无忧了？ 答案也是不一定。比如有一个127m的文件，正常会用一个 map 去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果 map 处理的逻辑比较复杂，用一个 map 任务去做，肯定也比较耗时。 增加 Map 的方法： 调整 maxSize 最大值，使 maxSize 小于 blockSize 增加 map 个数 // TODO maxSize 对应的配置参数… 1computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))&#x3D;blocksize&#x3D;128M 调整 Reduce 数过多的 reduce 问题 过多的 reduce， 会过多启动、初始化 reduce 消耗时间和资源 有多少个 reduce 就会有多少个输出文件，生成很多小文件，如果这些小文件作为下一个任务的输入，会出现小文件过多的问题 hive.exec.reducers.bytes.per.reducer=256000000: 每个 reduce 处理的数据量默认为 256MB hive.exec.reducers.max=1009: 每个任务最大的 reduce 数，默认 1009 mapreduce.job.reduces： 设置每个 job 的 reduce 个数 12-- 设置每个 job 的 reduce 个数set mapreduce.job.reduces=15 优化小结 Hadoop/Hive 处理数据过程，有几个显著特征： 不怕数据多，就怕数据倾斜 对 job 数比较多的作业运行效率相对比较低 对 sum、count 等聚合操作而言，不存在数据倾斜问题 count(distinct) 效率较低，数据量大容易出问题 优化可以从几个方面着手： 好的模型设计，事半功倍 解决数据倾斜问题。根据配置和业务进行处理 减少 job 数 设置合理的map、reduce task 数 对小文件进行合并，是行之有效的提高 Hive 效率的方法 优化把握整体，单一作业的优化不如整体最优 RefHive 自带的序列化与反序列化 https://cwiki.apache.org/confluence/display/Hive/DeveloperGuide#DeveloperGuide-HiveSerDe Hive 参数说明的官方文档：https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties Hive SQL的编译过程 Hive/HiveSQL常用优化方法全面总结","tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"}]},{"title":"Hive-函数","date":"2021-03-09T13:30:52.000Z","path":"2021/03/09/Hive-函数/","text":"[TOC] 函数分类 标准函数： 一列或多列作为参数传入，返回值是一个值的函数 如 to_date(string timestamp), sqrt(double a) 聚合函数： 接收0行、多行的列，返回单一的值 表生成函数： 接收 0 、 多个输入，产生多列 、 多行输出 如 explode 123show functions;desc function upper;desc function extended upper; 基础函数日期函数 current_date: current_timestamp： year(string date) month(string date) hour(string date) minute(string date) second(string date) from_unixtime(bigint unixtime[, string format])：转换从 1970-01-01 00:00:00 UTC 开始的秒为日期 datediff(string enddate, string startdate): 计算时间差 day(string date) / dayofmonth(date): 查询当月第几天 weekofyear(string date): 如weekofyear(“1970-11-01 00:00:00”) = 44, weekofyear(“1970-11-01”) = 44. last_day(string date)：查询月末的最后一天 date_add(date/timestamp/string startdate, tinyint/smallint/int days)： 增加指定多少天 date_sub(date/timestamp/string startdate, tinyint/smallint/int days)： 减少指定多少天 date_sub(current_date, dayofmonth(current_date)-1)：当月第一天 add_months(string start_date, int num_months, output_date_format)， 如 add_months(date_sub(current_date, dayofmonth(current_date)-1), 1)： 下月第一天 to_date(string timestamp)： 字符串转日期，2.1.0- 返回 String 类型，2.1.0+ 返回 date 类型 date_format(date/timestamp/string ts, string fmt)： 日期、时间戳、字符串类型格式化输出标准时间格式 next_day(string start_date, string day_of_week)： 返回第一个日期，该日期晚于start_date并命名为day_of_week。day_of_week 为两个或三个字符，如 “Mo”, “tue”, “FRIDAY”，next_day(‘2015-01-14’, ‘TU’) = 2015-01-20 1234567891011121314151617181920212223242526SELECT current_date;SELECT CURRENT_TIMESTAMP();-- unix 时间戳转换成日期SELECT FROM_UNIXTIME(11111111);SELECT FROM_UNIXTIME(11111, &#x27;yyyyMMdd&#x27;);SELECT FROM_UNIXTIME(1111111, &#x27;yyyy-MM-dd HH:mm:ss&#x27;);-- 日期转成时间戳SELECT UNIX_TIMESTAMP(&#x27;2019-09-15 14:23:00&#x27;);-- 时间差, 返回日期相差的天数SELECT datediff(&#x27;2020-04-18&#x27;, &#x27;2019-11-21&#x27;);SELECT abs(datediff(&#x27;2020-04-18&#x27;, &#x27;2019-11-21&#x27;));-- 日期为所处月的第几天SELECT dayofmonth(current_date);-- 日期所处月的最后一天日期SELECT last_day(current_date);-- 当月第一天SELECT DATE_SUB(current_date, dayofmonth(current_date) - 1);-- 下月第一天SELECT add_months(date_sub(current_date, dayofmonth(current_date) - 1), 1);-- must 字符串转换成 date yyyy-MM-ddSELECT to_date(&#x27;2020-01-01&#x27;);SELECT to_date(&#x27;2020-01-01 12:12:12&#x27;);-- 日期格式化成指定的字符串SELECT date_format(current_timestamp(), &#x27;yyyy-MM-dd HH:mm:ss&#x27;);SELECT date_format(current_date(), &#x27;yyyyMMdd&#x27;);SELECT date_format(&#x27;2020-06-01&#x27;, &#x27;yyyy-MM-dd HH:mm:ss&#x27;); 常用的日期处理 1234567-- 近3天的-- 近一周的where dt &gt;= date_add(next_day(&#x27;$do_date&#x27;, &#x27;mo&#x27;), -7) and dt &lt;= &#x27;$do_date&#x27;-- 近一月的where dt &gt;= date_format(&#x27;$do_date&#x27;, &#x27;yyyy-MM-01&#x27;) and dt &lt;= &#x27;$do_date&#x27; 条件函数 IF .. else case when.. end &lt;column-name&gt;: 多个条件的时候使用 nvl(T value, T default_value): value 为空的时候返回默认值 COALESCE(T v1, T v2, ...): 返回参数中第一个非空值 nullif(x, y): 相等为空，否则为x isnull / isnull( a ): assert_true(boolean condition): 不满足抛出异常 12345678910111213141516171819202122232425262728293031323334353637383940414243444546-- 测试表定义create table if not exists emp( empno int comment &#x27;员工号&#x27;, ename string comment &#x27;员工姓名&#x27;, job string comment &#x27;工作名称&#x27;, mgr int comment &#x27;&#x27;, hiredate date comment &#x27;雇佣日期&#x27;, sal int comment &#x27;薪水&#x27;, comm int, deptno int comment &#x27;部门号&#x27;) row format delimited fields terminated by &quot;,&quot;;select * from emp;-- if (boolean testCondition, T valueTrue, T valueFalseOrNull)-- 将 emp 表的员工工资等级分类：0-1500、1500-3000、3000以上SELECT sal, if(sal &lt;= 1500, &#x27;primary&#x27;, if(sal &lt;= 3000, &#x27;middle&#x27;, &#x27;advanced&#x27;))FROM emp;-- case when 判断SELECT ename, deptno, CASE WHEN deptno = 10 THEN &#x27;accounting&#x27; WHEN deptno = 20 THEN &#x27;research&#x27; WHEN deptno = 30 THEN &#x27;sales&#x27; ELSE &#x27;unknown&#x27; END deptnameFROM emp;-- 返回参数中的第一个非空值；如果所有值都为 NULL，那么返回NULLselect sal, coalesce(comm, 0)from emp;-- null 判断select *from empwhere isnotnull(comm);-- 空值转换函数 nvl(T value, T default_value)select empno, ename, job, mgr, hiredate, deptno, sal + nvl(comm, 0) sumsalfrom emp;-- nullif(x, y) 相等为空，否则为x SELECT nullif(&quot;b&quot;, &quot;b&quot;), nullif(&quot;b&quot;, &quot;a&quot;); 字符串函数 lower： length: concat / || ：字符拼接 concat_ws(separator, [string | array(string)]+): 可指定分隔符进行拼接 substr： 求子串, 指定开始和结束索引 split： . 需要进行正则转义 instr(string str, string substr)： 返回substr在str中第一次出现的位置 parse_url(string urlString, string partToExtract [, string keyToExtract])： 从 url 中抽取值，可抽取的值包括 HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO. 如 parse_url(‘http://facebook.com/path1/p.php?k1=v1&amp;k2=v2#Ref1&#39;, ‘HOST’) returns ‘facebook.com‘。 regexp_extract(string subject, string pattern, int index)： 按照正则匹配值 如 regexp_extract(‘foothebar’, ‘foo(.*?)(bar)’, 2)， Index 参数为 Java 的 group regexp_replace(string INITIAL_STRING, string PATTERN, string REPLACEMENT):正则替换 如 regexp_replace(“foobar”, “oo|ar”, “”) returns ‘fb.’ get_json_object(string json_string, string path)： 从 JSON 字符串中获取特定路径值 JSON 路径只能为 [0-9a-z_], 没有大写或特殊字符, keys 不可以以 数字开头 str_to_map(text[, delimiter1, delimiter2])： 返回 map 123456789-- 子串截取SELECT split(&quot;www.lagou.com&quot;, &quot;\\\\\\\\.&quot;);select empno || &quot; &quot; || ename idname-- 字符串拼接 指定分割符拼接 concat_ws(separator, [string | array(string)]+)SELECT concat_ws(&#x27;.&#x27;, &#x27;www&#x27;, array(&#x27;lagou&#x27;, &#x27;com&#x27;));SELECT substr(&#x27;www.lagou.com&#x27;, 5);SELECT substr(&#x27;www.lagou.com&#x27;, -5);SELECT substr(&#x27;www.lagou.com&#x27;, 5, 5); get_json_object 获取 JSON 字符串信息 1234567891011121314151617181920212223242526272829&#123; &quot;store&quot;: &#123; &quot;fruit&quot;:[ &#123; &quot;weight&quot;: 8, &quot;type&quot;: &quot;apple&quot; &#125;, &#123; &quot;weight&quot;: 9, &quot;type&quot;: &quot;pear&quot; &#125; ], &quot;bicycle&quot;: &#123; &quot;price&quot;: 19.95, &quot;color&quot;: &quot;red&quot; &#125; &#125;, &quot;email&quot;: &quot;amy@only_for_json_udf_test.net&quot;, &quot;owner&quot;: &quot;amy&quot;&#125;-- 获取值SELECT get_json_object(src_json.json, &#x27;$.owner&#x27;) FROM src_json;amy-- 获取数组值SELECT get_json_object(src_json.json, &#x27;$.store.fruit\\\\[0]&#x27;) FROM src_json;&#123;&quot;weight&quot;:8,&quot;type&quot;:&quot;apple&quot;&#125;-- 获取不存在的值SELECT get_json_object(src_json.json, &#x27;$.non_exist_key&#x27;) FROM src_json;NULL 数学函数 round: round x to d decimal places，可用于控制小数保留几位 ceil: 向上取整 floor: 向下取整。 exp(DOUBLE a), exp(DECIMAL a): 指数函数 log10(DOUBLE a), log10(DECIMAL a) log(DOUBLE base, DOUBLE a) abs(DOUBLE a) 1234select round(314.15926, 2);select round(314.15926, -2);select ceil(3.1415926);select floor(3.1415926); 集合函数 size(Map&lt;K.V&gt;) / size(Array&lt;T&gt;)： 返回元素个数 map_keys(Map&lt;K.V&gt;) / map_values(Map&lt;K.V&gt;): 将 Map 所有的 key、value 进行返回 array_contains(Array&lt;T&gt;, value): 数组中是否包含某个值 sort_array(Array&lt;T&gt;)： 对数组元素进行排序 类型转换函数 binary(string|binary)： 转换成二进制 cast(expr as )： 类型转换，无法转换时，返回 NULL 1SELECT CAST(&#x27;23232&#x27; AS INT); UDTF 聚集函数(UDAF) count / sum / avg / min / max collect_set(col) collect_list(col) ntile(INTEGER x): 将有序分区划分为x个称为存储桶的组，并为该分区中的每一行分配存储桶编号。 表生成函数(UDTF) 一行输入，多行输出 配合 lateral view 进行使用，解决 UDTF 不能添加额外列的问题。 explode(ARRAY a) explode(MAP&lt;Tkey,Tvalue&gt; m) posexplode (array)： 带有原始位置的炸裂函数 json_tuple(string jsonStr,string k1,…,string kn) parse_url_tuple(string urlStr,string p1,…,string pn) 1234567891011121314151617181920-- lateral view 常与 表生成函数explode结合使用，处理上述问题-- ==&gt; 解决 UDTF 不能添加额外列的问题-- lateral view udtf(expression) tableALias as ...with t1 as ( select &#x27;OK&#x27; cola, split(&#x27;www.lagou.com&#x27;, &#x27;\\\\\\\\.&#x27;) colb)select cola, colcfrom t1 lateral view explode(colb) t2 as colc;lateral view udtf(expression) tableALias as ...-- 炸裂 map 并给定别名select explode(map(&#x27;A&#x27;,10,&#x27;B&#x27;,20,&#x27;C&#x27;,30)) as (key,value);key valueA 10B 20C 30select posexplode(array(&#x27;A&#x27;,&#x27;B&#x27;,&#x27;C&#x27;)) as (pos,val);pos val2 C1 B0 A json_tuple 获取 JSON 多个值拆开 12select a.timestamp, b.*from log a lateral view json_tuple(a.appevent, &#x27;eventid&#x27;, &#x27;eventname&#x27;) b as f1, f2; parse_url_tuple 获取 URL 中的多个信息 12SELECT b.*FROM src LATERAL VIEW parse_url_tuple(fullurl, &#x27;HOST&#x27;, &#x27;PATH&#x27;, &#x27;QUERY&#x27;, &#x27;QUERY:id&#x27;) b as host, path, query, query_id LIMIT 1; 其他脱敏函数： 对姓名、电话号码进行脱敏，不显示全部内容 mask(string str[, string upper[, string lower[, string number]]]): 如 mask(“abcd-EFGH-8765-4321”, “U”, “l”, “#”) results in llll-UUUU-####-####. collect_list： 列出该字段的所有值，不去重 current_user()： 当前用户 md5(string/binary) version()† 窗口与分析函数 和聚合函数的不同之处是：对于每个组返回多行，而聚合函数对于每个组只返回一行。数据窗口大小可能会随着行的变化而变化。 窗口函数 使用窗口函数之前一般要要通过 over() 进行开窗 窗口函数是针对每一行数据的，如果 over 中没有参数，默认是全部的结果集 partition by 子句 在 over 窗口中进行分区，对某一列进行分区统计，窗口的大小就是分区的大小 order by 子句 对输入的数据进行排序，有 order by 缺少 window 子句，默认窗口为 range between unbounded preceding and current row over 子句 后面可指定标准的聚集函数， count, sum, min, max, avg 使用 PARTITION BY 语句，具有任何原始数据类型的一个或多个分区列。 带有 PARTITION BY 和 ORDER BY 以及任何数据类型的一个或多个分区和/或排序列， 带有窗口规格，Windows 可以在 WINDOW 子句中单独定义。 Window 子句 窗口规范支持以下格式： 指定 order by 并缺少 window 子句时，window 默认被指定为 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW 当同时缺少 order by 和 window 子句时，默认窗口指定为 ROW BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING 不支持 Rank 函数， rank、ntile、denseRank、cusmeDis、percentRank，不支持 Lead 和 Lag 函数 123(ROWS | RANGE) BETWEEN (UNBOUNDED | [num]) PRECEDING AND ([num] PRECEDING | CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING)(ROWS | RANGE) BETWEEN CURRENT ROW AND (CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING)(ROWS | RANGE) BETWEEN [num] FOLLOWING AND (UNBOUNDED | [num]) FOLLOWING 窗口范围 unbounded preceding: 组内第一行数据 n preceding: 组内当前行的前n行数据 current row: 当前行数据 n following: 组内当前行的后 n 行数据 unbounded following: 组内最后一行数据 123456789101112131415161718192021222324252627282930-- 查询员工姓名、薪水、部门薪水总和、占部门薪水的百分比select ename, sal, deptno, sum(sal) over (partition by deptno) depsalsum, round(sal / sum(sal) over(partition by deptno) * 100, 2) || &#x27;%&#x27; salofdeptsumpercentfrom emp;select ename, sal, deptno, sum(sal) over (partition by deptno order by ename)from emp;-- 等价。组内，第一行 ~ 当前行的和select ename, sal, deptno, sum(sal) over (partition by deptno order by ename rows between unbounded preceding and current row )from emp;-- 组内，第一行 ~ 最后一行的和select ename, sal, deptno, sum(sal) over (partition by deptno order by ename rows between unbounded preceding and unbounded following )from emp;-- 组内，按照分区前后两行和当前行的总和，前一行 + 当前行 + 后一行select ename, sal, deptno, sum(sal) over (partition by deptno order by ename rows between 1 preceding and 1 following )from emp; 排名函数 row_number(): 排名顺序增加不会重复 RANK(): 排名相等会在名次中留下空位；如1、2、2、4、5、… … DENSE_RANK(): 排名相等会在名次中不会留下空位 ；如1、2、2、3、4、… … 1234567891011121314151617CREATE TABLE IF NOT EXISTS t2( cname string comment &#x27;课程名&#x27;, sname string COMMENT &#x27;学生名&#x27;, score int COMMENT &#x27;课程分数&#x27;) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27; &#x27;;-- 求每个班级前3名的学员 with tmp as ( SELECT cname, sname, score, dense_rank() over (partition by cname order by score) rank FROM t2)select cname, sname, score, rankfrom tmpwhere rank &lt;= 3; 序列函数 lag: 返回当前数据行的上一行数据 常用 lead: 返回当前数据行的下一行数据 常用 first_value: 取分组内排序后，截止到当前行，第一个值 last_value: 分组内排序后，截止到当前行，最后一个值 ntile: 将分组的数据按照顺序切分成n片，返回当前切片值 12345678910111213141516171819202122232425262728create table userpv( cid string comment &#x27;&#x27;, ctime date comment &#x27;时间&#x27;, pv int COMMENT &#x27;页面访问次数&#x27;) row format delimited fields terminated by &#x27;,&#x27;;-- 上两行数据， 下三行数据select cid, ctime, pv, lag(pv, 2) over (partition by cid order by ctime) lagpv, lead(pv, 3) over (partition by cid order by ctime) leadpvfrom userpv;-- first_value 分组排序截止到当前行第一个值 / last_value 分组排序后截止到当前行最后一个值select cid, ctime, pv, first_value(pv) over (partition by cid order by ctime rows between unbounded preceding and unbounded following) firstpv, last_value(pv) over (partition by cid order by ctime rows between unbounded preceding and unbounded following) lastpvfrom userpv;-- ntile 按照cid进行分组并按照 ctime 排序，将分组内的数据平均分成 2 份select cid, ctime, pv, ntile(2) over (partition by cid order by ctime) ntilefrom userpv; UDF临时性添加函数 1234-- hive add jaradd jar /home/hadoop/udf.jarcreate temporary function myconcat as &#x27;con.janhen.hive.udaf.ConcatUDAF&#x27;;SHOW FUNCTIONS; 永久添加到 Hive 中 1234567# jar ==&gt; hdfs hdfs dfs -put hiveudf.jar /user/hadoop/jar/-- 加载函数create function mynvl2 as &#x27;com.janhen.bigdata.hive.nvl&#x27; using jar &#x27;hdfs:/user/hadoop/jar/hiveudf.jar&#x27;;show functions;drop function mynvl2; Ref Built-in Functions Windowing and Analytics Functions","tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"}]},{"title":"Hive-HQL","date":"2021-03-09T13:28:56.000Z","path":"2021/03/09/Hive-HQL/","text":"[TOC] 并不是所有的 HQL 都会被 Hive 转换成 MR 作业执行 HQL 是一种 SQL 方案，支持绝大部分的 SQL-92 标准 不支持行级别草俎哦、不支持事务 对于简单不需要聚合的操作，如 SELECT .. FROM xx LIMIT n，直接通过 FetchTask 获取数据 DML数据导入装载数据 LOCAL： LOAD DATA LOCAL …：从本地文件系统加载数据到Hive表中 LOAD DATA …：从HDFS加载数据到Hive表中 INPATH：加载数据的路径 OVERWRITE：覆盖表中已有数据；否则表示追加数据 PARTITION：将数据加载到指定的分区 一旦该表存在分区，那么在数据在加载时必须加载进入指定分区中，如下： 12345678-- 加载数据并指定分区，HDFS文件，已经被转移LOAD DATA INPATH &#x27;/user/hadoop/data&#x27; INTO student_info PARTITION(province=&#x27;sichuan&#x27;, city=&#x27;chengdu&#x27;);-- 加载数据覆盖表中已有数据LOAD DATA INPATH &#x27;data/sourceA.txt&#x27; OVERWRITE INTO TABLE tabA;-- 加载数据，覆盖表的数据，到指定的分区LOAD DATA INPATH &#x27;/user/hadoop/o&#x27; OVERWRITE INTO TABLE test3 PARTITION (part = &quot;a&quot;);-- 更改表的存储位置ALTER TABLE test ADD PARTITION (x = x1, y = y2) SET LOCATION &#x27;/user/test/x1/y1&#x27;; 插入数据 1234-- 插入数据insert into table tabC partition(month=&#x27;202001&#x27;) values (5, &#x27;wangwu&#x27;, &#x27;BJ&#x27;), (4, &#x27;lishi&#x27;, &#x27;SH&#x27;), (3, &#x27;zhangsan&#x27;, &#x27;TJ&#x27;);-- 插入查询的结果数据 insert into table tabC partition(month=&#x27;202002&#x27;) select id, name, area from tabC where month=&#x27;202001&#x27;; 创建表并插入数据 1create table if not exists tabD as select * from tabC; 多表（多分区）插入模式 一次查询，产生多个不相交的输出 Hive还有一个很有用的特性，可以通过一次查询，产生多个不相交的输出。 这样只通过对source表的一次查询，就将符合条件的数据插入test表的各个分区，非常方便 12345678-- 多个查询差生多个不相交的输出FROM sourceINSERT OVERWRITE TABLE test PARTITION (part = &#x27;a&#x27;)SELECT id, name WHERE id &gt;= 0 AND id &lt; 100INSERT OVERWRITE TABLE test PARTITION (part = &#x27;b&#x27;)SELECT id, name WHERE id &gt;= 100 AND id &lt; 200INSERT OVERWRITE TABLE test PARTITION (part = &#x27;c&#x27;)SELECT id, name WHERE id &gt;= 200 AND id &lt; 300 import 导入数据 1import table student2 partition(month=&#x27;201709&#x27;) from &#x27;/user/hive/warehouse/export/student&#x27;; 数据导出 将结果导出到本地 将查询结果格式化到本地 将结果导出到 HDFS 通过 DataX、Sqoop 等工具将结果导出到 HBase、MySQL等其他地方 修改表1234567-- 修改列alter table course_common1 change column id cid int;-- 增加字段alter table course_common1 add columns (common string);-- 删除字段：replace columns-- 在元数据中删除了字段，并没有改动hdfs上的数据文件alter table course_common1 replace columns( id string, cname string, score int); DDLDB 12345678910dfs -ls /user/hive/warehouse;create database if not exit comment &#x27;test comment&#x27; location &#x27;/usr/hive/mydb2.dbe&#x27;;desc database extended mydb2;-- 连同表一起删除DROP DATABASE IF EXISTS test CASCADE;DESC EXTENDED student;DESC FORMATTED student;-- 根据其他表创建新的表CREATE TABLE IF NOT EXISTS test.student2 LIKE test.student; Table CREATE TABLE [IF NOT EXISTS]：创建表 EXTERNAL： 外部表创建，生产中一般创建的都是外部表，删除表不删除数据 comment： 表注释 partition by： 对表中数据进行分区 clustered by： 建立分桶表 sorted by： 对表中的一个或多个字段进行排序，较少使用 存储子句: 可指定 SerDe, 默认没有使用 ROW FORMAT 或者 ROW FORMAT DELIMITED，会默认使用 SerDe。建表时需要为表指定列在指定列的同 时也会指定自定义的 SerDe。hive使用 Serde 进行行对象的序列与反序列化。 1234567ROW FORMAT DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char] [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)] stored as SEQUENCEFILE|TEXTFILE|RCFILE LOCATION： 表在 HDFS 上的位置 TBLPROPERTIES：定义表的属性 AS： 接查询语句，根据查询结果建表 LIKE： 复制现有的表结构，不会复制数据 内外部表表的类型有两种，分别是内部表(管理表)、外部 表。 默认情况下，创建内部表 删除内部表，表的元数据和数据一起删除 删除外部表，删除表的定义，数据保留 生产环境中，多使用外部表 外部表不能执行 TRUNCATE 表类型转换 1234-- 内部表转外部表ALTER TABLE t1 SET tblproperties(&#x27;EXTERNAL&#x27;=&#x27;TRUE&#x27;);-- 外部表转内部表。EXTERNAL 大写，false 不区分大小alter table t1 set tblproperties(&#x27;EXTERNAL&#x27;=&#x27;FALSE&#x27;); 分区表 按照分区字段将表中的数据放置在不同的目录中，提高SQL查询的 性能 Hive没有索引，分区的作用和索引非常类似，可将其看做一种简易索引。对于直接命中分区的查询，Hive不会执行MapReduce作业。 分区字段不是表中已经存在的数据，可以将分区字段看成伪列。 分区查看 12-- 查看分区SHOW PARTITIONS student_info; 新增分区，加载数据 123456789-- 增加分区，不加载数据alter table t3 add partition(dt=&#x27;2020-06-03&#x27;);-- 增加多个分区alter table t3 add partition(dt=&#x27;2020-06-05&#x27;) partition(dt=&#x27;2020-06-06&#x27;);-- 增加分区，加载数据alter table t3 add partition(dt=&#x27;2020-06-07&#x27;) location &#x27;/user/hive/warehouse/mydb.db/t3/dt=2020-06-07&#x27; partition(dt=&#x27;2020-06-08&#x27;) location &#x27;/user/hive/warehouse/mydb.db/t3/dt=2020-06-08&#x27;;-- 单独为外部表的分区键指定值和存储位置：ALTER TABLE student _info ADD PARTITION (province = sichuan, city = chengdu) LOCATION &#x27;hdfs://master:9000/student/sichuan/chengdu&#x27;; 修改分区的hdfs路径 1alter table t3 partition(dt=&#x27;2020-06-01&#x27;) set location &#x27;/user/hive/warehouse/t3/dt=2020-06-03&#x27;; 删除分区 1alter table t3 drop partition(dt=&#x27;2020-06-03&#x27;), partition(dt=&#x27;2020-06-04&#x27;); 动态分区 Hive 会根据 SELECT 语句中的最后一个查询字段作为动态分区的依据，而不是根据字段名来选择。如果指定了 n 个动态分区的字段，Hive 会将 select 语句中最后 n 个字段作为动态分区的依据。 Hive 默认没有开启动态分区，在执行这条语句前，必须对Hive进行一些参数设置： 123-- 开启自动分区set hive.exec.dynamic.partition = true;INSERT OVERWRITE TABLE test PARTITION(time) SELECT id, modify_time FROM source; 分桶表 分区不能更细粒度的划分数据，就需要使用分桶 技术将数据划分成更细的粒度。 使用 cluster by &lt;col-name&gt; into &lt;num&gt; buckets 分桶的原理 MR 中： key.hashCode % reduceTask Hive 中： 分桶字段.hashCode % 分桶个数 分桶表创建 123456create table course( id int, name string, score int ) clustered by (id) into 3 buckets row format delimited fields terminated by &quot;\\\\t&quot;; 分桶表加载数据 1234-- 普通表加载数据 load data local inpath &#x27;/home/hadoop/data/course.dat&#x27; into table course_common;-- 通过 insert ... select ... 给桶表加载数据 insert into table course select * from course_common; DQLSELECT SQL语句对大小写不敏感 各子句一般要分行 where 过滤正则匹配过滤 1234-- 正则匹配，使用 rlike。正则表达式，名字以A或S开头select ename, salfrom empwhere ename rlike &#x27;^(A|S).*&#x27;; lateral view lateral view 首先将UDTF应用于基础表的每一行，然后将结果输出行与输入行连接起来以形成具有提供的表别名的虚拟表。 语法 从 0.12.0 开始列别名可省略，从 UTDF 返回的 StructObjectInspector 的字段名称继承 12lateralView: LATERAL VIEW udtf(expression) tableAlias AS columnAlias (&#x27;,&#x27; columnAlias)*fromClause: FROM baseTable (lateralView)* 使用案例 123456789101112131415161718192021222324252627CREATE TABLE IF NOT EXISTS pageAds( pageid string, adid_list Array&lt;int&gt;);pageid adid_listfront_page [1,2,3]contact_page [3,4,5]-- 页面对应的广告SELECT pageid, adidFROM pageAds LATERAL VIEW explode(adid_list) adTable AS adid;-- 查看特定广告的展示次数SELECT adid, count(1) AS adcntFROM pageAds LATERAL VIEW explode(adid_list) adTable AS adid;pageid(string) adid(int)&quot;front_page&quot; 1&quot;front_page&quot; 2&quot;front_page&quot; 3&quot;contact_page&quot; 3&quot;contact_page&quot; 4&quot;contact_page&quot; 5adid adcnt1 12 13 24 15 1 多个 lateral view from clause 可有多个 lateral view 后续的 LATERAL VIEWS可以引用 LATERAL VIEW 左侧出现的任何表中的列。 表连接123456-- 内连接 select * from u1 join u2 on u1.id = u2.id;-- 左外连接 select * from u1 left join u2 on u1.id = u2.id;-- 全外连接 select * from u1 full join u2 on u1.id = u2.id; 多表连接 Hive 总是按照从左到右的顺序执行，Hive 会对每对 JOIN 连接对象启动一个 MapReduce 任务。 会首先启动一个 MapReduce job 对表 t 和表 c 进行连接操作；然后再 启动一个 MapReduce job 将第一个 MapReduce job 的输出和表 s 进行连接操作； 然后再继续直到全部操作； 12345select *from techer t left join course c on t.t_id = c.t_id left join score s on s.c_id = c.c_id left join student stu on s.s_id = stu.s_id; 笛卡尔积 满足下列条件 没有连接条件 连接条件无效 所有表中的所有行互相连接 Hive 默认不支持笛卡尔积 12set hive.strict.checks.cartesian.product=false;select * from u1, u2; 排序子句MR 全局排序 排序字段需要出现在 select 字段中 ORDER BY 执行全局排序，只有一个 reduce 输出规模较大时，耗时高 12345678-- 多列排序 select empno, ename, job, mgr, sal + nvl(comm, 0) salcomm, deptno from emp order by deptno, salcomm desc; MR 的内部排序(sort by) sort by 为每个 reduce 产生排序文件，在 reduce 内部进行排序，得到局部有序的结果 123456-- 设置reduce个数set mapreduce.job.reduces=2;-- 按照工资降序查看员工信息 select * from emp sort by sal desc;-- 将查询结果导入到文件中（按照工资降序）。生成两个输出文件，每个文件内部数据按 工资降序排列 insert overwrite local directory &#x27;/home/hadoop/output/sortsal&#x27; select * from emp sort by sal desc; MR 分区排序(distribute by) 将特定的行发送到特定的 reducer 中 distribute by 要写在 sort by 之前 可结合 sort by 操作，使分区数据有序 类似于 MR 中的分区操作 按照指定的条件将数据分组，常结合 sort by 使用 123456789101112131415161718192021-- 先按 deptno 分区，在分区内按照 sal + comm 排序set mapreduce.job.reduces=3;SELECT empno, ename, job, deptno, sal + nvl(comm, 0) salcommFROM emp DISTRIBUTE BY deptno SORT BY sal comm DESC;-- 将数据分到 3 个区中，每个分区都有数据insert overwrite local directory &#x27;/home/hadoop/output/distBy1&#x27; select empno, ename, job, deptno, sal + nvl(comm, 0) salcomm from emp distribute by deptno sort by salcomm desc; Cluster By distribute by 与 sort by 为同一个字段时，使用 cluster by 简化语法 只能是升序，不能指定排序规则 其他HQL 与 MR1234567Hive SQL &#x3D;&#x3D;&gt; AST(抽象语法树) &#x3D;&#x3D;&gt; QB(查询块) &#x3D;&#x3D;&gt; OperatorTree(操作树) &#x3D;&#x3D;&gt; 优化后的操作树 &#x3D;&#x3D;&gt; MapReduce 任务树 &#x3D;&#x3D;&gt; 优化后的 MapReduce 任务树 过程描述如下： SQL Parser：Antlr定义SQL的语法规则，完成SQL词法，语法解析，将SQL转化为抽象语法树AST Tree； Semantic Analyzer：遍历AST Tree，抽象出查询的基本组成单元QueryBlock； Logical plan：遍历QueryBlock，翻译为执行操作树OperatorTree； Logical plan optimizer: 逻辑层优化器进行OperatorTree变换，合并不必要的ReduceSinkOperator，减少shuffle数据量； Physical plan：遍历OperatorTree，翻译为MapReduce任务； Logical plan optimizer：物理层优化器进行MapReduce任务的变换，生成最终的执行计划。 Join 与 MR 如果其中有一张表为小表，直接使用 map 端 join 的方式（map端加载小表）进行聚合。 如果两张都是大表，那么采用联合 key，联合 key 的第一个组成部分是 join on 中的公共字段，第二部分是一个 flag，0 代表表 A，1 代表表 B，由此让 Reduce 区分 join 表的信息；在Mapper中同时处理两张表的信息，将 join on 公共字段相同的数据划分到同一个分区中，进而传递到一个 Reduce 中，然后在 Reduce 中实现聚合。 如果对于每个表在 join 子句中使用相同的列，则 Hive 将多个表上的联接转换为单个map / reduce作业 123SELECT a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key1) 对于 join 使用不同的列， 第一个 map / reduce 作业将 a 与 b 联接在一起，然后将结果与 c 联接到第二个 map / reduce 作业中。 第一个将 a 与 b 连接起来，并缓冲a的值，同时在减速器中流式传输b的值 第二个将缓冲第一个连接的结果，同时将c的值通过简化器流式传输 123SELECT a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key2) 可指定流式传输的表 1SELECT /*+ STREAMTABLE(a) */ a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key1) 如果除一个要连接的表之外的所有表都很小，则可以将其作为仅 Map 作业执行。 无需进行 reduce, 对于 A 的 mapper B 都会完全读取。 12SELECT /*+ MAPJOIN(b) */ a.key, a.valueFROM a JOIN b ON a.key = b.key; Join 相关的配置参数： hive.auto.convert.join： 如果可能，在运行时自动将联接转换为mapjoins hive.auto.convert.join.noconditionaltask：Hive是否启用基于输入文件大小的有关将公共联接转换为mapjoin的优化。 hive.auto.convert.join.noconditionaltask.size： 如果hive.auto.convert.join.noconditionaltask关闭，则此参数不起作用。 执行过程HQL 的执行过程 通常情况下NULL参与运算，返回值为 NULL NULL&lt;=&gt;NULL 的结果为 true，一般对 NULL 的比较实用 ISNULL 函数 Json 数据处理Hive 处理 json 数据的方式 内建的函数 get_json_object 自定义 UDF 函数 使用序列化反序列化工具 方式一: 内建的函数处理 处理简单的 json 串。 get_json_object(string json_string, string path): 解析 json 字符串 json_string，返回 path 指定的内容； json_tuple(jsonStr, k1, k2, ...): ：参数为一组键k1，k2，…和json字符串，返回值的元组。该方法比 get_json_object 高效，可以在一次调用中输入多个键, 对嵌套结果的解析操作复杂； explode / lateral view，使用explod将Hive一行中复杂的 array 或 map 结构拆分成多行。 12345678910111213141516171819202122232425CREATE TABLE IF NOT EXISTS jsont1( username string, age int, sex string, json string ) row format delimited fields terminated by &#x27;;&#x27;;load data local inpath &#x27;/root/lagoudw/data/weibo.json&#x27; overwrite into table jsont1;-- get 单层值 select username, age, sex, get_json_object(json, &quot;$.id&quot;) id, get_json_object(json, &quot;$.ids&quot;) ids, get_json_object(json, &quot;$.total_number&quot;) num from jsont1;-- get 数组select username, age, sex, get_json_object(json, &quot;$.id&quot;) id, get_json_object(json, &quot;$.ids[0]&quot;) ids0, get_json_object(json, &quot;$.ids[1]&quot;) ids1, get_json_object(json, &quot;$.ids[2]&quot;) ids2, get_json_object(json, &quot;$.ids[3]&quot;) ids3, get_json_object(json, &quot;$.total_number&quot;) num from jsont1;-- json_tuple 一次处理多个字段select json_tuple(json, &#x27;id&#x27;, &#x27;ids&#x27;, &#x27;total_number&#x27;) from jsont1; 含其他字段时，不能直接展开，需要使用 explod 展开 123456789101112-- 拆分 jsonselect username, age, sex, id, ids, num from jsont1 lateral view json_tuple(json, &#x27;id&#x27;, &#x27;ids&#x27;, &#x27;total_number&#x27;) t1 as id, ids, num;-- 拆分 JSON -&gt; 拆分 jsonarraywith tmp as( select username, age, sex, id, ids, num from jsont1 lateral view json_tuple(json, &#x27;id&#x27;, &#x27;ids&#x27;, &#x27;total_number&#x27;) t1 as id, ids, num ) select username, age, sex, id, ids1, numfrom tmp lateral view explode(split(regexp_replace(ids, &quot;\\\\\\\\[|\\\\\\\\]&quot;, &quot;&quot;), &quot;,&quot;)) t1 as ids1; 方式二: 使用 UDF 处理 能处理大部分数据，更灵活。 12345678910111213141516171819-- 创建临时函数add jar /root/lagoudw/jars/bigdata-hive-1.0-SNAPSHOT.jar;create temporary function json_json_array as &quot;com.janhen.bigdata.hive.ParseJsonArray&quot;;select username, age, sex, parse_json_array(json, &quot;ids&quot;) ids from jsont1;select username, age, sex, ids1 from jsont1 lateral view explode(parse_json_array(json, &quot;ids&quot;)) t1 as ids1;select username, age, sex, id, num from jsont1 lateral view json_tuple(json, &#x27;id&#x27;, &#x27;total_number&#x27;) t1 as id, num;-- 合并select username, age, sex, ids1, id, num from jsont1 lateral view explode(parse_json_array(json, &quot;ids&quot;)) t1 as ids1 lateral view json_tuple(json, &#x27;id&#x27;, &#x27;total_number&#x27;) t1 as id, num; 方式三: 使用SerDe处理 对象的序列化用途： 把对象转换成字节序列后保存到文件中 对象数据的网络传送 可以在表创建的时候指定 SerDe，之后无需指定分割符之类的信息 Read : HDFS files =&gt; InputFileFormat =&gt; &lt;key, value&gt; =&gt; Deserializer =&gt; Row object Write : Row object =&gt; Seriallizer =&gt; &lt;key, value&gt; =&gt; OutputFileFormat =&gt; HDFS files 123456789101112&#123;&quot;id&quot;: 1,&quot;ids&quot;: [101,102,103],&quot;total_number&quot;: 3&#125;&#123;&quot;id&quot;: 2,&quot;ids&quot;: [201,202,203,204],&quot;total_number&quot;: 4&#125;&#123;&quot;id&quot;: 3,&quot;ids&quot;: [301,302,303,304,305],&quot;total_number&quot;: 5&#125;&#123;&quot;id&quot;: 4,&quot;ids&quot;: [401,402,403,304],&quot;total_number&quot;: 5&#125;&#123;&quot;id&quot;: 5,&quot;ids&quot;: [501,502,503],&quot;total_number&quot;: 3&#125;create table jsont2( id int, ids array&lt;string&gt;, total_number int)ROW FORMAT SERDE &#x27;org.apache.hive.hcatalog.data.JsonSerDe&#x27;;load data local inpath &#x27;/data/lagoudw/data/json2.dat&#x27; into table jsont2; JSON 处理方式比较 1、简单格式的json数据，使用 get_json_object、json_tuple 处理 2、对于嵌套数据类型，可以使用 UDF 3、纯 json 串可使用 JsonSerDe 处理更简单 Ref LanguageManual LateralView LanguageManual Joins","tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"}]},{"title":"Scala集合","date":"2021-03-09T13:26:10.000Z","path":"2021/03/09/Scala集合/","text":"[TOC] 集合操作都有可变和不可变两种 集合的三大类：Seq、Set、Map scala.collection.mutable：定义了可变集合的特质和具体实现类 scala.collection.immutable：定义了不可变集合的特质和具体实现类 所有的集合都扩展自 Iterable 特质。 String 属于 IndexedSeq Queue 队列和 Stack 堆这两个经典的数据结构属于 LinearSeq List列表属于 Seq 中的 LinearSeq Seq按照一定顺序排列的元素序列； 元素的顺序是确定的，每个元素对应一个索引值； 两个重要的子特质： IndexedSeq：提供了快速随机访问元素的功能，它通过索引来查找和定位的 LinearSeq：提供了访问 head、tail 的功能，它是线型的，有头部和尾部的概念，通过遍历来查找。 ListList一旦被定义，其值就不能改变。 有头部和尾部的概念 head 返回的是列表第一个元素的值 tail 返回的是除第一个元素外的其它元素构成的新列表 定义了一个空列表对象Nil，定义为List[Nothing] 借助 Nil 可将多个元素用操作符 :: 添加到列表头部，常用来初始化列表； 操作符 ::: 用于拼接两个列表； 使用案例 12345678910111213141516171819202122232425262728293031323334353637def main(args: Array[String]): Unit = &#123; // :: 操作符表示向集合中添加元素 val list1 = 1 :: 2 :: 3 :: 4 :: Nil val list2 = 5 :: 6 :: 7 :: 8 :: Nil println(s&quot;list1: $list1&quot;) println(s&quot;list2: $list2&quot;) // 使用 ::: 操作符进行了拼接 list val list3 = list1 ::: list2 println(s&quot;list3: $list3&quot;) println(s&quot;list3.head: $&#123;list3.head&#125;&quot;) println(s&quot;list3.last: $&#123;list3.last&#125;&quot;) println(s&quot;list3.init: $&#123;list3.init&#125;&quot;) // 返回除最后一个元素之外的其他元素构成的新列表 println(s&quot;list3.tail: $&#123;list3.tail&#125;&quot;) // 返回除第一个元系之外的其他元素构成的新列表 val list4 = List(4, 2, 6, 1, 7, 9) println(s&quot;sorted: $&#123;quickSort(list4)&#125;&quot;)&#125;def quickSort(list: List[Int]): List[Int] = &#123; list match &#123; case Nil =&gt; Nil case head :: tail =&gt; val (less, greater) = tail.partition(_ &lt; head) quickSort(less) ::: head :: quickSort(greater) &#125;&#125;list1: List(1, 2, 3, 4)list2: List(5, 6, 7, 8)list3: List(1, 2, 3, 4, 5, 6, 7, 8)list3.head: 1list3.last: 8list3.init: List(1, 2, 3, 4, 5, 6, 7)list3.tail: List(2, 3, 4, 5, 6, 7, 8)sorted: List(1, 2, 4, 6, 7, 9) 源码 12345678910111213141516trait TraversableLike[+A, +Repr] extends Any with HasNewBuilder[A, Repr] with FilterMonadic[A, Repr] with TraversableOnce[A] with GenTraversableLike[A, Repr] with Parallelizable[A, ParIterable[A]]&#123; self =&gt; import Traversable.breaks._ def partition(p: A =&gt; Boolean): (Repr, Repr) = &#123; val l, r = newBuilder for (x &lt;- this) (if (p(x)) l else r) += x (l.result, r.result) &#125;&#125; Queue +=: ++=: 1234567891011121314151617181920212223val queue1 = new mutable.Queue[Int]()println(s&quot;queue1: $queue1&quot;)queue1 += 1queue1 ++= List(2, 3, 4)println(s&quot;queue1: $queue1&quot;)val dequeue: Int = queue1.dequeue()println(s&quot;dequeue: $dequeue&quot;)println(s&quot;queue1: $queue1&quot;)queue1.enqueue(5, 6, 7)println(s&quot;queue1: $queue1&quot;)println(s&quot;queue1.head: $&#123;queue1.head&#125;&quot;)println(s&quot;queue1.last: $&#123;queue1.last&#125;&quot;)queue1: Queue()queue1: Queue(1, 2, 3, 4)dequeue: 1queue1: Queue(2, 3, 4)queue1: Queue(2, 3, 4, 5, 6, 7)queue1.head: 2queue1.last: 7 Set &amp; / intersect: ++ / | / union： -- / &amp;~ / diff Map123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869val map = Map(&quot;a&quot; -&gt; 1, &quot;b&quot; -&gt; 2)map.keys.foreach(println(_))map.values.foreach(println)map.foreach(e =&gt; println(e._1 + &quot; ==&gt; &quot; + e._2))println(s&quot;map1(&#x27;b&#x27;): $&#123;map(&quot;b&quot;)&#125;&quot;)// 访问不存在的 Key 值时，抛出异常// println(map(&quot;c&quot;))// get 方法访问元素，返回一个 Option 对象val num: Option[Int] = map.get(&quot;c&quot;)num match &#123; case None =&gt; println(&quot;None&quot;) case Some(x) =&gt; println(x)&#125;// 获取Key值所对应的Value值，如果键Key不存在，那么就返回指定的默认值val num2: Int = map.getOrElse(&quot;d&quot;, 0)println(s&quot;num2: $num2&quot;)val map3 = scala.collection.mutable.Map(&quot;a&quot; -&gt; 1, &quot;b&quot; -&gt; 2)println(map3)map3(&quot;a&quot;) = 10println(s&quot;map3: $map3&quot;)map3(&quot;c&quot;) = 3println(s&quot;map3: $map3&quot;)// +=添加元素，-=删除元素map3 += (&quot;d&quot; -&gt; 4, &quot;f&quot; -&gt; 5)println(s&quot;map3: $map3&quot;)map3 -= &quot;d&quot;println(s&quot;map3: $map3&quot;)// Key, Value swapval kv: mutable.Map[Int, String] = for ((k, v) &lt;- map3) yield (v, k)println(kv)// Key, Value swap(R)map3.map(x =&gt; (x._2, x._1)).foreach(println(_))// 拉链操作创建Mapval a = Array(1, 2, 3)val b = Array(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)val c: Array[(Int, String)] = a.zip(b)val d: Map[Int, String] = a.zip(b).toMapprintln(s&quot;zip: $&#123;c.toBuffer&#125;&quot;)println(s&quot;zip: $d&quot;)ab12a ==&gt; 1b ==&gt; 2map1(&#x27;b&#x27;): 2Nonenum2: 0Map(b -&gt; 2, a -&gt; 1)map3: Map(b -&gt; 2, a -&gt; 10)map3: Map(b -&gt; 2, a -&gt; 10, c -&gt; 3)map3: Map(b -&gt; 2, d -&gt; 4, a -&gt; 10, c -&gt; 3, f -&gt; 5)map3: Map(b -&gt; 2, a -&gt; 10, c -&gt; 3, f -&gt; 5)Map(2 -&gt; b, 5 -&gt; f, 10 -&gt; a, 3 -&gt; c)(2,b)(5,f)(10,a)(3,c)zip: ArrayBuffer((1,a), (2,b), (3,c))zip: Map(1 -&gt; a, 2 -&gt; b, 3 -&gt; c) 操作 collect： collect通过执行一个并行计算（偏函数），得到一个新的数组对象 reduce： sorted / sortwith / sortby： 与 Java 集合转换12345import scala.collection.JavaConverters._val list: java.util.List[Int] = List(1,2,3,4).asJavaprintln(s&quot;java list: $list&quot;)val buffer: scala.collection.mutable.Buffer[Int] = list.asScalaprintln(s&quot;scala buffer: $buffer&quot;)","tags":[{"name":"Scala","slug":"Scala","permalink":"http://example.com/tags/Scala/"}]},{"title":"Scala语言基础","date":"2021-03-09T13:23:27.000Z","path":"2021/03/09/Scala语言基础/","text":"Scala 基础语言起源 12345马丁·奥德斯基（Martin Odersky）是编译器及编程的狂热爱好者。主流JVM的Javac编译器就是马丁·奥德斯基编写出来的，JDK5.0、JDK8.0的编译器就是他写的。 长时间的编程之后，他希望发明一种语言，能够让写程序这样的基础工作变得高效，简单。 当接触到Java语言后，对Java这门语言产生了极大的兴趣，所以决定将函数式编程语言的特点融合到Java中，由此发 明了Scala。 语言特性： OOP 函数式编程 静态类型，参考 Haskell、Errlang 并发性，使用 Actor 作为并发模型，可复用线程 应用场景： Kafka、Spar 等框架底层都是使用 Scala 作为底层源码开发语言 融合大数据生态，Flink 支持 Scala 开发 Scala 的 REPL REPL 是一个交互式解析器环境，R(read)、E(evaluate) 、P（print）、L（loop） 输入值，交互式解析器会读取输入内容并对它求值，再打印结果，并重复此过程。 在命令行输入Scala可启动Scala REPL。 基础语法 区分大小写 - Scala语言对大小写敏感 类名 - 对于所有的类名的第一个字母要大写。 方法名 - 所有方法名的第一个字母用小写。 程序文件名 - Scala程序文件的后缀名是 .scala，程序文件的名称可以不与对象名称完全匹配。 main()方法 - Scala程序从main()方法开始处理 常用类型 Int: Unit: 无值，用于不返回任何结果的方法的返回类型。 Null Nothing： 在Scala类层级的最低端，它是任何其他类型的子类型 Any: 是Scala中所有类的超类 AnyRef: 是Scala中所有引用类的超类 Scala和Java一样，有8种数值类型 Byte、Short、Int、Long、Float、Double、Char、Boolean 类型； Scala 并不刻意的区分基本类型和引用类型。 每一种数据类型都有对应的Rich类型，如RichInt、RichChar等，为基本类型提供了更多的有用操作。 类层次结构Scala中，所有的类，包括值类型和引用类型，都最终继承自一个统一的根类型Any。 Null Null是所有引用类型的子类型 Null类只有一个实例对象null null可以赋值给任意引用类型，但是不能赋值给值类型。 Nothing Nothing位于Scala类继承关系的底部，它是其他所有其他类型的子类型 Nothing对泛型结构有用 。比如，空列表Nil的类型就是List[Nothing] Nothing的可以给出非正常终止的信号。比如，使用Nothing处理异常 在Scala中，鼓励使用val。 简单数据类型可以省略，对于复杂的数据类型建议明确声明； 操作符 Scala中的操作符都是方法 对象相等性 Scala中，要比较两个基础类型的对象是否相等，可以使用 == 或 !=； == 或 != 还可以比较不同类型的两个对象 字符串字符串插值器 s 插值器： 对内嵌的每个表达式求值，对求值结果调用toString f 插值器： 除s插值器的功能外，还能进行格式化输出，在变量后用%指定输出格式 raw 插值器： 按照字符串原样进行输出 控制结构和函数if 表达式 if 表达式有返回值。 如果if 和 else 的返回值类型不一样，那么就返回两个返回值类型公共的父类。 for 表达式 for (i &lt;- 表达式 / 集合)，让变量 i遍历&lt;-右边的表达式/集合的所有值。 Scala为for循环提供了很多的特性，这些特性被称之为 for守卫式 或 for推导式。 123456789101112131415161718192021for (i &lt;- 1 until 10) &#123; println(s&quot;i = $i&quot;)&#125;// 双重循环。条件之间使用分号分隔for (i &lt;- 1 until 5; j &lt;- 2 until 5)&#123; println(i * j )&#125;// 守卫语句。for (i &lt;- 1 to 10; j &lt;- 1 to 10 if i==j)&#123; println(s&quot;i * j = $i * $j = $&#123;i * j&#125;&quot;)&#125;// for推导式, yield 接收返回的结果val result = for (i &lt;- 1 to 10) yield i// 使用大括号将生成器、守卫、定义包含在其中；并以换行的方式来隔开它们for &#123; i &lt;- 1 to 3 from = 4 - i j &lt;- from to 3 &#125; println(s&quot;i = $i; j = $j&quot;) while 表达式 while语句的本身没有任何返回值类型，即while语句的返回结果是Unit类型的 () 。 Scala内置控制结构特地去掉了 break 和 continue。 终止循环的方式： 使用Boolean类型的控制变量 使用 return 使用 breakable和break，需要导入scala.util.control.Breaks包 懒值当 val 被声明为lazy时(var不能声明为lazy)，初始化将被推迟，直到首次对此取值，适用于初始化开销较大的场景。 惰性求值 可根据 if 短路求值，避免不必要的 expensive 计算操作 12345678910def evaluate(input: Int): Unit = &#123; println(s&quot;evaluate called with $input&quot;) if (input &gt;= 10 &amp;&amp; expensiveComputation()) println(&quot;doing work...&quot;) else println(&quot;skipping&quot;)&#125;evaluate(0)evaluate(100) 通过 scala 的懒加载处理 123lazy val perform = expensiveComputation() if (input &gt;= 10 &amp;&amp; perform) println(“doing work…”) 文件操作导入scala.io.Source后，可引用Source中的方法读取文本文件的内容 Scala没有内建的对写入文件的支持。要写入文本文件，可使用 java.io.PrintWriter 数组和元组使用ArrayBuffer时，需要导包 import scala.collection.mutable.ArrayBuffer； 多维数组 123456val dim = Array.ofDim[Double](3,4)dim(1)(1) = 11.11for (i &lt;- 0 to 2; j &lt;- 0 to 3) &#123; print(dim(i)(j) + &quot; &quot;) if (j == 3) println()&#125; 元组和操作 内建了 22 个 Tuple 类 类与对象在Scala中，类并不用声明为public； val修饰的变量（常量），值不能改变，只提供getter方法，没有setter方法； var修饰的变量，值可以改变，对外提供getter、setter方法； 自定义getter和setter方法 Scala 类中的每一个属性，编译后会有一个私有的字段和相应的getter、setter方法生成。 12345678//getter方法println(person age)//setter方法person age_= (18)//getter方法println(person.age) JavaBean默认情况下，Scala 不遵循 JavaBean 约定，必须要使用 @scala.reflect.BeanProperty 注解来生成满足 JavaBean 约定的 getter 和 setter 方法 构造器没有定义构造器，Scala类中会有一个默认的无参构造器； 的构造器分为两种：主构造器和辅助构造器； 主构造器的定义与类的定义交织在一起，将主构造器的参数直接放在类名之后。 当主构造器的参数不用var或val修饰时，参数会生成类的私有val成员。 Scala中，所有的辅助构造器都必须调用另外一个构造器 单例对象没有提供Java那样的静态方法或静态字段； 可以采用object关键字实现单例对象，具备和Java静态方法同样的功能； 使用object语法结构【object是Scala中的一个关键字】达到静态方法和静态字段的目的；对象本质上可以拥有类的所有特性，除了不能提供构造器参数； 任何在Java中用单例对象的地方，在Scala中都可以用object实现： 作为存放工具函数或常量的地方 高效地共享单个不可变实例 Scala中的单例对象具有如下特点： 创建单例对象不需要使用new关键字 object中只有无参构造器 主构造代码块只能执行一次，因为它是单例的 应用程序对象 可以扩展App特质（trait) 来运行。 伴生类与伴生对象单例对象与某个类具有相同的名称时，它被称为这个类的“伴生对象”； 类和它的伴生对象必须存在于同一个文件中，而且可以相互访问私有成员（字段和方法）； apply 方法object 中的特殊方法 apply方法通常定义在伴生对象中，目的是通过伴生类的构造函数功能，来实现伴生对象的构造函数功能； 当遇到类名(参数1,…参数n)时apply方法会被调用； 在创建伴生对象或伴生类的对象时，通常不会使用new class/class() 的方式，而是直接使用 class()隐式的调用伴生对象的 apply 方法 借助 apply 实现工厂设计模式 12345678910111213141516171819202122232425262728293031abstract class Animal &#123; def speak&#125;class Dog extends Animal &#123; override def speak: Unit = &#123; println(&quot;woof&quot;) &#125;&#125;class Cat extends Animal &#123; override def speak: Unit = &#123; println(&quot;meow&quot;) &#125;&#125;object Animal &#123; def apply(str: String): Animal = &#123; if (str == &quot;dog&quot;) new Dog else new Cat &#125;&#125;object Test extends App &#123; val cat = Animal(&quot;cat&quot;) cat.speak val dog = Animal(&quot;dog&quot;) dog.speak&#125; 继承override方法重写 123456789101112class Programmer(name: String, age: Int) &#123; def coding(): Unit = &#123; println(&quot;coding...&quot;) &#125;&#125;class ScalaProgrammer(name: String, age: Int, workNo: String) extends Programmer(name, age) &#123; override def coding(): Unit = &#123; super.coding() println(&quot;我在写Scala代码。。。&quot;) &#125;&#125; 类型检查与转换 isInstanceOf： 测试某个对象是否属于某个给定的类 getClass classOf 1234567891011121314151617181920212223242526272829303132333435363738class Person &#123; def say(): Unit = &#123; print(&quot;Person...&quot;) &#125;&#125;class Student extends Person &#123; override def say(): Unit = &#123; print(&quot;Student...&quot;) &#125;&#125;object InstanceDemo &#123; def main(args: Array[String]): Unit = &#123; val person: Person = new Student var student: Student = null println(student.isInstanceOf[Student]) // function check if (person.isInstanceOf[Student]) &#123; student = person.asInstanceOf[Student] student.say() &#125; println(student.isInstanceOf[Student]) // getClass check println(person.getClass == classOf[Person]) println(person.getClass == classOf[Student]) // pattern match check person match &#123; case s: Student =&gt; s.say() println(&quot;Student2 type match&quot;) case _ =&gt; println(&quot;default...&quot;) &#125; &#125;&#125; 特质作为接口使用 在trait中可以定义抽象方法，与抽象类中的抽象方法一样，只要不给出方法的具体实现即可。 类可以使用extends关键字继承trait。 在Scala中没有implement的概念，无论继承类还是trait特质，统一都是extends。 类继承trait特质后，必须实现其中的抽象方法，实现时可以省略 override 关键字。 Scala不支持对类进行多继承，但是支持多重继承trait特质，使用with关键字即可。 特质构造顺序 执行父类的构造器； 执行trait的构造器，多个trait从左到右依次执行； 构造trait时会先构造父trait，如果多个trait继承同一个父trait，则父trait只会构造一次； 所有trait构造完毕之后，子类的构造器才执行 Ordered和OrderingOrdered 特质混入 Java 的 Comparable 接口，它定义了相同类型间的比较方式，但这种内部比较方式是单一的； 12345678trait Ordered[A] extends Any with java.lang.Comparable[A] &#123; def compare(that: A): Int def &lt; (that: A): Boolean = (this compare that) &lt; 0 def &gt; (that: A): Boolean = (this compare that) &gt; 0 def &lt;= (that: A): Boolean = (this compare that) &lt;= 0 def &gt;= (that: A): Boolean = (this compare that) &gt;= 0 def compareTo(that: A): Int = compare(that)&#125; Ordering 特质混入 Comparator 接口，提供第三方比较器，可以自定义多种比较方式，在实际开发中也是使用比较多的，灵活解耦合。 12345678910111213141516171819202122232425262728293031323334353637383940@annotation.implicitNotFound(msg = &quot;No implicit Ordering defined for $&#123;T&#125;.&quot;)trait Ordering[T] extends Comparator[T] with PartialOrdering[T] with Serializable &#123; outer =&gt; def tryCompare(x: T, y: T) = Some(compare(x, y)) def compare(x: T, y: T): Int override def lteq(x: T, y: T): Boolean = compare(x, y) &lt;= 0 override def gteq(x: T, y: T): Boolean = compare(x, y) &gt;= 0 override def lt(x: T, y: T): Boolean = compare(x, y) &lt; 0 override def gt(x: T, y: T): Boolean = compare(x, y) &gt; 0 override def equiv(x: T, y: T): Boolean = compare(x, y) == 0 def max(x: T, y: T): T = if (gteq(x, y)) x else y def min(x: T, y: T): T = if (lteq(x, y)) x else y override def reverse: Ordering[T] = new Ordering[T] &#123; override def reverse = outer def compare(x: T, y: T) = outer.compare(y, x) &#125; def on[U](f: U =&gt; T): Ordering[U] = new Ordering[U] &#123; def compare(x: U, y: U) = outer.compare(f(x), f(y)) &#125; class Ops(lhs: T) &#123; def &lt;(rhs: T) = lt(lhs, rhs) def &lt;=(rhs: T) = lteq(lhs, rhs) def &gt;(rhs: T) = gt(lhs, rhs) def &gt;=(rhs: T) = gteq(lhs, rhs) def equiv(rhs: T) = Ordering.this.equiv(lhs, rhs) def max(rhs: T): T = Ordering.this.max(lhs, rhs) def min(rhs: T): T = Ordering.this.min(lhs, rhs) &#125; implicit def mkOrderingOps(lhs: T): Ops = new Ops(lhs)&#125;object Ordering extends LowPriorityOrderingImplicits &#123; def apply[T](implicit ord: Ordering[T]) = ord def by[T, S](f: T =&gt; S)(implicit ord: Ordering[S]): Ordering[T] = new Ordering[T] &#123; def compare(x: T, y: T) = ord.compare(f(x), f(y)) override def lt(x: T, y: T): Boolean = ord.lt(f(x), f(y)) override def gt(x: T, y: T): Boolean = ord.gt(f(x), f(y)) override def gteq(x: T, y: T): Boolean = ord.gteq(f(x), f(y)) override def lteq(x: T, y: T): Boolean = ord.lteq(f(x), f(y)) &#125;&#125; 使用案例 12345678910111213141516171819import scala.util.Sortingcase class Project(tag: String, score: Int) extends Ordered[Project] &#123; override def compare(that: Project): Int = &#123; tag.compareTo(that.tag) &#125;&#125;object OrderDemo &#123; def main(args: Array[String]): Unit = &#123; val list = List(Project(&quot;hadoop&quot;, 40), Project(&quot;flink&quot;, 90), Project(&quot;spark&quot;, 80), Project(&quot;hive&quot;, 60)) println(list.sorted) val pairs = Array((&quot;a&quot;, 7, 2), (&quot;b&quot;, 9, 1), (&quot;c&quot;, 8, 3)) // Ordering.by[(String,Int,Int),Int](_._2) 从 Tuple3 转到 Int 型，根据 Tuple3 第二个元素进行排序 Sorting.quickSort(pairs)(Ordering.by[(String, Int, Int), Int](_._2)) println(pairs.toBuffer) &#125;&#125; 模式匹配和样例类 Scala没有Java中的switch case Scala的模式匹配可以匹配各种情况，比如变量的类型、集合的元素、有值或无值。 模式匹配match case中，只要有一个case分支满足并处理了，就不会继续判断下一个case分支了 守卫式匹配可增加 if 条件判断 匹配类型 可以直接匹配类型，而不是值 匹配数组、元组、集合case class样例类 默认实现了常用的方法，如 getter/setter, 默认序列化 主构造器函数结构的参数不需要显示 var/val 修饰，自动使用 val 修饰 自动定义了伴生对象，提供 apply 方法，无需 new 关键字就可构造出对象 生成 toString,equals,hashCode,copy 方法 继承了 Product, Serializable 两个特质 case class 为多例的， case object 为单例的 Option与模式匹配Option通常与模式匹配结合使用，用于判断某个变量是有值还是无值。 函数与抽象化 不仅可以定义一个函数然后调用它，还可以写一个未命名的函数字面量，然后可以把它当成一个值传递到其它函数或是赋值给其它变量。 函数字面量体现了函数式编程的核心理念。字面量包括整数字面量、浮点数字面量、布尔型字面量、字符字面量、字符串字面量、符号字面量、函数字面量等。 函数类型：(输入参数类型列表) =&gt; (输出参数类型列表)只有一个参数时，小括号可省略；函数体中只有1行语句时 函数与方法 使用 val 定义的是函数(function)，使用 def 定义的是方法(method)。 Scala 中的方法与 Java 的类似，方法是组成类的一部分 Scala 中的函数则是一个完整的对象。Scala 中用 22 个特质(从 Function1 到 Function22)抽象出了函数的概念 Scala 中用 val 语句定义函数，def 语句定义方法 方法不能作为单独的表达式而存在，而函数可以； 函数必须要有参数列表，而方法可以没有参数列表； 方法名是方法调用，而函数名只是代表函数对象本身； 在需要函数的地方，如果传递一个方法，会自动把方法转换为函数 一般情况下，不对二者做区分，认为都是函数，更多的时候使用def定义函数。 方法转换成函数 12def double(x: Int) = x*xdef f1 = double _ 匿名函数 函数没有名字就是匿名函数； 匿名函数，又被称为 Lambda 表达式。 占位符 第一个下划线代表第一个参数 第二个下划线代表第二个参数 第三个……，如此类推 高阶函数 接收一个或多个函数作为输入或输出一个函数。 常用的高阶函数：map、reduce、flatMap、foreach、filter、count。 闭包 闭包是一种函数，是在其上下文中引用了自由变量的函数； 闭包引用到函数外面定义的变量，定义这个函数的过程就是将这个自由变量捕获而构成的一个封闭的函数，也可理解为”把函数外部的一个自由变量关闭进来“。 闭包满足的条件： 闭包是一个函数 函数必须要有返回值 返回值依赖声明在函数外部的一个或多个变量，用 Java 的话说，就是返回值和定义全局变量有关 柯里化 函数编程中，接收多个参数的函数都可以转化为接收单个参数的函数，这个转化过程就叫柯里化(Currying)。 柯里化函数拥有多组参数列表，每组参数用小括号括起来。 Scala 源码中的柯里化 12345trait TraversableOnce[+A] extends Any with GenTraversableOnce[A] &#123; self =&gt; def fold[A1 &gt;: A](z: A1)(op: (A1, A1) =&gt; A1): A1 = foldLeft(z)(op) def aggregate[B](z: =&gt;B)(seqop: (B, A) =&gt; B, combop: (B, B) =&gt; B): B = foldLeft(z)(seqop)&#125; 部分应用函数 部分应用函数（Partial Applied Function）也叫偏应用函数，是指缺少部分（甚至全部）参数的函数 如果一个函数有n个参数, 而为其提供少于n个参数, 那就得到了一个部分应用函数。 偏函数 并不处理所有可能的输入，而只处理那些能与至少一个 case 语句匹配的输入； 偏函数中只能使用 case 语句，整个函数必须用大括号包围。与普通的函数字面量不同，普通的函数字面量可以使用大括号，也可以用小括号； Scala中的 Partial Function 是一个 trait。 123456789101112131415trait PartialFunction[-A, +B] extends (A =&gt; B) &#123; self =&gt; import PartialFunction._ def isDefinedAt(x: A): Boolean def orElse[A1 &lt;: A, B1 &gt;: B](that: PartialFunction[A1, B1]): PartialFunction[A1, B1] = new OrElse[A1, B1] (this, that) override def andThen[C](k: B =&gt; C): PartialFunction[A, C] = new AndThen[A, B, C] (this, k) def lift: A =&gt; Option[B] = new Lifted(this) def applyOrElse[A1 &lt;: A, B1 &gt;: B](x: A1, default: A1 =&gt; B1): B1 = if (isDefinedAt(x)) apply(x) else default(x) def runWith[U](action: B =&gt; U): A =&gt; Boolean = &#123; x =&gt; val z = applyOrElse(x, checkFallback[B]) if (!fallbackOccurred(z)) &#123; action(z); true &#125; else false &#125;&#125; 使用案例 1234567891011121314// 将 Int 类型的元素加 1val partialFunction = new PartialFunction[Any, Int] &#123; override def isDefinedAt(x: Any): Boolean = &#123; x.isInstanceOf[Int] &#125; override def apply(v1: Any): Int = &#123; v1.asInstanceOf[Int] + 1 &#125;&#125;val list = List(10, &quot;hadoop&quot;, 20, &quot;spark&quot;, 30, &quot;flink&quot;)list.collect(partialFunction).foreach(println)// simple list.collect(&#123;case x: Int =&gt; x + 1&#125;).foreach(println) 隐式机制 根据隐式转换函数的签名，在程序中使用到隐式转换函数接收的参数类型定义的对象时，会自动将其传入隐式转换函数，转换为另外一种类型的对象并返回，这就是“隐式转换” 隐式转换和隐式参数是Scala中两个非常强大的功能，利用隐式转换和隐式参数，可以提供类库，对类库的使用者隐匿掉具体的细节。 使用限制 implicit 关键字只能用来修饰方法、变量、参数 隐式转换的函数只在当前范围内才有效。如果隐式转换不在当前范围内定义，那么必须通过 import 语句将其导入 隐式转换函数定义的隐式转换函数，只要在编写的程序内引入，就会被Scala自动使用。 隐式转换函数由Scala自动调用，通常建议将隐式转换函数的名称命名为“one2one”的形式。 隐式参数和隐式值在函数定义的时候，支持在最后一组参数中使用 implicit ，表明这是一组隐式参数。 在调用该函数的时候，可以不用传递隐式参数，而编译器会自动寻找一个implicit 标记过的合适的值作为参数。 查看范围 当前作用域内可见的 val 或 var 定义隐式变量 隐式参数类型的伴生对象内隐式值 RefThe Scala Programming Language Scala 官网 Scala 2.11.8 Scala官网下载Scala 2.11.8安装包 为什么 Haskell 是我们构建生产软件系统的首选 Haskell","tags":[{"name":"Scala","slug":"Scala","permalink":"http://example.com/tags/Scala/"}]},{"title":"Vagrent","date":"2021-03-09T13:17:56.000Z","path":"2021/03/09/Vagrent/","text":"[TOC] Vagrant 快速搭建虚拟机环境，可通过 Vagrantfile 配置文件进行定制，类似 Docker 管理容器。 一些特性： 多种虚拟器支持，如 VirsualBox(默认)、 Vmware、Docker、Hyper-V 方便网络配置，支持端口转发，配置私有、公有网络 方便进行宿主机与虚拟机之间共享文件提供丰富的插件，简化日常使用 环境安装Virtual Box Oracle 开源的虚拟机软件，跨平台 在 winows 上无法同时运行 Hyper-V 和 VisualBox，两者都是基于 CPU 等底层硬件的 Hypervisor 机制来实现的，而他们必须独占管理 Hypervisor。通过开启启动项选择是否加载 Hyper-V 服务，实现伪同时运行。 问题由来： Docker 安装在 win10 上需要开启 Hyper-V，方便进行本地镜像的打包部署，同时需要 VirtualBox 进行模拟集群。 问题处理： 解决Win7/8/10系统中的Hyper-V和VMware虚拟机软件共存问题 Virtualbox “Callee RC: REGDB_E_CLASSNOTREG” (0x80040154)? Hyper-V Win10 自带虚拟化工具，实现在 Win10 上运行 Docker 环境，而无需开启 Docker 的远程访问，开启后无法使用其他虚拟器 对应的 vagrant 设置内存和CPU参数参考文档 12345678910111213141516boxes &#x3D; [ &#123; :name &#x3D;&gt; &quot;docker-kubernetes&quot;, :eth1 &#x3D;&gt; &quot;192.168.205.12&quot;, :mem &#x3D;&gt; &quot;2048&quot;, :cpu &#x3D;&gt; &quot;2&quot; &#125;]... config.vm.provider &quot;hyperv&quot; do |v| v.ip_address_timeout&#x3D;121 v.memory&#x3D;opts[:mem] v.cpus&#x3D;opts[:cpu] endbcdedit &#x2F;set hypervisorlaunchtype offbcdedit &#x2F; set hypervisorlaunchtype auto XShell SSH 命令工具 一些特性 标签化页面管理，方便管理打开的连接 支持连接目录管理，方便进行多种环境管理 支持分屏，方便对集群中的主从进行区分 支持透明图，无需切换窗口查看遗忘的命令 侧栏显示连接信息，方便集群中配置 IP 地址 Vagrant 管理 通过 Vagrantfile 文件设置好一些数值进行控制虚拟机，通过命令管理虚拟机 1234567# 全局管理vagrant global-statusvagrant global-status --prunevagrant destroy &lt;vm_id&gt;vagrant halt &lt;vm_id&gt; &lt;vm_id2&gt;vagrant reload &lt;vm_id1&gt; &lt;vm_id2&gt;..vagrant up &lt;vm_id1&gt; &lt;vm_id2&gt;.. 安装虚拟机环境 快速安装环境，支持从远程获取对应的 Vagrantfile，之后拉取远程镜像；支持导入本地的 box 作为镜像； 12345678# vagrant 命令# 初始化一个安装 centos&#x2F;7 虚拟机的 Vagrantfile# 根据目录下的 Vagrantfile 进行启动# 删除虚拟机# 查案虚拟机运行状态vagrant init centos&#x2F;7vagrant upvagrant status 多种虚拟机支持 支持多种虚拟机，对应的配置memory、Cpu 方式不同 1234# 使用 vmware 虚拟机# 使用 hyper-v，需要管理员权限运行 vagrant，通过 Cmder 默认使用 admin 启动的 powershell 处理vagrant up --provider&#x3D;vmware_fusionvagrant up --provider&#x3D;hyperv Vagrant 插件vagrant-hostmanager 实现多台虚拟机之间直接通过名称访问，原理为更改 host 文件 123456789# 安装并验证插件vagrant plugin install vagrant-hostmanagervagrant plugin list# 在 Vagrantfile 中修改config.hostmanager.enabled &#x3D; trueconfig.hostmanager.manage_guest &#x3D; trueconfig.hostmanager.manage_host &#x3D; true# 执行命令，更新虚拟机上的hosts，同时更新主机上的 hostsvagrant hostmanager vagrant-vbguest 处理 VisualBox 中无法设置共享目录问题 12345vagrant plugin install vagrant-vbguestvagrant vbguest --statusvagrant vbguest --do install node1# 配置 vagrantfileconfig.vbguest.auto_update&#x3D;false vagrant-bindfs 非使用 visualBox 自带的共享目录，自定义使用文件系统 nfs，性能更高 12345678910111213141516171819202122232425vagrant plugin install vagrant-bindfs# 。。。node1. vm. synced_folder &quot;.&#x2F;app&quot;,&quot;&#x2F;mnt&#x2F;app-data&quot;, type:&quot;nfsnode1. bindfs. bind_folder &quot;&#x2F;mnt&#x2F;app-data&quot;,&quot;&#x2F;app&quot;, force_user:&quot;root&quot;, force_group:&quot;root&quot;,o:&quot;nonempty&quot;# 代理设置插件# 在Vagrantfile中的config部分添加代理配置, 全部网络都走主机代理vagrant plugin install vagrant-proxyconfvim Vagrantfile Vagrant.configure(&quot;2&quot;) do |config| if Vagrant.has_plugin?(&quot;vagrant-proxyconf&quot;) config.proxy.http &#x3D; &quot;&lt;http:&#x2F;&#x2F;192.168.0.2:3128&#x2F;&gt;&quot; config.proxy.https &#x3D; &quot;&lt;http:&#x2F;&#x2F;192.168.0.2:3128&#x2F;&gt;&quot; config.proxy.no_proxy &#x3D; &quot;localhost,127.0.0.1,.example.com&quot; end # ... other stuff end# 复用虚拟机环境插件安装vagrant plugin listvagrant plugin install vagrant-scpvagrant scp# 处理虚拟机安装进行目录文件映射权限问题vagrant plugin install vagrant-vbguestvagrant plugin list Vagrantfile 构建虚拟机的硬件情况，实现控制 CPU、内存、Ip 等资源，同时支持虚拟机启动后执行初始化脚本，实现一些必要工具的安装，如 Docker。 通过配置可实现： 进行虚拟机目录与本地目录映射 选择网络 安装成功后执行特定脚本，直接安装要必要的工具以及 Docker 环境 12345678910# config.vm.box 配置使用哪个boxconfig.vm.box &#x3D; &quot;ubuntu16.04_louis&quot;# box ∈ vagrant box listconfig.vm.hostname # 机器应该有的主机名aa.vm.hostname &#x3D; &quot;aa.test.com&quot;config.vm.network # 在机器上配置网络config.vm.network&quot;forwarded_port&quot;,guest:80,host:8080aa.vm.network &quot;private_network&quot;, ip: &quot;192.168.55.100&quot;config.vm.provider # 配置提供程序特定的配置，用于修改特定于某个 提供程序的设置config.vm.provision # 配置置备 在机器上，使软件可以自动安装并创建机器时配置config.vm.synced_folder # 配置 机器上的同步文件夹 配置实例： 参数注入 脚本执行，进行必要软件(vim,git…)、必要环境(如pip,java,docker) 的安装 资源配置，可 CPU、内存…. 等硬件资源 123456789101112131415161718boxes &#x3D; [ &#123; :name &#x3D;&gt; &quot;docker-host&quot;, :eth1 &#x3D;&gt; &quot;192.168.205.10&quot;, :mem &#x3D;&gt; &quot;1024&quot;, :cpu &#x3D;&gt; &quot;1&quot; &#125;]boxes.each do |opts| config.vm.provider &quot;virtualbox&quot; do |v| v.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, opts[:mem]] v.customize [&quot;modifyvm&quot;, :id, &quot;--cpus&quot;, opts[:cpu]] end config.vm.network :private_network, ip: opts[:eth1] # 从主机特定文件读入脚本执行 config.vm.provision &quot;shell&quot;, privileged: true, path: &quot;.&#x2F;setup.sh&quot; endend 网络配置根据需要设置虚拟机网络 IP 地址固定，实现虚拟机中的软件根据名称访问，设置虚拟机可以访问外部的网络。 端口转发 将宿主机的端口与虚拟机的端口绑定，从而让外部通过端口可以访问虚拟机 若 guest_ip 和 host_ip 两项配置为空，则局域网下的所有设备都可以访问该虚拟机 12345678910111213141516Vagrant.configure(2&quot;) do |config|config.vm.network&quot;forwarded_port&quot;(必选) &#x2F;&#x2F;端口转发标示,guest(必选): # 虚拟端口,host(必选): # 宿主机端口，值必须大于1024,gust_ip(可选): # 虚拟机端口绑定虚拟机ip地址,host_ip(可选): # 虚拟机端口绑定宿主机端口ip,protocol(可选): # 指定通信协议，可以使用tcp&#x2F;udp,默认tcp,auto_correct(可选): # ture&#x2F;fasle,开机是否自动检测端口冲突end# 实际配置# 配置2个端口映射，把物理机的8080映射到虚拟机80，物理机的2100映射到虚拟机的22# host_ip 在主机 IP 较为固定情况下配置使用config.vm.network :&quot;forwarded_port&quot;, guest: 80, host: 8060,host_ip: &quot;10.2.11.203&quot;config.vm.network :&quot;forwarded_port&quot;, guest: 22, host: 2100, host_ip: &quot;10.2.11.203&quot; 私有网络 虚拟机之间处在同一网段的地址可相互访问，主机可以访问虚拟机，无法通过虚拟机进行团队合作，不与宿主机的 IP 在同一个网段，防止冲突 配置 vagrant 里面的虚拟机的私有网段的时候，切记不能和企业（公司）内部的 DHCP 分配的 IP 地址在同一网段，否则会发生冲突 1234567891011# 配置 Static IPconfig.vm.network &quot;private_network&quot;, ip: &quot;192.168.50.10&quot;config.vm.network &quot;private_network&quot;, ip: &quot;192.168.55.20&quot;# 配置通过 DHCP 进行获取 IP，之后执行 &#96;vagrant reload&#96;config.vm.network &quot;private_network&quot;, type: &quot;dhcp&quot;# 实际使用Vagrant.configure(&quot;2&quot;) do |config|config.vm.network &quot;private_network&quot;, ip: &quot;192.168.50.10&quot;,auto_config: falseend 公有网络 与宿主机一样的网络配置， vagrant1.3+ 支持设置固定 IP，虚拟机 IP 与主机 IP 处在同一个网段时，实现局域网之间的互通，需要有路由器分配 IP.一般来说开发和测试使用较为封闭的网络模型是比较好的方式，通常不建议 vm 配置有 public_network 的网卡关联 配置虚拟机自动获取公司内部DHCP服务器分配的IP地址，在局域网任何一台电脑上，都可以ssh到虚拟机，或访问虚拟机上提供的服务 12345678910111213141516171819config.vm.network &quot;public_network&quot;, ip: &quot;192.168.1.120&quot;# 配置动态 IP# 配置共有网络，使用主机上可以访问外网的接口(ipconfig)# 配置默认网关config.vm.network &quot;public_network&quot;,bridge: &quot;ens33&quot;config.vm.provision &quot;shell&quot;,run: &quot;always&quot;,inline: &quot;route add default gw 10.2.11.1&quot;# 配置静态 IP# auto_config：关闭自动配置# ifconfig enp0s8 10.2.11.196 netmask 255.255.255.0 up: 配置静态ip（这里的ip不能和公司内部的地址冲突）# route add default gw 10.2.11.1 指定网关（添加默认路由）# bridge： 绑定接口（物理机哪个接口可以上网）config.vm.network &quot;public_network&quot;, auto_config: false ,bridge: &quot;ens33&quot;config.vm.provision &quot;shell&quot;,run: &quot;always&quot;,inline: &quot;ifconfig eth1 10.2.11.196 netmask 255.255.0.0 up&quot;config.vm.provision &quot;shell&quot;,run: &quot;alway&quot;,inline: &quot;route add default gw 10.2.11.1&quot;config.vm.network &quot;public_network&quot;, auto_config: false config.vm.provision &quot;shell&quot;,run: &quot;always&quot;,inline: &quot;ip addr add 172.17.10.51&#x2F;21 dev eth1&quot; config.vm.provision &quot;shell&quot;,run: &quot;alway&quot;,inline: &quot;ip route add 172.17.8.0&#x2F;21 via 172.17.0.49&quot; 共享文件配置宿主机中的数据与虚拟机的数据映射 1234567# src： 是物理机的目录，相对路径，（相对于项目目录（&#x2F;vagrant&#x2F;ubuntu））# &#x2F;srv&#x2F;website: 虚拟机的目录，绝对路径，如果没有，会自动创建config.vm.synced_folder &quot;src&#x2F;&quot;, &quot;&#x2F;srv&#x2F;website&quot;endconfig.vm.synced_folder &quot;.&quot;, &quot;&#x2F;vagrant&quot;, disabled: trueconfig.vm.synced_folder &quot;src&#x2F;&quot;,&quot;&#x2F;srv&#x2F;website&quot;,owner: &quot;root&quot;,group: &quot;root&quot; Q&amp;A 出现的问题以及对应的处理 @Q: 处理本地下载对应镜像慢问题： 直接下载、设置代理 执行 vagrant up --provider=hyperv，在控制台找到下载地址，使用本地下载工具下载(代理) 12345678# 执行下载# 获取地址重新下载# 重命名为指定格式vagrant up --provider&#x3D;hyperv# 将下载的 .box 添加# 使用下载的 .box 进行初始化 vagrant box add centos-7_hyperv hyperv.boxvagrant init centos-7_hyperv @Q: 卸载重装 Vagrant 无法删除之前构建的虚拟机 @Q: 公有网络设置静态 IP 的接口选择问题，无法选择 Wifi、以太网接口?? 待验证 选择不同的连接网卡是否可相互通信？ 选择以太网的桥接可实现内网互通 @Q: 使用以太网接口指定公司网关显示网络不可达? 公司内网的安全性?? 相当于占用内网的一个 IP @Q: 二次使用 vagrantfile 时，报错 chmod: cannot access ‘/etc/systemd/system/docker.service.d/http-proxy.conf’: No such file or directory A： 通过 ssh 进入主机，创建该文件 // todo 搜寻更好的处理方法 1touch &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;http-proxy.conf 原因是修改了网络配置(改成桥接)，重新配置 docker 的代理，需要创建文件的方式来配置代理，而默认情况下无权限访问 @Q: 同步文件夹显示编码问题， ==&gt; Test-Node: Rsyncing folder: /cygdrive/d/develop/Env2/Test-Node/ =&gt; /vagrant D:/ProgramFile/Vagrant/embedded/gems/2.2.5/gems/vagrant-2.2.5/lib/vagrant/util/io.rb:32:in `encode’: “5” from GBK to UTF-8 (Encoding::UndefinedConversionError) 管理员权限编辑对应的 io.rb 文件，更改 vagrant 源码 https://github.com/hashicorp/vagrant/issues/9368 Ref： 多种类型虚拟机支持 使用vagrant和vitrualBox搭建虚拟开发环境 Box-Search: hyperv Vagrant使用指南: 插件、vagrant 代理、对应虚拟机代理 windows 下 使用 vagrant 来管理 linux 虚机开发环境 HyperV - Static Ip with Vagrant 征服诱人的Vagrant！ Vagrant学习文档 VAGRANT 网络配置 ifconfig命令和ip命令及route命令： 配置公有网络设定 IP、掩码、网关","tags":[{"name":"工具","slug":"工具","permalink":"http://example.com/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"Java 并发学习笔记","date":"2020-12-17T14:53:30.000Z","path":"2020/12/17/Java-并发学习笔记/","text":"线程 Java 代码首先会编译成Java字节码，字节码被类加载器加载到JVM里，JVM执行字节码，最终需要转化为汇编指令在CPU上进行执行。 Java中所使用的并发机制依赖于 JVM 的实现和 CPU 的指令。 创建方式(1) extends Thread 当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。 12MyThread t1 = new MyThread();t1.start(); (2) Runnable (3) Callable 与 Runnable 相比，Callable 可以有返回值，且可以跑出异常，返回值通过 FutureTask 进行封装。 (4) ThreadPool 继承与实现接口的比较 优先实现接口 ① Thread 只能够通过单继承来实现； ② Thread 创建开销大，Runnable 创建的开销小； ③ Runnable 实现解耦； 可以配合线程池使用 生命周期 12345678public enum State &#123; NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED;&#125; (1) 新建(NEW) 创建后尚未启动。 当程序使用 new 关键字 创建了一个线程之后，该线程就处于新建状态，此时仅由JVM为其分配内存，并初始化其成员变量的值。 (2) 可运行(Runnable)可能正在运行，也可能正在等待 CPU 时间片。 包含了操作系统线程状态中的 Running 和 Ready。 当线程对象调用了start()方法之后，该线程处于就绪状态。Java虚拟机会为其创建方法调用栈和程序计数器，等待调度运行。 (3) 阻塞(Blocked)等待获取一个排它锁，如果其线程释放了锁就会结束此状态。 主要分为三种阻塞方式： ① 同步阻塞： 等待获取锁，获取同步锁时该同步锁被别的线程占用，JVM 将线程放入到锁池 (lock pool) 中。 ② 等待阻塞 执行 o.wait() ，JVM会把该线程放入等待队列(waitting queue)中。 ③ 其他阻塞 I/O 阻塞： 等待 I/O 操作完成； 执行 Thread.sleep() ； 执行 t.join() 方法； (4) 无限期等待(Waiting)等待其它线程显式地唤醒，否则不会被分配 CPU 时间片； 都是交互性质的方法； Object.wait()、Thread.join()、LockSupport.part() 进入方法 退出方法 没有设置 Timeout 参数的 Object.wait() 方法 Object.notify() / Object.notifyAll() 没有设置 Timeout 参数的 Thread.join() 方法 被调用的线程执行完毕 LockSupport.park() 方法 LockSupport.unpark(Thread) (5) 限期等待(Timed Waiting) 无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。 调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。 睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。 阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用 Thread.sleep() 和 Object.wait() 等方法进入。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 / Object.notify() / Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 / 被调用的线程执行完毕 LockSupport.parkNanos() 方法 LockSupport.unpark(Thread) LockSupport.parkUntil() 方法 LockSupport.unpark(Thread) (6) 死亡(Terminated) 可以是线程结束任务之后自己结束，或者产生了异常而结束。 线程的终止(1) 正常终止 运行结束，正常终止； (2) 退出标志 定义了一个退出标志exit，当exit为true时，while循环退出，exit的默认值为false.在定义exit时，使用了一个Java关键字volatile，这个关键字的目的是使exit同步，也就是说在同一时刻只能由一个线程来修改exit的值。 volatile 无锁同步的应用场景之一； 123456class MyThread extends Thread &#123; public volatile boolean exit = false; // volatile public void run() &#123; // ... &#125;&#125; (3) Interrupt 方法结束 ① 阻塞下的结束 在线程处于阻塞状态下，调用 interrupt() 会抛出 InterrupteException，一定要先捕获InterruptedException异常之后通过break来跳出循环，才能正常结束run方法。 死循环中的退出，只有在捕获后进行显示的 break 才能实现； ② 未阻塞下的结束 使用 isInterrupted() 判断线程的中断标志来退出循环。当使用 interrupt() 方法时，中断标志就会置 true，和使用自定义的标志来控制循环是一样的道理。 1234567891011class MyThread implements Runnable &#123; public void run() &#123; while (!isInterrupted()) &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; break; // NOTE: after catch exception must break to skip loop &#125; &#125; &#125;&#125; (4) stop 方法终止 程序中可以直接使用thread.stop()来强行终止线程，但是stop方法是很危险的，就象突然关闭计算机电源，而不是按正常程序关机一样，可能会产生不可预料的结果，不安全主要是：thread.stop()调用之后，创建子线程的线程就会抛出ThreadDeatherror的错误，并且会释放子线程所持有的所有锁。一般任何进行加锁的代码块，都是为了保护数据的一致性，如果在调用thread.stop()后 导致了该线程所持有的所有锁的突然释放(不可控制) ，那么被保护数据就有可能呈现不一致性，其他线程在使用这些被破坏的数据时，有可能导致一些很奇怪的应用程序错误。因此，并不推荐使用stop方法来终止线程。 (5) Callable 通过 Future.camcel 来进行终止 Interrupt()一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。 (1) InterruptedException 该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。 Thread.sleep()； synchronized； join()； (2) interrupted() 无限循环不跳出，只有在该循环中执行 sleep() 等会抛出 InterruptedException 操作， 可通过其返回值来防止无线循环，作为一种退出标志； 调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。 (3) Executor 的中断操作 ① 关闭池子操作 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。 ② 关闭指定的线程(Future) 只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。 方法(1) join 进行线程之间的流程控制，进行线程通信的一种方式； (2) yield() 让出当前 CPU，之后重新进行竞争； (3) sleep() 不释放锁，在等待一定时间后自动唤醒； sleep() 与 wait() 的区别 想到对应在阻塞队列中、以及延时双删策略中的场景； ① 设计|定义： sleep() 是 Thread 的静态方法，wait() 是 Object 的成员方法； ② 锁的占用： sleep() 导致程序暂停执行指定的时间，它的监控状态依然保持着，不释放锁， 而 wait() 释放对象锁，进入等待此对象的等待池中； ③ 使用范围： sleep() 可以用在任何地方， wait() 只能够用在同步控制方法或同步控制块中使用； ④ 唤醒方式： sleep() 给定时间内自动唤醒，wait() 需要调用 notify 显视唤醒； start() 与 run() 的区别 start() 方法来启动线程，真正实现了多线程运行。这时无需等待 run 方法体代码执行完毕，可以直接继续执行下面的代码。 通过调用 Thread 类的 start() 方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行。 run ⽅法只是 thread 的⼀个普通 ⽅法调⽤，直接运行。 方法 run() 称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运行 run 函数当中的代码。 Run方法运行结束， 此线程终止。然后CPU再调度其它线程。 其他性质 (1) 进程与线程的比较 进程是 OS 资源分配的单位，有自己独立的寻址空间； 线程是 OS 独立运行的单元，其共享同一个进程内的所有数据； 线程相较于进程更加轻量； ⼀个进程中可以有多个线程，多个线程共享进程的堆和⽅法区 (JDK1.8 之后的元空间)资源，但是每个线程有⾃⼰的程序计数器、虚拟机栈 和 本地⽅法栈。 (2) 实现多线程的方式 Java 中通过将每个线程映射为一个进程实现的； 线程的实现3种模型:内核线程；用户线程；两者结合。 (3) 守护线程 是个服务线程，准确地来说就是服务其他的线程，这是它的作用——而其他的线程只有一种，那就是用户线程。所以java里线程分2种。 ① 停止执行情况 专门用于服务其他的线程，如果其他的线程(即用户自定义线程)都执行完毕，连main线程也执行完毕，那么jvm就会退出(即停止运行)——此时，连jvm都停止运行了，守护线程当然也就停止执行了。 ② 优先级 优先级较低 ③ 设置 通过 setDaemon(true) 在 Thread 未 start() 之前显视设置 Daemon 线程产生的新线程也是 Daemon 的 ④ 性质 为 JVM 级别的线程，即使你停止了Web应用，这个线程依旧是活跃的。 (4) 线程派生的联系 继承对应的优先级、daemon等属性； (5) 并发和并行 并发： 同⼀时间段，多个任务都在执⾏ (单位时间内不⼀定同时执⾏)； 并⾏： 单位时间内，多个任务同时执⾏。 线程间通信while 循环监测 线程B是一直执行着while(true) 循环的，直到长度为5才终止执行，显然这种方式是很消耗资源的。所以，就需要一种机制能避免上述的操作又能实现多个线程之间的通信，这就是接下来需要学习的“wait/notify线程间通信”。 通信方式(1) 进程间的通信方式 ① 管道(pipe)、有名管道(named pipe) ② 信号量(semophore) ③ 消息队列(message queue) ④ 信号(signal) ⑤ 共享内存(shared memory) ⑥ 套接字(socket) (2) 线程间的通信方式 1、锁机制： 1.1 互斥锁：提供了以排它方式阻止数据结构被并发修改的方法。 1.2 读写锁：允许多个线程同时读共享数据，而对写操作互斥。 1.3 条件变量：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。2、信号量机制：包括无名线程信号量与有名线程信号量3、信号机制：类似于进程间的信号处理。线程间通信的主要目的是用于线程同步，所以线程没有像进程通信中用于数据交换的通信机制。 等待/通知机制 Object.wait, notify 机制，需要配合 synchronized 一起使用 1、wait()/notify 方法 (1)wait() 和 notify() 方法要在同步块或同步方法中(synchronized 关键字) 调用，即在调用前，线程也必须获得该对象的对象级别锁。(2)wait方法是释放锁，notify方法是不释放锁的；(3)notify 每次唤醒 wait 等待状态的线程都是随机的，且每次只唤醒一个；(4)notifAll 每次唤醒 wait 等待状态的线程使之重新竞争获取对象锁，优先级最高的那个线程会最先执行；(5)当线程处于 wait() 状态时，调用线程对象的 interrupt() 方法会出现 InterruptedException 异常； 通过 等待通知模式实现阻塞队列 (1) 结构 1234Queue&lt;Object&gt; queue = new LinkedList&lt;&gt;();AtomicInteger count = new AtomicInteger();int capacity = 5;Object lock = new Object(); // use for thread communication (2) 入队 1234567891011121314void put(Object task) &#123; synchronzied(lock) &#123; while (count.get() == capacity) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; log.error(&quot;&quot;, e); &#125; &#125; queue.offer(task); count.getAndIncrement(); lock.notify(); // not empty conditon &#125;&#125; (2) 出队 12345678910111213141516Object take() &#123; Obejct oldFront = null; synchronized(lock) &#123; while (count.get() == 0) &#123; try &#123; lock.wait()； &#125; catch (Exception e) &#123; log.error(&quot;Error&quot;, e); &#125; &#125; oldFront = queue.poll(); count.getAndDecrment(); lock.notify(); // not full condition &#125; return oldFront;&#125; 应用 (1) MyBatis 中 在数据库连接这个地方使用到的：org.apache.ibatis.datasource.pooled.PooledDataSource 类中，所以不用花太多的时间去深究。1、获取连接的时候，如果数据库连接池没有空闲的连接，那么当前线程就会进入等待，直到被通知，这个地方就是popConnection()方法 *ThreadLocal 实现每⼀个线程都有⾃⼰的专属本地变量。 如果你创建了⼀个 ThreadLocal 变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是 ThreadLocal 变量名的由来。 如果使用 ThreadLocal 管理变量，则每一个使用该变量的线程都获得该变量的副本， 副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。 (1)概述 原理： 为每个使用该变量的线程都提供独立的变量副本，从而不会影响到其他线程所对应的副本。 是一种多线程间并发访问变量的解决方案，不使用锁来保证并发访问，本质是以空间换时间的方式，为每个线程提供变量的独立副本，以保证线程的安全。 (2) 作用 ThreadLocal 的作用是提供线程内的局部变量 ，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。 底层结构 一个Thread中只有一个ThreadLocalMap， 一个ThreadLocalMap中可以有多个ThreadLocal对象， 其中一个ThreadLocal对象对应一个ThreadLocalMap中一个的Entry实体 (也就是说：一个Thread可以依附有多个ThreadLocal对象)。 (1) Thread 中持有的结构 线程局部变量 ，那么理所当然就应该存储在自己的线程对象中 线程局部变量存储在 Thread 对象的 threadLocals 属性中 12345public class Thread implements Runnable &#123; ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ...&#125; (2) ThreadLocal.ThreadLocalMap 是实现 ThreadLocal 的原理，用于存储每一个线程的变量副本，Map中元素的键为线程对象，而值对应线程的变量副本。 KEY: 线程对象； VALUE: 对应线程的变量副本； 12ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; ......&#125; 一些操作 (1) ThreadLocal 4 大 public 方法 根据当前线程获取到对应的 ThreadLocalMap，借助该 Map 操作实现； get()、 set()、 remove()、 withInitial()。 最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上， ThreadLocal 可以理解为只是 ThreadLocalMap 的封装，传递了变量值。 1234567891011121314151617181920212223242526272829public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125;public static &lt;S&gt; ThreadLocal&lt;S&gt; withInitial(Supplier&lt;? extends S&gt; supplier) &#123; return new SuppliedThreadLocal&lt;&gt;(supplier);&#125; 与同步机制的比较 a.ThreadLocal与同步机制都是为了 &lt;u&gt;解决多线程中相同变量的访问冲突问题&lt;/u&gt;。 b.前者采用以&quot;空间换时间&quot;的方法，后者采用以&quot;时间换空间&quot;的方式 对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 Thread 造成的内存溢出问题 (1) 与线程池协作引发的内存溢出问题 ThreadLocal变量是维护在Thread内部的，线程不退出，对象的引用就会一直存在。 当我们使用线程池的时候，就意味着当前线程未必会退出(比如固定大小的线程池，线程总是存在的)。如果这样的话，将一些很大的对象设置到ThreadLocal中(这个很大的对象实际保存在Thread的threadLocals属性中)，这样的话就可能会出现内存溢出的情况。 一种场景就是说如果使用了线程池并且设置了固定的线程，处理一次业务的时候存放到ThreadLocalMap中一个大对象，处理另一个业务的时候，又一个线程存放到ThreadLocalMap中一个大对象，但是这个线程由于是线程池创建的他会一直存在，不会被销毁，这样的话，以前执行业务的时候存放到ThreadLocalMap中的对象可能不会被再次使用，但是由于线程不会被关闭，因此无法释放Thread 中的ThreadLocalMap对象，造成内存溢出。 也就是说，ThreadLocal在没有线程池使用的情况下，正常情况下不会存在内存泄露，但是如果使用了线程池的话，就依赖于线程池的实现，如果线程池不销毁线程的话，那么就会存在内存泄露。所以我们在使用线程池的时候，使用ThreadLocal要格外小心！ (2) 原因 ThreadLocal内存泄漏的根源是：由于 ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏 ，而不是因为弱引用。 弱引用与内存泄漏 弱引用被回收了只是回收了Entry的key引用，但是Entry应该还是存在的吧？ ThreadLocal的get(),set(),remove() 的时候都会清除线程ThreadLocalMap里所有key为null的value。 1234567static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 这里我们就需要重新认识一下，什么是：当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象，这里的重点是：只被弱引用关联的对象 上述过程尽管 GC 执行了垃圾收集，但是弱引用还是可以访问到结果的，也就是没有被回收，这是因为除了一个弱引用 userWeakReference 指向了User实例对象，还有 user 指向 User 的实例对象，只有当user和User实例对象的引用断了的时候，弱引用的对象才会被真正的回收 并不是所有弱引用的对象都会在第二次GC回收的时候被回收，而是 回收掉只被弱引用关联的对象 。因此，使用弱引用的时候要注意到！希望以后在面试的时候，不要上来张口就说，弱引用在第二次执行GC之后就会被回收！ 应用场景 (1) 解决数据库连接 避免方法中总是出现 Connection 参数，每个线程每次使用的都是用一个 Connection； (2) MyBatis 中用于 Session 管理 123456789101112private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s; &#125; *线程池(1) new Thread 弊端： 每次new Thread新建对象，Thread 为大对象，性能差 ； 线程缺乏统一管理，可能无限制的新建线程，相互竞争，有可能占用过多系统资源导致死机或 OOM； 缺少更多功能，如更多执行、定期执行、线程中断； (2) 线程池好处 重用性： 重用存在的线程，减少对象创建、消亡的开销，性能佳 ； 可控性： 可有效控制最大井发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞 ； 功能性： 提供定时执行、定期执行、单线程、井发数控制等功能； 线程池参数 corePoolSize: &lt;= x maximumPoolSize: 最大线程数 workQueue: 工作队列，为BlockingQueue threadFactory: 默认非守护，同优先级，名称 rejectHandler: BlockingQueue 满，无空闲的线程池，拒绝cel，默认直接抛出 exception keepAliveTime，unit: corePoolSize –&gt;&gt; maximumPoolSize 123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 四种拒绝策略： ThreadPoolExecutor 类中提供 AbortPolicythrows exception DiscardPolicy： 直接丢弃 CallerRunPolicy： 使用调用者 thread 执行 DiscardOldestPolicy： 丢弃 BlockingQueue 中最靠前的 task，执行当前 task 方法 (1) 主要方法 生命周期及 ExecutorService： - execute() - submit(): execute + Future - shutdown() : handle BlockingQueue in - shutdownNow() : BlockingQueue not handler (2) 监控方法： getTaskCount()：线程池已执行和未执行的任务总数 getCompIetedTaskCount()：已完成的任务数量 getPoolSize()：线程池当前的线程数量 getActiveCount()：当前线程池中正在执行任务的线程数量 Executors① Executors.newCachedThreadPool 创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute 将重用以前构造的线程(如果线程可用)。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源。 ② Executors.newFixedThreadPool 创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大多数 nThreads 线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线程将代替它执行后续的任务(如果需要)。在某个线程被显式地关闭之前，池中的线程将一直存在。 ③ Executors.newSingleThreadExecutor Executors.newSingleThreadExecutor()返回一个线程池(这个线程池只有一个线程),这个线程池可以在线程死后(或发生异常时)重新启动一个线程来替代原来的线程继续执行下去！ ④ Executors.newScheduIedThreadPool 创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。 1ScheduledExecutorService scheduledThreadPool= Executors.newScheduledThreadPool(3); scheduledThreadPool.schedule(newRunnable()&#123; @Override public void run() &#123; System.out.println(&quot;延迟三秒&quot;); &#125; &#125;, 3, TimeUnit.SECONDS); scheduledThreadPool.scheduleAtFixedRate(newRunnable()&#123; @Override public void run() &#123; System.out.println(&quot;延迟1秒后每三秒执行一次&quot;); &#125; &#125;,1,3,TimeUnit.SECONDS); ⑤ 线程池配置 CPU 密集型任务，就需要尽量压榨 CPU，参考值可以设为 NCPU + 1IO 密集型任务，参考值可以设置为 2 * NCPU； 选用基础： - 小型应用不适合 - 线程调度时间开销大 @@计算密集型与IO密集型 密集型： CPU 核 + 1IO 密集： CPU 核数 / (1-阻塞系数) 一般0。8~0.9 @@如何正确的使用线程池 设置线程池，比设置界限； hook 机制嵌入行为，由 beforeMethod, afterMethod 记录线程执行前和后做日志，异常结果； 优雅的关闭，hook 机制，推荐使用 JavaBean 创建线程池，在 destoryMethod 里面在销毁时调用 shutdown； JMM(1) 概述 Java 并发采用的是共享内存模型，线程之间的通信总是隐式执行。 定义： Java 线程之间的通信由 JMM 控制， JMM 决定一个线程对共享变量的写入何时对另一个线程可见。 Java内存模型(JMM)解决了可见性和有序性的问题，而锁解决了原子性的问题，理想情况下我们希望做到“同步”和“互斥” 主内存与工作内存 主内存副本拷贝，非对整个obj拷贝。 Java借助共享内存实现线程间的通信 内存间的交互操作 8中操作, 主内存，保证原子性； 对于long和double的特殊规则(了) 64位 对于volatile变量的特殊规则 语义： 可见性, 实现对于其修改立即写回主内存中, 非保证原子性; 有序性, 禁止指令重排序, 是一种同步机制, 轻量, 与DCL实现安全的单例. 原子性、可见性与有序性volatile：finale: this 引用逃逸(读初始化一般的data)；synchronized: “万能”, 重量, 阻塞 硬件的效率与一致性:缓存一致性协议 关键字*volatile 能够在线程之间保持可见性，能够被 多线程同时读，并且保证不会读到过期的值，但 只能被单线程写。基于 happens-before 原则，对 volatile 字段的写入操作先于读操作，即使两个线程同时修改和获取 volatile 变量。 volatile是轻量级的synchronized，他的意思是：当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。如果volatile变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度 (1) 特性 a.volatile关键字为域变量的访问提供了一种免锁机制， b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新， c.因此每次使用该域就要重新计算，而不是使用寄存器中的值 d.volatile不会提供任何原子操作，它也不能用来修饰final类型的变量 volatile 保证可见性 有volatile变量修饰的共享变量进行写操作的时候会引发了两件事情：(1)将当前处理器缓存行的数据写回到系统内存；(2)这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效； 底层实现细节(了)： ① 发生 volatile W， JVM 向处理器发送 Lock 前缀的汇编命令，将该变量缓存行写到系统内存； ② 为了保证写回到的数据被其他线程立即可见，借助 缓存一致性协议 实现，每个处理器 嗅探总线 上传播的数据检查自己是否过期，过期强制从系统内存中把数据读到处理器缓存中。 volatile 如何禁止指令重排序 借助内存屏障和禁止指令重排实现 对 volatile 变量写操作时，会在写操作之后加上一条 store 屏障指令，将本地内存中的共享变量刷新到主内存； 对 volatile 变量的读操作，会在读操作之前加上一条 load 屏障指令，从主内存中读取共享变量。 使用volatile关键字修饰共享变量可以禁止重排序。若用volatile修饰共享变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序volatile禁止指令重排序的一些规则： 1.当第二个操作是voaltile写时，无论第一个操作是什么，都不能进行重排序 2.当地一个操作是volatile读时，不管第二个操作是什么，都不能进行重排序 3.当第一个操作是volatile写时，第二个操作是volatile读时，不能进行重排序 涉及到内存屏障(Memory Barrier)，它是让一个CPU处理单元中的内存状态对其它处理单元可见的一项技术。 一些应用 无锁读取数据： ConcurrencyHashMap 的 get 操作，通过 volatile 替换锁，AQS 中 state 变量； 作为终止标识，exit 来进行终止，类似 interrupt 终止； 那么在禁止重排序时是一个较好的使用场景，否则我们不需要再使用它，如 DCL 中通过 volatile 修饰； 热部署的变量： 通过线程修改之后立即被其他线程可见； 适用场景： (1) 对变量的写操作不依赖于当前值(比如 i++)，或者说是单纯的变量赋值(boolean flag = true)。 (2)该变量没有包含在具有其他变量的不变式中，也就是说，不同的 volatile 变量之间，不能互相依赖。只有在状态真正独立于程序内其他内容时才能使用 volatile。 synchronized字解决的是多个线程之间访问资源的同步性。 (1) 一些性质： 提供原子性，实现同步功能； 是 JVM 提供的同步工具，使用 lock 和 unlock 字节码指令，保证被它修饰 的⽅法或者代码块在任意时刻只能有⼀个线程执⾏； 与 CAS 比较： 相比于 CAS 可以保证 一块 而非一个变量的原子性； 与 Lock 比较： 相比于 JDK Lock 可以保存 程序运行信息 ，便于解决死锁和异常； (2) 使用的位置： code bloker： 显视锁住当前调用对象 synchronized(this)，通过监视器锁实现； method: 锁住调用对象，通过访问标识位实现； static method: 锁住该类的所有对象； class: 显视锁住类对象 synchronized(xxx.class)； 适用同一个对象调用锁住 obj 的可以实现同步，使其中的一个线程阻塞等待另一个线程执行完毕；不同对象调用时不适用； synchronized 保证可见性原理 通过 javap -v xxx.class 获取字节码指令分析 关键字synchronized可以修饰方法或者以同步块的形式来进行使用，它主要确保多个线程在同一个时刻，只能有一个线程处于方法或者同步块中，它保证了线程对变量访问的可见性和排他性。 JMM 对 synchronized 的规定： 线程解锁前，必须把共享变量的最新值刷新到主内存； 线程加锁时，将清空工作内存 中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值(注意，加锁与解锁是同一把锁)； 本质是对一个对象的监视器(monitor) 进行获取，而这个获取过程是排他的，也就是说同一时刻只有一个线程获取到由 synchronized 所保护对象的监视器。 (1) 对代码块同步 monitorenter 和 monitorexit 指令 Synchronized 每个对象有一个 内置的监视器锁(monitor) 。当 monitor 被占用时就会处于锁定状态，线程执行monitorenter 指令时尝试获取monitor的所有权，过程如下：1、如果 monitor 的进入数为0，则该线程进入 monitor，然后将进入数设置为1，该线程即为 monitor 的所有者。2、如果线程己经占有该 monitor，只是重新进入，则进入monitor 的进入数加1．3．如果其他线程巳经占用了 monitor ,则该线程进入阻塞状态，直到 monitor 的进入数为0，再重新尝试获取monitor的所有权。 (2) 同步方法 调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了， 执行线程将先获取 monitor，获取成功之后才能执行方法体 ，方法执行完后再释放 monitor Synchronize和lock都属于同步阻塞。 synchronized 其他性质 (1) 作为锁 见下部分锁相关 (2) 原子性 @Q: CAS 机制与 synchronized 保证原子性的区别？ ① CAS 仅能够保证一个变量的原子性，而 synchronized 可用于方法、类、字段等多处； ② CAS 通过不断循环重试实现，存在不必要的开销，但是是一种无锁的实现； ③ CAS 存在 ABA 问题； Q: JDK1.6+ 的 synchronized 关键字做了哪些优化? 对锁的实现引⼊了⼤量的优化，如偏向锁、轻量级锁、⾃旋锁、适应性⾃旋锁、锁消除、锁粗 化等技术来减少锁操作的开销。 锁主要存在四种状态，依次是：⽆锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈⽽逐渐升级。锁可以升级不可降级，提⾼获得锁和释放锁的效率。 三大特性原子性 提供了互斥访问，同一时刻只能有一个线程对它进行操作。 (1) 实现方式： 锁的同步机制： synchronized | Lock CAS 机制： 包括 AtomicInteger 等原子类 可见性 一个线程对主内存中共享变量的修改，能够及时地被其他线程观察到。 (1) 不可见的原因： 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主存间及时更新 (2) 实现方式 volatile 关键字可以保证共享变量的可⻅性。 有序性： 代码在执⾏的过程中的先后顺序。 Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性，导致代码的执⾏顺 序未必就是编写代码时候的顺序。 volatile、synchronized、Lock *happen-before 原则 单一线程原则 Single Thread Rule 一个线程内，程序前面的操作先于后面的操作。也叫程序次序原则。 管程锁定原则 Monitor Lock Rule 一个 unlock option 先于后面同一个锁的 lock option。 volatile 变量规则 Volatile Variable Rule 对一个 volatile 变量的写操作先于后面对这个变量的读操作。 传递性原则 Transitivity A –&gt; B, B –&gt; C ==&gt;&gt; A –&gt; C 线程启动规则 Thread Start Rule丶。 入 Thread 对象的 start() 先于此线程的每一个动作 线程中断规则 Thread Interruption Rule 对线程 interrupt() 的调用先于被中断线程的代码检测到中断事件的发生，即 isInterrupt(). 线程加入规则 Thread Join Rule Thread 对象的结束先于 join() 方法返回 对象终结规则 Finalizer Rule 一个对象的初始化完成(构造函数结束)先于它的 finalize() 方法的开始 线程同步的实现说明： 需要使用线程同步的根本原因在于对普通变量的操作不是原子的。 1、 互斥同步 (1) 同步方法 、同步代码块 (2) 使用重入锁实现线程同步 (3) 使用阻塞队列实现线程同步 2、 非阻塞同步 主要是 CAS 不断尝试实现 (1) 使用原子变量实现线程同步 3、 无同步方案 (1) 使用局部变量实现线程同步 如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本， 副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。 (2) 使用特殊域变量(volatile)实现线程同步 注：多线程中的非同步问题主要出现在对域的读写上，如果让域自身避免这个问题，则就不需要修改操作该域的方法。 锁与锁优化线程安全 Java语言中的线程安全绝对线程安全相对线程安全线程兼容线程对立 2. 线程安全的实现方法1)同步互斥Synchronized：存在挂起、恢复，是阻塞 实现的，且java线程直接映射到OS原生线程上的，存在用户态到内核态的_转换_，因而性能较差。 Lock：可重用锁 2)非阻塞基于CAS+Loop实现 3)无同步 可重入代码 TLC，线程本地， 是消息队列架构模式 锁乐观锁 乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是 在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作 (比较跟上一次的版本号，如果一样则更新)，如果失败则要重复读-比较-写的操作。 java中的乐观锁基本都是通过CAS操作实现的，CAS是一种更新的原子操作， 比较当前值跟传入值是否一样，一样则更新，否则失败。 悲观锁 悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block直到拿到锁。java中的悲观锁就是 Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如RetreenLock。 JVM 锁优化锁有四种状态，无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁 通过 对象头实现 (1) 原理： 基于对象头的Mark Word， 23位表示偏向的线程ID 偏向锁 偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入(CAS)的开销，看起来让这个线程得到了偏护 而偏向锁只需要在置换 ThreadID 的时候依赖一次CAS原子指令 如果一个线程获得了锁，那么锁就进入了偏向模式。当这个线程再次请求锁时，无需再做任何同步操作 (1) 设计原因 为什么会出现这种设计的方式那？这是因为根据HotSpot的作者研究，他发现 锁不仅不存在多线程竞争，而且总是由同一线程多次获得 ，为了让线程获得锁的代价更低而引入了的偏向锁这个概念。 (2) 锁的升级 在锁竞争比较激烈的场景，最有可能的情况是每次不同的线程来请求相同的锁，这样的话偏向锁就会失效，倒不如不开启这种模式，幸运的是Java虚拟机提供了参数可以让我们有选择的设置是否开启偏向锁。如果偏向锁失败，虚拟机并不会立即挂起线程，而是使用轻量级锁进行操作。 (3) 性质： 线程获取到锁之后，消除这个线程的重入开销； 1-XX:+UseBiasedLocking 轻量级锁 轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。 如果偏向锁失败，虚拟机并不会立即挂起线程，而是使用轻量级锁进行操作。轻量级锁他只是简单的将对象头部作为指针，指向持有锁的线程堆栈的内部，来判断一个线程是否持有对象锁。 如果线程获得轻量级锁成功，则可以顺利进入临界区。如果轻量级锁加锁失败，则表示其他线程抢先夺到锁，那么当前线程的轻量级锁就会膨胀为重量级锁。 轻量级锁所适应的场景是 线程交替执行同步块 的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。 (1) 说明： 嵌入在线程栈中的对象使用 Displaced Mark Word 复制对象头到堆栈中，借助CAS实现同步。还是需要进行 CAS , 出现竞争时，会尝试自旋 (2) 原理： 绝大部分锁在整个同步周期内都是不存在竞争的 自旋锁(无锁) (1) 原理 自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等(自旋)，等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。 (2) 优缺点 (3) 时间阈值 在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是 由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。 (4) 一些实现 在通过一定的自旋失败后，通常转化为加悲观锁实现，如 ConcurrentHashMap 中对于 put 在尝试 3 次失败后进行转换成对链表头进行加锁； 1-XX:+UseSpinning 自适应锁原来默认是10，现在可以实现自适应自旋 自适应，由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 如ConcurrentHashMap的tryLock() -XX:+UseSpinning 1.7默认开启-XX:PreBlockSpin 默认为10，代表 锁消除不存在共享数据竞争，需要对其进行逃逸分析，从而减少不必要的锁。 锁粗化防止在循环中加锁，进行资源的浪费 锁的对比 程序锁优化1.减少锁粒度 将大对象(这个对象可能会被很多线程访问)，拆成小对象，大大增加并行度，降低锁竞争。降低了锁的竞争，偏向锁，轻量级锁成功率才会提高。 () 应用 ① 最最典型的减小锁粒度的案例就是ConcurrentHashMap。进而提高并发程度如将 HashMap –&gt; ConcurrentHashMap使用Segment(16)增加并行度。 2. 减少锁持有时间 只用在有线程安全要求的程序上加锁 只在有必要的时候进行同步，这样就明显减少了线程持有锁的时间，从而提高系统的性能。 12345public synchronized void syncMethod()&#123; method1(); // cost much time mutextMethod(); // 实际需要进行同步的方法 method2();&#125; 3. 锁分离如根据功能进行锁分离(1) 应用 ① ReadWriteLock，即保证了线程安全，又提高了性能。 在读多写少的情况下，通过 ReentrantReadWriteLock 替换 ReentrantLock，实现对于 Read 的不加锁实现； ② 读写分离思想可以延伸， 只要操作互不影响，锁就可以分离 。比如LinkedBlockingQueue 从头部取出，从尾部放数据。 如果使用独占锁的话，则要求两个操作在进行时首先要获取当前队列的锁，那么take和put就不是先真正的并发了，因此，在JDK中正是实现了两种不同的锁，一个是takeLock一个是putLock。 4. 锁粗化不在循环中加锁，来回加和释放的开销大 12345678910111213public void syncMethod() &#123; synchronized (lock) &#123; //第一次加锁 method1(); &#125; method3(); synchronized (lock) &#123; //第二次加锁 mutextMethod(); &#125; method4(); synchronized (lock) &#123; //第三次加锁 method2(); &#125;&#125; 如果第一次和第二次加锁和线程上下文切换的时间超过了method1()、method2()method3()、method4() 的时间. 改进后的代码的执行时间可能小于上述分别加锁的时间，这就是锁粗化，也是一种锁优化的方式，但是要根据具体的场景； 5. 锁消除 锁消除是在 编译器级别的事情。在即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作。 引发原因： ① 多数是因为程序员编码不规范引起。 ② 有时这些锁并不是程序员所写的，有的是JDK实现中就有锁的，比如Vector和StringBuffer 这样的类，它们中的很多方法都是有锁的。当我们在一些不会有线程安全的情况下使用这些类的方法时，达到某些条件时，编译器会将锁消除来提高性能。 **6. JVM 锁优化(volatile, synchronized) ** 见上部分 *synchronized(1) 作用范围 (2) 核心组件 Wait Set：哪些调用wait方法被阻塞的线程被放置在这里； Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck； Owner：当前已经获取到所资源的线程被称为Owner； !Owner：当前释放锁的线程。 () 底层实现 是非公平锁，等待的线程会先尝试自旋获取锁，如果获取不到就进入 ContentionList； 每个对象后有个 monitor 对象， 加锁就是在竞争 monitor 对象 ， 代码块加锁是在前后分别加上monitorenter和monitorexit指令来实现的，方法加锁是通过一个标记位来判断的。 与 ReentrantLock 对比 相同点： 都是可重入锁。 ① 底层实现：ReentrantLock 是 API 级别的，synchronized 是 JVM 级别的，为关键字，能够在出现异常时打印出对应的错误堆栈用于分析问题，同时 JVM 对 synchronized 提供了锁升级的优化； ② 锁的实现方式： ReentrantLock 是同步非阻塞，采用的是乐观并发策略，而 synchronized 是同步阻塞，使用的是悲观并发策略。 ③ 锁的使用的安全性： ReentrantLock 需要显视加锁解锁，可能因为忘记解锁而陷入死锁，而 synchronized 为隐式加锁，不会因为忘记解锁而陷入死锁。 ④ 功能灵活性： ReentrantLock 可尝试获取锁； RentrantLock 可中断获取锁，提供了⼀种能够中断等待锁的线程的机制，lock.lockInterruptibly() ； RentrantLock 能够支持公平锁, synchronized 只能实现非公平锁； RentrantLock 可实现选择性通知： synchronizedf 使用 notify / notifyAll 进行通知时，通知的线程由 JVM 选择，ReentrantLock 更加灵活的绑定多个 Condition, 进行选择性通知。 1 ReentrantLock显示的获得、释放锁，synchronized隐式获得释放锁2 ReentrantLock可响应中断、可轮回，synchronized是不可以响应中断的，为处理锁的不可用性提供了更高的灵活性3 ReentrantLock是API级别的，synchronized是JVM级别的4 ReentrantLock可以实现公平锁5 ReentrantLock通过Condition可以绑定多个条件6 底层实现不一样， synchronized是同步阻塞，使用的是悲观并发策略，lock是同步非阻塞，采用的是乐观并发策略7 Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现。8 synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁。9 Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断。10 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。11 Lock可以提高多个线程进行读操作的效率，既就是实现读写锁等。 synchronized 与volatile 的比较 ① 实现与性能：volatile关键字是线程同步的 轻量级实现，所以 volatile性能肯定⽐synchronized关键字要好。 但是 volatile关键字只能⽤于变量⽽synchronized关键字可以修饰⽅法以及代码块。 synchronized关键字在JavaSE1.6之后进⾏了主要包括为了减少获得锁和释放锁带来的性能消耗 ⽽引⼊的偏向锁和轻量级锁以及其它各种优化之后执⾏效率有了显著提升，实际开发中使⽤ synchronized 关键字的场景还是更多⼀些。 ② 阻塞： 多线程访问volatile关键字不会发⽣阻塞，⽽synchronized关键字可能会发⽣阻塞 ③ 三特性的： volatile关键字能保证数据的可⻅性，但不能保证数据的原⼦性。synchronized关键字两者都能 保证。 ④ 使用场景： volatile关键字主要⽤于解决变量在多个线程之间的可⻅性，⽽ synchronized关键字解决的是 多个线程之间访问资源的同步性。 死锁两个进程都在等待对方执行完毕才能继续往下执行的时候就发生了死锁。结果就是两个进程都陷入了无限的等待中。 (1) 死锁的四个必要条件： 互斥条件：该资源任意⼀个时刻只由⼀个线程占⽤。 持有和等待条件： ⼀个进程因请求资源⽽阻塞时，对已获得的资源保持不放。 不可剥夺条件：线程已获得的资源在末使⽤完之前不能被其他线程强⾏剥夺，只有⾃⼰使⽤完毕后 才释放资源。 循环等待条件：:若⼲进程之间形成⼀种头尾相接的循环等待资源关系。 (2) 避免线程死锁 ① 破坏互斥条件 ：这个条件我们没有办法破坏，因为我们⽤锁本来就是想让他们互斥的（临界资源需要互斥访问）。 ② 破坏请求与保持条件 ：⼀次性申请所有的资源。 ③ 破坏不剥夺条件 ：占⽤部分资源的线程进⼀步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 ④ 破坏循环等待条件 ：靠按序申请资源来预防。按某⼀顺序申请资源，释放资源则反序释放。 相关问题 (1) 如何确保N个线程可以访问N个资源同时又不导致死锁？ ① 指定获取锁的顺序，并强制线程按照指定的顺序获取锁。因此，如果所有的线程都是以同样的顺序加锁和释放锁，就不会出现死锁了； ② 使用带有超时时间的锁； ③ 通过死锁的检测和恢复机制进行规避； (2) 写一个发生死锁的程序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 class DeadLock1 implements Runnable &#123; private static Object resource1 = new Object(); private static Object resource2 = new Object(); private int flag = 0; public DeadLock1(int flag) &#123; this.flag = flag; &#125; @Override public void run() &#123; if (flag == 1) &#123; synchronized (resource1) &#123; try &#123; Thread.sleep(500); System.out.println(&quot;flag1 one level&quot;); synchronized (resource2) &#123; System.out.println(&quot;flag 1&quot;); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; if (flag == 2) &#123; synchronized (resource2) &#123; try &#123; Thread.sleep(500); System.out.println(&quot;flag2 one level&quot;); synchronized (resource1) &#123; System.out.println(&quot;flag 2&quot;); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(new DeadLock1(1)); Thread t2 = new Thread(new DeadLock1(2)); t1.start(); t2.start(); &#125;&#125; 其他锁无锁 CAS算法的过程是这样：它包含三个参数CAS(V,E,N): V表示要更新的变量，E表示预期值，N表示新值。仅当V值等于E值时，才会将V的值设为N，如果V值和E值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。最后，CAS返回当前V的真实值。 可重入锁(递归锁) 可重入锁，也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。 偏向锁对于偏向的线程没有重入的开销。 公平锁和非公平锁 公平锁(Fair) 加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得。 非公平锁(Nonfair) 加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待。 非公平锁性能比公平锁高5~10倍，因为公平锁需要在多核的情况下维护一个队列 Java中的synchronized是非公平锁，ReentrantLock 默认的lock()方法采用的是非公平锁。 读写锁 读读不互斥，读写互斥，写写互斥 为了提高性能，Java提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的,在一定程度上提高了程序的执行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm自己控制的，你只要上好相应的锁即可。 (1) 读锁 如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁 (2) 写锁 如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！ Java中读写锁有个接口java.util.concurrent.locks.ReadWriteLock，也有具体的实现ReentrantReadWriteLock。 共享锁和独占锁 java并发包提供的加锁模式分为独占锁和共享锁。 (1) 独占锁 独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock就是以独占方式实现的互斥锁。独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。 (2) 共享锁 共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。 AQS的内部类Node定义了两个常量 SHARED 和 EXCLUSIVE ，他们分别标识 AQS队列中等待线程的锁获取模式。 java的并发包中提供了ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问，或者被一个 写操作访问，但两者不能同时进行。 重量级锁(Mutex Lock) Synchronized是通过对象内部的一个叫做监视器锁(monitor)来实现的。但是监视器锁本质又是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。 因此，这种 依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”。JDK中对Synchronized做的种种优化，其核心都是为了减少这种重量级锁的使用。JDK1.6以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。 分段锁 是一种思想ConcurrentHashMap是学习分段锁的最好实践 活锁 因为活跃性而引入的问题 并发中的设计模式单例模式保证全局唯一，并发情况下使用安全 见设计模式单例 7 种单例模式： 饿汉式； 双重监测懒汉式； 线程安全懒汉式； 静态内部类持有懒汉式； 枚举式； 变种的饿汉式； 变种的懒汉式； Future 模式Future模式的核心思想：异步调用 不仅可以在子线程完成后收集其结果，还可以设定子线程的超时时间，避免主任务一直等待。 () 性质Future模式不会立即返回你需要的数据，但是，他会返回一个契约 ，以后在使用到数据的时候就可以通过这个契约获取到需要的数据。 在广义的Future模式中，虽然获取数据是一个耗时的操作，但是服务程序不等数据完成就立即返回客户端一个伪造的数据(就是上述说的“契约”)，实现了Future模式的客户端并不急于对其进行处理，而是先去处理其他业务，充分利用了等待的时间，这也是Future模式的核心所在，在完成了其他数据无关的任务之后，最后在使用返回比较慢的Future数据。这样在整个调用的过程中就不会出现长时间的等待，充分利用时间，从而提高系统效率。 () JDK 中的 Future 模式 FutureTask实现了 Callable，Future接口，RunnableFuture接口继承了Future和Runnable接口。因为RunnableFuture实现了Runnable接口，因此FutureTask可以提交给Executor进行执行，FutureTask有两个构造方法，如下： Runnable 与 Callable 的区别 (1) Callable规定的方法是call()，Runnable规定的方法是run()；(2) Callable的任务执行后可返回值，而Runnable的任务是不能返回值得；(3) call()方法可以抛出异常，run()方法不可以；(4) 运行Callable任务可以拿到一个Future对象，Future 表示异步计算的结果 () 异常 Future 的 get() 可能会阻塞当前线程的执行，会抛出 InterruptedExcpeiton、ExecutionException，若线程已经取消，抛出 CancellationException，取消由cancel 方法来执行。isDone确定任务是正常完成还是被取消了。 () 可取消性 一旦计算完成，就不能再取消计算。如果为了可取消性而使用Future 但又不提供可用的结果，则可以声明Future&lt;?&gt; 形式类型、并返回 null 作为底层任务的结果。 生产者消费者使用生产者消费者模式实现的一个例子；模仿分布式爬虫； 单生产者单消费者 单生产者多消费者 多生产者单消费者 多生产者多消费者 Refs 《Java 并发编程的艺术》 《深入理解Java虚拟机(第二版)》","tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"Docker 学习笔记","date":"2020-12-17T14:41:19.000Z","path":"2020/12/17/Docker-学习笔记/","text":"Docker 基础 类似精简的 Linux 环境，含 root 权限、进程空间、用户空间和网络空间，以及运行在其中的应用程序 Client： 客户端通过 CLI 命令与 Docker 交互Docker daemon： 宿主机的守护进程，通过 RESTful 接口处理 Client 的命令，连接 Registry 进行镜像的拉取的推送，具体配置见 [Daemon配置](#Daemon 配置)Registry： 保存 image 的地方，实现 image 的维护、复用Image： 静态的镜像，可根据 Image 运行 containerContainer： 依据 Image 生成的具体的容器，实际运行的程序 Docker 底层实现原理： Namespaces：做隔离pid，net，ipc，mnt，uts Control groups(cgroups)：做资源限制 Union file systems: Container和image的分层，分层文件系统 镜像 一个特殊的文件系统，提供容器运行时所需的程序，同时包含一些为运行时准备的配置参数，无法更改 镜像的获取 根据 Dockerfile 构建镜像，配合 sh 脚本实现一些定制的初始化和参数判断逻辑，可重建 根据容器构建镜像，在只读镜像上操作可写容器重新打包成镜像，Docker 无状态，volume 不会打包进镜像，较少使用 从远程 Registry 拉取镜像 123456# 从远程 registry 拉取docker commit wonderful_mendeleev janhen/centos-vim-gcc:1.0.0# 从 Dockerfile 构建docker build -t janhen/myimage:1.0 .# 从容器创建docker pull &lt;registry_host&gt;/&lt;username OR project_name&gt;/&lt;image_name&gt;:&lt;image_tag&gt; 镜像 tag 1234# image 的查、交互docker imagesdocker history &lt;image_id&gt;docker tag &lt;image_old_name&gt; &lt;image_new_name&gt; 镜像清理 处理同一个版本多次覆盖，默认查找顺序为 Local -&gt; Registry 的问题 1234567# 删除指定的 imagedocker rmi &lt;image_id OR image_name&gt;# 强制删除指定|全部 imagedocker rmi -f $(docker images)# 删除 &lt;none&gt; 的镜像(#)docker rmi $(docker images -f &quot;dangling=true&quot; -q)docker images | grep none | awk &#x27;&#123;print $3&#125;&#x27; | xargs docker rmi 容器 是镜像运行时的实体，构建在镜像上，可对容器进行写操作 Container 的启动并运行 单机上使用最多，控制部署时候的各种参数，包含网络、存储、密码、变量… 常用的启动指定： 指定网络，根据需要选择端口转发、单机桥接网络、多机网络、主机网络 指定文件映射，将程序中的配置文件、数据文件隔离出来，避免应容器销毁而丢失 指定命令，内部运行的程序自带的命令，如 Redis 中的命令控制持久化方式… 指定变量，通过命令方式、环境变量方式指定，让运行容器更加定制化 1234567891011121314151617181920212223242526# 容器的运行# --name: 按照特定名称启动，作为容器标识# -d: 后台运行# -i: 交互式运行容器，打开STDIN，用于控制台交互 # -t: 终端方式交互, 通过 bash、shell... 进行命令式交互# -p: 映射宿主机与容器的端口号# --network=&lt;value&gt;: 指定网络连接类(#)# -v: 进行宿主机文件与容器文件的映射(#)# --&lt;param&gt;=&lt;value&gt;: 进行特定参数指定，传入中的参数，在容器中的文件处可引用# -e: 指定环境变量, 对应镜像提供，与 Dockerfile 中指定的 ENV 等同，可进入容器使用 env 查看(#)# --privileged=true: 给容器扩展的权限# --rm: 在容器终止运行后自动删除容器文件，避免磁盘浪费，常用于测试# --restart=&lt;strategy&gt;: 重启策略，与 --rm 参数冲突，提供多种策略# --entrypoint: 覆盖默认镜像的 ENTRYPOINT# --link: 添加链接到另一个 container, 不建议使用# -w: 指定工作目录，等价于 Dockerfile 中的 WORKDIR# 启动过后执行一段 Shell 脚本, 用于测试环境类镜像使用docker run ubuntu:18.04 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;# 以命令行方式进入容器，查看镜像具体情况docker run -it --entrypoint bash openjdk:7-jre # Dockerfile 中环境变量配合运行指定 JVM 运行参数、运行端口，参数名仿照 spring-boot maven 插件docker run -d -p 7070:7070 -e JVM_OPTS=&quot;-Xms1024m -Xmx2048m&quot; -e PROGRAM_ARGS=&quot;--server.port=7070&quot; com.blinkfox/web-demo:1.0.0docker run -e &quot;JAVA_OPTS=-agentlib:jdwp=transport=dt_socket,address=5005,server=y,suspend=n&quot; -p 8080:8080 -p 5005:5005 -t springio/gs-spring-boot-dockerdocker run -d --name test1 \\ -e MYENV=AAAA \\ busybox /bin/sh -c &quot;while true;do sleep 3600;done&quot; 容器的信息查看 1234567891011121314151617181920# 容器整体信息查询docker infodocker info | grep &quot;Docker Root Dir&quot;docker ps [(-a)|(-aq)]?# 配置信息docker inspect &lt;container&gt;docker inspect -f &#123;&#123;xx.yy&#125;&#125; &lt;container&gt;# 交互，调试# 日志， -f ： follow log output，持续实时显示日志， -t:......# 命令交互# 在容器中执行特定命令# 日志查看docker logs &lt;contain_id OR container_name&gt;docker logs -f &lt;container_id OR container_name&gt;# 容器内部执行docker exec -it &lt;container_id&gt; bashdocker exec &lt;container_id&gt; ip adocker exec -it &lt;container_id OR container_name&gt; env# 运行信息docker stat &lt;container&gt; 容器基础命令 123456789# 容器的启、停docker container start|stop|restart &lt;container_id OR contaienr_name&gt;# 导入导出# 导出容器成指定的 tar 包# 容器快照文件导入为*镜像*# URL/目录导入docker export 7691a814370e &gt; ubuntu.tarcat ubuntu.tar | docker import - test/ubuntu:v1.0docker import http://example.com/exampleimage.tgz example/imagerepo 容器的清理 12345678# 删除|强制删除指定的容器docker container rm &lt;container_id OR container_name&gt;docker contaienr rm -f &lt;container_id OR container_name&gt;# 删除所有容器docker rm $(docker ps -aq)docker rm -f $(docker ps -aq)# 删除已停止运行的容器(#)docker rm $(docker ps -f &quot;status=exited&quot; -q) Container 交互 容器内部可执行的命令，特定目录存储的配置内容，可以通过 CLI 的监控命令 支持更改 /etc/hosts， /etc/hostname，/etc/resolv.conf ，只针对运行时，临时的更改 几种交互方式： 运行时直接进入交互、运行时直接执行命令交互，包含对文件的操作、内部命令执行 运行后按特定终端进入交互、运行后按特定命令交互，同上 日志交互，logs，支持最后几行、最近的时间点、实时显示 基本情况，inspect，返回运行情况 JSON 字符串，可通过 Go Templete 获取特定情况 运行的资源情况，stats，实时显示 CPU、内存、网络、磁盘情况 1234567891011121314151617181920212223242526272829303132# 进入容器内部docker exec -it -u root jenkins sh# 执行特定命令# 创建之后执行# 在已运行的容器中执行命令docker run -it --rm ubuntu:18.04 ip adocker run -it --rm ubuntu:18.04 --hostname=test.com --dns=172.16.3.3 ip adocker run -it --rm ubuntu:18.04 cat /etc/resolv.confdocker exec -it gitlab cat /etc/resolv.confdocker exec -it gitlab cat /etc/hostnamedocker exec -it gitlab cat /etc/hosts# 容器内部执行# 查看挂载情况# 查看定义的环境变量# 查看 dns 情况, 与在宿主机上的 /etc/docker/daemon.json 上配置 dns 类似?# 查看容器IP地址配置# 查看路由情况mountenvcat /etc/resolv.confip addr show eth0ip route# logs 查看# 特定时间偏移, 特定时间段docker logs -f -t --since=40m --tail=10 jenkinsdocker logs -t --since=&quot;2019-08-01T13:23:37&quot; --until &quot;2018-08-31T12:23:37&quot; jenkins# inpect 查看docker inspect -f &#x27;&#123;&#123;.State.Pid&#125;&#125;&#x27; 1f1f4c1f931a# stat 查看docker stats &lt;container_id OR container_name&gt;# 拷贝文件，作为 Dockerfile 中 COPY 的...docker cp &lt;host_machine file OR dir&gt; &lt;container_name&gt;:&lt;container_dir&gt; Registry Docker 的私有仓库，实现容器的复用共享 发布镜像到 Registry 的方式： 发布镜像到仓库 直接将本地已经构建好的镜像发布到仓库中 根据指定 Dockerfile 由 Docker hub 进行构建形成镜像 自动在 git 发生变化的时候拉取数据进行构建重新发布到仓库上，自动构建发布，CICD 保证镜像的可再生性 私有 Registry 搭建： 官方提供的 registry Vmware 开源的 harbor，见 工具与环境 123456789# 登录 docker hub 账号和密码# 推送镜像到 docker hub# docker hub 关联 github or bitbucketdocker login 172.17.11.29:5111 -u admin -p Harbor12345# 重命名镜像的名称(tag)docker push 172.17.11.29:5111/centos-vim-gcc:1.0.0docker tag janhen/centos-vim-gcc:1.0.0 172.17.11.29:5111/study-docker/centos-vim-gcc:1.0.0docker push 172.17.11.29:5111/study-docker/centos-vim-gcc:1.0.0 Docker 网络 进行容器之间的访问，包含单机上的访问，多台机器之间的访问； 含端口映射、容器互联 关联文档: 使用网络 | 高级网络配置 Linux 上网络访问 Linux 网络命名空间，进行网络的隔离 Veth pair： 进行网络命名空间的连接，实现两个 net namspce 连接通信 12345678910# 网络命名空间# ip link# 给命名空间分配 ip 地址, 默认情况下只有 mac 地址# 启动接口# 连接双方使其网络互通ip netns listip netns delete test1ip netns exec test2 ip linkip netns exec testl ip link set dev veth-testl upip netns exec testz ip link set dev veth-test2 up Docker 网络访问 通过link 方式实现容器之间的访问，直接通过名称而非 IP，适用于单台机器 一个容器对应一个网络空间 类似局域网连接，通过中间的交换机实现两个容器之间的通信， docker0 的内网指定默认为 172.17.0/16，自定义为 172.17.18.0/16… 访问外部网络，需要经过 NAT 转换 12345678910# 查看容器网络， bridge 网络docker network lssudo docker network inspect &lt;network_id OR network_name&gt;ip ayum install bridge-utils# 展示系统当前桥接brctl showip a# 创建指定类型的网络docker network create -d bridge net-my Docker link 网络连接 通过命名 Docker 进行相连，类似网络命名空间中的 Veth pair，目前不推荐使用 命令格式： –link : 替代方案： docker-compose.yml 中使用 depends_on，使用 overlay 网络 123456789101112# 类似给 net-test2 添加 DNS 记录# link 方向性; 使用少docker run -d --name net-test2 \\ --link net-test1 busybox \\ /bin/sh -c &quot;while true; do sleep 3600; done&quot;docker exec -it net-test2 /bin/sh ip a ping net-test1# -d 指定网络类型， bridge|overlaydocker network create -d bridge net-mydocker run -it --rm --name busybox1 --network my-net busybox shdocker run -it --rm --name busybox2 --network my-net busybox sh 12345678910111213# --link &lt;name&gt; 支持通过名称访问容器 docker run -d --name flask-redis \\ -p 5000:5000 \\ --link redis \\ -e REDIS_HOST=redis \\ janhen/flask-redis docker run -d --name test1 \\ -e PENG=testt1 \\ busybox docker run -d --name test2 \\ -e PENG=testest \\ busybox \\ /bin/sh -c &quot;while true; do sleep 3600; done&quot; 自定义网络连接 避免使用 –link 进行容器之间网络的连接 1dockernetwork create -d bridge net-demo Docker 单机网络Docker bridge 网络 可以创建自己的桥接网络，进行区分，docker-compose 默认管理的容器共享同一个 bridge 网络 12345678# 创建自己的桥接网络docker network create -d bridge my-bridgedocker network lsbrctl showdocker run -d \\ -- name net-test3 \\ --network my-bridge busybox /bin/sh -c &quot;while true; do sleep 3600; done&quot;docker network connect mybridge net-test2 bridge 性能一般，对性能要求较高，可使用个 SR-IOV 网卡嵌入容器内。 Docker host 和 none网络 none 网络： 不会有网络信息，孤立的网络，用来做私有的工具，如保存密码??，使用场景少 host 网络：无网络信息，与主机共享网络命名空间，存在端口冲突问题 1docker run -d -p 80:80 nginx Docker 多机网络 实现多个不同机器之间的容器进行通信 Overlay 网络 依赖一个分布式存储，保存对应的 IP，防止网络(172.18.0.0/16)、容器名称等的冲突 实现 Docker 的多机网络，见 [Internel 访问](#Internel 访问) 两台机器之间可以相互通信，为了实现不同容器之间的通信需要借助第三方的分布式存储 使用etcd 建立的 cluster 中容器名称不允许重复、Ip 地址不允许重复 1234567891011121314151617# 创建 overlay 网络，实现多态主机之间的同步创建 overlay 网络docker network lsdocker netword create -d overlay net-overlay-demo# 查看网络情况，子网范围，容器情况docker network inspect net-overlay-demo# 启动容器指定到 overlay 网络docker run -d --name node1-test1 \\ --net net-overlay-demo \\ busybox sh -c &quot;while true; do sleep 3600; done&quot;docker run -d --name node2-test1 \\ --net net-overlay-demo \\ busybox sh -c &quot;while true; do sleep 3600; done&quot;# 查看节点上容器的地址# 查看 cluster 中网络的情况docker exec node1-test1 ip adocker exec node2-test1 ip adocker network inspect net-overlay-demo Etcd 分布式存储 存储分布式系统中的 key-val，开源免费，保证 overlay 网络中分配的容器与容器对应的IP地址在整个网络中唯一 关联： GitHub 1234567891011121314151617# 在对应的两台机器上安装 etcd，容器安装/binary 安装# 通过命令指定好集群启动# 验证 cluster 的运行情况# 进入 etcd 文件夹执行健康检查，两台机器同时执行./etcdctl cluster-health# 关闭 Docker 服务# 使用 etcd 作为分布式存储启动 docker， 手动启动 dockerd 守护进程# 验证systemctl stop dockersudo /usr/bin/dockerd -H tcp://0.0.0.0:2375 \\ -H unix://var/run/docker.sock \\ --cluster-store=etcd://192.168.xx.xx:2379 \\ --cluster-advertise=192.168.xx.xx:2375 &amp; docker version Docker 持久化 将容器与数据存储隔离开，如 Mysql 运行程序与数据保存位置 两种持久化的方式： 本地 FS 的 Volumn 基于 plugin 的 Volume， 如 NAS 本机上三种持久化实现, -mount 选项选择数据卷： bind :挂载在 Linux FS 中任意位置 volume：统一挂载在 daemon 设置的 docker 目录下，默认为 /var/lib/docker/volumes/&lt;unique_str_id OR volume_name&gt; tmpfs： 只挂载在内存中，易丢失 使用命令: 12345678docker volume create -d local testdocker volume inspect &lt;contaienr&gt;# 清理docker volume prune &lt;&gt;docker volume rm &lt;&gt;docker run -d --mount type=bind, source=/data, destination=/redis/data xxxx# 指定 :ro 容器无法对挂载数据卷内的数据进行修改docker run -d -v /webapp:/opt/webapp:ro 数据卷容器 实现多个容器操作数据，任意容器修改都可被其他容器看到 –volumes-from 参数所挂载的数据卷容器无需处在运行状态 1docker run -d --volumes-from dbdata xxx Volume 通过 Dockerfile 中的 Volumn 控制，在宿主机上 docker 文件下建立目录存放文件 建议 -v 参数指定在 docker 目录下 volume 的名称，默认为 /var/lib/docker/volumes/&lt;-v_name OR long_str&gt; 针对官方镜像，到 Docker Hub 上查看对应的 volume 挂载目录位置 1234567891011121314# 创建 volume，查看所有|指定|删除volumedocker volume create volume1docker volume lsdocker volume inspect volume1docker volume rm volume2# 运行-&gt;删除-&gt;验证docker run -d -v mysql1:/var/lib/mysql \\ --name mysql1 \\ -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql docker rm -f mysql1 mysql2docker run -d -v mysql1:/var/lib/mysql --name mysql1 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql docker exec -it mysql2 /bin/bash mysql -u root show databases; Bind Mouting 指定容器目录与宿主机目录绑定，宿主机文件更改影响到容器中的运行 可以实现本台电脑 –&gt; 虚拟机 –&gt; 容器三者的目录映射 1234# -v: &lt;宿主机目录&gt;:&lt;容器目录&gt; 进行一一映射docker run -d -v $(pwd):/usr/share/nginx/html -p 80:80 --name web janhen/my-nginx# 使用 Docker 作为本地开发环境docker run -d -p 80:5000 --name flask janhen/flask-skeleton Dockerfile 编写 用于生成 Docker Image 的文件，一般只用于 docker build -t janhen/xx:99 . 命令执行使用 关联： Dockerfile 指令 语法Dockerfile 的基本语法 FROM,WORKDIR,ENV,COPY,ADD RUN,CMD,ENTRYPOINT VOLUME,EXPOSE FROM： 根据特定的镜像制作，从头制作、 根据指定环境制作、某个镜像作为构建阶段使用 RUN ： 运行命令脚本, 可以通过此安装一些环境并对环境进行配置，如安装 Node 环境，每运行一个命令增加一层 ==&gt; 建议将多个命令合并成一个命令使用 WORKDIR： 设定当前工作目录, 类似 cd 改变目录, 没有目录自动创建(#) 直接通过绝对路径定位 通过绝对路径+相对路径定位目录 ADD and COPY： 将本地文件添加到 docker image 中,常 配合 WORKDIR 使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748FROM python:3.7# LABEL 镜像的 metadata，帮助信息LABEL maintainer=&quot;janhen &lt;ipaam414@gmail.com&gt;&quot;RUN yum update &amp;&amp; yum install -y vim \\ python-devRUN apt-get update &amp;&amp; apt-get install -y perl \\ pwgen --no-install-recommends &amp;&amp; rm -rf \\ /var/lib/apt/lists/*RUN /bin/bash -c &#x27;source $HOME/.bashrc;echo $HOME&#x27;WORKDIR /rootWORKDIR /testWORKDIR demoRUN pwdADD hello /ADD test.tar.gz /WORKDIR /rootADD hello test/COPY hello test/# ENV 设定环境变量, 建议使用ENV MYSQL_VERSION 5.6RUN apt-get install -y mysql-server = &quot;$&#123;MYSQL_VERSION&#125;&quot; \\ &amp;&amp; rm -rf /var/lib/apt/lists/*# CMD# 设置容器启动后默认执行的命令和参数# docker run 指定其他命令, CMD 被忽略# 定义多个 CMD，只运行最后一个docker run [image] # CMD 会被执行docker run -it [image] /bin/bash # CMD 不会执行CMD [&quot;mongod&quot;]# ENTRYPOINT# 设置容器启动时运行的命令# 容器以应用程序/服务的形式运行# 不会被忽略, 一定会执行# 最佳实践: 通过 shell 脚本作为 entrypoint COPY docker-entrypoint.sh /usr/local/bin/ # 添加到容器中ENTRYPOINT [&quot;docker-entrypoint.sh&quot;] # 指定入口脚本EXPOSE 27017ENTRYPOINT [&quot;scripts/dev.sh&quot;]# 进行宿主机与容器中文件的映射# 映射容器中的 /tmp 到宿主机上，默认在 /var/lib/docker/volumes/&lt;long_id OR name&gt; 下建立对应的映射VOLUME /tmp 命令格式 不同的命令执行写法，以及对应的区别 Shell 格式, 默认通过 shell 执行 Exec 格式, ENTRYPOINT [“/bin/bash”, “-c”, “echo”, “hello $name”] 针对 Exec 无法映射变量问题的处理： 通过命令方式编写语句 12ENV name DockerENTRYPOINT [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo&quot;, &quot;hello $name&quot;] 命令区别 1、RUN、CMD和ENTRYPOINT命令区别 RUN 运行在 image 的构建阶段执行，执行结果会被打包进 image 文件 CMD 在容器启动后执行，可用于在容器内启动某个服务、进程，只可使用一次，与 run 中年执行命令冲突 ENTRYPOINT 在容器启动后执行，出现多行不会忽略，一定执行，通常配合 COPY 到容器中的 sh 脚本使用 2、COPY 与 ADD 命令区别 ADD 可以获取网络资源，可以直接解压缩 注意事项 1、CMD 的最后一次有效性 官方镜像中大多最后运行 CMD，方便覆盖实现定制化的参数的启动 2、目录 COPY . /app 与 COPY . /app/ 映射不同 Docker Compose 多容器管理，通过 yml 配置管理容器之间的依赖关系，底层 python 编写，前身为开源的 Fig 项目。主要用于本地开发使用。 关联文档：Compose 模板文件 | Doc 管理 docker-compose 的启动、停止、交互 123456789101112131415161718# compose 后台启动# 启动并查看日志docker-compose updocker-compose up -ddocker-compose -f &lt;compose_name&gt; up -d # 停止服务# 停止并删除 容器、网络、volumesdocker-compose stop &lt;service&gt;docker-compose down &lt;service&gt;docker-compose build# compose 查看运行情况，状态、端口情况# 查看 compose 中定义容器使用的 imagesdocker-compose psdocker-compose images# 进入 compose 中的 servicedocker-compose exec mysql bash# 扩展docker-compose scale &lt;service_name&gt;=&lt;count&gt; service 的扩展 实现水平扩展，负载均衡，在不存在端口冲突的情况下通过 haproxy 进行负载均衡，在 Docker Swarm 运行时可直接通过 deploy 中的参数指定复制扩展的个数 通过 docker-compose scale 命令进行扩展 处理 scale 中端口映射重复问题 在 docker-compose 中增加 dockercloud/haproxy 进行负载均衡 12345678docker-compose up -d# 启动时指定扩展docker-compose up --scale web=3 -d# 运行后进行扩展docker-compose scale web=4# 验证扩展情况docker-compose psfor i in `seq 10`; do curl 127.0.0.1:8080; done 语法 对应 docker-compose.yml 文件的语法 三大实体： service: 服务 networks: 网络指定，指定网络类型，一般为 bridge、overlay，根据需要指定多个网络，进行一定的隔离 volumes: 进行数据卷的映射 image 获取方式： 通过 image 获取本地的或是拉取远程的，或者通过 build 进行构建，传入 Dockerfile 的目录以及对应的 Dockerfile 名称 ports: 进行宿主端口与容器端口的映射 depends_on: 解决容器的依赖，启动先后问题 links: 服务之间的依赖关系，在容器内部可以直接使用依赖服务名称对应的 IP 地址，不建议使用 deploy: 进行部署，控制集群中的各种情况，用于 Docker swarm，version 3 支持 12345678910111213141516# 特定片段参考# 设置网络, 可多个# frontend, backend 前后端设置networks: - frontend - backend# 端口设置# 直接引号设置# 宿主机与容器端口映射ports: - &quot;6379&quot;ports: - 5000:80# 依赖depends_on: - mysql Docker Swarm Docker 自带的服务编排框架，大多数都由其中的 Manager 做管理，较难定制，不适合太多节点的部署 Docker Swarm 特点： 符合传统IT的管理模式 平台本身集成性好，可当成云管平台使用 内置太多不易进行定制化，不好 Debug，不易干预 不提供存储选项：Docker Swarm不提供将容器连接到存储的无障碍方式，其数据量需要在主机和手动配置上进行大量即兴创作 监控不良：Docker Swarm提供有关容器的基本信息，如果您正在寻找基本的监控解决方案，那么Stats命令就足够了。如果您正在寻找高级监控，那么Docker Swarm永远不是一个选择。虽然有像CAdvisor这样的第三方工具可以提供更多监控，但使用Docker本身实时收集有关容器的更多数据是不可行的。 Swarm 架构 Raft consensus group： 进行控制分布式场景下的协商: 内置的分布式的存储数据库，通过 Raft 协议进行同步，包含 Leader 选举、Log 复制 Internel distributed state store： 分布式存储数据库，功能如保证分布式场景下 Ip 等唯一，类似 etcd Manager: 可以保存 Raft 关联的文件，用于 Secret 实现 Worker: 主要运行容器，通过 Gossip network 进行通信，保证分布式下的一致性 Gossip network： 各个 Worker 之间同步实现的协议 扩展： Service: 通过 swam manager 进行控制，具体 service 部署到哪个 node 上 Replicas： 一个 Service 对应多个 Replicas，用于扩展 集群搭建管理 让几台服务器搭建成一个 Swarm Cluster 1234567891011# 配置 Manager Nodedocker swarm init --advertise-addr=192.169.xx.xx# 配置 Worker Node 加入到特定的 Manager Nodedocker swarm join --token xxxfsdfsdf &lt;ip&gt;:&lt;port&gt;# 查看当前 Node 情况# 节点查看# 节点降级docker node ls docker node inspect &lt;node_name&gt;docker node demote &lt;node_name&gt;docker node ps Swarm管理Swarm Services 管理 单个 Service 的管理，一个 Service 可扩展到多个 cluster node 上的 Container 运行 123456789101112131415161718192021222324# 创建容器，运行位置有 mananger 进行控制运行在哪个节点上# 类似 docker run 命令，在本地创建 container# 查看 service 情况# MODE: replicated# REPLICAS: 1/1 支持水平扩展，类似 docker compose 中的 scale# 查看具体的 service 情况# 运行在哪个节点上# 扩展servie，通过复制的方式(#) docker service create --name demo busybox \\ sh -c &quot;while true; do sleep 3600; done&quot;docker service lsdocker service ps demodocker service scale demo=5docker service ps demo # 本机查看 docker 容器运行# 强制删除某个正在运行中的容器# 集群自动恢复，确保一定数目的 scale 扩展有效，系统稳定运行时# 显示节点中容器运行情况# 删除服务，对应的集群节点容器删除docker psdocker rm -f e64432docker service lsdocker service ps demodocker service rm demo RoutingMesh Swarm 网络通信原理，管理集群服务间的通信，访问集群中任何一个节点特定端口都会被重定向到实际运行服务的节点上 DNS 服务发现，单机情况下可以通过 service 的名称进行相互访问，多机情况下通过 swarm 进行相互访问 VIP： 非真实机器的IP地址，避免多个IP地址变化问题，造成系统运行不稳定，一个 service 对应一个 LVS： 根据虚拟 IP 找出容器中的具体的 IP 地址 两种体现： Internel：容器之间通过 overlay 网络访问 Ingress ：服务绑定接口的情况，此服务通过任意 Swarm 节点对应接口访问 Internel 访问 容器间实现相互访问，通过 overlay 网络实现，实现 service 与 service 之间的通信 whoami 镜像： 提供 web 服务，访问 8000 端口，返回 container 的 hostname 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# 创建 overlay 网络# 创建 whoami 服务# 后台运行# 端口映射# 网络指定# 查看所有 service # 查看 whoami 服务运行位置# 到对应机器上验证docker network create -d overlay net-demodocker service create -d \\ --name whoami \\ -p 8000:8000 \\ --network net-demo jwilder/whoamidocker service lsdocker service ps whoamidocker pscurl 127.0.0.1:8000# 创建 busybox 的容器# 连接到同一个 overlay 网络# 查看所有服务，当前 busybox service 是否启动完成# 查看服务 client 服务具体位置# 进入对应的机器查看对应运行的 container# 进入容器# 10.0.0.7 IP 地址，为虚拟 IP， 将 whoiam 通过 scale 扩展# 通过 scale 进行扩展 whoami # 查看 whoami 位置，并进入# 进入对应 client contaienr 中# 连接 whoami # 查询 dns，只有一个虚拟IP 10.0.0.7# 进入容器 whoami 查看网络地址# 进入容器 whoami(另一) 查看网络地址# 进入容器 client# 查看 task.whoami，返回对应的多个节点，为真实的 IP 地址（#）docker service create -d \\ --name client \\ --network net-demo busybox \\ sh -c &quot;while true; do sleep 3600; done&quot;docker service lsdocker service ps clientdocker psdocerer exec -it &lt;container_id&gt; sh ping whoami docker service scale whoami=2 docker service ps whoamidocker service ps clientdocker exec -it &lt;container_client_id&gt; sh ping whoami nslookup whoamidocker exec 5b79 ip adocker exec df9 ip adocerk exec -it &lt;container_client_id&gt; sh nslookup task.whoami# 扩展 whoami 服务# 查案 client 对应的 task.whoami，显示三个对应的(whoami)IP 地址# ==&gt; 虚拟IP: 不会随 service 的扩展而变化, 包括增加、减少、机器之间的迁移不会变化(#)# 访问多次服务 whoami，相应的对应机器上的容器会因为负载均衡而不同，通过 LVS 实现docker service scale whoami=3docker service ps whoami--- nslookup task.whoami wget whoami:8000 more index.html rm -rf index.html wget whoami:8000 两种体现： Internal: 容器键通过 overlay 网络(VIP)访问 Ingress: 服务绑定接口, 通过任意 swarm 节点的接口访问’ DNS + VIP + iptables + LVS 实现的过程图： // todo 具体 Swarm 网络中数据的流动情况 小结： 容器之间连接到 overlay 网络进行通信，service 之间的通信通过 VIP + LVS 实现 Ingress 负载均衡 绑定端口实现的容器之间的访问，通过 : 直接访问服务 作用体现：集群中的 Node 对应的端口提供相同的服务，即使 Node 本地无服务也支持访问 Ingress Network 的数据包走向图 在 IPTables + IPVS 发往目的网络 12345678910111213141516# 常看网络桥接情况# 查看机器的网络命令空间# 进入 ingress_sbox 网络命名空间iptablesbrctl showsudo ls /var/run/docker/netnssudo nsenter --net=/var/run/docker/netns/ingress_sboxip aiptables -nL -t mangle# 安装 LVS 管理工具# # 查看 LVS 情况，展示可选的服务 IP 地址，展示机器的 weight, yum install ipvsadmsudo nsenter --net=/var/run/docker/netns/ingress_sboxiptables -nL -t mangleipvsadm -l Docker Stack 部署 进行多服务部署，可以使用 docker-compose.yml ，只能用于 swarm cluster，无法用于其他的服务编排框架 docker-compose.yml 文件更改 compose file version 3: 增加 deploy 命令，具体参数如下 1234567891011121314151617181920212223242526# deploy# endpoint_mode: vip 模式(默认), dnsrr 模式 循环访问(少用)# labels: 帮助描述信息# mode: global, replicated， global 全局唯一, 无法通过 scale 横向扩展，一般外部服务使用此种方式，如 mysql,nginx,redis等； replicated 默认，可通过复制来进行扩展# placement: # constraint: # - node.role == manager # 限制部署到 manager 节点上# preferences: 优先喜好# -# replicas: 在 mod 是 replicated 的时候定义初始化时候需要的 replicas# resources: 进行资源的限制# limits:# cpus: &#x27;0.50&#x27; # CPU 使用限制# memeory: 50M # 内存使用限制# reservations: # 优先保留，最小的情况# cpus: &#x27;0.25&#x27;# memory: 20M# restart_policy: # 容器宕机后的处理# conditon: on-failure # 什么情况下重启# delay: 5s # 延迟# max_attempts: 3 # 最大重试次数# window: 120s# update_config: # service 更新的配置# parallelism: 2# delay: 10s# order: stop-first 部署的过程： 更改单机的 docker-compose.yml 为对应 cluster 部署(deploy) 按条件执行命令： 如下 验证： 通过访问任意一个 cluster 中的地址即可访问 12345678910# 整个 application 定义为一个 stack 为 wordpress# 可通过 -c=docker-compose.yml 进行简化# 查看运行情况# mysql: 限制只运行一个，只能运行在 manager 节点# 通过 stack 查看服务情况docker stack deploy wordpress --compose-file=docker-compose.ymldocker stack lsdocker stack ps wordpressdocker stack services wordpressdocker stack rm wordpress Docker Secret 管理 对一些密码进行管理， 处理 docker-compose.yml 中存储密码不安全问题，借助内部分布式存储数据库控制，只作用于 Docker Swarm 关联： Doc-CLI Secret 类型： username password， SSH key, TLS 认证，不想让人看到的数据 生产环境至少要两个 Manager，分布式存储的天然加密环境 Secret 的管理： 将 Secret 存储在 Manager 中的分布式存储中的 Raft Database Secret 给某个 service 指派 Service 基本使用 Secret 的创建方式：文件方式、输入方式。 存放在容器中的 /run/secrets/&lt;secret_file_name&gt; 文件中 123456789101112131415161718192021222324252627282930313233# 按文件方式进行创建# 删除文件，保证安全性# 查看 secret# 借助管道按照输入方式创建 secretvim passworddocker secret create my-file-pw passwordrm -rf passworddocker secret lsecho &quot;mypassword&quot; | docker secret create my-input-pwdocker secret rm my-input-pw# 通过 swarm service 创建过程中指定 secret 进行使用# 进入容器查看指定目录，找到 manager 通过 Raft Database 保存的 secretdocker service create -d --name client \\ --secret my-file-pw busybox \\ sh -c &quot;while true; do sleep 3600; done&quot;docker service ls docker service ps clientdocker psdocker exec -it &lt;client_container_id&gt; sh cd /run/secrets/ ls cat my-file-pw # 原文# 实际使用# 在创建 service 的时候指定好 secret，并在环境变量中指定在容器中的位置docker service create -d --name db \\ --secret my-file-pw \\ -e MYSQL_ROOT_PASSWORD_FILE=/run/secrets/my-file-pw mysqldocker service ps db--docker exec -it &lt;db_container_id&gt; shls /run/secretscat /run/secrets/my-file-pwmysql -u root -p 在 Stack 中的使用 在服务配置下增加 secrets，指定对应的 Secret 对应的密码参数使用指定的 secrets 在容器中的位置 可以连通创建 secret 一起使用，不建议 12345# -c 简化 --compose-file # 查看服务是否全部启动完成docker stack deploy wordpress \\ -c=docker-compose.ymldocker stack services wordpress Docker Service 更新 在运行过程中对 service 依赖的镜像进行升级，实现升级过程中不会中断原来的服务 单 Service 更新进行 service 的更新，不会暂停运行的项目 @Q: 存在一段时间有 1.0和2.0并存的情况，如何处理?? 12345678910111213141516171819# 创建 overlay 网络，启动服务# 等待服务启动完毕docker network create -d overlay net-demodocker network lsdocker service create -d --name web \\ --publish 8080:5000 \\ --network net-demo janhen/python-flask-demo:1.0.0docker service ps web# 扩展服务# 检查服务运行情况# 编写测试脚本方便验证docker service scale web=2docker service ps webcurl 127.0.0.1:8080sh -c &quot;while true; do curl 127.0.0.1:8080&amp;&amp;sleep 1; done&quot;# 更新镜像，一般通过 Dockerfile 进行构建，指定对应更新的版本，发布到私有 registry# 运行环境拉取镜像，执行更新命令docker service update --image janehn/python-plask-demo:2.0.0 web 12345# 更新镜像并设置参数, 覆盖 docker-compose.ymldocker service update --image westos.org/game2048 \\ --update-parallelism 10 \\ --update-delay 10s \\ nginx 端口更新 对 service 与宿主机的端口映射进行更改 删除掉原来的端口映射，无法做到更新时业务不中断，通过 VIP + 端口实现原理导致的 12docker service update --publish-rm 8080:500 \\ --publish-add 8088:5000 web Stack 更新 更改 Swarm Cluster 中多个容器中对于镜像、网络、部署配置的更新，关联 .deploy.update_config 下的配置 可更改 docker-compose.yml 中 deploy 下的 update_config 控制更新时的细节，允许几个 scale 进行更新，延迟信息。。。 第一次通过 deploy 进行启动进行了多 service 的部署 第二次通过 deploy 部署时，自动检测到 docker-compose.yml 的变化，进行更新 1docker stack deploy wordpress --compose-file docker-compose.yml Docker Swarm 监控 实现对 Docker Swarm Cluster 中运行节点上容器的监控 CAdvisor+InfluxDB+Grafana docker swarm集群的监控方案，开源免费 cAdvisor：数据收集模块，需要部署在集群中的每一个节点上，当然前提条件是节点接受task。 InfluxDB：数据存储模块 Grafana：数据展示模块 Docker Universal Control Plane(UCP) docker原厂的可视化集群管理GUI，企业级的，只支持docker EE portainer 在集群中部署portainer的service，只能被调度给manager角色的节点 关联： Web 其他Daemon 配置 对容器的 dockerd 守护线程进行配置 关联： Configure the daemon dameon.json 配置文件编写： 源镜像地址配置 私有源非 Https 配置 Debug 模式开启 /etc/docker/daemon.json ip: 永久绑定到某个固定的 IP 地址 bridge： 将 Docker 默认桥接到创建的网桥上 1234567891011121314151617181920&#123; &quot;registry-mirrors&quot;: [ &quot;https://dockerhub.azk8s.cn&quot;, &quot;https://reg-mirror.qiniu.com&quot; ], &quot;insecure-registries&quot;: [ &quot;172.17.11.29:80&quot;, &quot;172.17.11.29:5111&quot;, &quot;192.168.205.23:80&quot;, &quot;192.168.205.23:5111&quot;, &quot;172.17.10.150:80&quot; ], &quot;debug&quot;: false, &quot;dns&quot; : [ &quot;114.114.114.114&quot;, &quot;8.8.8.8&quot; ], &quot;ip&quot;: &quot;0.0.0.0&quot;, &quot;bridge&quot;: &quot;bridge-my&quot;&#125; 12345# 更改后使其生效sudo systemctl daemon-reloadsudo systemctl restart docker.servicesudo systemctl status docker -lsudo docker info 设置运行时目录，存储驱动 设置 Http/Https 代理 加快拉取国外访问、处理国内制作镜像无法访问国外资源问题 123456789101112131415161718# 添加配置mkdir -p /etc/systemd/system/docker.service.dvim /etc/systemd/system/docker.service.d/http-proxy.conf[Service] Environment=&quot;HTTP_PROXY=https://172.17.10.18:5720/&quot; &quot;NO_PROXY=localhost,127.0.0.1&quot;# 配置生效systemctl daemon-reloadsystemctl restart dockersystemctl show --property=Environment docker# 重置rm -f /etc/systemd/system/docker.service.d/http-proxy.confsystemctl daemon-reloadsystemctl restart dockersystemctl show --property=Environment docker Docker systemd http-proxy 监控与管理 人工进行容器的管理、监控、资源调整、故障排除，包括日志查看、容器实时运行情况、资源重分配，在无法使用或没有监控方案情况下使用 dockerd 支持 在发生故障后，通过设置 Docker 守护线程的一些参数方便调试 123456# 开启守护线程的 debug 模式，给出更多的信息提示dockerd --debug \\ --tls=true \\ --tlscert=/var/docker/server.pem \\ --tlskey=/var/docker/serverkey.pem \\ --host tcp://192.169.9.2:2376 容器的运行日志查看 使用 Go 模板尽心格式化日志输出 可使用日志驱动程序插件，企业版支持统一格式查看远程的日志，默认双重日志 Format command and log output 1234567docker container inspect --format &#x27;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&#x27; $&#123;CID&#125;# 获取某个镜像对应的全部容器docker container ls | grep &lt;image&gt; | awk &#x27;&#123;print $1&#125;docker inspect -f &#x27;&#123;&#123;.HostConfig.LogConfig.Type&#125;&#125;&#x27; &lt;CONTAINER&gt;docker logs -f &lt;container_id&gt;# 通过 Go 的模板语法进行格式化展示数据docker image ls --format &quot;&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;&quot; 容器日志 在 daemon 中的日志配置，根据实际需要进行优化，可选择日志插件 指定容器日志最大大小 20M 最大的文件个数 5 压缩， 开 容器的运行情况 通过 stats 实时查看容器的资源信息 123# 实时查看容器统计信息，CPU、内存、网络、磁盘docker stats 13b9203f9f0b d42877298134 44fb90cd2f2cdocker container stats --format &quot;table &#123;&#123;.Name&#125;&#125;\\t&#123;&#123;.CPUPerc&#125;&#125;\\t&#123;&#123;.MemUsage&#125;&#125;&quot; 容器的资源分配 容器使用多少宿主机的资源，可以通过 docker-compose.yml 中设置 123# 通过参数限定容器访问内存、CPUdocker run --help | grep cpu docker run --help | grep memory 容器可用性 容器支持重启，可以通过 --restart 指定重启策略，保证可用性 容器网络 1234# 查看所有网络docker network ls# 查看容器网络映射docker port nostalgic_morse 5000 .dockerignore 针对非 SpringBoot 项目，如前端项目需要忽略一些文件。 123.gitnode_modulesnpm-debug.log 默认的重要文件： /var/run/docker.sock /var/lib/docker/volumes/ Docker 卸载1234567891011121314151617181920212223# 停止并删除容器docker rm -f `docker ps -aq`# 删除安装yum list installed|grep docker yum -y remove docker-ce.x86_64 yum -y remove docker-ce-cli.x86_64 yum -y remove containerd.io.x86_64 # 所有镜像、Volume删除 # 删除 docker-compose rm -rf /var/lib/docker rm -rf /hdapp rm -rf /etc/docker rm -f /usr/local/bin/docker-compose # 测试卸载情况 yum list installed|grep docker # 删除 docker0 网卡 yum install bridge-utils ip link set dev docker0 down brctl delbr docker0 RefsDocker-guide: 中文的 GitBook 官方镜像示例： Docker Hub 中一些镜像的开源示例 play-with-docker ： 方便环境搭建， 保存 docker 4h，在网站上创建多个网络，进行互通访问 10分钟看懂Docker和K8S： 快速入门 docker学习笔记： 他人博客笔记 Docker – 从入门到实践 如何调试 Docker： 总结调试方法 关于对docker run –link的理解： Docker 桥接网络理解 工具和示例： Docker 相关工具 Dockerfile 最佳实践： 编写 Dockerfile 的一些建议 CentOS7.4—构建LVS+Keepalived高可用群集： LVS docker镜像操作： 容器制作、本地导入、镜像导出","tags":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"}]},{"title":"Arthas","date":"2020-12-17T13:10:57.000Z","path":"2020/12/17/Arthas/","text":"概述 Arthas 是Alibaba开源的Java诊断工具。 Github 当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决： 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到JVM的实时运行状态？ 怎么快速定位应用的热点，生成火焰图？ JVM 信息JVM 相关命令的 1.dashboard -&gt; thread -&gt; 3.jvm -&gt; 4.sysprop -&gt; 查看和修改JVM的系统属性 5.getstatic -&gt; 查看类的静态属性 dashboard 当前系统的实时数据面板 线程、内存、运行信息 thread 当前JVM 线程堆栈信息 -b: 找出持有锁的 -n: 根据 cpu 使用排序 -i: 指定时间间隔 –state : 过滤线程状态 使用最繁忙的 5个线程 1thread -i 2000 -n 5 查看指定线程堆栈 1thread &lt;id&gt; 查看特定状态的线程: RUNNABLE, TIMED_WAITING, WAITING, BLOCKED.. 12thread -i 2000 --state TIMED_WAITINGthread -i 2000 --state RUNNABLE jvm 查看当前JVM 的信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182 RUNTIME ------------------------------------------------------------------------------------------------------------------------------------ MACHINE-NAME 8@e57d77f3ad01 JVM-START-TIME 2020-12-10 19:38:01 MANAGEMENT-SPEC-VERSION 1.2 SPEC-NAME Java Virtual Machine Specification SPEC-VENDOR Oracle Corporation SPEC-VERSION 1.8 VM-NAME Java HotSpot(TM) 64-Bit Server VM VM-VENDOR Oracle Corporation VM-VERSION 25.11-b03 INPUT-ARGUMENTS -Xmx4096M -Xms4096M -Xmn1536M ... CLASS-PATH ... BOOT-CLASS-PATH ... ------------------------------------------------------------------------------------------------------------------------------------ CLASS-LOADING ------------------------------------------------------------------------------------------------------------------------------------ LOADED-CLASS-COUNT 34980 TOTAL-LOADED-CLASS-COUNT 46897 UNLOADED-CLASS-COUNT 11917 IS-VERBOSE false ------------------------------------------------------------------------------------------------------------------------------------ COMPILATION ------------------------------------------------------------------------------------------------------------------------------------ NAME HotSpot 64-Bit Tiered Compilers TOTAL-COMPILE-TIME 549939(ms) ------------------------------------------------------------------------------------------------------------------------------------ GARBAGE-COLLECTORS ------------------------------------------------------------------------------------------------------------------------------------ ParNew 5889/191768(ms) [count/time] ConcurrentMarkSweep 18/12942(ms) [count/time] ------------------------------------------------------------------------------------------------------------------------------------ MEMORY-MANAGERS ------------------------------------------------------------------------------------------------------------------------------------ CodeCacheManager Code Cache ... ------------------------------------------------------------------------------------------------------------------------------------ MEMORY ------------------------------------------------------------------------------------------------------------------------------------ HEAP-MEMORY-USAGE 4133945344(3.85 GiB)/4294967296(4.00 GiB)/4133945344(3.85 GiB)/289171584(275.78 MiB) [committed/init/max/used] NO-HEAP-MEMORY-USAGE 398196736(379.75 MiB)/2555904(2.44 MiB)/1862270976(1.73 GiB)/340835576(325.05 MiB) [committed/init/max/used] PENDING-FINALIZE-COUNT 0 ------------------------------------------------------------------------------------------------------------------------------------ OPERATING-SYSTEM ------------------------------------------------------------------------------------------------------------------------------------ OS Linux ARCH amd64 PROCESSORS-COUNT 6 LOAD-AVERAGE 0.35 VERSION 3.10.0-957.el7.x86_64 ------------------------------------------------------------------------------------------------------------------------------------ THREAD ------------------------------------------------------------------------------------------------------------------------------------ COUNT 99 DAEMON-COUNT 75 PEAK-COUNT 99 STARTED-COUNT 70889 DEADLOCK-COUNT 0 ------------------------------------------------------------------------------------------------------------------------------------ FILE-DESCRIPTOR ------------------------------------------------------------------------------------------------------------------------------------ MAX-FILE-DESCRIPTOR-COUNT 1048576 OPEN-FILE-DESCRIPTOR-COUNT 298 Affect(row-cnt:0) cost in 19 ms. sysprop 查看当前JVM的系统属性(System Property) 查看日志匹配，方便进行日志的收集查看日志文件位置，方便日志的查看查看执行的参数，SpringBoot 之后拼接的参数，方便定位自定义参数的实际指定情况查看 JVM 运行的时区，方便处理日志的时间问题查看运行时的版本，方便查看已知的 JDK bug 修复情况 123456sysprop FILE_LOG_PATTERNsysprop CONSOLE_LOG_PATTERsysprop LOG_FILEsysprop sun.java.commandsysprop user.timezonesysprop java.runtime.version getstatic 查看类的静态属性 , 推荐直接使用 ognl 命令 -c: 类加载器的 hash id -E: 开启正则表达式匹配，默认通配符匹配 &lt;class-pattern&gt; Class name pattern, use either ‘.’ or ‘/‘ as separator &lt;field-pattern&gt; Field name pattern &lt;express&gt; the content you want to watch, written by ognl 123456789getstatic com.janhen.SapConstants JOB_RUNNING_INTERVALfield: JOB_RUNNING_INTERVAL@Integer[2]Affect(row-cnt:1) cost in 331 ms.[arthas@8]$ getstatic com.janhen.SapConstants ALCNTC_INTERFACE_NOfield: ALCNTC_INTERFACE_NO@String[MD038]Affect(row-cnt:1) cost in 33 ms. 查看私有的静态变量 1getstatic org.springframework.amqp.rabbit.connection.CachingConnectionFactory DEFAULT_CHANNEL_CACHE_SIZE 查看集合信息 1getstatic org.springframework.amqp.rabbit.connection.CachingConnectionFactory txStarts 指定的 classloader 加载的类查看 12getstatic -c 73ad2d6 io.netty.channel.nio.NioEventLoop logger &#x27;getClass().getName()&#x27;field: logger 类加载sc 查看JVM已加载的类信息 各个字段的类型，以及访问标识符 父类信息、接口信息、类加载器信息、加载的来源文件 search-class -d, –details: Display the details of class -f, –field: Display all the member variables Class name pattern, use either ‘.’ or ‘/‘ as separato 1sc -df org.springframework.amqp.rabbit.connection.CachingConnectionFactory* sm 查看已加载类的方法信息 声明的类、 构造器、注解、参数、异常、类加载器 -c, –classloader The hash code of the special class’s classLoader -d, –details Display the details of method&lt;class-pattern&gt; Class name pattern, use either ‘.’ or ‘/‘ as separator&lt;method-pattern&gt; Method name pattern 1sm -d org.springframework.amqp.rabbit.connection.CachingConnectionFactory 查看具体的方法信息 1sm -d org.springframework.amqp.rabbit.connection.CachingConnectionFactory toString classloader 查看classloader的继承树，urls，类加载信息 12345678910111213 classloader name numberOfInstances loadedCountTotal org.springframework.boot.loader.LaunchedURLClassLoader 1 15617 java.net.URLClassLoader 1060 5560 BootstrapClassLoader 1 4535 java.net.FactoryURLClassLoader 2 1666 sun.reflect.DelegatingClassLoader 1406 1406 com.taobao.arthas.agent.ArthasClassloader 1 1116 sun.misc.Launcher$AppClassLoader 1 47 com.alibaba.fastjson.util.ASMClassLoader 1 13 sun.misc.Launcher$ExtClassLoader 1 10 org.apache.cxf.common.util.ASMHelper$TypeHelperClassLoader 1 6 Affect(row-cnt:10) cost in 330 ms. redefine 载入外部 .class，直接修改线上的代码，不能恢复 -c, –classloader classLoader hashcode .class file paths *ognl 执行ognl表达式， ognl命令实际上包含了getstatic的功能 查看Spring的配置 -c, –classLoader The hash code of the special class’s classLoader, default classLoader is SystemClassLoader. 查看 Spring 中运行时指定属性的值，先找到持有 ApplicationContext 的类对应的类加载器 12sc -df com.janhen.SpringContextUtil | grep classLoaderHashognl -c b1bc7ed &#x27;#spCtx=@com.janhen.SpringContextUtil@context,#spCtx.getEnvironment().getProperty(&quot;spring.redis.sentinel.nodes&quot;)&#x27; 设置静态属性值 一般由配置中心修改，防止 setstatic 不知道什么时候因为什么修改的应该无法更改 final 的静态变量 1ognl &#x27;#field=@demo.MathGame@class.getDeclaredField(&quot;random&quot;), #field.setAccessible(true), #field.set(null,null)&#x27; 替换方式实现： 可以写一个新的类，里面设置 static field的值。然后用 classloader 命令把这个新的类 load到JVM里再执行。 上传class到服务器上 redefine https://github.com/WangJi92/arthas-idea-plugin/issues/1 tt 记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测 -n &lt;count&gt;: 指定次数, 通过 -n 参数指定需要记录的次数，当达到记录次数时 Arthas 会主动中断tt命令的记录过程，避免人工操作无法停止的情况 1tt -t org.springframework.amqp.rabbit.connection.CachingConnectionFactory toString 监控与执行获取运行时的方法信息、返回信息、执行过程的耗时通过字节码增强技术实现，使用完成之后需要执行shutdown 或者 将增强过的类执行reset 命令。 monitor -c, –cycle The monitor interval (in seconds), 60 seconds by default Path and classname of Pattern Matching Method of Pattern Matching watch 查看方法参数 -n, –limits Threshold of execution times -b, –before Watch before invocation -x, –expand Expand level of object (1 by default) 查看入参对象(Object)以及返回对象(Set) 123456watch com.janhen.ConsumingRtnProcessor getBinAlreadyExistContainerBarcodes &quot;&#123;params, returnObj&#125;&quot; -b -x 2watch com.janhen.ConsumingRtnProcessor verifyContainer &quot;&#123;params, returnObj&#125;&quot; -bwatch -E .*ConsumingRtnProcessor verify|verifyContainer &quot;&#123;params, returnObj&#125;&quot; -b -x 3watch -E .*ConsumingRtnProcessor verify|verifyBin|verifyContainer &quot;&#123;params,returnObj&#125;&quot; -b -x 3watch -E .*ReceiveBillDao update &quot;&#123;params,returnObj&#125;&quot; -b -x 3watch com.janhen.StockServiceImpl query &quot;&#123;params,target&#125;&quot; -x 3 trace 跟踪方法耗时 跟踪方法的耗时情况，包含各个阶段的 1trace com.janhen.OrderBillServiceImpl getByBillNumber|query 匹配特定类的所有方法 1trace -E .*OrderServiceImpl .* 1trace -E com.janhen.OrderServiceImpl query RefConfigure logging drivershttps://docs.docker.com/config/containers/logging/configure/ Java线上诊断神器Arthas-2https://kamzhuyuqing.github.io/2018/12/20/Java%E7%BA%BF%E4%B8%8A%E8%AF%8A%E6%96%AD%E7%A5%9E%E5%99%A8Arthas-2/ 技术征文 | 那些年，我用 Arthas 排查过的问题https://mp.weixin.qq.com/s/gJ4ZVvFBuiXbirjTxjwGeQ 是否可以考虑支持setstatichttps://github.com/alibaba/arthas/issues/641","tags":[{"name":"工具","slug":"工具","permalink":"http://example.com/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"Kafka","date":"2020-12-17T12:09:37.000Z","path":"2020/12/17/Kafka/","text":"","tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"}]},{"title":"Percona-Toolkit","date":"2020-12-17T11:20:54.000Z","path":"2020/12/17/Percona-Toolkit/","text":"概述 perl 语言编写, 不同的 linux 发行版不同的安装 DSN 语法 h: host P: 端口 u: 用户 p: 密码 S: mysql_socket D: 数据库 A: charset t: table F: mysql_read_default_file 1h&#x3D;172.17.10.233,P&#x3D;3306,u&#x3D;root,p&#x3D;root,D&#x3D;testdb3,t&#x3D;testtable1 分类 这些工具主要包括开发、性能、配置、监控、复制、系统、实用六大类 PT 工具分类 工具类别 工具命令 工具作用 备注 开发类 pt-duplicate-key-checker 列出并删除重复的索引和外键 优化使用，实用 pt-online-schema-change 在线修改表结构 pt-query-advisor 分析查询语句，并给出建议，有bug 已废弃 pt-show-grants 规范化和打印权限 分析使用 pt-upgrade 在多个服务器上执行查询，并比较不同 性能类 pt-index-usage 分析日志中索引使用情况，并出报告 索引查看，实用 pt-pmp 为查询结果跟踪，并汇总跟踪结果 pt-visual-explain 格式化执行计划 pt-table-usage 分析日志中查询并分析表使用情况 pt 2.2新增命令 配置类 pt-config-diff 比较配置文件和参数 pt-mysql-summary 对mysql配置和status进行汇总 整体信息，实用 pt-variable-advisor 分析参数，并提出建议 监控类 pt-deadlock-logger 提取和记录mysql死锁信息 死锁信息，实用 pt-fk-error-logger 提取和记录外键信息 pt-deadlock-logger pt-mext 并行查看status样本信息 pt-query-digest 分析查询日志，并产生报告 常用命令 pt-trend 按照时间段读取slow日志信息 已废弃 复制类 pt-heartbeat 监控mysql复制延迟 pt-slave-delay 设定从落后主的时间 pt-slave-find 查找和打印所有mysql复制层级关系 pt-slave-restart 监控salve错误，并尝试重启salve pt-table-checksum 校验主从复制一致性 实用 pt-table-sync 高效同步表数据 实用 系统类 pt-diskstats 查看系统磁盘状态 pt-fifo-split 模拟切割文件并输出 pt-summary 收集和显示系统概况 pt-stalk 出现问题时，收集诊断数据 pt-sift 浏览由pt-stalk创建的文件 pt 2.2新增命令 pt-ioprofile 查询进程IO并打印一个IO活动表 pt 2.2新增命令 实用类 pt-archiver 将表数据归档到另一个表或文件中 pt-find 查找表并执行命令 pt-kill Kill掉符合条件的sql 常用命令 pt-align 对齐其他工具的输出 pt 2.2新增命令 pt-fingerprint 将查询转成密文 pt 2.2新增命令 信息查看pt-summary 可查看挂载情况、网络情况、进程情况 –sleep: 通过 vmstat 收集的 sleep 时间, 默认 5 –summarize-mounts: 挂载的文件系统、磁盘使用, 默认 TRUE –summarize-network: 网络收集、配置, 默认 TRUE –summarize-processes: top process vmstat 输出, 默认 TRUE 1pt-summary pt-mysql-summary 精细地对 mysql 的配置和 sataus 信息进行汇总, 优先执行各种类型字段在对应数据库中的数量btree 在对应 db 中的数量连接的 host 当前连接情况, Process list主从连接情况 –all-databases: 默认 false –databases: 查看指定的数据库 12345678910# 查看所有数据库pt-mysql-summary \\ --host=127.0.0.1 --port=3306 \\ -u root -p root \\ --all-databases# 查看指令数据库pt-mysql-summary \\ --host=127.0.0.1 --port=3306 \\ -u root -p root \\ --databases testdb 1234567891011121314151617181920212223状态统计:Aborted_clients: 取消的连接Com_change_db: 更改 db 命令?Com_commit: 事务提交的个数Com_insert: 插入语句Com_select: 查询语句Com_show_engine_status: 查看存储引擎情况Com_show_table_status: 查看表状态Com_show_variables: 查看变量Connections: 连接数Created_tmp_disk_tables: 创建的临时表Handler_commitHandler_rollbackHandler_updateHandler_writeInnodb_buffer_pool_bytes_data: 缓存池数据Innodb_row_lock_time: 行锁的时间Innodb_row_lock_waits: 锁等待Innodb_rows_deletedInnodb_rows_insertedSelect_full_join: 全表连接Select_full_range_join: 范围连接Sort_rows: 排序的行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107pt-mysql-summary \\ --host=127.0.0.1 --port=3306 \\ -u root -p root \\ --databases testdb1,testdb2# Note Processlist, Schema, InnoDB, Binary Logging Server_id: 315 Master_id: 391 Slave_UUID: 7f80892a-650a-11ea-bb0f-0242ac110002 Version | 5.6.47-log MySQL Community Server (GPL) Started | 2020-07-01 19:35 (up 43+14:06:36) Databases | 9 Datadir | /var/lib/mysql/ Processes | 60 connected, 4 running Replication | Is not a slave, has 1 slaves connected# Processlist ################################################ Command COUNT(*) Working SUM(Time) MAX(Time) ------------------------------ -------- ------- --------- --------- Binlog Dump 1 1 8000 8000 Daemon 1 1 20000 20000 Query 1 1 0 0 Sleep 60 0 22500 3500 User COUNT(*) Working SUM(Time) MAX(Time) ------------------------------ -------- ------- --------- --------- event_scheduler 1 1 20000 20000 user1 45 1 0 0 user2 1 1 8000 8000 user3 15 0 0 0 Host COUNT(*) Working SUM(Time) MAX(Time) ------------------------------ -------- ------- --------- --------- 127.0.0.1 1 1 0 0 172.17.0.1 2 0 0 0 192.168.199.116 1 1 8000 8000 ... localhost 1 1 20000 20000 db COUNT(*) Working SUM(Time) MAX(Time) ------------------------------ -------- ------- --------- --------- NULL 3 3 30000 20000 testdb1 6 0 0 0 testdb2 10 0 0 0 testdb3 15 0 0 0 testdb4 30 0 0 0 testdb5 1 0 0 0 State COUNT(*) Working SUM(Time) MAX(Time) ------------------------------ -------- ------- --------- --------- 60 0 0 0 Master has sent all binlog to 1 1 8000 8000 Waiting for next activation 1 1 20000 20000 init 1 1 0 0# Schema ##################################################### Database Tables Views SPs Trigs Funcs FKs Partn testdb1 35 4 testdb3 223 1 4 Database InnoDB testdb1 35 testdb3 223 Database BTREE testdb1 112 testdb3 653 v d b s t i c d d t a a i m e n h e a i r t g a x t a c t n c e i l t r i e y h t n l m i a i t i a n r m n l t e t Database === === === === === === === === === === testdb1 209 34 13 3 4 17 5 testdb3 3482 283 88 1 2 132 37 433 73 4# InnoDB ##################################################### Version | 5.6.47 Buffer Pool Size | 18.0G Buffer Pool Fill | 100% Buffer Pool Dirty | 0% File Per Table | ON Page Size | 16k Log File Size | 2 * 500.0M = 1000.0M Log Buffer Size | 8M Flush Method | Flush Log At Commit | 2 XA Support | ON Checksums | ON Doublewrite | ON...# Binary Logging ############################################# Binlogs | 15 Zero-Sized | 0 Total Size | 14.2G binlog_format | ROW expire_logs_days | 7 sync_binlog | 0 server_id | 391 binlog_do_db | binlog_ignore_db | pt-deadlock-logger 死锁检测, 收集和保存 mysql 上最近的死锁信息，可以直接打印死锁信息和存储死锁信息到数据库中，死锁信息包括发生死锁的服务器、最近发生死锁的时间、死锁线程 id、死锁的事务 id、发生死锁时事务执行了多长时间等信息。 –columns=A: 控制输出的列 –daemonize: 后台运行 –log=s: 后台运行将输出到处到指定文件 –tab: 使用 tab 进行分割 1234pt-deadlock-logger \\ --h 127.0.0.1 \\ -u root -p root \\ --tab pt-duplicate-key-checker 找出重复的索引和外键，并生成删除重复索引的 SQL 语句 1234pt-duplicate-key-checker \\ -h 127.0.0.1 \\ -u root -p root \\ -d testdb3,testdb1 1234567891011121314151617181920212223# ######################################################################### testdb3.testtable1 # ######################################################################### idx_testtable1_06 is a left-prefix of id_testtable1_unique_01# Key definitions:# KEY &#96;idx_testtable1_06&#96; (&#96;dcUuid&#96;)# UNIQUE KEY &#96;id_testtable1_unique_01&#96; (&#96;dcUuid&#96;,&#96;billNumber&#96;),# Column types:# &#96;dcuuid&#96; varchar(38) not null comment &#39;配送中心uuid&#39;# &#96;billnumber&#96; varchar(30) not null comment &#39;单号&#39;# To remove this duplicate index, execute:ALTER TABLE &#96;testdb3&#96;.&#96;testtable1&#96; DROP INDEX &#96;idx_testtable1_06&#96;;...# ######################################################################### Summary of indexes # ######################################################################### Size Duplicate Indexes 30832348# Total Duplicate Indexes 23# Total Indexes 707 pt-show-grants 查看授权情况 –flush: 刷新权限 1234# Show all grantspt-show-grants \\ -h 127.0.0.1 -P3306 \\ -u root -p $MYSQL_ROOT_PASSWORD 1234# Show database grantspt-show-grants \\ -u root -p root \\ -D testdb4 pt-variable-advisor 分析 mysql 的参数变量，并对可能存在的问题提出建议 12345678pt-variable-advisor --h 172.17.10.233 --u root --p root pt-variable-advisor --h localhost --u root --p root \\ --source-of-variables /etc/mysql/mysql.conf.d/mysqld.cnf pt-variable-advisor \\ h=172.17.10.233,P=3306,u=root,p=root, \\ S=/var/run/mysqld/mysqld.sock \\ --source-of-variables=mysql pt-table-checksum 校验 MySQL 主从复制的完整性，存在锁表问题。 参数： –databases=：指定需要被检查的数据库，多个则用逗号隔开 –tables=：指定需要被检查的表，多个用逗号隔开 -h=127.0.0.1 ：Master的地址 -u=xiaoml：用户名 -p=123456：密码 -P=3306：端口 –tables-regex=s： 表正则匹配 –ignore-tables-regex=s： 忽略的表 –replicate=s: 将校验结果保存到表中 percona.checksums –replicate-database=s: 指定数据库复制校验 123pt-table-checksum -u root -p root \\ --databases testdb5 \\ --tables=QRTZ_TRIGGERS 使用依赖： 需要一个既能登录主库，也能登录从库，而且还能同步数据库的账号 生产环境使用 pt-table-checksum 检查MySQL数据一致性https://segmentfault.com/a/1190000004309169 pt-diskstats 为 GUN/LINUX 打印磁盘 io 统计信息,可以分析从远程机器收集的数据 分析pt-index-usage 从 log 文件中读取查询语句，并用 explain 分析他们是如何利用索引。 完成分析之后会生成一份关于索引没有被查询使用过的报告。 1234pt-index-usage /var/lib/mysql/slow.log \\ --h localhost --u root --p 123456 \\ -d testdb3 \\ --no-report --create-save-results-database *pt-query-digest 分析查询执行日志，并产生一个查询报告，为 MySQL、PostgreSQL、 memcached 过滤、重放或者转换语句。pt-query-digest --database=s: 连接的数据库, 非分析的数据库 --limit=A: 限制输出的百分比/数量， (default 95%:20) --report-all： 所有的查询输出 --ignore-attributes=a: 忽略收集的属性 --timeline: 展示时间线的事件 --review type: DSN 保存查询结果供之后 review, 默认数据库和表为 percona_schema.query_review --report-histogram=s: 属性的直方图，默认为 Query_time --type tcpdump: 类型, 分析多种不同类型的日志 binlog: 分析 binlog genlog: slowlog: 分析慢查询 tcpdump: --order-by: 默认根据查询时间排序， Query_time:sum ，attribute:aggregate 参数的语法 sum Sum/total attribute value min Minimum attribute value max Maximum attribute value cnt Frequency/count of the query 12# 按照总耗时排序--order-by Query_time:sum --since=s: 过滤开始时间 --until=s 过滤结束时间 --limit=A: 限制输出的百分比/数量， (default 95%:20) --filter: 过滤指定的事件, 不同的扫描条件 12# 过滤语句 select：--filter &#x27;$event-&gt;&#123;arg&#125; =~ m/^select/i&#x27;， 12# 过滤指定用户：--filter &#x27;($event-&gt;&#123;user&#125; || &quot;&quot;) =~ m/^dba/i&#x27; ， 12# 过滤全表扫描：--filter &#x27;(($event-&gt;&#123;Full_scan&#125; || &quot;&quot;) eq &quot;yes&quot;) ||(($event-&gt;&#123;Full_join&#125; || &quot;&quot;) eq &quot;yes&quot;)&#x27; 12# 过滤指定数据库--filter &#x27;$event-&gt;&#123;db&#125; &amp;&amp; $event-&gt;&#123;db&#125; =~ /testdb3/ &amp;&amp; $event-&gt;&#123;user&#125; =~ /root/&#x27; 使用案例分析所有慢查询日志 1pt-query-advisor /var/lib/mysql/slow-query.log 指定的查询分析 1pt-query-digest --query &quot;select * from mysql.user&quot; 1234567891011121314151617pt-query-digest \\ -h127.0.0.1 -P3306 \\ -uroot -proot \\ --since &#x27;2020-07-25 00:00:00&#x27; \\ --until &#x27;2020-07-26 00:00:00&#x27; \\ --limit 20 \\ /var/lib/mysql/mysql-slow.log.200725 pt-query-digest \\ -uroot -pimws \\ --since &#x27;2020-07-25 00:00:00&#x27; \\ --until &#x27;2020-07-26 00:00:00&#x27; \\ --order-by Query_time:cnt \\ --limit 20 \\ /var/lib/mysql/mysql-slow.log.200725 \\ &gt; slow-analyse-2.log 更改相关*pt-online-schema-change 在线更改表结构，适用于大表结构的更改 --host: 连接mysql的地址 -P=3306: 连接mysql的端口号 --user: 连接mysql的用户名 --password: 连接mysql的密码 --database=s / D: 连接mysql的库名 t: 连接mysql的表名 --alter: 修改表结构的语句 --charset=utf8: 使用utf8编码，避免中文乱码 --no-version-check: 不检查版本，在阿里云服务器中一般加入此参数，否则会报错 --execute: 执行修改表结构 --new-table-name=s: 新创建的表，默认为 &lt;old-table-name&gt;_new --dry-run: 常见并更改表, 不会创建触发器、复制数据.. --print: 打印 SQL 执行语句 --statistics： 打印内部计数器的统计信息 123456alert_sql=&quot;ADD COLUMN addColumn varchar(30) DEFAULT &#x27;QTY&#x27; COMMENT &#x27;增加列备注&#x27;,ADD COLUMN addColumn2 varchar(30) DEFAULT 0 COMMENT &#x27;增加列2备注&#x27;,CHANGE COLUMN modColumn varchar(100)&quot;pt-online-schema-change \\ --user=root --password=root --host=127.0.0.1 \\ --alter &quot;$alert_sql&quot; \\ D=testdb3,t=testtable1 \\ --print --dry-run -pt-heartbeat 监控 mysql 复制延迟，测量复制落后主 mysql 或者主 PostgreSQL 多少时间，可以使用这个脚本去更新主或者监控复制 通过 show slave status\\G 命令中的 Seconds_Behind_Master 值来判断主从延迟并不靠谱。 原理：pt-heartbeat 通过真实的复制数据来确认 mysql 和 postgresql 复制延迟，避免了对复制机制的依赖，能得出准确的落后复制时间。 包含两部分： 第一部分在主上 pt-heartbeat 的 --update 线程会在指定的时间间隔更新一个时间戳， 第二部分是 pt-heartbeat 的 --monitor 线程或者 --check 线程连接到从上检查复制的心跳记录（前面更新的时间戳），并和当前系统时间进行比较，得出时间的差异。 可以手工创建 heartbeat 表或者添加 –create-table 参数。 -D / –database=s: 指定数据库, 必须的参数 –update, –monitor, –check: 互斥参数 –daemonize, –check: 互斥参数 –config: 指定配置文件的位置， key 必须为全称 –create-table： 创建heartbeat表如果该表不存在，该表由–database和–table参数来确认 –file： 将最新的–monitor信息输出到文件中，新的信息会覆盖旧的信息，通常和–daemonize参数一起使用 –frames： 统计的时间窗口，默认为1m,5m,15m -master-server-id： 指定master的server_id，在检测从的延迟时，必须指定该参数 1234567891011121314151617181920212223# 新建 heartbeat 表, 保存主从执行情况master_server_id=$( mysql -uroot -proot \\ -e &quot;SHOW VARIABLES LIKE &#x27;server_id&#x27;\\G&quot; \\ | grep Value \\ | sed -n -e &#x27;s/^.*: //p&#x27;)slave_server=192.168.199.116pt-heartbeat \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --create-table \\ --update mysql -uroot -proot -e &quot;SELECT * FROM testdb3.heartbeat &quot;;pt-heartbeat \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --update &amp; 查看主从延迟 12345678910111213pt-heartbeat \\ -h $slave_server \\ --monitor \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --print-master-server-idpt-heartbeat \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --check 123#实时延迟，1分钟延迟，5分钟延迟，15分钟延迟0.00s [ 0.00s, 0.00s, 0.00s ] 3910.00s [ 0.00s, 0.00s, 0.00s ] 391 守护线程方式执行， 2s 执行一次 1234567pt-heartbeat \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --update --daemonize --interval=2pt-heartbeat --stop 监控从库并输出日志 1234567pt-heartbeat \\ -u root -proot \\ -D testdb3 \\ --master-server-id=$master_server_id \\ --monitor --print-master-server-id \\ --daemonize --interval=2 \\ --log=/var/lib/mysql/slave-lag.log 使用pt-heartbeat监控主从复制延迟https://cloud.tencent.com/developer/article/1183713pt-heartbeathttps://www.cnblogs.com/ivictor/p/5901853.html -pt-table-sync 主从过程中不同步的表进行同步, 解决主从数据不一致的问题。 注意事项：使用 --dry-run 和 --print 选项总是先测试同步。 无法同步表结构，和索引等对象，只能同步数据 使用该工具来解决主从数据不一致的问题，也可以用来对两个不在一个主从拓扑实例，进行数据 sync –[no]check-slave: 检查目标服务器是否是从数据库，默认为 Yes –sync-to-master and/or –replicate: 只有当需要sync的表都有唯一键(主键或唯一索引)，才能使用–sync-to-master and/or –replicate。(没有唯一键，则只能在desitination上直接修改，而指定–sync-to-master and/or –replicate时只能在主库上修改)，如果sync主从时没有指定–replicate或者–sync-to-master则所有修改都在从库上执行(不论表上是否有唯一键) 123456789# 查看数据不一致pt-table-sync --print \\ h=127.0.0.1,P=3306,u=root,p=root h=127.0.0.1,P=3307 \\ --database=testdb5 --tables=testtable1 # 修复pt-table-sync --execute \\ h=127.0.0.1,P=3306,u=root,p=root h=127.0.0.1,P=3307 \\ --database=testdb5 --tables=testtable2 pt-archiver 将 mysql 数据库中表的记录归档到另外一个表或者文件，也可以直接进行记录的删除操作 只是归档旧的数据，不会对线上数据的 OLTP 查询造成太大影响，可以将数据插入另外一台服务器的其他表中，也可以写入到一个文件中，方便使用 load data infile 命令导入数据。还可以用来执行 delete 操作, 默认的会删除源中的数据。使用的时候请注意 12345678910# create tablemysql -uroot -proot \\ -e &quot;CREATE TABLE IF NOT EXISTS testdb4.bak_mis_wm_testtable1 LIKE testdb4.mis_wm_testtable1&quot;# archive data to bak table and filept-archiver \\ --source h=172.17.10.233,u=root,p=root,D=testdb4,t=mis_wm_testtable1 \\ --dest h=172.17.10.233,u=root,p=root,D=testdb4,t=bak_mis_wm_testtable1 \\ --file &#x27;/var/lib/mysql/%Y-%m-%d-%D.%t&#x27; \\ --where &quot;dispatchState = &#x27;FINISHED&#x27;&quot; \\ --limit 1000 --commit-each Refspercona-toolkit工具的使用Percona-Toolkit 示例说明https://blog.csdn.net/kk185800961/article/details/85016523 pt-query-digest（percona toolkit）小解https://www.cnblogs.com/shengdimaya/p/7063204.html","tags":[{"name":"工具","slug":"工具","permalink":"http://example.com/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"","date":"2020-12-17T01:14:13.711Z","path":"2020/12/17/Blog/","text":"","tags":[]},{"title":"设计模式-单例模式","date":"2020-11-10T15:07:09.000Z","path":"2020/11/10/设计模式-单例模式/","text":"","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"React HOC","date":"2020-11-10T14:45:35.000Z","path":"2020/11/10/React-HOC/","text":"高阶组件： Higher-Order Components: 是个函数，接受一个组件，返回一个新的组件。 HOC 在 React 的第三⽅库中很常⻅见，例如 React-Redux 的 connect。 组件是将 props 转换为 UI，⽽⾼阶组件是将组件转换为另⼀个组 件。 是 React 中⽤于复⽤组件逻辑的⼀种⾼级技巧。 不在 render 方法中使用 HOC： React 的 diff 算法使⽤组件标识来确定它是应该更新现有⼦树还是将其丢弃并挂载新⼦树。 重新挂载组件会导致该组件及其所有⼦组 件的状态丢失。 装饰器ES7中出现的 装饰器语法来更优雅的书写代码。 1npm install -D @babel/plugin-proposal-decorators conﬁg-overrides.js 1234567//配置完成后记得重启下 const &#123; addDecoratorsLegacy &#125; = require(&quot;customizecra&quot;);module.exports = override( ..., addDecoratorsLegacy()//配置装饰器 ); 必须为 class 组件 需要插件支持… 123456@fooclass Child extends Component &#123; render () &#123; return &lt;div&gt;Child&lt;/div&gt; &#125;&#125; 表单组件⽤ @Form.create() 的⽅式实现： getFieldDecorator： ⽤于和表单进⾏双向绑定 getFieldsValue：获取⼀组输⼊控件的值，如不传⼊参数，则获 取全部组件的值 getFieldValue： 获取⼀个输⼊控件的值 validateFields：校验并获取⼀组输⼊域的值与 Error，若 ﬁeldNames 参数为空，则校验全部组件 设计要求： 数据搜集、校验、提交 传递一个 input 组件包装函数接管输入事件并统一管理表单数据 传递一个校验函数具备数据校验功能 弹窗组件要求弹窗内容在A处声明，却在B处展示。 Portal 传送门 16.3 引入 createPortal(Children, container) 方便遮罩 1import &#123;createPortal&#125; from &#x27;react-dom&#x27;; 多个弹窗： 挂载到 DOM 中，会有多个 组件复合 1this.props.children","tags":[{"name":"React","slug":"React","permalink":"http://example.com/tags/React/"}]},{"title":"Linux 常用命令","date":"2020-11-10T14:27:31.000Z","path":"2020/11/10/Linux-常用命令/","text":"概述命令设计Postel 原则： 宽进严出尽可能自由宽松接受输入格式，并输出格式良好的严谨输出格式。宽进减少了过滤器在面对非预期输入时出错的可能性，以及特定情况下崩溃的可能性。严出提高过滤器被其他程序用作输入的可能性。 命令的风格 POSIX GNU MS-DOS 123# POSIX 集中短参数tar -c -f xx.tar xx.txt yy.txttar -cfxx.tar xx.txt yy.txt 命令的参数: 可用选项 选项参数: key=val 子命令: 分割子命令显示不同的信息 密码参数: 防止根据 history 获取出用户密码 位置参数: 多个值按序解析 支持多种类型的参数: 如发布的日志，传入文件名称自动解析文件内容作为参数，传入字符串 支持自定义参数的解析: 可提供自定义的转换器，将参数映射成一个枚举项，指定的类对象 参数类型: File, Date, URL, Pattern.. 12# Show interval and count vmstat 1 10 常见参数 –usage: 给定短的使用消息 -verbose: 显示 Debug 日志 -v / -vvv: 的个数越多显示的日志越详细, 如 ansible 执行时通过 -vvv 显示运行时候的详细信息 -V/--version: 显示版本信息 -a:所有项，与 --all 同名的选项添加（append), 与 tar 中一样 -b缓冲区(buffer) 大小/block 的大小， du、df、tar 中使用批处理（batch）禁用提示/设置通过属性接受文件的输入 -c命令（带参数），如 sh、python检查（check) 不带参数，检查命令/配置是否正确 -d调试（debug)，带或不带参数，设置调试信息级别删除(delete)目录（directory) -D定义(define) 带参数 -e执行(execute) (带参数)编辑(edit)，如 crontab排除(exclude) -f文件(file)(带参数)强制(force), 如 git push -f xxx、ssh -h表头（header)帮助(help) -i初始化交互执行，如 docker exec -it &lt;container-name&gt; bash -I包含 -k: 保留，禁止资源的常规删除 -l:列表加载：登陆： ssh 等要求网络身份 常用的命令缩写:-h: 主机-P: 端口-u: 用户-p: 密码-t: 测试配置文件-c: 指定配置文件地址 常用的子命令start:stop:restart:reload: 命令工具fzf 模糊搜索工具 配置 Ctrl + R 快捷键自动根据 history 中的数据搜索 the_silver_searcher GitHub 替代 grep 的 Linux 工具，类似于ack的代码搜索工具，但速度更快。 可通过 .gitignore、 .hgignore 、.ignore 忽略指定文件 1yum -y install the_silver_searcher navi Github 命令行和应用程序启动器的交互式备忘单工具。 基于 fzf 对命令进行搜索, 可按照特定的标签进行组织命令，支持通过 &lt;name&gt; 指定参数 nohup 允许用户退出帐户/关闭终端之后继续运行相应的进程 /dev/null，代表linux的空设备文件，所有往这个文件里面写入的内容都会丢 失，俗称黑洞 标准输入0，从键盘获得输入 /proc/self/fd/0 标准输出1，输出到屏幕（控制台） /proc/self/fd/1 错误输出2，输出到屏幕（控制台） /proc/self/fd/2 &gt;/dev/null 标准输出1重定向到 /dev/null 中，此时标准输出不存在，没有任 何地方能够找到输出的内容 2&gt;&amp;1 错误输出将会和标准输出输出到同一个地方 &gt;/dev/null 2&gt;&amp;1 不会输出任何信息到控制台，也不会有任何信息输出到文件中 1234nohup flume-ng agent --conf /opt/apps/flume-1.9/conf \\ --conf-file /data/lagoudw/conf/flume-log2hdfs3.conf \\ -name a1 \\ -Dflume.root.logger=INFO,LOGFILE &gt; /dev/null 2&gt;&amp;1 &amp; lrzsz 文件的上传和下载工具，只支持文件，不支持文件夹，配合 tar 命令使用，配合 SSH 连接使用 12345yum -y install lrzsz# 选择本地文件上传到服务器rz # 从服务器下载文件到本地sz &lt;file&gt; ipvsadm LVS 管理工具 12# 查案负载情况ipvsadm -l zsh 辅助命令编写，带有提示 可进行 alias 指定, 主题选择，插件选择 sort 用于排序。 -f ：忽略大小写 -b ：忽略最前面的空格 -M ：以月份的名字来排序，例如 JAN，DEC -n ：使用数字 -r ：反向排序 -u ：相当于 unique，重复的内容只出现一次 -t ：分隔符，默认为 tab -k ：指定排序的区间 1du -sm * | sort -nr | head -n 10 uniq 可以将重复的数据只取一个。 -i ：忽略大小写 -c ：进行计数 当前目录下的磁盘情况 tee输出重定向会将输出内容重定向到文件 1tee [-a] &lt;file&gt; paste 字符转换 12paste [-d] file1 file2-d ：分隔符，默认为 tab rsync 远程同步工具 速度快、避免复制相同内容和支持符号链接。 rsync只对差异文件做更新。scp是把所有文件都复制过去。 -r -v: 显示复制过程 -l: 复制符号链接 1yum install -y rsync 1rsync -rvl /opt/module root@linux123:/opt/ 基础命令cat -n: 显示文本的行号 -T, --show-tabs: 使用 ^I 标示 Tab 字符 -E, --show-ends : 显示 $ 作为每行的末尾Ctrl + D 终止输入 1cat &gt; SampleTextFile.txt File 显示文件字符集 1file -i test_info.sh iconv:文本字符集转换 -f, –from-code=NAME: 来源字符集编码 -t, –to-code=NAME： 目的字符集编码 -o, –output=FILE： 输出文件名 1iconv -f ISO-8859-1 -t UTF-8 in.txt &gt; out.txt 信息查看RedHat 类系统信息查看 1cat /etc/os-release 系统相关 系统服务相关，包括查看状态、停止运行、重新加载、开机自启 主机域名映射，实现 hosts 环境变量控制，实现增加环境变量 1234567891011# 查看系统应用状态# 停止系统应用# 重新加载系统应用# 将系统应用开机自启# 查看失败的系统应用systemctl status redis_6379systemctl status dockersystemctl stop redis_6379systemctl reload docker.servicesystemctl enable docker.servicesystemctl --failed 系统基本信息 123456# 查看系统总信息# 查看系统的位数, 配合下载 URL 使用# 查看系统内核版本uname -auname -muname -r CPU 情况 12345678910# 总核数 = 物理CPU个数 X 每颗物理CPU的核数 # 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数# 查看物理CPU个数cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l# 查看每个物理CPU中core的个数(即核数)cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq# 查看逻辑CPU的个数cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l# 查看CPU信息（型号）cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c CPU 整体信息 1lscpu 各个 CPU 的情况 1mpstat -P ALL 连续的 CPU 情况 1mpstat -P ALL 1 300 12# 查看僵尸进程ps -al | gawk &#x27;&#123;print $2,$4&#125;&#x27; | grep Z 查看进程实际使用的内存情况 1ps -e -o &#x27;pid,comm,args,pcpu,rsz,vsz,stime,user,uid&#x27; | sort -nrk5 运行负载情况 12toptop -p 3306 内存使用情况 1free -m 12# 查看内存使用百分比free | sed -n &#x27;2p&#x27; | gawk &#x27;x = int(( $3 / $2 ) * 100) &#123;print x&#125;&#x27; | sed &#x27;s/$/%/&#x27; 1234# 释放内存echo 1 &gt;/proc/sys/vm/drop_cachesecho 2 &gt;/proc/sys/vm/drop_cachesecho 3 &gt;/proc/sys/vm/drop_caches 磁盘占用情况 可以作为部署时候的参考 12df -hdf -sh * 文件句柄数 1ulimit -n 网络查看端口使用 12ss -nelp | grep 22netstat -lntp | grep 22 查看IP 地址 12# Show all interface ip addrifconfig | grep -Eo &#x27;inet (addr:)?([0-9]*\\.)&#123;3&#125;[0-9]*&#x27; | grep -Eo &#x27;([0-9]*\\.)&#123;3&#125;[0-9]*&#x27; | grep -v &#x27;127.0.0.1&#x27; 123# Specified interfaceifconfig eno1 | grep -Eo &#x27;inet (addr:)?([0-9]*\\.)&#123;3&#125;[0-9]*&#x27; | grep -Eo &#x27;([0-9]*\\.)&#123;3&#125;[0-9]*&#x27;ifconfig eth0 | grep -Eo &#x27;inet (addr:)?([0-9]*\\.)&#123;3&#125;[0-9]*&#x27; | grep -Eo &#x27;([0-9]*\\.)&#123;3&#125;[0-9]*&#x27; 12345678910# 连接指定端口 telnet IP PORT # dns 解析相关nslookup sina.com # 从主机到互联网另一端的主机走的什么路径 traceroute sina.com sar # 网络状况分析跟踪 tcpdump Tcp 端口监听情况 123netstat -lntp | grep &lt;port&gt;ps -ef | grep &lt;port&gt;lsof -i tcp:&lt;port&gt; Tcp 状态连接统计 1netstat -an | awk &#x27;/^tcp/ &#123;++s[$NF]&#125; END &#123;for(a in s) print a,s[a]&#125;&#x27; bridge-utils： yum install bridge-utils 1234567891011# Linux 本地系统的转发支持， 0,1 语义..# 设置开启转发sysctl net.ipv4.ip_forwardsysctl -w net.ipv4.ip_forward=1# iptables 关联命令# 查看 NAT 的端口映射， 显示伪装地址，端口映射情况iptables -t nat -nL# 查看 bridge 情况brctl show# 网络运行情况netstat -anop 12# 查看本机网卡nmcli d 网卡配置 打开文件**/etc/sysconfig/network**来修改主机名和DNS 1234567891011121314vi /etc/sysconfig/network-scripts/ifcfg-ens160ONBOOT=yesBOOTPROTO=staticDNS1=172.17.0.211DNS2=172.17.0.221IPADDR=172.17.10.137 # 更改NETMASK=255.255.240.0GATEWAY=172.17.0.49systemctl restart networkping 8.8.8.8ping 172.17.0.49ping baidu.com 域名主机名配置 1234vi /etc/hostnamehostnamectl hostnamectl set-hostname cnodeecho &quot;172.17.10.153 cnode1&quot; &gt;&gt; /etc/hosts 防火墙相关 线上服务器必须使用，当前为 Centos7 自带防火墙，局域网一般可以关闭 开启、关闭防火墙，基本信息查看 开放或关闭某个|一个数据段的端口， 开放或关闭某个|多个服务 12345678910111213141516171819202122232425262728293031323334353637383940414243# 停止并关闭开机启动防火墙systemctl stop firewalldsystemctl disable firewalld# 查看防火墙版本号# 查看防火墙状态# 启动防火墙# 列出所有zone# 查看特定区域，不指定默认为 publicfirewall-cmd --versionfirewall-cmd --statesystemctl start firewalld.servicefirewall-cmd --get-zonesfirewall-cmd --get-default-zonefirewall-cmd --list-zonefirewall-cmd --list-allfirewall-cmd --zone=pulic# 查看开放的端口# 开启需要的端口# 重新加载端口# 查看开放端口验证# 查看某个端口firewall-cmd --list-portfirewall-cmd --permanent --zone=public --add-port=3306/tcpfirewall-cmd --permanent --zone=public --add-port=22/tcpfirewall-cmd --reloadfirewall-cmd --list-portfirewall-cmd --query-port=22/tcpfirewall-cmd --add-port=22/tcp# 查看开放的端口# 删除某个|某段的端口# 重新加载# 验证开放端口情况# 关闭防火墙firewall-cmd --list-portfirewall-cmd --permanent --remove-port=2000-20002/tcp firewall-cmd --reloadfirewall-cmd --list-portfirewall-cmd --zone=public --list-ports# 开启|关闭某个服务firewall-cmd --add-service ftp --permanentfirewall-cmd --remove-service --permanentfirewall-cmd --zone=public --list-services iptables 相关 12# 对于请求 8082 端口的全部丢弃掉iptables -I INPUT -p tcp --dport 8082 -j DROP net-tools 常用的网络工具 可以使用 Linux 旧有支持的命令，以及扩展的网络工具 route： 如 route -n 命令，等价于现在自带的 ip -r 命令 netstat： 常用的网络工具 ifconfig： 废弃命令，在 Linux 上使用 ip address 代替，简写成 ip a 12345678910# 添加默认网关模板以及对应的实例# 验证设置网关的结果route add default gw &#123;IP-ADDRESS&#125; &#123;INTERFACE-NAME&#125;route add default gw 192.168.2.254 eth0route -n# Linux 自带命令# 配置默认网关# 验证执行情况ip route add default via 192.168.1.254ip r 磁盘查看指定目录下文件的大小，排序并只显示TOP10 1du -sh * | sort -hr | head -n 10 123456sudo find /var/lib/docker/containers -name *.logsudo du -d1 -h /var/lib/docker/containers | sort -hsudo du -d1 -h /var/lib/docker | sort -hdocker inspect --format=&#x27;&#123;&#123;.LogPath&#125;&#125;&#x27; iwms-openapi 磁盘挂载 du -sh *: 查看目录占用的空间情况 df -h：查看磁盘占用情况 df -T：查看所有磁盘的文件系统类型(type) fdisk -l：查看所有被系统识别的磁盘 mount -t type device dir：挂载device到dir 123fdisk /dev/sdb# 格式化分区mkfs -t ext4 /dev/vdb1 mkfs -t ext4 /dev/vdb1: 格式化分区 123456umount /data ##卸载data目录下分区# 分区的UUIDls -l /dev/disk/by-uuid/# 开机自动挂载vim /etc/fstab /dev/sdb /data ext4 defaults 0 0 12# 查看硬盘以及分区情况lsblk 123456789101112131415# 比如要扩充 /var# 在创建好文件系统后 新建临时挂载点 storagemkdir /storage# 将/dev/sdb1挂载到/storage下mount /dev/sdb1 /storage# 拷贝/var下的所有内容到新的硬盘cp -pdr /var /storage# 或在/var 目录下执行：find . -depth -print | cpio - pldvm /temp# 删除当前/var目录下的内容rm -rf /var/*# 重新挂载硬盘到/var目录umount /dev/sdb1mount /dev/sdb1 /var# 过程中若提示磁盘忙，使用fuser找出将正在使用磁盘的程序并结束掉；fuser -m -v /var 123partprobe /dev/sdapartx -a /dev/sdb# 验证情况 软连接删除后，存放的数据不删除 1234ln –snf /var/www/test1 /var/test # 意不要在后面加 ”/”rm –rf &lt;软链接名称&gt;ln –snf &lt;新的源文件或目录&gt; &lt;目标文件或目录&gt; 目录文件 重要的配置文件位置 用户相关 /etc/passwd： 用户列表文件，是否是系统用户，是否可以登录 /etc/group： 用户组列表文件 /etc/sudoers: 可以有 sudo 权限的配置 /etc/profile： 环境变量配置 /etc/hosts： host 文件位置 /etc/hostnames: 主机名 /etc/sysconfig/network-scripts/ifcfg-ensxx: 网卡设置 /etc/yum.repos.d/xxx.repo： 软件安装源 /var/logs： 日志存放位置 执行路径 /usr/local/bin、/usr/bin、/usr/local/sbin、/usr/sbin /home//bin: 可执行路径，常通过 ln -s … 的方式使全局可用 文件操作 基本操作， ls、touch、mkdir、cd、rm、cp、mv、pwd 1234567891011121314# 复制、移动、重命名cp -r /user/newTest /test mv /test/newTest /usr mv aaa bbbrm -rf /user/newTst# 文件的查看cat -n /etc/passwd tail /etc/passwdtail -3 /etc/passwdtail -f nohup.out# 文件压缩与解压tar -cvf &lt;zip_name&gt; &lt;folder_name&gt;# 复制并重命名copy -a nginx_playbooks wordpress_playbooks 文件上传下载 文件下载： wget、curl 文件上传： scp 1scp tar 命令 -z, –gzip, –gunzip, –ungzip 通过 gzip 过滤归档 -c, –create: 创建一个新归档 -v, –verbose: 详细地列出处理的文件 -f, –file=ARCHIVE: 使用归档文件或 ARCHIVE 设备 -C, –directory=DIR: 改变至目录 DIR -x, –extract, –get: 从归档中解出文件 -j, –bzip2 : 通过 bzip2 过滤归档 -t, –list: 列出归档内容 打包 1tar -cvf /mydata/etc.tar /etc 打包并压缩 1tar -zcvf /mydata/etc.tar.gz /etc 用bzip2压缩文件夹/etc到文件/etc.tar.bz2： 1tar -jcvf /mydata/etc.tar.bz2 /etc 解压缩到指定目录 1tar -zxvf etc.tar.gz -C /usr/local/ 找出指定时间范围内的日志文件，打包传输 12345678910find . -name &quot;*04-29*&quot; -exec cp &#123;&#125; 200428_200505 \\;find . -name &quot;*04-28*&quot; -exec cp &#123;&#125; 200428_200505 \\;find . -name &quot;*04-30*&quot; -exec cp &#123;&#125; 200428_200505 \\;find . -name &quot;*04-31*&quot; -exec cp &#123;&#125; 200428_200505 \\;find . -name &quot;*05-01*&quot; -exec cp &#123;&#125; 200428_200505 \\;find . -name &quot;*05-02*&quot; -exec cp &#123;&#125; 200428_200505 \\;find . -name &quot;*05-03*&quot; -exec cp &#123;&#125; 200428_200505 \\;find . -name &quot;*05-04*&quot; -exec cp &#123;&#125; 200428_200505 \\;find . -name &quot;*05-05*&quot; -exec cp &#123;&#125; 200428_200505 \\;tar -zcvf 200428_200505.tar.gz 200428_200505/ 常用工具find -maxdepth levels -atime n File was last accessed n*24 hours ago. -mtime n File’s data was last modified n24 hours ago. -size n[cwbkMG] -type c File is of type c 12# 找出指定目录下文件的个数 find DIR_NAME -type f | wc -l 1234# 找出 /opt 目录下大于 800 M 的文件find /opt -type f -size +800M -print0 | xargs -0 du -h | sort -nr # 找到文件并移到 opt 目录 find / -name &quot;*tower*&quot; -exec rm &#123;&#125; \\; 12# 找出系统中占用容量最大的前 12 个目录 du -hm --max-depth=2 | sort -nr | head -12 12# 当前目录搜索lin开头的文件，然后用其搜索后的结果集，再执行ls -l的命令（这个命令可变，其他命令也可以），其中 -exec 和 &#123;&#125; \\; 都是固定格式 find . -name &quot;lin*&quot; -exec ls -l &#123;&#125; \\; grep-v: 过滤掉 -i: 忽略大小写 -n: 打印行号 -H, --with-filename: 打印文件名 -r: 递归处理 -d, --directories=ACTION: 目录处理策略, read,recurse,skip -c/--count: 打印匹配的数量 -w: 匹配整个词 -x: 整行 查看指定进程并过滤掉 grep 自身 1ps -ef | grep namenode | grep -v grep 正则匹配 123grep &quot;python|PYTHON&quot; filegrep -E &quot;python|PYTHON&quot; filegrep -F &quot;py.*&quot; file 打印匹配行的前后5行 1grep -5 &#x27;parttern&#x27; INPUT_FILE 12grep Full gclogs/fanruan.gc.log.2020-07-26grep -n Full gclogs/fanruan.gc.log.2020-07-26 搜索指定字符，并显示匹配到的行号 1grep -n man /etc/man_db.conf 1233:# This file is used by the man-db package to configure the man and cat paths.4:# It is also used to provide a manpath for those without one by examining5:# their PATH environment variable. For details see the manpath(5) man page. 查看单个/多个文件某字符出现的次数 12345678910grep Full gclogs/* | wc -l# countgrep -c processor /proc/cpuinfo# Show filename:countgrep -c Full gclogs/*gclogs/fanruan.gc.log:1gclogs/fanruan.gc.log.2020-07-17:434gclogs/fanruan.gc.log.2020-07-18:1gclogs/fanruan.gc.log.2020-07-19:3... 查看某个配置文件，排除掉里面以 # 开头的注释内容： 1grep &#x27;^[^#]&#x27; /etc/openvpn/server.conf 查看某个配置文件，排除掉里面以 # 开头和 ; 开头的注释内容： 1grep &#x27;^[^#;]&#x27; /etc/openvpn/server.conf sed 轻量级流编辑器，一般用来处理文本类文件 非交互式的编辑器, 它不会修改文件，除非使用 shell 重定向来保存结果。默认情况下，所有的输出行都被打印到屏幕上 sed -i 会实际写入 p 参数表示打印，一般配合 -n（安静模式）进行使用 c. 替换 s： 搜索并替换 123# 显示网络接口的 Ip 地址 ifconfig eth0 |grep &#x27;inet&#x27; |sed &#x27;s/^.*inet//g&#x27; |sed &#x27;s/netmask.*$//g&#x27; |sed -n &#x27;1p&#x27;192.168.199.183 12# 显示第 7 ~ 10 行内容sed -n &#x27;7,10p&#x27; /opt/log4j2.properties 12# 将文件中每一行以 # 开头的都替换掉空字符并展示sed &#x27;s/^#*//g&#x27; /opt/log4j2.properties 12# 将 1 ~ 4 行内容替换成 GitNavi.comcat -n /opt/log4j2.properties |sed &#x27;1,4c GitNavi.com 日期和日历 date +%Y: 显示当前年份 date +%m: 显示当前⽉份 date +%d: 显示当前是哪⼀天 date &quot;+%Y-%m-%d %H:%M:%S&quot; : 按照指定格式显示 date -d &#39;1 days ago&#39;: 显示前⼀天⽇期 date -d yesterday +&quot;%Y-%m-%d&quot;: 同上 date -d next-day +&quot;%Y-%m-%d&quot;: 显示明天⽇期 date -d &#39;next monday&#39;: 显示下周⼀时间 date -s 字符串时间: 设置系统时间 cal查看日历。cal -3: 查看当前，上个，下个月的日历cal 2020: 查看指令年份的 用户与权限 open files: 可打开的文件限制 file size: 可创建单个文件的最大大小? max memory size: 最大可用的内存大小 stack size: 最大可使用的栈大小 1234567891011121314151617ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 59459max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 59459virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited -代表⽂件 d 代表⽬录 c 字符流， s socket p 管道 l 链接⽂档(link ﬁle) b 设备⽂件 12345chmod [&#123;ugoa&#125;&#123;+-=&#125;&#123;rwx&#125;] [⽂件或⽬录] [mode=421 ] [⽂件或⽬录]# 改变⽂件或者⽬录的所有者chown [最终⽤户] [⽂件或⽬录] # 改变⽂件或者⽬录的所属组chgrp [最终⽤户组] [⽂件或⽬录] 12345678910useradd &lt;user-name&gt;passwd &lt;user-name&gt;# 切换⽤户，只能获得⽤户的执⾏权限，不能获得环境变量su &lt;user-name&gt; # 切换到⽤户并获得该⽤户的环境变量及执⾏权限su - &lt;user-name&gt;# 删除⽤户但保存⽤户主⽬录userdel &lt;user-name&gt;# ⽤户和⽤户主⽬录，都删除userdel -r ⽤户名 123# 让用户支持权限命令visudo%vagrant ALL=(ALL) ALL /etc/sudoers Allow root to run any commands anywhere root ALL=(ALL) ALL hadoop ALL=(ALL) ALL cat /etc/passwd 查看创建了哪些⽤户 12345usermod -g &lt;⽤户组&gt; &lt;⽤户名&gt;groupadd &lt;组名&gt; &lt;代表⽬录&gt;groupdel &lt;组名&gt;groupmod -n &lt;新组名&gt; &lt;⽼组名&gt;cat /etc/group Refs 《UNIX 编程艺术》","tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"Linux 常用服务","date":"2020-11-10T13:21:25.000Z","path":"2020/11/10/Linux-常用服务/","text":"SSH 默认安装好客户端，对于海外的服务器进行转发有时连接效果较好 配置配置文件存放在 ~/.ssh/config 文件中 1vim ~/.ssh/config 端口更改 123Port=1022service sshd restart 12345# 如果 60s 内没用任何数据,将会自动断开。vim /etc/ssh/ssh_config#添加ServerAliveInterval 60ServerAliveCountMax 3 禁止密码登陆，可避密码泄漏 12345678910# 禁用root账户登录(非必要)PermitRootLogin no# 是否允许用户自行使用成对的密钥系统进行登入行为RSAAuthentication yes# 是否让 sshd 去检查用户home目录的权限数据StrictModes noPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys# 禁止密码登录PasswordAuthentication no SSH 免密码密钥认证 1234567ssh-keygen -t rsa# 将公钥传递给远程 root ssh-copy-id -i /root/.ssh/id_rsa.pub root@linux121ssh-copy-id -i /root/.ssh/id_rsa.pub root@linux122ssh-copy-id -i /root/.ssh/id_rsa.pub root@linux123# 指定端口传递ssh-copy-id -i /root/.ssh/id_rsa.pub -oPort=6000 root@127.0.0.1 SSH 文件传输 12# 通过 SSH 复制远程服务器指定文件到本地scp root@linux121:/root/frp_0.13.0_linux_amd64.tar.gz frp.tar.gz SSH 连接执行命令 连接上指定的机器，同时执行指定的命令，封装 zookeeper 集群的启动 12345678910echo &quot;start zookeeper server...&quot;if(($#==0));then echo &quot;no params&quot;;exit;fihosts=&quot;linux121 linux122 linux123&quot;for host in $hostsdo ssh $host &quot;source /etc/profile; $1&quot;done crond Linux 自带的定时调度服务 查看查看用户的定时任务 1234# 查看当前用户的定时任务crontab -l# 查看指定用户的定时任务crontab -u &lt;username&gt; -l 按照时间查看定时任务 查看每日的任务 1ls -la /etc/cron.daily/ 1234drwxr-xr-x. 2 root root 4096 Sep 14 15:16 .drwxr-xr-x. 76 root root 4096 Nov 10 21:15 ..-rwx------. 1 root root 219 Apr 1 2020 logrotate-rwxr-xr-x. 1 root root 618 Oct 30 2018 man-db.cron 查看每小时的任务 1ls -la /etc/cron.hourly/ 查看每周的任务 1ls -la /etc/cron.weekly/ 查看每月的任务 1ls -la /etc/cron.monthly/ 查看 /etc/crontab 1less /etc/crontab 查看任务执行日志 1tail -f /var/log/cron 定义任务1234567+---------------- minute (0 - 59)| +------------- hour (0 - 23)| | +---------- day of month (1 - 31)| | | +------- month (1 - 12)| | | | +---- day of week (0 - 6) (Sunday&#x3D;0 or 7)| | | | |* * * * * command to be executed 定时删除日志 每天凌晨2点删除 /usr/apps/logs 目录下7天前包含 log 的日志文件 10 2 * * * &#x2F;usr&#x2F;bin&#x2F;find &#x2F;usr&#x2F;apps&#x2F;logs&#x2F; -type f -mtime +7 -name &quot;*log*&quot; -exec rm -rf &#123;&#125; \\; journal 日志查看服务 Linux 日志分类 内核及系统日志： 日志数据由系统服务 syslog 统一管理 用户日志：这种日志数据用于记录 Linux 系统用户登录及退出系统的相关信息 程序日志：有些应用程序运会选择自己来独立管理一份日志文件, 通过配置日志格式和回滚策略 Linux 中常用日志文件 /var/log/cron： 与定时任务相关的日志信息 /var/log/maillog： 与邮件相关的日志信息 /var/log/secure： 与安全相关的日志信息, 可基于此日志过滤攻击的 IP /var/log/boot.log： 守护进程启动和停止相关的日志消息 /var/log/messages / /var/log/syslog： 存储所有的全局系统活动数据,包括启动、IO错误、网络错误、程序故障等 /varlog/dmesg：记录Linux系统在引导过程中的各种事件信息 /var/log/lastlog：最近几次成功登录事件和最后一次不成功登录事件 /var/log/wtmp：记录每个用户登录、注销及系统启动和停机事件 /var/log/rpmpkgs： RPM软件包日志 /var/log/kern： 存储内核的错误和警告数据，用于排除与定制内核相关的故障 /var/log/btmp： 记录错误的登陆尝试 1journalctl -f -n 1000 logrotate 日志回滚服务 /etc/logrotate.d/ 12345678910tree &#x2F;etc&#x2F;logrotate.d&#x2F;etc&#x2F;logrotate.d├── bootlog├── chrony├── ppp├── subscription-manager├── syslog├── vsftpd├── wpa_supplicant└── yum 使用配合 cron 实现日志的分割压缩处理 123logrotate /etc/logrotate.d/nginxlogrotate -d /etc/logrotate.d/nginxlogrotate -vf /etc/logrotate.d/nginx 123456789101112/var/log/nginx/access_log &#123; rotate 7 size 5k dateext dateformat -%Y-%m-%d missingok compress sharedscripts postrotate test -r /var/run/nginx.pid &amp;&amp; kill -USR1 `cat /var/run/nginx.pid` endscript&#125; How to limit nginx access log file size and compress? firewalld防火墙状态查看 1systemctl status firewalld iptables1234567891011iptables -nvL # 开放指定的端口iptables -I INPUT -p tcp --dport 9000 -j ACCEPT# 暴露docker swarm需要的端口，如果不使用docker swarm不需要打开端口iptables -A INPUT -p tcp --dport 2377 -j ACCEPTiptables -A INPUT -p tcp --dport 7946 -j ACCEPTiptables -A INPUT -p udp --dport 7946 -j ACCEPTiptables -A INPUT -p tcp --dport 4789 -j ACCEPTiptables -A INPUT -p udp --dport 4789 -j ACCEPT ntpd 时间同步工具 123yum install ntpntpdate time.pool.aliyun.comsystemctl enable ntpd 三台机器时钟同步 时间同步的⽅式：在集群中找⼀台机器，作为时间服务器。 通过⽹络连接外⽹进⾏时钟同步, 此台机器需要保证能连上外⽹。 集群中其他机器与这台机器定时的同步时间，每隔一段时间(⼗分钟)同步⼀次时间。 1.时间服务器配置（必须root⽤户） 第⼀步:确定是否安装了ntpd的服务 1yum -y install ntpd 启动ntpd的服务 service ntpd start 设置ntpd的服务开机启动 chkconfig ntpd on 第⼀步:确定是否安装了ntpd的服务 rpm -qa | grep ntpd 第⼆步:编辑/etc/ntp.conf 1234567891011121314编辑第⼀台机器的/etc/ntp.confvim /etc/ntp.conf # 在⽂件中添加如下内容 restrict 192.168.80.0 mask 255.255.255.0 nomodify# 注释⼀下四⾏内容 #server 0.centos.pool.ntp.org #server 1.centos.pool.ntp.org #server 2.centos.pool.ntp.org #server 3.centos.pool.ntp.org # 去掉以下内容的注释，如果没有这两⾏注释，那就⾃⼰添加上 server 127.127.1.0 # local clock fudge 127.127.1.0 stratum 10 配置以下内容，保证BIOS与系统时间同步添加⼀⾏内容 12vim /etc/sysconﬁg/ntpdSYNC_HWLOCK=yes 第三步： 重新启动ntpd 12service ntpd statusservice ntpd start 使NTP服务可以在系统引导的时候⾃动启动 ： 1chkconfig ntpd on 2.其他机器配置（必须root⽤户） 第⼀步：在其他机器配置10分钟与时间服务器同步⼀次 crontab -e 编写脚本 另外两台机器与192.168.80.121进⾏时钟同步 1*/10 * * * * /usr/sbin/ntpdate 192.168.80.121 第⼆步：修改任意机器时间, 进行验证 1date -s &quot;2020-12-31 11:11:11&quot; 第三步：⼗分钟后查看机器是否与时间服务器同步 1date","tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"Hive 安装","date":"2020-11-09T17:34:47.000Z","path":"2020/11/10/Hive-安装/","text":"软件安装安装MySQL 数据库 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;# 安装 Docker# &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;curl -fsSL https:&#x2F;&#x2F;get.docker.com | bash -s docker --mirror Aliyuncurl -sSL https:&#x2F;&#x2F;get.daocloud.io&#x2F;docker | shsudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-enginesudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2sudo yum-config-manager \\ --add-repo \\ http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.reposystemctl start dockersystemctl daemon-reloadsystemctl enable docker# &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;# 安装 MySQL、配置 MYSQL# &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;mysql_volume_root&#x3D;&#x2F;opt&#x2F;lagou&#x2F;software&#x2F;mysqlmysql_container_name&#x3D;Mysql_linux121docker rm -f mysql_container_namedocker run -d --name mysql_container_name \\ --privileged \\ --restart&#x3D;always \\ -v $mysql_volume_root&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql \\ -v $mysql_volume_root&#x2F;conf&#x2F;mysqld.cnf:&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf \\ -v $mysql_volume_root&#x2F;logs:&#x2F;var&#x2F;log&#x2F;mysql \\ -p 3306:3306 \\ -e MYSQL_ROOT_PASSWORD&#x3D;hadoop123janhen \\ mysql:5.7docker exec -it $mysql_container_name \\ mysql -uroot -p hadoop123janhen \\ -e &quot;SET GLOBAL validate_password_policy&#x3D;0&quot;CREATE user &#39;hive&#39;@&#39;%&#39; IDENTIFIED BY &#39;youpassword&#39;;GRANT ALL ON *.* TO &#39;hive&#39;@&#39;%&#39;;FLUSH PRIVILEGES;mysql -uhive -p Hive123Hadoop 复制 MySQL 驱动 复制 mysql-connector-java-5.1.46.jar 拷贝到 $HIVE_HOME/lib 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;# 安装 Hive、配置 Hive# &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;# 配置环境变量vi &#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile#.#├── bin#│ ├── beeline#│ ├── hive#│ ├── hive-config.sh#│ ├── hiveserver2#│ └── schematool ...#├── conf#│ ├── hive-default.xml.template#│ ├── hive-env.sh.template#│ ├── hive-site-local.xml ...#├── hcatalog#│ ├── bin#│ ├── etc ...#├── lib#│ ├── asm-3.1.jar#│ ├── avro-1.7.7.jar#│ ├── derby-10.10.2.0.jar#│ ├── druid-common-0.9.2.jar#│ ├── findbugs-annotations-1.3.9-1.jar#│ ├── hbase-annotations-1.1.1.jar#│ ├── hbase-hadoop2-compat-1.1.1.jar#│ ├── hbase-hadoop2-compat-1.1.1-tests.jar#│ ├── hbase-hadoop-compat-1.1.1.jar#│ ├── hive-beeline-2.3.7.jar#│ ├── hive-exec-2.3.7.jar#│ ├── hive-hcatalog-core-2.3.7.jar#│ ├── hive-hplsql-2.3.7.jar#│ ├── hive-jdbc-2.3.7.jar#│ ├── mysql-metadata-storage-0.9.2.jar#│ ├── netty-3.6.2.Final.jar#│ ├── snappy-java-1.0.5.jar#│ └── zookeeper-3.4.6.jar#│ └── ...#└── scripts# └── ... 配置环境变量 12345vi /etc/profileexport HIVE_HOME=/opt/lagou/servers/hive-2.3.7export PATH=$PATH:$HIVE_HOME/binsource /etc/profile 配置本地元数据管理$HIVE_HOME/conf/hive-site.xml 当启动一个hive 服务时，其内部会启动一个metastore服务。Hive根据 hive.metastore.uris 参数值来判断，如果为空，则为本地模式。 缺点：每启动一次hive服务，都内置启动了一个metastore；在hive-site.xml中暴露 的数据库的连接信息； 优点：配置较简单，本地模式下hive的配置中指定mysql的相关信息即可。 在xml文件中 &amp;amp; 表示 &amp; 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt; &lt;!-- hive元数据的存储位置 --&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://linux121:3306/hivemetadata?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定驱动程序 --&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;!-- 连接数据库的用户名 --&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt; &lt;/property&gt; &lt;!-- 连接数据库的口令 --&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;youpassword&lt;/value&gt; &lt;/property&gt; &lt;!-- 数据默认的存储位置(HDFS) --&gt; &lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/user/hive/warehouse&lt;/value&gt; &lt;/property&gt; &lt;!-- 在命令行中，显示当前操作的数据库 --&gt; &lt;property&gt; &lt;name&gt;hive.cli.print.current.db&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 在命令行中，显示数据的表头 --&gt; &lt;property&gt; &lt;name&gt;hive.cli.print.header&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 操作小规模数据时，使用本地模式，提高效率 --&gt; &lt;property&gt; &lt;name&gt;hive.exec.mode.local.auto&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 对数据进行初始化 1schematool -dbType mysql -initSchema 配置远程元数据管理12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt; &lt;!-- 使用 metastore 服务管理元数据 --&gt; &lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://linux121:9083,thrift://linux123:9083&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.metastore.client.socket.timeout&lt;/name&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/property&gt; &lt;!-- 数据默认的存储位置(HDFS) --&gt; &lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/user/hive/warehouse&lt;/value&gt; &lt;/property&gt; &lt;!-- 在命令行中，显示当前操作的数据库 --&gt; &lt;property&gt; &lt;name&gt;hive.cli.print.current.db&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 在命令行中，显示数据的表头 --&gt; &lt;property&gt; &lt;name&gt;hive.cli.print.header&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 操作小规模数据时，使用本地模式，提高效率 --&gt; &lt;property&gt; &lt;name&gt;hive.exec.mode.local.auto&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置日志Hive的log默认存放在 /tmp/root 目录下 123vi $HIVE_HOME/conf/hive-log4j2.properties# 增加配置property.hive.log.dir = /opt/janhen/hive-2.3.7/logs 配置参数配置方式 用户自定义配置文件(hive-site.xml) 启动hive时指定参数(-hiveconf) hive命令行指定参数(set) 配置的优先级 1set ---&gt; -hiveconf ---&gt; hive-site.xml ---&gt; hive-default.xml 启动时指定参数 12# 启动时指定参数hive -hiveconf hive.exec.mode.local.auto=true 命令执行时更改 123-- 查看全部参数 hive&gt; set;hive&gt; set hive.exec.mode.local.auto; 启动与验证1234567891011121314151617# ================================================# 启动 Hive Metastore# ================================================cd $HIVE_HOME/binnohup hive --service metastore &amp;lsof -i:9083tail -f -n 500 nohup.out# ================================================# 启动 HiveServer2# ================================================nohup hiveserver2 &amp;lsof -i:10000# 浏览器验证http://linux123:10002/ 初始化元数据 - MySql 1schematool -dbType mysql -initSchema 连接 Hive 12hivehive&gt; show functions; 下载网址：http://archive.apache.org/dist/hive/ 文档网址：https://cwiki.apache.org/confluence/display/Hive/LanguageManual","tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"}]},{"title":"Hadoop 集群环境搭建","date":"2020-11-09T17:23:23.000Z","path":"2020/11/10/Hadoop-集群环境搭建/","text":"环境准备集群规划 框架 linux121 linux122 linux123 HDFS NameNode、DataNode DataNode SecondaryNameNode、DataNode YARN NodeManager NodeManager NodeManager、ResourceManager 安装 JDK 12345678910111213mkdir -p /usr/local/javawget http://download.janhen.com/tools/jdk-8u251-linux-x64.tar.gztar -zxvf jdk-8u251-linux-x64.tar.gz -C /usr/local/javavi /etc/profileexport JAVA_HOME=/usr/local/java/jdk1.8.0_251export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATHsource /etc/profileln -s /usr/local/java/jdk1.8.0_251/bin/java /usr/bin/javajava -version SSH 免密登陆 123456789mkdir /root/.ssh chmod 700 /root/.sshcd ~/.sshssh-keygen -t rsa -P &quot;&quot;cat id_rsa.pub &gt;&gt; authorized_keysscp authorized_keys linux122:/root/.ssh/scp authorized_keys linux123:/root/.ssh/ 本地域名配置 123xxx linux121xxx linux122xxx linux123 准备安装的目录 12mkdir -p &#x2F;opt&#x2F;janhen&#x2F; 12345678910111213141516171819202122232425262728# 防火墙关闭systemctl status firewalldvi /etc/selinux/config# ================================================# 软件安装# ================================================mkdir -p /opt/janhen/cd /opt/janhenwget https://archive.apache.org/dist/hadoop/common/hadoop-2.9.2/hadoop-2.9.2.tar.gztar -zxvf hadoop-2.9.2.tar.gz# 环境变量配置vim /etc/profileexport JAVA_HOME=/usr/local/java/jdk1.8.0_251export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATHexport HADOOP_HOME=/opt/janhen/hadoop-2.9.2export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbinsource /etc/profileln -s /usr/local/java/jdk1.8.0_251/bin/java /usr/bin/javajava -versionhadoop version 配置1234567891011121314151617# ================================================# 配置# ================================================# 配置# JDK路径明确配置给HDFSvi $HADOOP_HOME/etc/hadoop/hadoop-env.shvi $HADOOP_HOME/etc/hadoop/core-site.xmlvi $HADOOP_HOME/etc/hadoop/hdfs-site.xmlvi $HADOOP_HOME/etc/hadoop/mapred-env.shvi $HADOOP_HOME/etc/hadoop/mapred-site.xmlvi $HADOOP_HOME/etc/hadoop/yarn-env.shvi $HADOOP_HOME/etc/hadoop/yarn-site.xmlvi $HADOOP_HOME/etc/hadoop/slaves# 更改权限chown -R root:root $HADOOP_HOME 验证1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# ================================================# 手动启动# ================================================hadoop namenode -formathadoop_tmp_dir=/home/hadoop/data/tmpmetadata_file=fsimage_0000000000000000000cd $hadoop_tmp_dir/dfs/name/current# 启动NameNodehadoop-daemon.sh stop namenodehadoop-daemon.sh start namenode# 启动DataNodehadoop-daemon.sh start datanode# 启动 yarnyarn-daemon.sh start resourcemanager# 启动 yarn 从即诶单yarn-daemon.sh start nodemanagerjps | grep NameNodejps | grep DataNodejps | grep ResourceManagerjps | grep NodeManager# ================================================# 集群启动# ================================================start-dfs.shstart-yarn.sh# ================================================# 测试集群# ================================================hdfs dfs -mkdir -p /test/inputcat &gt; /root/test.txt &lt;&lt;EOFhello hdfs ...EOF#上传linxu文件到Hdfshdfs dfs -put /root/test.txt /test/inputhdfs dfs -get /test/input/test.txt# --------测试词频统计执行--------cat &gt; /root/wc.txt &lt;&lt;EOFhadoop mapreduce yarnhdfs hadoop mapreducemapreduce yarn sparkflink hqlEOFhdfs dfs -ls /hdfs dfs -du /hdfs dfs -mkdir /wcinputhdfs dfs -put /root/wc.txt /wcinputhadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar wordcount /wcinput /wcoutputhdfs dfs -cat /wcoutput/part-r-00000# --------日志收集--------# 启动历史服务器mr-jobhistory-daemon.sh start historyserverjps | grep JobHistoryServercurl http://linux121:19888/jobhistory# --------日志配置--------yarn-daemon.sh stop resourcemanageryarn-daemon.sh stop nodemanagermr-jobhistory-daemon.sh stop historyserveryarn-daemon.sh start resourcemanageryarn-daemon.sh stop resourcemanageryarn-daemon.sh start nodemanagermr-jobhistory-daemon.sh start historyserver19888,9000,50090,50010,6379,9092,8088,8080# 验证地址jobhistorylinux121:19888 RefsHadoop 安装包地址","tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://example.com/tags/Hadoop/"}]},{"title":"MapReduce 中的排序","date":"2020-11-09T17:21:07.000Z","path":"2020/11/10/MapReduce-中的排序/","text":"shuffle阶段的排序是默认行为，不管是否需要 默认排序是按照字典顺序排序，且实现该排序的方法是 快速排序 排序：重写 compareTo()方法，序列以及反序列化方法 对于全局排序需要保证只有一个reduceTask 排序的分类 （1）部分排序 默认的，根据输入记录的键对数据集排序，保证输出的每个文件内部排序 （2）全排序 最终结果只有一个文件，只设置一个 ReduceTask 可实现 大型文件效率低 替代方案： 创建多个排序好的文件，串联起来，使用一个分区描述输出的全局排序，如 a-g 分区、h-n分区、o-z 分区。 （3）辅助排序(GroupingComparator)： 让指定字段相同的key 进入到同一个 Redus 芳芳 reduce 端的一个功能，决定哪些数据作为一组 （4）二次排序： 自定义排序中， compareTo 作为判断条件为两个的情况 排序发生的阶段： Map side 发生在 spill 后 partition 前 Reduce side 发生在 copy 后 reduce 前 GroupingComparator可以自定义实现不同的 key 作为一组 案例： 求出每隔订单中成交金额最大的交易 可以用于实现 TopN 自定义 GroupingComparator，结果进行最大值排序，在 reduce 输出时，控制只输出前 n 个数","tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://example.com/tags/Hadoop/"}]},{"title":"MapReduce 工作机制","date":"2020-11-09T17:19:59.000Z","path":"2020/11/10/MapReduce-工作机制/","text":"MapTask 的并行度 由客户端提交job时的切片个数决定 Key 相同去往同个分区 org.apache.hadoop.mapreduce.task.JobContextImpl#getPartitionerClass NumReduceTasks: 决定分区的结果，最好与 xx 数量一致 默认情况下，一个 ReduceTask 对应一个输出文件 split 大小默认是 blocksize，块的数量约等于分片的数量，1.1 比例 *工作机制Read 阶段： Map 阶段： Collect 阶段： Spill 阶段： Combine 阶段： ReduceTaskReduceTask 并行度并行度数量可以手动设置 ReduceTask=0，无 Reduce 阶段，文件数和 MapTask 数量一致 默认值为1，输出文件为1个 数据分布不均匀，会出现数据倾斜 一个ReduceTask对应一个输出文件 *工作机制Copy 阶段： Merge 阶段： Sort 阶段： Reduce 阶段： Shuffle 机制(核心)map阶段处理的数据。==&gt;. reduce 阶段 按照相同 key 分组，分区规则 hashcode % numreducetasks MR程序默认使用的HashPartitioner，保证了相同的key去往同个分区 环形缓冲区默认为 100M，阈值为 80% 溢写文件合并，保留分区，同时进行归并排序 Copy: 根据分区编号拉取所有 Map 数据的同个分区的数据 merge: sort: 分区 *工作流程// TODO 补图 分区、排序、溢写，copy 到对应 reduce 机器上，增加 combiner，压缩溢血文件。","tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://example.com/tags/Hadoop/"}]},{"title":"HDFS 读写流程","date":"2020-11-09T17:18:56.000Z","path":"2020/11/10/HDFS-读写流程/","text":"读取流程// TODO 补图 客户端通过 Distributed FileSystem 向 NN 请求下载文件，NN 通过查询元数据， 找到文件块所在的 DN 地址。 挑选一台 DN（就近原则，然后随机）服务器，请求读取数据。 DN 开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。 客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。 写入流程// TODO 补图 客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件 是否已存在，父目录是否存在。 NameNode返回是否可以上传。 客户端请求第一个 Block上传到哪几个DataNode服务器上。 NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。 客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后 dn2调用dn3，将这个通信管道建立完成。 dn1、dn2、dn3逐级应答客户端。 客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单 位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个确认队列 等待确认。 当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行 3-7步）。","tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://example.com/tags/Hadoop/"}]},{"title":"大数据概览","date":"2020-11-09T17:17:14.000Z","path":"2020/11/10/大数据概览/","text":"HDFS 相关 MapReduce Yarn Hive Impala HBase Zookeeper","tags":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"旋转数组类问题","date":"2020-11-09T17:03:57.000Z","path":"2020/11/10/旋转数组类问题/","text":"数组旋转 k 位 189. Rotate Array 123456Input: [1,2,3,4,5,6,7] and k = 3Output: [5,6,7,1,2,3,4]Explanation:rotate 1 steps to the right: [7,1,2,3,4,5,6]rotate 2 steps to the right: [6,7,1,2,3,4,5]rotate 3 steps to the right: [5,6,7,1,2,3,4] 123456789public void rotate(int[] nums, int k) &#123; if (nums.length == 1) return ; int n = nums.length; k = k % n; // prevent unnecessary rotate reverse(nums, 0, n-k-1); reverse(nums, n-k, n-1); reverse(nums, 0, n-1);&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"Leetcode","slug":"Leetcode","permalink":"http://example.com/tags/Leetcode/"}]},{"title":"二分查找","date":"2020-11-09T16:56:19.000Z","path":"2020/11/10/二分查找/","text":"二分查找（1） 算法 （2） 复杂度 O(logN) （3）性质 适用于处理 ceil、floor 等操作； 配合索引相当于是实现了跳表结构； 1、 普通二分查找 12345678910111213int binarySearch(int[] arr, int target) &#123; int lo = 0, hi = arr.length - 1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (arr[mid] == target) return mid; if (arr[mid] &lt; target) lo = mid + 1; else hi = mid - 1; &#125; return -1;&#125; 2、 带有重复元素的二分查找-最先&amp;最后 （1） 查找含有重复元素的数组集合中元素第一次出现的位置 在相等的情况下，进行判断决定是否进行缩小范围或找到对应的值； 12345678910111213int binarySearchFirst(int[] nums, int lo, int hi, int aim) &#123; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (nums[mid] == aim) &#123; if (mid == 0 || nums[mid-1] != nums[mid]) return mid; else hi = mid - 1; &#125; else if (nums[mid] &lt; aim) &#123; lo = mid + 1; &#125; else hi = mid - 1; &#125; return -1;&#125; （2） 查找含有重复元素的数组集合中元素最后一次出现的位置 1234567891011121314int binarySearchLast(int[] nums, int key, int lo, int hi) &#123; while (lo &lt;= hi) &#123; int mid = (hi - lo) / 2 + lo; if (nums[mid] == key) &#123; if (mid == nums.length - 1 || nums[mid] != nums[mid + 1]) return mid; else lo = mid + 1; &#125; else if (nums[mid] &lt; key) &#123; lo = mid + 1; &#125; else &#123; hi = mid - 1; &#125; &#125; return -1;&#125; 3、 二分查找-大于&amp;小于 （1） 查找小于等于给定元素的最小元素在数组中的位置 123456789101112public int binarySearchFloor(int[] nums, int key, int lo, int hi) &#123; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (nums[mid] &lt;= key) &#123; if (mid == nums.length-1 || nums[mid+1] &gt; key) return mid; else lo = mid + 1; &#125; else &#123; hi = mid - 1; &#125; &#125; return -1;&#125; （2） 查找大于等于给定元素的最小元素在数组中的位置 123456789101112public int binarySearchCeil(int[] nums, int key, int lo, int hi) &#123; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (nums[mid] &gt;= key) &#123; if (mid == 0 || nums[mid-1] &lt; key) return mid; else hi = mid - 1; &#125; else &#123; lo = mid + 1; &#125; &#125; return -1;&#125; 4、 带偏移的二分查找 用于旋转数组的查找，偏移后数据有序； 1234567891011121314int binarySearchOffset(int[] nums, int key, int offset) &#123; int lo = 0, hi = nums.length - 1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; int realMid = (mid + offset) % nums.length; if (nums[realMid] == key) &#123; return mid; &#125; else if (nums[mid] &lt; key) &#123; lo = mid + 1; &#125; else hi = mid - 1; &#125; return -1;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"基础排序","date":"2020-11-09T16:51:39.000Z","path":"2020/11/10/基础排序/","text":"排序 基本的排序算法，以及变种 算法 稳定性 时间复杂度 空间复杂度 备注 选择排序 × N2 1 冒泡排序 √ N2 1 插入排序 √ N ~ N2 1 与初始的逆序度相关 希尔排序 × N 的若干倍乘于递增序列的长度 1 每次交换逆序度数量减少大于1 快速排序 × NlogN logN 三向切分快速排序 × N ~ NlogN logN 适用于有大量重复值 归并排序 √ NlogN N 堆排序 × NlogN 1 无法利用局部性原理 基础排序选择排序（1） 算法: 选择数组中最小的元素, 将它与数组的第一个元素交换, 之后开始次小元元素…（2） 复杂度 比较: N²/2, 交换: N最坏: O(n²) 最好: O(n²)， 平均: O(n²) （3） 性质: 运行时间与输入无关； 不稳定； 原地排序； 1234567891011void selectSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = 0; i &lt; arr.length; i ++) &#123; int minIndex = i; for (int j = i + 1; j &lt; arr.length; j ++) &#123; if (arr[j] &lt; arr[minIndex]) minIndex = i; &#125; swap(arr,i, minIndex); &#125;&#125; 冒泡排序（1） 算法: 从左到右不断交换相邻逆序的元素, 经过一次循环确定最后一个元素到达最右侧存在传入数组已经有序的情况 （2） 复杂度分析: 最坏: O(n²) 最好: O(n), 集合有序, 需要进行一次冒泡 平均: O(n²) （3） 性质： 元素交换的次数为固定值, 原始数据的逆序度 需要三次赋值操作； 稳定； 原地排序； 1、基础冒泡 1234567void bubbleSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = arr.length - 1; i &gt; 0; i --) // insure N-1~1 position, 0 must in correct position for (int j = 0; j &lt; i; j ++) if (arr[j] &gt; arr[j + 1]) swap(arr, j, j + 1);&#125; 2、 有序性优化 对于已经有序的数据，不进行元素交换。 12345678910111213void bubbleSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; boolean hasSorted = false; for (int i = arr.length - 1; i &gt; 0 &amp;&amp; !hasSorted; i --) &#123; // except bad condtion hasSorted = true; for (int j = 0; j &lt; i; j ++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; // when equal not modify original order hasSorted = false; swap(arr, j, j + 1); &#125; &#125; &#125;&#125; 插入排序（1）算法: 将数组分为两部分，将后部分元素逐一与前部分元素比较，如果前部分元素比array[i]小，就将前部分元素往后移动。当没有比array[i]小的元素，即是合理位置，在此位置插入array[i]。 （2） 复杂度分析最坏: O(n²), 数组逆序, 需要 N²/2 比较 N²/2 交换最好: O(n), 正序, 需要 N-1 比较 0 次交换平均: O(n^2) N²/4 比较 N²/4 交换 （3） 性质: 复杂度取决于数组的初始顺序， 移动次数为逆序对的数量； 稳定； 原地排序； 1、基础插入排序 1234567public static void insertSortB(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = 1; i &lt; arr.length; i++) for (int j = i; j &gt; 0 &amp;&amp; arr[j] &lt; arr[j - 1]; j --) swap(arr, j, j - 1);&#125; 2、 赋值优化 1234567891011void insertSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = 1; i &lt; arr.length; i ++) &#123; int e = arr[i], j; // e current element, j should put position for (j = i; j &gt; 0; j --) &#123; if (e &lt; arr[j-1]) arr[j] = arr[j-1]; &#125; arr[j] = e; &#125;&#125; 3、链表实现插入排序 147. Insertion Sort List(Medium) 1 希尔排序（1） 算法：使用插入排序对间隔 h 的序列进行排序。通过不断减小 h，最后令 h=1，就可以使得整个数组是有序的。 （2） 复杂度分析： 希尔排序的运行时间达不到平方级别，使用递增序列 1, 4, 13, 40, … 的希尔排序所需要的比较次数不会超过 N 的若干倍乘于递增序列的长度。 （3） 性质： 交换不相邻元素，将逆序数量减少大于1； 基于原来的插入排序； 不稳定； 原地排序； 1234567891011121314void shellSort(int[] arr) &#123; int N = arr.length; int h = 1; while (h &lt; N/3) h = 3 * h + 1; while (h &gt; 0) &#123; for (int i = h; i &lt; N; i += h) &#123; for (int j = i; j &gt;= h; j -= h) &#123; if (arr[j] &lt; arr[j-h]) swap(arr, j, j - h); else break; &#125; &#125; h /= 3; &#125;&#125; 快速排序（1） 思想: 分治, 分区 （2） 复杂度:由每次选取的分割点控制最好: 每次分割点都为中间的元素， O(logN)最坏: 每次分割点都为最后元素 O(n²) （3） 性质: 每趟排序就有一个元素排在了最终的位置上，第n趟结束，至少有n个元素已经排在了最终的位置上； 非稳定 原地排序 （4） 归并 VS 快排:归并由下到上, 先处理子问题之后合并，快排由上到下, 先进行分区然后处理子问题； 归并非原地排序，需要辅助空间，快排通过原地分区函数实现原地排序； 归并排序为稳定的排序，保留原来相同值的顺序； （5） 优化: 三数取中法 随机选取法 1、随机取枢纽元 小数据集使用插入排序； 随机选择枢纽元比较； 12345678910111213void quickSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; quickSort(arr, 0, arr.length);&#125;void quickSort(int[] arr, int lo, int hi) &#123; if (hi - lo &lt; INSERTION_SORT_THRESHOLD) &#123; insertSort(arr, lo, hi); return; &#125; int j = partition(arr, lo, hi); quickSort(arr, lo, j - 1); quickSort(arr, j +1, hi);&#125; 快速选择； 123456789101112int partition(int[] arr, int lo, int hi) &#123; swap(arr,lo,lo +(int) Math.random() * (hi-lo+1); int pivot = arr[lo]; int i = lo, j = hi + 1; while (true) &#123; while (arr[++ i] &lt; pivot) if (i == hi) break; while (arr[-- j] &gt; pivot) if (j == lo) break; if (i &gt;= j) break; swap(arr, i, j); &#125; swap(arr, j, lo);&#125; 2、三路快排优化 对重复元素较多的情形优化； 函数返回重复元素第一次和最后一次出现位置； 类似荷兰国旗问题的处理； 相关： 75. Sort Colors 1234567891011121314int[] partition(int[] arr, int lo,int hi) &#123; int pivot = arr[lo]; int lt = lo - 1, gt = hi + 1; int i = lo; while (i &lt; gt) &#123; // 各个区间的语义 if (arr[i] == pivot) i ++; else if (arr[i] &lt; pivot) swap(arr, i ++, ++ lt); else swap(arr, i, -- gt); &#125; return new int[]&#123;lt+1, gt-1&#125;;&#125; 3、 三数取中值确定枢纽元优化 枢纽元的选取上进行优化； 选取边界和中间数将三处进行排序，选择中间元素作为枢纽元，并放入 [hi-1] 位置； 之后 [lo], [hi] 可以作为快排内循环的哨兵； 123456789// sort three element AND put hi-1 positionint medianOf3(int[] arr, int lo, int hi) &#123; int mid = lo + (hi - lo) / 2; if (arr[lo] &gt; arr[mid]) swap(arr, lo, mid); if (arr[lo] &gt; arr[hi]) swap(arr, lo, hi); if (arr[mid] &gt; arr[hi]) swap(arr, mid, hi); swap(arr, mid, hi - 1); return arr[hi - 1]; // pivot is mid value, and position is hi-1&#125; 1234567891011int partition(int[] arr, int lo, int hi, int pivot) &#123; // pivot original position hi - 1 int i = lo, j = hi - 1; while (true) &#123; while (arr[++ i] &lt; pivot); // NOTE: [hi-1] as sentinel while (arr[-- j] &gt; pivot); // [lo] as sentinel if (i &gt;= j) break; swap(arr, i, j); &#125; swap(arr, i, hi - 1); // put pivot as correct position return i;&#125; 1234567891011void quickSort(int[] arr, int lo, int hi) &#123; if (hi - lo &lt;= INSERTITION_SORT_THRESHOLD) &#123; insertSort(arr, lo, hi); return; &#125; int median = medianOf3(arr, lo, hi); int i = partition(arr, lo, hi, median); quickSort(arr, lo, i - 1); quickSort(arr,i +1, hi);&#125; 归并排序（1） 算法 （2） 复杂度 大部分为 O(NlogN) T(n) = 2T(n/2) + n = 2(2T(n/4) + n/2) + n = 4T(n/4) + 2n = 4(2T(n/8) + n/4) + 2n = 8T(n/8) + 3n = 8*(2T(n/16) + n/8) + 3n = 16T(n/16) + 4n …… = 2^k * T(n/2^k) + k * n （3） 性质 大数据量情况下出现无法分配空间情况； 稳定的排序； 非原地排序； 1、基础归并排序 ① 对排序的两个子数组 [lo,mid], [mid+1, hi]，在 [mid] &gt;= [mid+1] 数组整体有序情况下跳过合并； ② 分配当前两个数组对应的数组空间作为辅助； 1234567891011void mergeSort(int[] arr, int lo, int hi) &#123; if (hi - lo &lt; INSERTITION_SORT_THRESHOLD) &#123; insertSort(arr, lo, hi); return; &#125; int mid = lo + (hi - lo) / 2; mergeSort(arr, lo, mid); mergeSort(arr, mid + 1, hi); if (arr[mid] &gt; arr[mid + 1]) loopArrQueue merge(arr, lo, mid, hi);&#125; 123456789101112void merge(int[] arr, int lo, int mid, int hi) &#123; int[] aux = new int[hi - lo + 1]; int i = lo, j = mid + 1; for (int k = 0; k &lt; aux.length; k ++) &#123; if (i &gt; mid) aux[k] = arr[j ++]; else if (j &gt; hi) aux[k] = arr[i ++]; else if (arr[i] &lt; arr[j]) aux[k] = arr[i ++]; else aux[k] = arr[j ++]; &#125; for (int k = 0; k &lt; aux.length; k ++) arr[k + lo] = aux[k];&#125; 2、 自底向上的归并排序 考虑处理两种情况： 12P1 __ __ | __ __ | __ __ | _ i + sz &lt; arr.length to controlP2 __ __ | __ __ | __ __ | __ _ min&#123;i + sz + sz - 1, arr.length - 1&#125; to control sz 为两个子数组的区间大小 123456789void mergeSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; int N = arr.length; for (int sz = 1; sz &lt; N; sz += sz) &#123; for (int i = 0; i + sz &lt; N; i += sz + sz) &#123; loopArrQueue merge(arr, i, i + sz - 1, Math.min(i + sz + sz - 1, N-1)); &#125; &#125;&#125; 3、使用链表进行归并排序 找出中间节点，分割链表； 对分割的链表分别进行归并排序； 将链表合并； 相关： 148. Sort List(Medium) 12345678910111213public class ListNode implements Cloneable &#123; public int val; public ListNode next; public ListNode(int val) &#123; this.val = val; &#125; public ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637public ListNode sortList(ListNode head) &#123; if (head == null || head.next == null) return head; // 1. find mid node and cut two list ListNode preMid = findPreMid(head); ListNode mid = preMid.next; preMid.next = null; // 2. handle two sub problem ListNode l1 = sortList(head); ListNode l2 = sortList(mid); // 3. merge result return merge(l1, l2); &#125; private ListNode findPreMid(ListNode head) &#123; ListNode pre = null, fast = head, slow = head; while (fast != null &amp;&amp; fast.next != null) &#123; pre = slow; slow = slow.next; fast = fast.next.next; &#125; return pre; &#125; private ListNode merge(ListNode l1, ListNode l2) &#123; if (l1 == null) return l2; if (l2 == null) return l1; if (l1.val &lt; l2.val) &#123; l1.next = merge(l1.next, l2); return l1; &#125; else &#123; l2.next = merge(l1, l2.next); return l2; &#125; &#125; 堆排序（1） 算法 （2） 复杂度 O(logN) （3） 性质 无法利用到现代处理器的缓存局部性原理，一般不使用； 不稳定； 原地排序，适用于嵌入式系统中内存小的情况； 1、 基础堆排序 先通过向堆中不断插入元素，向上调整形成堆结构； 之后不断删除堆顶元素实现排序； 1234567891011void heapSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = 0; i &lt; arr.length; i ++) heapify(arr, i); // heapInsert int N = arr.length; while (N &gt; 0) &#123; // heapify: delete and adjust heap structure swap(arr, -- N, 0); sink(arr, N, 0); &#125;&#125; 123456void heapify(int[] arr, int k) &#123; while (arr[k] &gt; arr[(k - 1) / 2]) &#123; swap(arr, k, (k - 1) / 2); k = (k - 1) / 2; &#125;&#125; 1234567891011void sink(int[] arr, int N, int k) &#123; while (2 * k + 1 &lt; N) &#123; int j = 2 * k + 1; if (j + 1 &lt; N &amp;&amp; arr[j] &lt; arr[j + 1]) j ++; if (arr[k] &gt;= arr[j]) break; swap(arr, k, j); k = j; &#125;&#125; 2、算法优化 与 java.util.ProrityQueue 中实现逻辑相同 ① 通过 sink 向下调整进行优化； ② 下沉操作中使用赋值替代交换，常数级优化； 1234567891011void heapSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; int N = arr.length; for (int i = (N - 2) / 2; i &gt;= 0; i --) // build heap sink(arr, i, N); while (N &gt; 0) &#123; // delete max ⇔ put into last position swap(arr, 0, -- N); sink(arr, 0, N); &#125;&#125; 123456789101112void sink(int[] arr, int k, int N) &#123; int val = arr[k]; while (k * 2 + 1 &lt; N) &#123; int j = k * 2 + 1; if (j + 1 &lt; N &amp;&amp; arr[j] &lt; arr[j + 1]) j = j + 1; if (val &gt;= arr[j]) break; arr[k] = arr[j]; k = j; &#125; arr[k] = val;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"}]}]